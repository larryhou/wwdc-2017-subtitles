[Script Info]
; Script generated by FFmpeg/Lavc57.89.100
ScriptType: v4.00+
PlayResX: 384
PlayResY: 288

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,16,&Hffffff,&Hffffff,&H0,&H0,0,0,0,0,100,100,0,0,1,1,0,2,10,10,10,0

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:26.52,0:00:27.81,Default,,0,0,0,,And welcome to the Accelerate
Dialogue: 0,0:00:27.81,0:00:28.17,Default,,0,0,0,,Session.
Dialogue: 0,0:00:28.17,0:00:29.30,Default,,0,0,0,,My name is Eric Bainville.
Dialogue: 0,0:00:29.30,0:00:30.83,Default,,0,0,0,,I'm with the CoreOS Vector and
Dialogue: 0,0:00:30.83,0:00:31.57,Default,,0,0,0,,Numerics Group.
Dialogue: 0,0:00:32.33,0:00:34.92,Default,,0,0,0,,Our group is maintaining the
Dialogue: 0,0:00:34.92,0:00:35.96,Default,,0,0,0,,Accelerate framework.
Dialogue: 0,0:00:36.34,0:00:37.57,Default,,0,0,0,,And this is our agenda for
Dialogue: 0,0:00:37.57,0:00:37.79,Default,,0,0,0,,today.
Dialogue: 0,0:00:37.79,0:00:38.93,Default,,0,0,0,,So first I will introduce
Dialogue: 0,0:00:38.93,0:00:41.29,Default,,0,0,0,,Accelerate, what's inside, how
Dialogue: 0,0:00:41.29,0:00:42.68,Default,,0,0,0,,to use it, and through a few
Dialogue: 0,0:00:42.68,0:00:43.96,Default,,0,0,0,,examples I'll show you why you
Dialogue: 0,0:00:43.96,0:00:44.74,Default,,0,0,0,,want to use that.
Dialogue: 0,0:00:44.74,0:00:47.35,Default,,0,0,0,,And then we focus on new
Dialogue: 0,0:00:47.35,0:00:48.58,Default,,0,0,0,,improvements and additions we
Dialogue: 0,0:00:48.58,0:00:50.20,Default,,0,0,0,,have this year, first with
Dialogue: 0,0:00:50.20,0:00:51.79,Default,,0,0,0,,Compression, lossless data
Dialogue: 0,0:00:51.79,0:00:54.18,Default,,0,0,0,,compression library, then BNNS,
Dialogue: 0,0:00:54.24,0:00:55.57,Default,,0,0,0,,Basic Neural Network
Dialogue: 0,0:00:55.57,0:00:56.13,Default,,0,0,0,,Subroutines.
Dialogue: 0,0:00:57.01,0:00:58.68,Default,,0,0,0,,And after that my colleague
Dialogue: 0,0:00:58.68,0:00:59.84,Default,,0,0,0,,Steve will come on stage and
Dialogue: 0,0:00:59.84,0:01:01.25,Default,,0,0,0,,tell us what's new in simd.
Dialogue: 0,0:01:01.56,0:01:02.80,Default,,0,0,0,,And finally, our very own
Dialogue: 0,0:01:03.00,0:01:04.44,Default,,0,0,0,,Jonathan Hogg will come on stage
Dialogue: 0,0:01:04.44,0:01:05.88,Default,,0,0,0,,and tell us -- introduce the
Dialogue: 0,0:01:05.88,0:01:07.18,Default,,0,0,0,,sparse matrices package.
Dialogue: 0,0:01:07.69,0:01:08.67,Default,,0,0,0,,It will be the first time
Dialogue: 0,0:01:08.72,0:01:10.21,Default,,0,0,0,,commercialized shipping with
Dialogue: 0,0:01:10.21,0:01:12.39,Default,,0,0,0,,sparse matrices solver package.
Dialogue: 0,0:01:12.81,0:01:14.20,Default,,0,0,0,,But let's start with Accelerate.
Dialogue: 0,0:01:15.19,0:01:17.54,Default,,0,0,0,,Accelerate is a low-level system
Dialogue: 0,0:01:17.54,0:01:19.36,Default,,0,0,0,,framework dedicated to high
Dialogue: 0,0:01:19.36,0:01:20.85,Default,,0,0,0,,performance primitive on the
Dialogue: 0,0:01:20.85,0:01:21.36,Default,,0,0,0,,CPU.
Dialogue: 0,0:01:22.58,0:01:25.19,Default,,0,0,0,,Actually, it's everywhere when
Dialogue: 0,0:01:25.19,0:01:26.69,Default,,0,0,0,,you have a significant workload
Dialogue: 0,0:01:26.69,0:01:27.71,Default,,0,0,0,,to run on the CPU.
Dialogue: 0,0:01:28.47,0:01:30.14,Default,,0,0,0,,Inside Accelerate there's a lot
Dialogue: 0,0:01:30.14,0:01:32.20,Default,,0,0,0,,of libraries, like vImage for
Dialogue: 0,0:01:32.20,0:01:33.52,Default,,0,0,0,,image processing, the Swiss
Dialogue: 0,0:01:34.12,0:01:35.47,Default,,0,0,0,,knife of image processing.
Dialogue: 0,0:01:35.86,0:01:37.64,Default,,0,0,0,,We also have vDSP inside for
Dialogue: 0,0:01:37.64,0:01:39.33,Default,,0,0,0,,DFT's and FFT's signal
Dialogue: 0,0:01:39.33,0:01:41.79,Default,,0,0,0,,processing, vForce for vector
Dialogue: 0,0:01:41.79,0:01:42.43,Default,,0,0,0,,functions.
Dialogue: 0,0:01:43.05,0:01:44.69,Default,,0,0,0,,And then we have a whole lot of
Dialogue: 0,0:01:44.77,0:01:46.59,Default,,0,0,0,,linear algebra libraries for
Dialogue: 0,0:01:46.59,0:01:48.63,Default,,0,0,0,,dense and sparse matrices.
Dialogue: 0,0:01:48.63,0:01:50.13,Default,,0,0,0,,So that's BLAS and LAPACK for
Dialogue: 0,0:01:50.13,0:01:51.44,Default,,0,0,0,,dense vectors and matrices.
Dialogue: 0,0:01:51.91,0:01:53.06,Default,,0,0,0,,And Sparse BLAS and Sparse
Dialogue: 0,0:01:53.06,0:01:55.00,Default,,0,0,0,,Solvers for sparse vectors and
Dialogue: 0,0:01:55.00,0:01:55.58,Default,,0,0,0,,matrices.
Dialogue: 0,0:01:56.20,0:01:57.66,Default,,0,0,0,,Last year we also introduced
Dialogue: 0,0:01:57.66,0:01:59.08,Default,,0,0,0,,BNNS, Basic Neural Network
Dialogue: 0,0:01:59.08,0:02:01.15,Default,,0,0,0,,Subroutines, which is also
Dialogue: 0,0:02:01.15,0:02:02.15,Default,,0,0,0,,[inaudible] for neural networks.
Dialogue: 0,0:02:02.36,0:02:04.77,Default,,0,0,0,,This is used by, for example,
Dialogue: 0,0:02:04.77,0:02:06.73,Default,,0,0,0,,Core ML and also Vision and NLP
Dialogue: 0,0:02:06.73,0:02:07.41,Default,,0,0,0,,frameworks.
Dialogue: 0,0:02:08.22,0:02:09.63,Default,,0,0,0,,Slightly outside Accelerate but
Dialogue: 0,0:02:09.63,0:02:11.48,Default,,0,0,0,,still maintained by us, we have
Dialogue: 0,0:02:11.48,0:02:13.07,Default,,0,0,0,,simd, which is a set of headers
Dialogue: 0,0:02:13.07,0:02:14.81,Default,,0,0,0,,and function allowing you to
Dialogue: 0,0:02:14.81,0:02:16.54,Default,,0,0,0,,directly talk to the CPU vector
Dialogue: 0,0:02:16.54,0:02:17.03,Default,,0,0,0,,units.
Dialogue: 0,0:02:18.00,0:02:19.19,Default,,0,0,0,,And finally, Compression, a
Dialogue: 0,0:02:19.52,0:02:20.62,Default,,0,0,0,,lossless data compression
Dialogue: 0,0:02:20.62,0:02:21.05,Default,,0,0,0,,library.
Dialogue: 0,0:02:22.31,0:02:23.70,Default,,0,0,0,,How do you use Accelerate?
Dialogue: 0,0:02:24.68,0:02:26.22,Default,,0,0,0,,Well, so you import Accelerate
Dialogue: 0,0:02:26.22,0:02:27.34,Default,,0,0,0,,or you include the Accelerate
Dialogue: 0,0:02:27.37,0:02:28.95,Default,,0,0,0,,header and then link with
Dialogue: 0,0:02:28.95,0:02:30.29,Default,,0,0,0,,Accelerate frameworks on your
Dialogue: 0,0:02:30.29,0:02:30.73,Default,,0,0,0,,own set.
Dialogue: 0,0:02:30.73,0:02:31.98,Default,,0,0,0,,Now, I will show you a few
Dialogue: 0,0:02:31.98,0:02:34.09,Default,,0,0,0,,examples about why you want to
Dialogue: 0,0:02:34.09,0:02:35.00,Default,,0,0,0,,use Accelerate.
Dialogue: 0,0:02:35.47,0:02:36.60,Default,,0,0,0,,Let's start with that one.
Dialogue: 0,0:02:37.11,0:02:37.89,Default,,0,0,0,,So let's say you have this
Dialogue: 0,0:02:37.89,0:02:39.28,Default,,0,0,0,,vector X of floating point
Dialogue: 0,0:02:39.28,0:02:40.94,Default,,0,0,0,,values and you want to scale
Dialogue: 0,0:02:40.94,0:02:41.24,Default,,0,0,0,,them.
Dialogue: 0,0:02:42.13,0:02:43.17,Default,,0,0,0,,So you have this scale.
Dialogue: 0,0:02:43.17,0:02:45.00,Default,,0,0,0,,And so you multiply each value
Dialogue: 0,0:02:45.00,0:02:46.22,Default,,0,0,0,,and store it in the Y vector.
Dialogue: 0,0:02:46.22,0:02:48.21,Default,,0,0,0,,So it's a very simple loop.
Dialogue: 0,0:02:48.70,0:02:49.68,Default,,0,0,0,,That's perfectly fine.
Dialogue: 0,0:02:50.18,0:02:51.07,Default,,0,0,0,,But actually, there is a
Dialogue: 0,0:02:51.07,0:02:52.95,Default,,0,0,0,,function for you in Accelerate
Dialogue: 0,0:02:52.95,0:02:53.93,Default,,0,0,0,,doing the same thing, it's
Dialogue: 0,0:02:53.93,0:02:54.70,Default,,0,0,0,,called vsmul.
Dialogue: 0,0:02:55.79,0:02:57.67,Default,,0,0,0,,So that's one single line
Dialogue: 0,0:02:57.67,0:02:58.65,Default,,0,0,0,,replacing your code.
Dialogue: 0,0:02:58.99,0:03:01.00,Default,,0,0,0,,And the good thing is that we
Dialogue: 0,0:03:01.00,0:03:02.77,Default,,0,0,0,,optimize it for you on all the
Dialogue: 0,0:03:02.77,0:03:03.72,Default,,0,0,0,,supported hardware.
Dialogue: 0,0:03:04.23,0:03:05.26,Default,,0,0,0,,And of course, we maintain it
Dialogue: 0,0:03:05.26,0:03:06.32,Default,,0,0,0,,for you so you don't have your
Dialogue: 0,0:03:06.32,0:03:07.57,Default,,0,0,0,,loop to maintain again.
Dialogue: 0,0:03:08.02,0:03:09.86,Default,,0,0,0,,And, of course, it's faster, as
Dialogue: 0,0:03:09.86,0:03:10.85,Default,,0,0,0,,Accelerate says.
Dialogue: 0,0:03:11.36,0:03:12.77,Default,,0,0,0,,So that's a reference speed and
Dialogue: 0,0:03:12.77,0:03:14.18,Default,,0,0,0,,energy consumption for the loop.
Dialogue: 0,0:03:14.41,0:03:15.54,Default,,0,0,0,,And this is what you get with
Dialogue: 0,0:03:15.54,0:03:16.14,Default,,0,0,0,,Accelerate.
Dialogue: 0,0:03:16.86,0:03:18.17,Default,,0,0,0,,Six times faster.
Dialogue: 0,0:03:19.52,0:03:21.62,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:03:22.12,0:03:23.95,Default,,0,0,0,,And six times less energy
Dialogue: 0,0:03:23.95,0:03:25.09,Default,,0,0,0,,consumed, which is very
Dialogue: 0,0:03:25.09,0:03:25.57,Default,,0,0,0,,important.
Dialogue: 0,0:03:25.80,0:03:26.88,Default,,0,0,0,,Let me give you another one.
Dialogue: 0,0:03:27.26,0:03:28.74,Default,,0,0,0,,So this time we still have this
Dialogue: 0,0:03:28.88,0:03:30.60,Default,,0,0,0,,array X, and we want to clip the
Dialogue: 0,0:03:30.60,0:03:31.98,Default,,0,0,0,,values between the low and high
Dialogue: 0,0:03:31.98,0:03:33.75,Default,,0,0,0,,bound and store that in Y.
Dialogue: 0,0:03:34.18,0:03:35.16,Default,,0,0,0,,Again, you could go with this
Dialogue: 0,0:03:35.16,0:03:35.47,Default,,0,0,0,,code.
Dialogue: 0,0:03:35.58,0:03:36.38,Default,,0,0,0,,That's perfectly fine.
Dialogue: 0,0:03:36.38,0:03:36.79,Default,,0,0,0,,That's good.
Dialogue: 0,0:03:37.34,0:03:38.65,Default,,0,0,0,,But we have a function for you
Dialogue: 0,0:03:38.65,0:03:40.31,Default,,0,0,0,,in vDSP; it's called vclip.
Dialogue: 0,0:03:40.94,0:03:42.10,Default,,0,0,0,,Does the same thing.
Dialogue: 0,0:03:42.10,0:03:43.59,Default,,0,0,0,,And, again, we maintain it for
Dialogue: 0,0:03:43.59,0:03:43.76,Default,,0,0,0,,you.
Dialogue: 0,0:03:43.76,0:03:44.85,Default,,0,0,0,,We optimize it for you.
Dialogue: 0,0:03:45.62,0:03:46.80,Default,,0,0,0,,And, of course, it's faster.
Dialogue: 0,0:03:46.85,0:03:48.28,Default,,0,0,0,,That's a reference for the loop.
Dialogue: 0,0:03:48.70,0:03:49.74,Default,,0,0,0,,And this is what you get with
Dialogue: 0,0:03:49.74,0:03:52.13,Default,,0,0,0,,Accelerate, eight times faster
Dialogue: 0,0:03:52.13,0:03:53.76,Default,,0,0,0,,and also eight times less energy
Dialogue: 0,0:03:53.76,0:03:54.25,Default,,0,0,0,,consumed.
Dialogue: 0,0:03:55.15,0:03:58.17,Default,,0,0,0,,Another one, matrices.
Dialogue: 0,0:03:58.17,0:03:59.02,Default,,0,0,0,,So let's say you have two
Dialogue: 0,0:03:59.02,0:04:00.77,Default,,0,0,0,,matrices A and B, and you want
Dialogue: 0,0:04:00.77,0:04:02.13,Default,,0,0,0,,to compute the product of A and
Dialogue: 0,0:04:02.13,0:04:04.02,Default,,0,0,0,,B and add the result into the C
Dialogue: 0,0:04:04.02,0:04:04.51,Default,,0,0,0,,matrix.
Dialogue: 0,0:04:05.03,0:04:06.74,Default,,0,0,0,,It doesn't sound simple.
Dialogue: 0,0:04:06.78,0:04:08.27,Default,,0,0,0,,But actually, it's very simple.
Dialogue: 0,0:04:08.27,0:04:09.52,Default,,0,0,0,,That's just three lines of code.
Dialogue: 0,0:04:09.52,0:04:10.17,Default,,0,0,0,,You can see that.
Dialogue: 0,0:04:11.36,0:04:12.44,Default,,0,0,0,,And we have, of course, a
Dialogue: 0,0:04:12.44,0:04:13.72,Default,,0,0,0,,function for you in Accelerate
Dialogue: 0,0:04:13.72,0:04:15.40,Default,,0,0,0,,doing that; it's called sgemm
Dialogue: 0,0:04:15.40,0:04:16.75,Default,,0,0,0,,for the Cblas package.
Dialogue: 0,0:04:17.91,0:04:20.34,Default,,0,0,0,,And really, really, you never
Dialogue: 0,0:04:20.34,0:04:22.05,Default,,0,0,0,,want to write code computing
Dialogue: 0,0:04:22.05,0:04:23.21,Default,,0,0,0,,metrics vector products or
Dialogue: 0,0:04:23.21,0:04:24.79,Default,,0,0,0,,matrix metrics or anything
Dialogue: 0,0:04:24.79,0:04:25.65,Default,,0,0,0,,related to metrics.
Dialogue: 0,0:04:25.65,0:04:26.58,Default,,0,0,0,,You don't want to write that
Dialogue: 0,0:04:26.58,0:04:27.08,Default,,0,0,0,,code ever.
Dialogue: 0,0:04:28.20,0:04:29.97,Default,,0,0,0,,You want to call BLAS, LAPACK,
Dialogue: 0,0:04:29.97,0:04:31.20,Default,,0,0,0,,or anything in Accelerate.
Dialogue: 0,0:04:31.64,0:04:32.95,Default,,0,0,0,,Why? Well, first because we
Dialogue: 0,0:04:32.95,0:04:34.25,Default,,0,0,0,,maintain that for you, and it
Dialogue: 0,0:04:34.25,0:04:35.30,Default,,0,0,0,,will be optimized and
Dialogue: 0,0:04:35.33,0:04:37.34,Default,,0,0,0,,multithreaded on all the
Dialogue: 0,0:04:37.34,0:04:38.55,Default,,0,0,0,,architectures we support.
Dialogue: 0,0:04:39.81,0:04:41.68,Default,,0,0,0,,And this time -- this is a
Dialogue: 0,0:04:41.68,0:04:42.71,Default,,0,0,0,,reference for the loop -- this
Dialogue: 0,0:04:42.71,0:04:43.99,Default,,0,0,0,,is what you get with Accelerate.
Dialogue: 0,0:04:43.99,0:04:47.00,Default,,0,0,0,,I'm not sure you can see it.
Dialogue: 0,0:04:47.69,0:04:52.13,Default,,0,0,0,,Yeah. That's 100 times faster
Dialogue: 0,0:04:52.13,0:04:54.24,Default,,0,0,0,,and 26 times more energy
Dialogue: 0,0:04:54.24,0:04:54.72,Default,,0,0,0,,efficient.
Dialogue: 0,0:04:54.93,0:04:56.30,Default,,0,0,0,,That's your battery here.
Dialogue: 0,0:04:56.99,0:04:58.30,Default,,0,0,0,,Okay. One more example, this
Dialogue: 0,0:04:58.30,0:04:59.35,Default,,0,0,0,,time in vImage.
Dialogue: 0,0:04:59.49,0:05:01.16,Default,,0,0,0,,So let's say you have a 32-bit
Dialogue: 0,0:05:01.16,0:05:02.66,Default,,0,0,0,,per pixel image with four
Dialogue: 0,0:05:02.66,0:05:04.01,Default,,0,0,0,,components per pixel.
Dialogue: 0,0:05:04.01,0:05:05.21,Default,,0,0,0,,That's alpha, red, green, and
Dialogue: 0,0:05:05.21,0:05:05.54,Default,,0,0,0,,blue.
Dialogue: 0,0:05:05.92,0:05:07.75,Default,,0,0,0,,And you want to apply a 4 by 4
Dialogue: 0,0:05:07.75,0:05:09.11,Default,,0,0,0,,transformation matrix to every
Dialogue: 0,0:05:09.11,0:05:10.12,Default,,0,0,0,,pixel in the image.
Dialogue: 0,0:05:10.88,0:05:11.75,Default,,0,0,0,,But you could write the code.
Dialogue: 0,0:05:11.75,0:05:12.74,Default,,0,0,0,,You could write it here, that
Dialogue: 0,0:05:12.74,0:05:13.28,Default,,0,0,0,,would be too long.
Dialogue: 0,0:05:13.54,0:05:14.53,Default,,0,0,0,,But really, you don't want to
Dialogue: 0,0:05:14.53,0:05:15.19,Default,,0,0,0,,write this code.
Dialogue: 0,0:05:15.35,0:05:16.32,Default,,0,0,0,,We have a function for you in
Dialogue: 0,0:05:16.32,0:05:18.04,Default,,0,0,0,,vImage, MatrixMultiply -- that's
Dialogue: 0,0:05:18.04,0:05:19.18,Default,,0,0,0,,one of the most used functions
Dialogue: 0,0:05:19.18,0:05:21.03,Default,,0,0,0,,in vImage -- doing exactly that
Dialogue: 0,0:05:21.03,0:05:23.91,Default,,0,0,0,,and optimized to as fast as it
Dialogue: 0,0:05:23.91,0:05:25.45,Default,,0,0,0,,can on all the architectures we
Dialogue: 0,0:05:25.45,0:05:25.87,Default,,0,0,0,,support.
Dialogue: 0,0:05:26.83,0:05:30.07,Default,,0,0,0,,Last one, this is convolution
Dialogue: 0,0:05:30.07,0:05:30.31,Default,,0,0,0,,layer.
Dialogue: 0,0:05:30.38,0:05:33.04,Default,,0,0,0,,That's the working horse of the
Dialogue: 0,0:05:33.04,0:05:34.53,Default,,0,0,0,,neural networks, the convolution
Dialogue: 0,0:05:34.53,0:05:35.41,Default,,0,0,0,,neural networks.
Dialogue: 0,0:05:35.96,0:05:38.42,Default,,0,0,0,,So this layer takes input stacks
Dialogue: 0,0:05:38.49,0:05:40.02,Default,,0,0,0,,-- that's the right thing on the
Dialogue: 0,0:05:40.02,0:05:42.08,Default,,0,0,0,,left -- that's a stack of
Dialogue: 0,0:05:42.08,0:05:42.72,Default,,0,0,0,,images.
Dialogue: 0,0:05:43.07,0:05:45.20,Default,,0,0,0,,And it will put output image
Dialogue: 0,0:05:45.20,0:05:46.06,Default,,0,0,0,,stack, the blue thing.
Dialogue: 0,0:05:46.29,0:05:48.05,Default,,0,0,0,,And each pixel in the output is
Dialogue: 0,0:05:48.05,0:05:49.15,Default,,0,0,0,,the result of a treaty
Dialogue: 0,0:05:49.15,0:05:51.38,Default,,0,0,0,,convolution on all the entire
Dialogue: 0,0:05:51.38,0:05:52.23,Default,,0,0,0,,input stack.
Dialogue: 0,0:05:52.23,0:05:53.89,Default,,0,0,0,,And we do that for every of the
Dialogue: 0,0:05:53.89,0:05:54.81,Default,,0,0,0,,three that I mentioned for
Dialogue: 0,0:05:54.81,0:05:55.51,Default,,0,0,0,,output image.
Dialogue: 0,0:05:56.07,0:05:56.92,Default,,0,0,0,,So at the end, that's a
Dialogue: 0,0:05:56.92,0:05:59.18,Default,,0,0,0,,six-dimensional loop.
Dialogue: 0,0:05:59.18,0:06:00.15,Default,,0,0,0,,And you really don't want to
Dialogue: 0,0:06:00.15,0:06:00.75,Default,,0,0,0,,write this loop.
Dialogue: 0,0:06:01.34,0:06:02.90,Default,,0,0,0,,And even when the dimensions are
Dialogue: 0,0:06:02.90,0:06:04.34,Default,,0,0,0,,small, you're multiplying all of
Dialogue: 0,0:06:04.34,0:06:04.89,Default,,0,0,0,,them together.
Dialogue: 0,0:06:04.89,0:06:07.07,Default,,0,0,0,,So that's millions or even
Dialogue: 0,0:06:07.07,0:06:08.38,Default,,0,0,0,,billions of floating points
Dialogue: 0,0:06:08.38,0:06:09.15,Default,,0,0,0,,operation here.
Dialogue: 0,0:06:09.79,0:06:11.08,Default,,0,0,0,,Of course, we have a function
Dialogue: 0,0:06:11.08,0:06:12.63,Default,,0,0,0,,for you this time in BNNS doing
Dialogue: 0,0:06:12.63,0:06:12.91,Default,,0,0,0,,that.
Dialogue: 0,0:06:13.40,0:06:14.52,Default,,0,0,0,,And when you run a Core ML
Dialogue: 0,0:06:14.52,0:06:16.62,Default,,0,0,0,,model, you will spend, like, 80%
Dialogue: 0,0:06:16.62,0:06:17.87,Default,,0,0,0,,of the time in this function.
Dialogue: 0,0:06:18.64,0:06:19.39,Default,,0,0,0,,All right.
Dialogue: 0,0:06:19.39,0:06:21.11,Default,,0,0,0,,So that was a few examples.
Dialogue: 0,0:06:21.19,0:06:22.96,Default,,0,0,0,,I could continue almost forever
Dialogue: 0,0:06:22.96,0:06:24.94,Default,,0,0,0,,because we have more than 2,800
Dialogue: 0,0:06:24.94,0:06:26.52,Default,,0,0,0,,API's in Accelerate.
Dialogue: 0,0:06:27.15,0:06:28.25,Default,,0,0,0,,So usually that would be a
Dialogue: 0,0:06:28.25,0:06:29.39,Default,,0,0,0,,function for you inside.
Dialogue: 0,0:06:29.66,0:06:30.76,Default,,0,0,0,,And every time you use an
Dialogue: 0,0:06:30.76,0:06:32.46,Default,,0,0,0,,Accelerate function, the
Dialogue: 0,0:06:32.46,0:06:34.15,Default,,0,0,0,,benefits are that's less code
Dialogue: 0,0:06:34.15,0:06:36.52,Default,,0,0,0,,for you to write; we maintain it
Dialogue: 0,0:06:36.52,0:06:38.09,Default,,0,0,0,,for you; of course, it will be
Dialogue: 0,0:06:38.09,0:06:39.22,Default,,0,0,0,,faster and more energy
Dialogue: 0,0:06:39.22,0:06:40.76,Default,,0,0,0,,efficient; and it will be
Dialogue: 0,0:06:40.76,0:06:43.33,Default,,0,0,0,,optimal -- as close to optimal
Dialogue: 0,0:06:43.33,0:06:44.35,Default,,0,0,0,,as possible on all the
Dialogue: 0,0:06:44.35,0:06:45.48,Default,,0,0,0,,architectures we support,
Dialogue: 0,0:06:45.48,0:06:46.61,Default,,0,0,0,,including the new ones.
Dialogue: 0,0:06:46.61,0:06:47.99,Default,,0,0,0,,So when we release new hardware,
Dialogue: 0,0:06:48.70,0:06:49.82,Default,,0,0,0,,you will get your code running
Dialogue: 0,0:06:49.82,0:06:51.51,Default,,0,0,0,,as fast as it can from day one.
Dialogue: 0,0:06:52.60,0:06:53.97,Default,,0,0,0,,Okay. So that was it for
Dialogue: 0,0:06:53.97,0:06:54.54,Default,,0,0,0,,Accelerate.
Dialogue: 0,0:06:54.54,0:06:56.47,Default,,0,0,0,,Now let's focus on Compression.
Dialogue: 0,0:06:58.83,0:07:00.91,Default,,0,0,0,,Compression is a lossless data
Dialogue: 0,0:07:00.91,0:07:01.75,Default,,0,0,0,,compression library.
Dialogue: 0,0:07:01.75,0:07:04.10,Default,,0,0,0,,It's a very simple API with a
Dialogue: 0,0:07:04.10,0:07:06.08,Default,,0,0,0,,few select compressors inside.
Dialogue: 0,0:07:06.41,0:07:08.14,Default,,0,0,0,,So they are represented on this
Dialogue: 0,0:07:08.14,0:07:09.05,Default,,0,0,0,,little graph here.
Dialogue: 0,0:07:09.47,0:07:11.10,Default,,0,0,0,,On the x-axis you see the
Dialogue: 0,0:07:11.10,0:07:12.51,Default,,0,0,0,,relative compression ratio
Dialogue: 0,0:07:12.74,0:07:13.53,Default,,0,0,0,,compared to ZLIB.
Dialogue: 0,0:07:13.53,0:07:14.62,Default,,0,0,0,,ZLIB is in the center.
Dialogue: 0,0:07:14.62,0:07:16.60,Default,,0,0,0,,And on the y-axis is the
Dialogue: 0,0:07:16.60,0:07:18.42,Default,,0,0,0,,compression speed.
Dialogue: 0,0:07:18.52,0:07:20.56,Default,,0,0,0,,It's not that exponential.
Dialogue: 0,0:07:21.08,0:07:22.35,Default,,0,0,0,,So inside the compression
Dialogue: 0,0:07:22.35,0:07:24.49,Default,,0,0,0,,library we have a selection of
Dialogue: 0,0:07:24.49,0:07:25.48,Default,,0,0,0,,compressors, as I said.
Dialogue: 0,0:07:26.03,0:07:27.87,Default,,0,0,0,,We offer LZMA for better
Dialogue: 0,0:07:27.87,0:07:30.17,Default,,0,0,0,,compression, optimized versions
Dialogue: 0,0:07:30.17,0:07:32.36,Default,,0,0,0,,of LZ4 for fast compression.
Dialogue: 0,0:07:32.84,0:07:35.15,Default,,0,0,0,,Of course we have ZLIB with the
Dialogue: 0,0:07:35.15,0:07:36.78,Default,,0,0,0,,optimized ZLIB decoder, and our
Dialogue: 0,0:07:36.78,0:07:39.20,Default,,0,0,0,,very own LZFSE, which compresses
Dialogue: 0,0:07:39.20,0:07:41.42,Default,,0,0,0,,slightly more than ZLIB but much
Dialogue: 0,0:07:41.42,0:07:41.78,Default,,0,0,0,,faster.
Dialogue: 0,0:07:42.80,0:07:44.37,Default,,0,0,0,,And last year we open sourced
Dialogue: 0,0:07:44.54,0:07:46.23,Default,,0,0,0,,LZFSE; it's on GitHub.
Dialogue: 0,0:07:47.14,0:07:49.32,Default,,0,0,0,,Okay. The API now.
Dialogue: 0,0:07:49.87,0:07:51.63,Default,,0,0,0,,That, too, API's in the
Dialogue: 0,0:07:51.63,0:07:52.29,Default,,0,0,0,,compression.
Dialogue: 0,0:07:52.69,0:07:54.12,Default,,0,0,0,,The first one is a buffer API.
Dialogue: 0,0:07:54.12,0:07:55.17,Default,,0,0,0,,So that's when you have the
Dialogue: 0,0:07:55.17,0:07:57.99,Default,,0,0,0,,entire data to compress.
Dialogue: 0,0:07:57.99,0:07:59.11,Default,,0,0,0,,And so you have a buffer with
Dialogue: 0,0:07:59.11,0:08:00.25,Default,,0,0,0,,the data to compress, you just
Dialogue: 0,0:08:00.25,0:08:02.41,Default,,0,0,0,,call one function, provide the
Dialogue: 0,0:08:02.41,0:08:03.46,Default,,0,0,0,,output buffer, and you will get
Dialogue: 0,0:08:03.46,0:08:04.99,Default,,0,0,0,,the output in one single code.
Dialogue: 0,0:08:05.15,0:08:06.48,Default,,0,0,0,,That's good for encode and
Dialogue: 0,0:08:06.48,0:08:06.86,Default,,0,0,0,,decode.
Dialogue: 0,0:08:07.23,0:08:09.31,Default,,0,0,0,,And if the data is huge or you
Dialogue: 0,0:08:09.31,0:08:12.09,Default,,0,0,0,,get it in small pieces, you want
Dialogue: 0,0:08:12.09,0:08:13.09,Default,,0,0,0,,to use a stream API.
Dialogue: 0,0:08:13.93,0:08:15.61,Default,,0,0,0,,In that case you will create a
Dialogue: 0,0:08:15.61,0:08:17.81,Default,,0,0,0,,stream object and send data
Dialogue: 0,0:08:17.81,0:08:19.39,Default,,0,0,0,,inside and get smaller data
Dialogue: 0,0:08:19.39,0:08:19.92,Default,,0,0,0,,outside.
Dialogue: 0,0:08:19.92,0:08:20.78,Default,,0,0,0,,And you will call that
Dialogue: 0,0:08:20.78,0:08:22.08,Default,,0,0,0,,repeatedly until the entire
Dialogue: 0,0:08:22.08,0:08:23.61,Default,,0,0,0,,stream is processed.
Dialogue: 0,0:08:25.44,0:08:27.08,Default,,0,0,0,,And this, what we have, what's
Dialogue: 0,0:08:27.08,0:08:29.32,Default,,0,0,0,,new, we added a compression tool
Dialogue: 0,0:08:29.32,0:08:29.99,Default,,0,0,0,,command line.
Dialogue: 0,0:08:30.87,0:08:33.15,Default,,0,0,0,,So you can compress with
Dialogue: 0,0:08:33.15,0:08:34.30,Default,,0,0,0,,Compression from the command
Dialogue: 0,0:08:34.30,0:08:34.52,Default,,0,0,0,,line.
Dialogue: 0,0:08:35.66,0:08:37.03,Default,,0,0,0,,Okay. That's for Compression.
Dialogue: 0,0:08:37.03,0:08:39.05,Default,,0,0,0,,Now let's switch to BNNS, Basic
Dialogue: 0,0:08:39.05,0:08:40.37,Default,,0,0,0,,Neural Network Subroutines.
Dialogue: 0,0:08:40.78,0:08:42.46,Default,,0,0,0,,As I said, this is the energy
Dialogue: 0,0:08:42.46,0:08:44.39,Default,,0,0,0,,running of the CPU and
Dialogue: 0,0:08:44.39,0:08:45.92,Default,,0,0,0,,supporting all the neural
Dialogue: 0,0:08:45.92,0:08:48.75,Default,,0,0,0,,network and the machine learning
Dialogue: 0,0:08:48.84,0:08:49.45,Default,,0,0,0,,libraries.
Dialogue: 0,0:08:49.89,0:08:52.69,Default,,0,0,0,,So you use BNNS almost anytime.
Dialogue: 0,0:08:52.69,0:08:55.16,Default,,0,0,0,,When you type on the keyboard or
Dialogue: 0,0:08:55.16,0:08:56.77,Default,,0,0,0,,when you run face recognition,
Dialogue: 0,0:08:57.49,0:09:00.22,Default,,0,0,0,,all these applications use BNNS.
Dialogue: 0,0:09:00.22,0:09:03.57,Default,,0,0,0,,And BNNS provides lower-level
Dialogue: 0,0:09:03.81,0:09:04.85,Default,,0,0,0,,functions for this.
Dialogue: 0,0:09:05.01,0:09:07.28,Default,,0,0,0,,So that's convolutional layers,
Dialogue: 0,0:09:07.46,0:09:08.29,Default,,0,0,0,,pooling layers.
Dialogue: 0,0:09:08.86,0:09:10.30,Default,,0,0,0,,We also have fully connected
Dialogue: 0,0:09:10.30,0:09:10.69,Default,,0,0,0,,layers.
Dialogue: 0,0:09:10.69,0:09:13.65,Default,,0,0,0,,And these, we added separate
Dialogue: 0,0:09:13.70,0:09:15.54,Default,,0,0,0,,activation layers doing just the
Dialogue: 0,0:09:15.54,0:09:16.52,Default,,0,0,0,,activation function.
Dialogue: 0,0:09:16.82,0:09:18.24,Default,,0,0,0,,And these layers also can do
Dialogue: 0,0:09:18.24,0:09:20.26,Default,,0,0,0,,efficient conversion, data type
Dialogue: 0,0:09:20.55,0:09:21.03,Default,,0,0,0,,conversions.
Dialogue: 0,0:09:21.66,0:09:24.47,Default,,0,0,0,,Speaking of which, data types.
Dialogue: 0,0:09:24.79,0:09:27.28,Default,,0,0,0,,So when you train a machine
Dialogue: 0,0:09:27.28,0:09:29.53,Default,,0,0,0,,learning model, what you get is
Dialogue: 0,0:09:29.60,0:09:31.25,Default,,0,0,0,,megabytes or hundreds of
Dialogue: 0,0:09:31.25,0:09:33.03,Default,,0,0,0,,megabytes of data, usually
Dialogue: 0,0:09:33.03,0:09:34.66,Default,,0,0,0,,32-bit floating point data for
Dialogue: 0,0:09:34.66,0:09:35.08,Default,,0,0,0,,your model.
Dialogue: 0,0:09:35.08,0:09:37.08,Default,,0,0,0,,That's the convolution weights,
Dialogue: 0,0:09:37.08,0:09:40.22,Default,,0,0,0,,etc. It turns out you can
Dialogue: 0,0:09:40.22,0:09:41.94,Default,,0,0,0,,convert these guys into smaller
Dialogue: 0,0:09:41.94,0:09:43.63,Default,,0,0,0,,types, like 16-bit floating
Dialogue: 0,0:09:43.63,0:09:45.66,Default,,0,0,0,,point or even 8-bit integer
Dialogue: 0,0:09:45.96,0:09:47.93,Default,,0,0,0,,signed or unsigned and still get
Dialogue: 0,0:09:47.93,0:09:49.08,Default,,0,0,0,,the same precision for your
Dialogue: 0,0:09:49.08,0:09:49.48,Default,,0,0,0,,model.
Dialogue: 0,0:09:50.06,0:09:51.61,Default,,0,0,0,,But, of course, when you convert
Dialogue: 0,0:09:51.61,0:09:53.36,Default,,0,0,0,,32-bit floating point to 8-bit,
Dialogue: 0,0:09:53.36,0:09:54.57,Default,,0,0,0,,your model is four times
Dialogue: 0,0:09:54.57,0:09:55.12,Default,,0,0,0,,smaller.
Dialogue: 0,0:09:55.66,0:09:56.66,Default,,0,0,0,,And that's something you ship
Dialogue: 0,0:09:56.66,0:09:57.32,Default,,0,0,0,,with your app.
Dialogue: 0,0:09:57.32,0:09:59.91,Default,,0,0,0,,So you want to consider that.
Dialogue: 0,0:09:59.91,0:10:02.32,Default,,0,0,0,,This year we optimized BNNS to
Dialogue: 0,0:10:02.32,0:10:03.46,Default,,0,0,0,,support these types.
Dialogue: 0,0:10:03.85,0:10:06.53,Default,,0,0,0,,So this is what we support now,
Dialogue: 0,0:10:06.81,0:10:08.46,Default,,0,0,0,,optimized in the convolutional
Dialogue: 0,0:10:08.46,0:10:08.75,Default,,0,0,0,,layers.
Dialogue: 0,0:10:08.75,0:10:10.22,Default,,0,0,0,,The green stuff is new.
Dialogue: 0,0:10:11.19,0:10:13.42,Default,,0,0,0,,See, we added fp16 storage for
Dialogue: 0,0:10:13.42,0:10:15.13,Default,,0,0,0,,input and weights and also int8.
Dialogue: 0,0:10:16.21,0:10:18.18,Default,,0,0,0,,And this is what we support for
Dialogue: 0,0:10:18.18,0:10:19.85,Default,,0,0,0,,the fully connected layers.
Dialogue: 0,0:10:19.85,0:10:21.66,Default,,0,0,0,,So we're still accumulating to
Dialogue: 0,0:10:21.66,0:10:24.43,Default,,0,0,0,,32 bits, but we can take 16-bit
Dialogue: 0,0:10:24.43,0:10:25.75,Default,,0,0,0,,or even 8-bit inputs and
Dialogue: 0,0:10:25.75,0:10:26.13,Default,,0,0,0,,weights.
Dialogue: 0,0:10:27.10,0:10:28.01,Default,,0,0,0,,Now, for the activation
Dialogue: 0,0:10:28.01,0:10:30.55,Default,,0,0,0,,functions, this is what we had
Dialogue: 0,0:10:30.55,0:10:30.95,Default,,0,0,0,,last year.
Dialogue: 0,0:10:30.95,0:10:32.17,Default,,0,0,0,,And this year we added a few
Dialogue: 0,0:10:32.17,0:10:33.70,Default,,0,0,0,,more, including the most
Dialogue: 0,0:10:33.70,0:10:34.65,Default,,0,0,0,,requested, Softmax.
Dialogue: 0,0:10:34.65,0:10:36.04,Default,,0,0,0,,So now we have an optimized
Dialogue: 0,0:10:36.04,0:10:37.07,Default,,0,0,0,,Softmax in BNNS.
Dialogue: 0,0:10:37.99,0:10:39.62,Default,,0,0,0,,And if you set the activation
Dialogue: 0,0:10:39.62,0:10:41.72,Default,,0,0,0,,function to identity, then you
Dialogue: 0,0:10:41.72,0:10:43.53,Default,,0,0,0,,can change the input and output
Dialogue: 0,0:10:44.12,0:10:45.47,Default,,0,0,0,,types to different combinations.
Dialogue: 0,0:10:45.72,0:10:47.24,Default,,0,0,0,,This is what we support now.
Dialogue: 0,0:10:47.24,0:10:48.99,Default,,0,0,0,,And you will get optimized type
Dialogue: 0,0:10:48.99,0:10:51.15,Default,,0,0,0,,conversion from BNNS.
Dialogue: 0,0:10:51.67,0:10:53.39,Default,,0,0,0,,Last but not least, performance.
Dialogue: 0,0:10:54.30,0:10:56.31,Default,,0,0,0,,So we worked a lot with the Core
Dialogue: 0,0:10:56.31,0:10:58.17,Default,,0,0,0,,ML team and the Vision and NLP
Dialogue: 0,0:10:58.62,0:11:00.79,Default,,0,0,0,,teams to optimize what they
Dialogue: 0,0:11:00.79,0:11:01.74,Default,,0,0,0,,really use a lot.
Dialogue: 0,0:11:02.69,0:11:05.50,Default,,0,0,0,,So that includes convolutions
Dialogue: 0,0:11:05.50,0:11:08.68,Default,,0,0,0,,with padding and Stride 1 and 2
Dialogue: 0,0:11:08.68,0:11:10.62,Default,,0,0,0,,convolutions also and smaller
Dialogue: 0,0:11:10.62,0:11:10.98,Default,,0,0,0,,kernels.
Dialogue: 0,0:11:10.98,0:11:13.30,Default,,0,0,0,,Because the new neural networks
Dialogue: 0,0:11:13.38,0:11:14.56,Default,,0,0,0,,have a lot of layers with
Dialogue: 0,0:11:14.56,0:11:16.72,Default,,0,0,0,,smaller convolutions -- that's 3
Dialogue: 0,0:11:16.72,0:11:17.97,Default,,0,0,0,,by 3 and 1 by 1.
Dialogue: 0,0:11:18.07,0:11:19.44,Default,,0,0,0,,So we optimized these cases.
Dialogue: 0,0:11:19.85,0:11:21.28,Default,,0,0,0,,And especially for the 3 by 3
Dialogue: 0,0:11:21.28,0:11:22.39,Default,,0,0,0,,case, we have Winograd
Dialogue: 0,0:11:22.39,0:11:24.17,Default,,0,0,0,,convolutions, which can be up to
Dialogue: 0,0:11:24.17,0:11:25.78,Default,,0,0,0,,four times faster than the
Dialogue: 0,0:11:25.78,0:11:27.09,Default,,0,0,0,,reference implementation.
Dialogue: 0,0:11:27.33,0:11:29.06,Default,,0,0,0,,And that's it for BNNS.
Dialogue: 0,0:11:29.06,0:11:31.05,Default,,0,0,0,,So let me invite Steve on stage,
Dialogue: 0,0:11:31.05,0:11:32.19,Default,,0,0,0,,and he will tell us everything
Dialogue: 0,0:11:32.19,0:11:32.80,Default,,0,0,0,,about simd.
Dialogue: 0,0:11:32.94,0:11:33.22,Default,,0,0,0,,Thank you.
Dialogue: 0,0:11:34.52,0:11:37.22,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:11:37.72,0:11:38.58,Default,,0,0,0,,>> Thanks very much, Eric.
Dialogue: 0,0:11:38.77,0:11:39.51,Default,,0,0,0,,Thank you, everyone.
Dialogue: 0,0:11:40.13,0:11:41.42,Default,,0,0,0,,As Eric said, my name's Steve.
Dialogue: 0,0:11:41.42,0:11:42.45,Default,,0,0,0,,And today I'm going to talk to
Dialogue: 0,0:11:42.45,0:11:43.51,Default,,0,0,0,,you a little bit about the simd
Dialogue: 0,0:11:43.51,0:11:43.84,Default,,0,0,0,,module.
Dialogue: 0,0:11:43.84,0:11:44.64,Default,,0,0,0,,I don't think I'll get to cover
Dialogue: 0,0:11:44.64,0:11:45.97,Default,,0,0,0,,everything, but we'll cover
Dialogue: 0,0:11:45.97,0:11:46.21,Default,,0,0,0,,some.
Dialogue: 0,0:11:47.32,0:11:50.37,Default,,0,0,0,,So the simd module lives outside
Dialogue: 0,0:11:50.37,0:11:51.04,Default,,0,0,0,,of Accelerate.
Dialogue: 0,0:11:51.04,0:11:52.54,Default,,0,0,0,,It's a small collection of
Dialogue: 0,0:11:52.54,0:11:53.58,Default,,0,0,0,,headers and user include.
Dialogue: 0,0:11:53.84,0:11:55.02,Default,,0,0,0,,And it's a module you import in
Dialogue: 0,0:11:55.02,0:11:55.41,Default,,0,0,0,,Swift.
Dialogue: 0,0:11:55.96,0:11:57.23,Default,,0,0,0,,And there's sort of three main
Dialogue: 0,0:11:57.23,0:11:58.55,Default,,0,0,0,,use cases that are going to
Dialogue: 0,0:11:58.55,0:11:59.41,Default,,0,0,0,,drive you to use simd.
Dialogue: 0,0:12:00.21,0:12:01.91,Default,,0,0,0,,The first is if you're doing 2
Dialogue: 0,0:12:01.91,0:12:04.99,Default,,0,0,0,,by 2, 3 by 3, 4 by 4 vector and
Dialogue: 0,0:12:04.99,0:12:06.05,Default,,0,0,0,,matrix arithmetic, the sort of
Dialogue: 0,0:12:06.05,0:12:07.16,Default,,0,0,0,,thing that comes up all the time
Dialogue: 0,0:12:07.16,0:12:08.51,Default,,0,0,0,,when doing graphics or geometry
Dialogue: 0,0:12:08.51,0:12:09.18,Default,,0,0,0,,operations.
Dialogue: 0,0:12:10.58,0:12:12.44,Default,,0,0,0,,It also provides a bigger set of
Dialogue: 0,0:12:12.44,0:12:13.60,Default,,0,0,0,,vector times, both integer
Dialogue: 0,0:12:13.60,0:12:14.62,Default,,0,0,0,,vectors and floating point
Dialogue: 0,0:12:14.62,0:12:16.73,Default,,0,0,0,,vectors on lengths up to 64
Dialogue: 0,0:12:16.73,0:12:18.63,Default,,0,0,0,,bytes for doing sort of general
Dialogue: 0,0:12:18.63,0:12:19.31,Default,,0,0,0,,vector programming.
Dialogue: 0,0:12:19.31,0:12:21.23,Default,,0,0,0,,It lets you target all the
Dialogue: 0,0:12:21.23,0:12:22.45,Default,,0,0,0,,architectures we support on all
Dialogue: 0,0:12:22.45,0:12:24.67,Default,,0,0,0,,the platforms we support pretty
Dialogue: 0,0:12:24.67,0:12:25.05,Default,,0,0,0,,easily.
Dialogue: 0,0:12:25.05,0:12:26.22,Default,,0,0,0,,And you can write one piece of
Dialogue: 0,0:12:26.22,0:12:27.64,Default,,0,0,0,,code that gets you good vector
Dialogue: 0,0:12:27.84,0:12:28.80,Default,,0,0,0,,code gen for all of those
Dialogue: 0,0:12:28.80,0:12:29.44,Default,,0,0,0,,architectures.
Dialogue: 0,0:12:30.62,0:12:31.97,Default,,0,0,0,,The last reason you'll use simd
Dialogue: 0,0:12:32.66,0:12:34.42,Default,,0,0,0,,is that it's a great set of
Dialogue: 0,0:12:34.42,0:12:35.69,Default,,0,0,0,,types and operations for
Dialogue: 0,0:12:35.69,0:12:37.68,Default,,0,0,0,,interoperating between all of
Dialogue: 0,0:12:37.68,0:12:39.64,Default,,0,0,0,,the various things that do 3 by
Dialogue: 0,0:12:39.64,0:12:41.10,Default,,0,0,0,,3, 4 by 4 operations on the
Dialogue: 0,0:12:41.10,0:12:41.42,Default,,0,0,0,,platform.
Dialogue: 0,0:12:41.42,0:12:42.49,Default,,0,0,0,,So things like SceneKit,
Dialogue: 0,0:12:42.69,0:12:45.56,Default,,0,0,0,,SpriteKit, ARKit, Vision -- all
Dialogue: 0,0:12:45.56,0:12:46.56,Default,,0,0,0,,those different things you have
Dialogue: 0,0:12:46.81,0:12:48.41,Default,,0,0,0,,lots of matrices and vectors
Dialogue: 0,0:12:48.41,0:12:49.08,Default,,0,0,0,,flying around.
Dialogue: 0,0:12:49.52,0:12:51.25,Default,,0,0,0,,And the simd types are a great
Dialogue: 0,0:12:51.25,0:12:52.13,Default,,0,0,0,,set of things to use with that.
Dialogue: 0,0:12:52.53,0:12:54.14,Default,,0,0,0,,I should say that SpriteKit in
Dialogue: 0,0:12:54.14,0:12:55.17,Default,,0,0,0,,particular -- or SceneKit in
Dialogue: 0,0:12:55.17,0:12:56.34,Default,,0,0,0,,particular added a bunch of new
Dialogue: 0,0:12:56.34,0:12:56.95,Default,,0,0,0,,stuff this year.
Dialogue: 0,0:12:56.95,0:12:57.91,Default,,0,0,0,,So check out their session.
Dialogue: 0,0:12:57.91,0:12:59.01,Default,,0,0,0,,There's some nice stuff for
Dialogue: 0,0:12:59.01,0:12:59.80,Default,,0,0,0,,working with simd there.
Dialogue: 0,0:12:59.80,0:13:01.35,Default,,0,0,0,,I'm going to show you a few
Dialogue: 0,0:13:01.35,0:13:02.71,Default,,0,0,0,,examples of what you can do.
Dialogue: 0,0:13:04.30,0:13:04.97,Default,,0,0,0,,So let's say you want to
Dialogue: 0,0:13:04.97,0:13:06.76,Default,,0,0,0,,multiply a three-dimensional
Dialogue: 0,0:13:06.76,0:13:07.73,Default,,0,0,0,,matrix by a vector.
Dialogue: 0,0:13:07.99,0:13:09.62,Default,,0,0,0,,You can do that using BLAS,
Dialogue: 0,0:13:09.70,0:13:10.67,Default,,0,0,0,,which Eric talked about earlier,
Dialogue: 0,0:13:11.18,0:13:11.83,Default,,0,0,0,,looks like this.
Dialogue: 0,0:13:12.38,0:13:15.78,Default,,0,0,0,,And this is fine, but BLAS takes
Dialogue: 0,0:13:15.83,0:13:17.11,Default,,0,0,0,,all the parameters just as raw
Dialogue: 0,0:13:17.11,0:13:17.56,Default,,0,0,0,,pointers.
Dialogue: 0,0:13:17.59,0:13:19.07,Default,,0,0,0,,So we have to tell it these are
Dialogue: 0,0:13:19.07,0:13:20.11,Default,,0,0,0,,the dimensions of the matrix,
Dialogue: 0,0:13:20.11,0:13:20.91,Default,,0,0,0,,these are the dimensions of the
Dialogue: 0,0:13:20.91,0:13:22.30,Default,,0,0,0,,vector, this is how the memory's
Dialogue: 0,0:13:22.30,0:13:22.71,Default,,0,0,0,,laid out.
Dialogue: 0,0:13:23.02,0:13:23.71,Default,,0,0,0,,There's a lot of other
Dialogue: 0,0:13:23.71,0:13:24.80,Default,,0,0,0,,information we have to pass,
Dialogue: 0,0:13:25.83,0:13:26.71,Default,,0,0,0,,which both makes the code a
Dialogue: 0,0:13:26.71,0:13:28.66,Default,,0,0,0,,little harder to write and it
Dialogue: 0,0:13:28.66,0:13:29.68,Default,,0,0,0,,makes it harder to read.
Dialogue: 0,0:13:29.98,0:13:31.48,Default,,0,0,0,,In you're not fluent with BLAS
Dialogue: 0,0:13:31.48,0:13:33.15,Default,,0,0,0,,already, this last line here,
Dialogue: 0,0:13:33.15,0:13:34.27,Default,,0,0,0,,it's not really obvious that
Dialogue: 0,0:13:34.27,0:13:35.21,Default,,0,0,0,,that's doing a matrix vector
Dialogue: 0,0:13:35.21,0:13:35.60,Default,,0,0,0,,product.
Dialogue: 0,0:13:36.06,0:13:37.07,Default,,0,0,0,,So we'd like to have something
Dialogue: 0,0:13:37.07,0:13:38.31,Default,,0,0,0,,simpler than that.
Dialogue: 0,0:13:39.06,0:13:40.21,Default,,0,0,0,,We could also write this with
Dialogue: 0,0:13:40.21,0:13:40.63,Default,,0,0,0,,GLKit.
Dialogue: 0,0:13:41.14,0:13:42.80,Default,,0,0,0,,GLKit makes it considerably
Dialogue: 0,0:13:42.80,0:13:43.16,Default,,0,0,0,,nicer.
Dialogue: 0,0:13:43.52,0:13:44.97,Default,,0,0,0,,We have dedicated types for a
Dialogue: 0,0:13:44.97,0:13:46.50,Default,,0,0,0,,three-dimensional matrix and for
Dialogue: 0,0:13:46.50,0:13:47.96,Default,,0,0,0,,three-dimensional vector; we
Dialogue: 0,0:13:47.96,0:13:48.37,Default,,0,0,0,,call this
Dialogue: 0,0:13:48.37,0:13:50.70,Default,,0,0,0,,GLKMatrix3MultiplyVector3
Dialogue: 0,0:13:50.70,0:13:51.15,Default,,0,0,0,,function.
Dialogue: 0,0:13:51.68,0:13:52.49,Default,,0,0,0,,It's pretty clear that's a
Dialogue: 0,0:13:52.49,0:13:53.20,Default,,0,0,0,,multiplication.
Dialogue: 0,0:13:53.54,0:13:55.42,Default,,0,0,0,,But we can make this even nicer
Dialogue: 0,0:13:55.79,0:13:56.25,Default,,0,0,0,,using simd.
Dialogue: 0,0:13:56.25,0:13:58.18,Default,,0,0,0,,This is what it looks like in
Dialogue: 0,0:13:58.18,0:13:58.50,Default,,0,0,0,,simd.
Dialogue: 0,0:13:59.02,0:14:00.79,Default,,0,0,0,,Okay? Totally explicit that it's
Dialogue: 0,0:14:00.79,0:14:01.78,Default,,0,0,0,,diagonal matrix.
Dialogue: 0,0:14:02.18,0:14:03.69,Default,,0,0,0,,And multiply a matrix by a
Dialogue: 0,0:14:03.69,0:14:05.01,Default,,0,0,0,,vector is just using the
Dialogue: 0,0:14:05.01,0:14:05.94,Default,,0,0,0,,multiplication operator.
Dialogue: 0,0:14:06.36,0:14:07.94,Default,,0,0,0,,It's really nice, it's really
Dialogue: 0,0:14:07.94,0:14:09.58,Default,,0,0,0,,simple, and it's also really
Dialogue: 0,0:14:09.58,0:14:09.80,Default,,0,0,0,,fast.
Dialogue: 0,0:14:10.54,0:14:12.05,Default,,0,0,0,,All of simd for the most part is
Dialogue: 0,0:14:12.05,0:14:13.30,Default,,0,0,0,,implemented as header inlines.
Dialogue: 0,0:14:13.62,0:14:14.79,Default,,0,0,0,,So this is just going to give me
Dialogue: 0,0:14:14.79,0:14:16.63,Default,,0,0,0,,three vector multiplications on
Dialogue: 0,0:14:16.63,0:14:17.24,Default,,0,0,0,,my CPU.
Dialogue: 0,0:14:17.65,0:14:18.71,Default,,0,0,0,,It's really fast, there's no
Dialogue: 0,0:14:18.71,0:14:20.06,Default,,0,0,0,,call overhead, there's no
Dialogue: 0,0:14:20.06,0:14:21.07,Default,,0,0,0,,parameter checking, there's no
Dialogue: 0,0:14:21.07,0:14:21.40,Default,,0,0,0,,nothing.
Dialogue: 0,0:14:21.73,0:14:23.52,Default,,0,0,0,,I get just nice simple code gen
Dialogue: 0,0:14:23.52,0:14:23.81,Default,,0,0,0,,from this.
Dialogue: 0,0:14:24.53,0:14:25.50,Default,,0,0,0,,So that's a Swift example.
Dialogue: 0,0:14:26.08,0:14:27.71,Default,,0,0,0,,The next example that I'm going
Dialogue: 0,0:14:27.71,0:14:28.90,Default,,0,0,0,,to show you will be in C.
Dialogue: 0,0:14:30.29,0:14:31.91,Default,,0,0,0,,Here I'm going to show you an
Dialogue: 0,0:14:31.91,0:14:33.43,Default,,0,0,0,,example of how you can use simd
Dialogue: 0,0:14:33.43,0:14:34.21,Default,,0,0,0,,to write vector code.
Dialogue: 0,0:14:34.81,0:14:35.81,Default,,0,0,0,,So let's say that we want to
Dialogue: 0,0:14:35.81,0:14:37.51,Default,,0,0,0,,compute a logistic curve with a
Dialogue: 0,0:14:37.51,0:14:39.27,Default,,0,0,0,,given midpoint and maximum
Dialogue: 0,0:14:39.27,0:14:39.67,Default,,0,0,0,,slope.
Dialogue: 0,0:14:40.18,0:14:41.24,Default,,0,0,0,,This is a function that comes up
Dialogue: 0,0:14:41.32,0:14:43.01,Default,,0,0,0,,all the time in sort of
Dialogue: 0,0:14:43.01,0:14:43.87,Default,,0,0,0,,computational mathematics,
Dialogue: 0,0:14:43.87,0:14:44.86,Default,,0,0,0,,especially machine learning.
Dialogue: 0,0:14:44.86,0:14:46.22,Default,,0,0,0,,So this is a useful function to
Dialogue: 0,0:14:46.22,0:14:47.00,Default,,0,0,0,,be able to optimize.
Dialogue: 0,0:14:47.00,0:14:47.94,Default,,0,0,0,,We care a lot about this.
Dialogue: 0,0:14:48.88,0:14:50.13,Default,,0,0,0,,And what I've put in the comment
Dialogue: 0,0:14:50.29,0:14:51.41,Default,,0,0,0,,in the body of the function here
Dialogue: 0,0:14:52.18,0:14:54.29,Default,,0,0,0,,is sort of a typical scalar
Dialogue: 0,0:14:54.29,0:14:55.22,Default,,0,0,0,,implementation, just
Dialogue: 0,0:14:55.22,0:14:56.50,Default,,0,0,0,,mathematically what this looks
Dialogue: 0,0:14:56.50,0:14:56.70,Default,,0,0,0,,like.
Dialogue: 0,0:14:56.91,0:14:59.37,Default,,0,0,0,,But we want to compute this on
Dialogue: 0,0:14:59.58,0:15:01.24,Default,,0,0,0,,16 floating point values
Dialogue: 0,0:15:01.24,0:15:02.46,Default,,0,0,0,,simultaneously because we can
Dialogue: 0,0:15:02.46,0:15:03.66,Default,,0,0,0,,get better efficiency that way.
Dialogue: 0,0:15:03.90,0:15:05.95,Default,,0,0,0,,So that's what this simd float16
Dialogue: 0,0:15:05.95,0:15:06.90,Default,,0,0,0,,type in the function is --
Dialogue: 0,0:15:06.93,0:15:08.23,Default,,0,0,0,,that's just a vector of 16
Dialogue: 0,0:15:08.23,0:15:08.72,Default,,0,0,0,,floats.
Dialogue: 0,0:15:09.38,0:15:10.77,Default,,0,0,0,,And we're going to see if we can
Dialogue: 0,0:15:10.77,0:15:11.68,Default,,0,0,0,,implement the body of this
Dialogue: 0,0:15:11.68,0:15:11.97,Default,,0,0,0,,function.
Dialogue: 0,0:15:12.68,0:15:14.75,Default,,0,0,0,,So vector code is complicated.
Dialogue: 0,0:15:14.75,0:15:16.81,Default,,0,0,0,,I just break this apart into
Dialogue: 0,0:15:16.81,0:15:18.89,Default,,0,0,0,,three pieces so we can write
Dialogue: 0,0:15:18.89,0:15:20.13,Default,,0,0,0,,each one of them individually.
Dialogue: 0,0:15:20.49,0:15:21.50,Default,,0,0,0,,Let's start with this first
Dialogue: 0,0:15:21.50,0:15:22.88,Default,,0,0,0,,section, the linear section.
Dialogue: 0,0:15:23.37,0:15:25.98,Default,,0,0,0,,So we're just subtracting a
Dialogue: 0,0:15:25.98,0:15:26.76,Default,,0,0,0,,scalar from a vector.
Dialogue: 0,0:15:26.76,0:15:27.56,Default,,0,0,0,,We're going to subtract it from
Dialogue: 0,0:15:27.56,0:15:28.68,Default,,0,0,0,,every lane of the vector, and
Dialogue: 0,0:15:28.68,0:15:29.68,Default,,0,0,0,,then we're going to multiply by
Dialogue: 0,0:15:29.68,0:15:30.08,Default,,0,0,0,,a scalar.
Dialogue: 0,0:15:30.69,0:15:32.58,Default,,0,0,0,,What does that look like in
Dialogue: 0,0:15:33.50,0:15:34.14,Default,,0,0,0,,simd?
Dialogue: 0,0:15:34.21,0:15:35.41,Default,,0,0,0,,We just subtract and we
Dialogue: 0,0:15:35.41,0:15:35.90,Default,,0,0,0,,multiply.
Dialogue: 0,0:15:35.90,0:15:36.85,Default,,0,0,0,,It's really, really simple.
Dialogue: 0,0:15:37.37,0:15:38.76,Default,,0,0,0,,This works in C, it works in
Dialogue: 0,0:15:38.76,0:15:40.43,Default,,0,0,0,,Swift, it works in C++, it works
Dialogue: 0,0:15:40.43,0:15:41.15,Default,,0,0,0,,in Objective-C.
Dialogue: 0,0:15:41.54,0:15:42.29,Default,,0,0,0,,It's really nice.
Dialogue: 0,0:15:42.29,0:15:43.51,Default,,0,0,0,,It looks a lot like shader
Dialogue: 0,0:15:43.51,0:15:44.48,Default,,0,0,0,,programming if you've done any
Dialogue: 0,0:15:44.48,0:15:44.78,Default,,0,0,0,,of that.
Dialogue: 0,0:15:45.77,0:15:47.18,Default,,0,0,0,,And this last piece down here
Dialogue: 0,0:15:48.18,0:15:49.45,Default,,0,0,0,,where we take a reciprocal,
Dialogue: 0,0:15:49.56,0:15:51.33,Default,,0,0,0,,again, the same thing, we just
Dialogue: 0,0:15:51.41,0:15:52.87,Default,,0,0,0,,write code that looks like the
Dialogue: 0,0:15:52.87,0:15:53.02,Default,,0,0,0,,math.
Dialogue: 0,0:15:53.02,0:15:54.20,Default,,0,0,0,,It looks just like the scaler
Dialogue: 0,0:15:54.20,0:15:55.14,Default,,0,0,0,,code, it looks just like the
Dialogue: 0,0:15:55.14,0:15:55.74,Default,,0,0,0,,math we're doing.
Dialogue: 0,0:15:56.88,0:15:57.91,Default,,0,0,0,,What about this middle section?
Dialogue: 0,0:15:58.34,0:15:59.00,Default,,0,0,0,,That's a little bit more
Dialogue: 0,0:15:59.00,0:15:59.54,Default,,0,0,0,,complicated.
Dialogue: 0,0:15:59.54,0:16:01.21,Default,,0,0,0,,What we want to do here is for
Dialogue: 0,0:16:01.30,0:16:02.46,Default,,0,0,0,,every element in the vector, we
Dialogue: 0,0:16:02.46,0:16:03.78,Default,,0,0,0,,want to compute the exponential
Dialogue: 0,0:16:03.78,0:16:05.54,Default,,0,0,0,,function of that and put that in
Dialogue: 0,0:16:05.54,0:16:06.94,Default,,0,0,0,,the corresponding element of the
Dialogue: 0,0:16:06.94,0:16:07.59,Default,,0,0,0,,result factor.
Dialogue: 0,0:16:07.84,0:16:10.06,Default,,0,0,0,,We can do that with a for loop.
Dialogue: 0,0:16:10.72,0:16:12.81,Default,,0,0,0,,And this is fine, this works.
Dialogue: 0,0:16:13.69,0:16:14.99,Default,,0,0,0,,But we have a nice new feature
Dialogue: 0,0:16:14.99,0:16:16.84,Default,,0,0,0,,for you this year, which is that
Dialogue: 0,0:16:17.41,0:16:18.61,Default,,0,0,0,,basically all of the math
Dialogue: 0,0:16:18.61,0:16:20.21,Default,,0,0,0,,functions just work on vectors
Dialogue: 0,0:16:20.21,0:16:21.12,Default,,0,0,0,,of floats and doubles.
Dialogue: 0,0:16:21.12,0:16:22.88,Default,,0,0,0,,So any length of vector, float,
Dialogue: 0,0:16:22.88,0:16:23.23,Default,,0,0,0,,and double.
Dialogue: 0,0:16:23.71,0:16:25.24,Default,,0,0,0,,You can call XPath, you can call
Dialogue: 0,0:16:25.24,0:16:26.41,Default,,0,0,0,,sine, you can call cosine,
Dialogue: 0,0:16:26.58,0:16:26.87,Default,,0,0,0,,whatever.
Dialogue: 0,0:16:27.15,0:16:28.10,Default,,0,0,0,,The math functions, they just
Dialogue: 0,0:16:28.10,0:16:28.54,Default,,0,0,0,,work on them.
Dialogue: 0,0:16:28.92,0:16:30.18,Default,,0,0,0,,It's a really nice convenience
Dialogue: 0,0:16:30.18,0:16:31.51,Default,,0,0,0,,feature when you're writing this
Dialogue: 0,0:16:31.51,0:16:31.97,Default,,0,0,0,,kind of code.
Dialogue: 0,0:16:32.74,0:16:35.09,Default,,0,0,0,,And this is going to target the
Dialogue: 0,0:16:35.09,0:16:38.09,Default,,0,0,0,,NEON extensions when I write for
Dialogue: 0,0:16:38.09,0:16:38.36,Default,,0,0,0,,ARM.
Dialogue: 0,0:16:38.46,0:16:39.85,Default,,0,0,0,,And when I compile for Intel,
Dialogue: 0,0:16:39.85,0:16:41.21,Default,,0,0,0,,it's going to target AVX and
Dialogue: 0,0:16:41.21,0:16:41.58,Default,,0,0,0,,SSE.
Dialogue: 0,0:16:41.81,0:16:43.21,Default,,0,0,0,,So I'm going to get fast code on
Dialogue: 0,0:16:43.21,0:16:43.91,Default,,0,0,0,,all the platforms.
Dialogue: 0,0:16:43.91,0:16:44.73,Default,,0,0,0,,This is really nice.
Dialogue: 0,0:16:45.31,0:16:46.86,Default,,0,0,0,,We have one other big new
Dialogue: 0,0:16:46.86,0:16:47.99,Default,,0,0,0,,feature this year that a lot of
Dialogue: 0,0:16:47.99,0:16:49.85,Default,,0,0,0,,people have asked for, which is
Dialogue: 0,0:16:49.85,0:16:50.55,Default,,0,0,0,,quaternions.
Dialogue: 0,0:16:50.99,0:16:52.08,Default,,0,0,0,,I'm going to give you a real
Dialogue: 0,0:16:52.08,0:16:53.04,Default,,0,0,0,,quick introduction to them.
Dialogue: 0,0:16:53.82,0:16:55.82,Default,,0,0,0,,Just that quaternions extend the
Dialogue: 0,0:16:55.82,0:16:57.67,Default,,0,0,0,,complex numbers in the same way
Dialogue: 0,0:16:57.67,0:16:58.72,Default,,0,0,0,,the complex numbers extend the
Dialogue: 0,0:16:58.72,0:16:59.18,Default,,0,0,0,,reals.
Dialogue: 0,0:17:00.68,0:17:02.20,Default,,0,0,0,,So complex number, you might
Dialogue: 0,0:17:02.20,0:17:03.80,Default,,0,0,0,,remember from school, has a real
Dialogue: 0,0:17:03.80,0:17:06.37,Default,,0,0,0,,part and an imaginary part.
Dialogue: 0,0:17:06.92,0:17:10.07,Default,,0,0,0,,Quaternions have a real part and
Dialogue: 0,0:17:10.07,0:17:12.02,Default,,0,0,0,,they have three imaginary parts;
Dialogue: 0,0:17:12.13,0:17:12.84,Default,,0,0,0,,sometimes you call that the
Dialogue: 0,0:17:12.84,0:17:13.38,Default,,0,0,0,,vector part.
Dialogue: 0,0:17:13.78,0:17:15.51,Default,,0,0,0,,My mom always said that if
Dialogue: 0,0:17:15.51,0:17:16.76,Default,,0,0,0,,having one square root of minus
Dialogue: 0,0:17:16.76,0:17:17.90,Default,,0,0,0,,one is good, having three square
Dialogue: 0,0:17:17.90,0:17:18.86,Default,,0,0,0,,roots of minus one must be
Dialogue: 0,0:17:18.86,0:17:19.15,Default,,0,0,0,,great.
Dialogue: 0,0:17:20.71,0:17:21.49,Default,,0,0,0,,She was a smart lady.
Dialogue: 0,0:17:21.49,0:17:25.00,Default,,0,0,0,,You should listen to her.
Dialogue: 0,0:17:25.25,0:17:26.43,Default,,0,0,0,,There's a lot of fascinating
Dialogue: 0,0:17:26.43,0:17:27.53,Default,,0,0,0,,mathematical structure about the
Dialogue: 0,0:17:27.53,0:17:28.88,Default,,0,0,0,,quaternions -- we don't really
Dialogue: 0,0:17:28.88,0:17:29.44,Default,,0,0,0,,care about that.
Dialogue: 0,0:17:29.96,0:17:30.93,Default,,0,0,0,,We're interested in one thing.
Dialogue: 0,0:17:32.03,0:17:33.07,Default,,0,0,0,,Quaternions have a notion of
Dialogue: 0,0:17:33.07,0:17:34.20,Default,,0,0,0,,length that's just like the
Dialogue: 0,0:17:34.20,0:17:35.02,Default,,0,0,0,,complex numbers.
Dialogue: 0,0:17:35.02,0:17:36.17,Default,,0,0,0,,You sum the squares of the
Dialogue: 0,0:17:36.17,0:17:37.01,Default,,0,0,0,,components and you take the
Dialogue: 0,0:17:37.01,0:17:38.40,Default,,0,0,0,,square root, that's the length
Dialogue: 0,0:17:38.40,0:17:38.89,Default,,0,0,0,,of a quaternion.
Dialogue: 0,0:17:39.80,0:17:42.00,Default,,0,0,0,,Quaternions of length one, we
Dialogue: 0,0:17:42.00,0:17:43.89,Default,,0,0,0,,call those unit quaternions, and
Dialogue: 0,0:17:43.89,0:17:45.56,Default,,0,0,0,,they have this really nice
Dialogue: 0,0:17:45.56,0:17:48.29,Default,,0,0,0,,property, which is that you can
Dialogue: 0,0:17:48.29,0:17:50.13,Default,,0,0,0,,use them to represent rotations
Dialogue: 0,0:17:50.46,0:17:51.73,Default,,0,0,0,,in three-dimensional space.
Dialogue: 0,0:17:52.72,0:17:53.80,Default,,0,0,0,,That's all we care about.
Dialogue: 0,0:17:53.80,0:17:55.16,Default,,0,0,0,,Forget about all the other math
Dialogue: 0,0:17:55.16,0:17:57.82,Default,,0,0,0,,that I just mentioned.
Dialogue: 0,0:17:57.90,0:17:59.39,Default,,0,0,0,,So I'll show you a quick code
Dialogue: 0,0:17:59.39,0:18:00.14,Default,,0,0,0,,example of that.
Dialogue: 0,0:18:00.57,0:18:01.61,Default,,0,0,0,,Say we have a vector that's a
Dialogue: 0,0:18:01.61,0:18:02.65,Default,,0,0,0,,vector in the XY plane.
Dialogue: 0,0:18:03.85,0:18:05.13,Default,,0,0,0,,And let's build a quaternion.
Dialogue: 0,0:18:05.48,0:18:06.34,Default,,0,0,0,,This is a quaternion that
Dialogue: 0,0:18:06.34,0:18:08.15,Default,,0,0,0,,represents a rotation around the
Dialogue: 0,0:18:08.15,0:18:08.96,Default,,0,0,0,,y-axis.
Dialogue: 0,0:18:10.53,0:18:12.67,Default,,0,0,0,,Quaternions act on vectors --
Dialogue: 0,0:18:12.67,0:18:14.01,Default,,0,0,0,,that's the simd act function.
Dialogue: 0,0:18:14.81,0:18:16.36,Default,,0,0,0,,It's not multiplication.
Dialogue: 0,0:18:16.36,0:18:18.24,Default,,0,0,0,,When you multiply a vector by a
Dialogue: 0,0:18:18.24,0:18:20.67,Default,,0,0,0,,matrix -- when you rotate a
Dialogue: 0,0:18:20.67,0:18:21.99,Default,,0,0,0,,vector by a matrix, you just
Dialogue: 0,0:18:21.99,0:18:22.69,Default,,0,0,0,,multiply it.
Dialogue: 0,0:18:22.93,0:18:23.89,Default,,0,0,0,,With quaternions it's called an
Dialogue: 0,0:18:23.89,0:18:24.29,Default,,0,0,0,,action.
Dialogue: 0,0:18:24.71,0:18:26.36,Default,,0,0,0,,And we don't care too much about
Dialogue: 0,0:18:26.36,0:18:28.13,Default,,0,0,0,,the details of that, but that's
Dialogue: 0,0:18:28.13,0:18:29.15,Default,,0,0,0,,why this is the act function.
Dialogue: 0,0:18:29.51,0:18:31.11,Default,,0,0,0,,So this is a nice way to
Dialogue: 0,0:18:31.11,0:18:32.25,Default,,0,0,0,,represent rotations.
Dialogue: 0,0:18:32.69,0:18:33.84,Default,,0,0,0,,There's a lot of other ways to
Dialogue: 0,0:18:33.84,0:18:34.86,Default,,0,0,0,,represent rotations.
Dialogue: 0,0:18:35.06,0:18:36.38,Default,,0,0,0,,Why do you want to use this one
Dialogue: 0,0:18:36.38,0:18:37.35,Default,,0,0,0,,and when do you want to use this
Dialogue: 0,0:18:37.35,0:18:37.51,Default,,0,0,0,,one?
Dialogue: 0,0:18:37.60,0:18:40.12,Default,,0,0,0,,You know, you might use matrices
Dialogue: 0,0:18:40.12,0:18:41.35,Default,,0,0,0,,instead, you might use Euler
Dialogue: 0,0:18:41.35,0:18:42.84,Default,,0,0,0,,angles or yaw/pitch/roll, you
Dialogue: 0,0:18:42.84,0:18:43.92,Default,,0,0,0,,can use axis and angle
Dialogue: 0,0:18:43.92,0:18:44.50,Default,,0,0,0,,representation.
Dialogue: 0,0:18:44.50,0:18:45.49,Default,,0,0,0,,There's lots of choices.
Dialogue: 0,0:18:45.95,0:18:47.63,Default,,0,0,0,,Quaternions are an especially
Dialogue: 0,0:18:47.63,0:18:48.86,Default,,0,0,0,,good choice for a certain class
Dialogue: 0,0:18:48.86,0:18:50.11,Default,,0,0,0,,of operations that I'm going to
Dialogue: 0,0:18:50.11,0:18:51.59,Default,,0,0,0,,tell you about.
Dialogue: 0,0:18:52.34,0:18:53.79,Default,,0,0,0,,The first nice thing about
Dialogue: 0,0:18:53.79,0:18:54.72,Default,,0,0,0,,quaternions is they take less
Dialogue: 0,0:18:54.72,0:18:55.75,Default,,0,0,0,,memory than matrices do.
Dialogue: 0,0:18:56.02,0:18:59.32,Default,,0,0,0,,This is nice and it's great, but
Dialogue: 0,0:18:59.32,0:19:00.35,Default,,0,0,0,,that's not really why we want to
Dialogue: 0,0:19:00.35,0:19:01.49,Default,,0,0,0,,use them.
Dialogue: 0,0:19:02.07,0:19:02.88,Default,,0,0,0,,The better thing about
Dialogue: 0,0:19:02.88,0:19:04.62,Default,,0,0,0,,quaternions is that while they
Dialogue: 0,0:19:04.62,0:19:06.94,Default,,0,0,0,,are not especially fast to do a
Dialogue: 0,0:19:06.94,0:19:08.17,Default,,0,0,0,,rotation with, you can see here
Dialogue: 0,0:19:08.17,0:19:09.48,Default,,0,0,0,,they're about a third the speed
Dialogue: 0,0:19:09.48,0:19:10.70,Default,,0,0,0,,of using matrices to actually
Dialogue: 0,0:19:11.06,0:19:11.96,Default,,0,0,0,,compute a rotation.
Dialogue: 0,0:19:13.42,0:19:15.09,Default,,0,0,0,,When you want to do a sequence
Dialogue: 0,0:19:15.09,0:19:16.21,Default,,0,0,0,,of operations, when you want to
Dialogue: 0,0:19:16.21,0:19:17.60,Default,,0,0,0,,combine rotations or you want to
Dialogue: 0,0:19:17.60,0:19:18.77,Default,,0,0,0,,interpolate rotations, you want
Dialogue: 0,0:19:18.77,0:19:19.49,Default,,0,0,0,,to do anything like that,
Dialogue: 0,0:19:19.85,0:19:21.84,Default,,0,0,0,,they're the most natural setting
Dialogue: 0,0:19:21.84,0:19:23.02,Default,,0,0,0,,to do those operations in.
Dialogue: 0,0:19:23.48,0:19:24.81,Default,,0,0,0,,So when we want to multiply two
Dialogue: 0,0:19:24.81,0:19:25.92,Default,,0,0,0,,rotations together, you can see
Dialogue: 0,0:19:25.92,0:19:27.85,Default,,0,0,0,,quaternions are about 30% faster
Dialogue: 0,0:19:28.05,0:19:29.20,Default,,0,0,0,,than vectors and matrices.
Dialogue: 0,0:19:29.58,0:19:31.32,Default,,0,0,0,,But they also let us do things
Dialogue: 0,0:19:31.32,0:19:32.37,Default,,0,0,0,,that are hard to do with
Dialogue: 0,0:19:32.37,0:19:32.86,Default,,0,0,0,,matrices.
Dialogue: 0,0:19:32.86,0:19:35.34,Default,,0,0,0,,So let's say we want to
Dialogue: 0,0:19:35.34,0:19:36.95,Default,,0,0,0,,interpolate between two
Dialogue: 0,0:19:36.95,0:19:38.11,Default,,0,0,0,,different rotated coordinate
Dialogue: 0,0:19:38.11,0:19:38.56,Default,,0,0,0,,frames.
Dialogue: 0,0:19:39.26,0:19:40.54,Default,,0,0,0,,That's a little subtle with
Dialogue: 0,0:19:40.54,0:19:42.04,Default,,0,0,0,,matrices, but it's really
Dialogue: 0,0:19:42.04,0:19:43.11,Default,,0,0,0,,natural with quaternions.
Dialogue: 0,0:19:43.54,0:19:45.03,Default,,0,0,0,,And the reason it's natural has
Dialogue: 0,0:19:45.03,0:19:46.89,Default,,0,0,0,,to do with this sphere that I've
Dialogue: 0,0:19:46.89,0:19:47.81,Default,,0,0,0,,drawn over on the side of the
Dialogue: 0,0:19:47.81,0:19:48.31,Default,,0,0,0,,screen here.
Dialogue: 0,0:19:48.43,0:19:49.34,Default,,0,0,0,,You might say, "Well, why are
Dialogue: 0,0:19:49.34,0:19:50.84,Default,,0,0,0,,you drawing rotations on a
Dialogue: 0,0:19:50.84,0:19:51.17,Default,,0,0,0,,sphere?"
Dialogue: 0,0:19:51.88,0:19:52.77,Default,,0,0,0,,There's a good reason for that.
Dialogue: 0,0:19:53.61,0:19:55.75,Default,,0,0,0,,Quaternions you can think of as
Dialogue: 0,0:19:55.85,0:19:57.07,Default,,0,0,0,,points on the four-dimensional
Dialogue: 0,0:19:57.07,0:19:57.80,Default,,0,0,0,,projective sphere.
Dialogue: 0,0:19:58.87,0:20:00.59,Default,,0,0,0,,And that sounds complicated and
Dialogue: 0,0:20:00.59,0:20:02.93,Default,,0,0,0,,mathematical, and it is, but
Dialogue: 0,0:20:03.17,0:20:04.82,Default,,0,0,0,,it's the natural space of
Dialogue: 0,0:20:04.82,0:20:05.96,Default,,0,0,0,,rotations for three-dimensional
Dialogue: 0,0:20:05.96,0:20:06.38,Default,,0,0,0,,space.
Dialogue: 0,0:20:06.83,0:20:08.41,Default,,0,0,0,,So when I do operations on the
Dialogue: 0,0:20:08.41,0:20:09.97,Default,,0,0,0,,surface of this sphere, that
Dialogue: 0,0:20:09.97,0:20:11.45,Default,,0,0,0,,corresponds exactly to your
Dialogue: 0,0:20:11.45,0:20:12.82,Default,,0,0,0,,natural intuition for what
Dialogue: 0,0:20:12.82,0:20:13.85,Default,,0,0,0,,should happen with rotations.
Dialogue: 0,0:20:13.95,0:20:16.58,Default,,0,0,0,,So for instance, if we want to
Dialogue: 0,0:20:16.58,0:20:17.73,Default,,0,0,0,,interpolate between them, we
Dialogue: 0,0:20:17.73,0:20:19.67,Default,,0,0,0,,just interpolate along a great
Dialogue: 0,0:20:19.67,0:20:20.77,Default,,0,0,0,,circle on the sphere -- that's
Dialogue: 0,0:20:20.77,0:20:22.20,Default,,0,0,0,,this simd slerp function that
Dialogue: 0,0:20:22.20,0:20:23.38,Default,,0,0,0,,stands for spherical linear
Dialogue: 0,0:20:23.38,0:20:24.06,Default,,0,0,0,,interpolation.
Dialogue: 0,0:20:24.68,0:20:26.66,Default,,0,0,0,,And that's really easy to use
Dialogue: 0,0:20:26.66,0:20:27.93,Default,,0,0,0,,and it does exactly what you
Dialogue: 0,0:20:27.93,0:20:28.27,Default,,0,0,0,,want.
Dialogue: 0,0:20:28.64,0:20:30.35,Default,,0,0,0,,If we have a whole sequence of
Dialogue: 0,0:20:30.39,0:20:31.42,Default,,0,0,0,,points that we want to
Dialogue: 0,0:20:31.42,0:20:33.60,Default,,0,0,0,,interpolate between, we could
Dialogue: 0,0:20:33.60,0:20:35.50,Default,,0,0,0,,call slerp repeatedly to
Dialogue: 0,0:20:35.50,0:20:36.79,Default,,0,0,0,,interpolate between them, but
Dialogue: 0,0:20:37.06,0:20:38.95,Default,,0,0,0,,that will have a noticeable jump
Dialogue: 0,0:20:38.95,0:20:40.73,Default,,0,0,0,,a little bit in the rotation
Dialogue: 0,0:20:40.83,0:20:41.84,Default,,0,0,0,,when you get to corners.
Dialogue: 0,0:20:42.89,0:20:45.14,Default,,0,0,0,,Instead we can use the simd
Dialogue: 0,0:20:45.14,0:20:46.62,Default,,0,0,0,,spline function to get a
Dialogue: 0,0:20:46.62,0:20:48.57,Default,,0,0,0,,completely smooth interpolation
Dialogue: 0,0:20:48.57,0:20:49.79,Default,,0,0,0,,using a whole sequence of
Dialogue: 0,0:20:49.79,0:20:50.94,Default,,0,0,0,,rotated coordinate frames.
Dialogue: 0,0:20:51.63,0:20:52.81,Default,,0,0,0,,There's a ton of other
Dialogue: 0,0:20:53.02,0:20:54.80,Default,,0,0,0,,operations like this in the simd
Dialogue: 0,0:20:54.80,0:20:56.75,Default,,0,0,0,,headers that you can use to do
Dialogue: 0,0:20:56.75,0:20:58.62,Default,,0,0,0,,these types of operations.
Dialogue: 0,0:20:58.94,0:20:59.85,Default,,0,0,0,,If you want to work with
Dialogue: 0,0:20:59.85,0:21:01.79,Default,,0,0,0,,rotations, the API is really
Dialogue: 0,0:21:01.79,0:21:02.36,Default,,0,0,0,,pretty full.
Dialogue: 0,0:21:02.36,0:21:03.67,Default,,0,0,0,,I encourage you to check it out.
Dialogue: 0,0:21:04.18,0:21:05.33,Default,,0,0,0,,And as I said, this was one of
Dialogue: 0,0:21:05.33,0:21:06.31,Default,,0,0,0,,the most requested features from
Dialogue: 0,0:21:06.31,0:21:06.85,Default,,0,0,0,,developers.
Dialogue: 0,0:21:06.85,0:21:08.73,Default,,0,0,0,,So I encourage you to file bugs
Dialogue: 0,0:21:08.73,0:21:10.02,Default,,0,0,0,,to say, "Hey, can you guys add
Dialogue: 0,0:21:10.02,0:21:11.02,Default,,0,0,0,,this other thing as well?"
Dialogue: 0,0:21:11.02,0:21:12.02,Default,,0,0,0,,We're really responsive to that.
Dialogue: 0,0:21:12.02,0:21:13.21,Default,,0,0,0,,We love to get feature requests
Dialogue: 0,0:21:13.21,0:21:13.85,Default,,0,0,0,,from our users.
Dialogue: 0,0:21:14.66,0:21:16.21,Default,,0,0,0,,With that, I'm going to turn you
Dialogue: 0,0:21:16.21,0:21:18.35,Default,,0,0,0,,over to Jonathan Hogg, who's
Dialogue: 0,0:21:18.35,0:21:19.43,Default,,0,0,0,,going to tell you all about
Dialogue: 0,0:21:19.59,0:21:21.37,Default,,0,0,0,,really, really big matrices.
Dialogue: 0,0:21:22.52,0:21:26.95,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:21:27.45,0:21:29.85,Default,,0,0,0,,>> Hi. So you've heard from
Dialogue: 0,0:21:29.85,0:21:32.21,Default,,0,0,0,,Steve about simd, which is
Dialogue: 0,0:21:32.21,0:21:33.20,Default,,0,0,0,,really great for very, very
Dialogue: 0,0:21:33.20,0:21:34.15,Default,,0,0,0,,small matrices.
Dialogue: 0,0:21:34.34,0:21:35.90,Default,,0,0,0,,And I'm going to tell you in a
Dialogue: 0,0:21:35.90,0:21:37.39,Default,,0,0,0,,little while about very big
Dialogue: 0,0:21:37.39,0:21:38.23,Default,,0,0,0,,matrices.
Dialogue: 0,0:21:38.52,0:21:39.86,Default,,0,0,0,,But first I'm going to tell you
Dialogue: 0,0:21:39.86,0:21:40.89,Default,,0,0,0,,about BLAS and LAPACK.
Dialogue: 0,0:21:41.40,0:21:43.35,Default,,0,0,0,,These are libraries for handling
Dialogue: 0,0:21:43.73,0:21:44.41,Default,,0,0,0,,dense matrices.
Dialogue: 0,0:21:44.41,0:21:46.44,Default,,0,0,0,,So you can get up to 30,000 or
Dialogue: 0,0:21:46.44,0:21:48.77,Default,,0,0,0,,40,000 rows of columns here on a
Dialogue: 0,0:21:48.77,0:21:49.27,Default,,0,0,0,,MacBook.
Dialogue: 0,0:21:50.85,0:21:51.52,Default,,0,0,0,,What do we have?
Dialogue: 0,0:21:52.82,0:21:55.05,Default,,0,0,0,,So BLAS stands for Basic Linear
Dialogue: 0,0:21:55.05,0:21:56.89,Default,,0,0,0,,Algebra Subroutines, and these
Dialogue: 0,0:21:56.89,0:21:59.06,Default,,0,0,0,,do basic operations on matrices
Dialogue: 0,0:21:59.06,0:21:59.72,Default,,0,0,0,,and vectors.
Dialogue: 0,0:22:00.65,0:22:02.44,Default,,0,0,0,,We have BLAS 1, which does
Dialogue: 0,0:22:02.56,0:22:04.00,Default,,0,0,0,,vector vector operations.
Dialogue: 0,0:22:04.18,0:22:05.85,Default,,0,0,0,,And then we move through BLAS 2
Dialogue: 0,0:22:05.85,0:22:08.06,Default,,0,0,0,,for matrix vector, to BLAS 3 for
Dialogue: 0,0:22:08.06,0:22:09.36,Default,,0,0,0,,matrix matrix operations.
Dialogue: 0,0:22:09.75,0:22:10.55,Default,,0,0,0,,And you've already seen from
Dialogue: 0,0:22:10.55,0:22:13.05,Default,,0,0,0,,Eric that we can be 100 times
Dialogue: 0,0:22:13.05,0:22:14.55,Default,,0,0,0,,faster on the matrix matrix
Dialogue: 0,0:22:14.55,0:22:16.24,Default,,0,0,0,,multiply than your simple loop.
Dialogue: 0,0:22:17.26,0:22:18.24,Default,,0,0,0,,If you want to do things more
Dialogue: 0,0:22:18.24,0:22:20.04,Default,,0,0,0,,complicated than this, then we
Dialogue: 0,0:22:20.04,0:22:21.19,Default,,0,0,0,,have LAPACK.
Dialogue: 0,0:22:21.91,0:22:22.88,Default,,0,0,0,,These do your matrix
Dialogue: 0,0:22:22.88,0:22:24.39,Default,,0,0,0,,factorizations, your linear
Dialogue: 0,0:22:24.39,0:22:26.65,Default,,0,0,0,,solves, your find Eigenvalues,
Dialogue: 0,0:22:26.74,0:22:28.49,Default,,0,0,0,,Eigenvectors, SVD's -- pretty
Dialogue: 0,0:22:28.95,0:22:31.07,Default,,0,0,0,,much everything you want to do.
Dialogue: 0,0:22:32.90,0:22:33.87,Default,,0,0,0,,That's all I'm going to tell you
Dialogue: 0,0:22:33.87,0:22:35.65,Default,,0,0,0,,about dense matrices because we
Dialogue: 0,0:22:35.65,0:22:38.29,Default,,0,0,0,,want to actually talk about
Dialogue: 0,0:22:38.96,0:22:39.38,Default,,0,0,0,,sparse matrices.
Dialogue: 0,0:22:39.38,0:22:41.41,Default,,0,0,0,,What is a sparse matrix?
Dialogue: 0,0:22:44.14,0:22:46.52,Default,,0,0,0,,So James Wilkinson was one of
Dialogue: 0,0:22:46.52,0:22:47.61,Default,,0,0,0,,the founding fathers of
Dialogue: 0,0:22:47.61,0:22:49.00,Default,,0,0,0,,computational linear algebra.
Dialogue: 0,0:22:49.23,0:22:51.65,Default,,0,0,0,,This was his definition, "Sparse
Dialogue: 0,0:22:51.65,0:22:52.90,Default,,0,0,0,,matrix is any one where
Dialogue: 0,0:22:52.90,0:22:56.08,Default,,0,0,0,,exploiting zeros is useful to
Dialogue: 0,0:22:57.20,0:22:57.30,Default,,0,0,0,,us."
Dialogue: 0,0:22:57.52,0:22:59.05,Default,,0,0,0,,Let's see what sparse matrix
Dialogue: 0,0:22:59.05,0:23:00.45,Default,,0,0,0,,actually looks like.
Dialogue: 0,0:23:01.42,0:23:03.78,Default,,0,0,0,,So here are two sparse matrices.
Dialogue: 0,0:23:03.88,0:23:05.10,Default,,0,0,0,,One's actually the Cholesky
Dialogue: 0,0:23:05.10,0:23:06.79,Default,,0,0,0,,factorization of the other.
Dialogue: 0,0:23:07.42,0:23:09.27,Default,,0,0,0,,And each pixel here represents
Dialogue: 0,0:23:09.27,0:23:10.40,Default,,0,0,0,,multiple non-zeros.
Dialogue: 0,0:23:11.37,0:23:14.83,Default,,0,0,0,,Where they are white, all of the
Dialogue: 0,0:23:14.83,0:23:16.94,Default,,0,0,0,,entries behind that pixel are
Dialogue: 0,0:23:16.94,0:23:17.31,Default,,0,0,0,,zero.
Dialogue: 0,0:23:17.84,0:23:19.75,Default,,0,0,0,,Where there's blue, that means
Dialogue: 0,0:23:19.75,0:23:21.07,Default,,0,0,0,,at least one non-zero's present.
Dialogue: 0,0:23:21.07,0:23:22.76,Default,,0,0,0,,So you can see these matrices
Dialogue: 0,0:23:23.03,0:23:24.16,Default,,0,0,0,,are mostly empty.
Dialogue: 0,0:23:25.25,0:23:26.94,Default,,0,0,0,,In fact, if you were to store
Dialogue: 0,0:23:26.94,0:23:28.90,Default,,0,0,0,,this as a dense matrix, it's
Dialogue: 0,0:23:28.90,0:23:30.23,Default,,0,0,0,,about 30,000 by 30,000.
Dialogue: 0,0:23:30.23,0:23:32.70,Default,,0,0,0,,So it takes us 6.5 gigabytes.
Dialogue: 0,0:23:33.40,0:23:34.45,Default,,0,0,0,,If we store it as a sparse
Dialogue: 0,0:23:34.45,0:23:37.71,Default,,0,0,0,,matrix, we require 260 times
Dialogue: 0,0:23:38.02,0:23:40.37,Default,,0,0,0,,less storage -- only 26
Dialogue: 0,0:23:40.37,0:23:41.03,Default,,0,0,0,,megabytes.
Dialogue: 0,0:23:41.39,0:23:43.11,Default,,0,0,0,,If we wanted to multiply this
Dialogue: 0,0:23:43.11,0:23:46.25,Default,,0,0,0,,matrix by a vector, we'd require
Dialogue: 0,0:23:46.44,0:23:48.59,Default,,0,0,0,,almost 200 times fewer floating
Dialogue: 0,0:23:48.59,0:23:49.75,Default,,0,0,0,,point operations.
Dialogue: 0,0:23:50.66,0:23:51.72,Default,,0,0,0,,But if we want to do something
Dialogue: 0,0:23:51.72,0:23:53.91,Default,,0,0,0,,more complicated like factorize
Dialogue: 0,0:23:53.91,0:23:58.25,Default,,0,0,0,,this matrix, things get better,
Dialogue: 0,0:23:58.78,0:24:00.60,Default,,0,0,0,,at least in the floating point.
Dialogue: 0,0:24:00.97,0:24:03.62,Default,,0,0,0,,We require 2,000 times fewer
Dialogue: 0,0:24:03.62,0:24:05.03,Default,,0,0,0,,floating point operations to
Dialogue: 0,0:24:05.25,0:24:06.51,Default,,0,0,0,,factorize this matrix.
Dialogue: 0,0:24:07.50,0:24:09.09,Default,,0,0,0,,And the dense matrix is still
Dialogue: 0,0:24:09.09,0:24:10.47,Default,,0,0,0,,the same size, the factor's
Dialogue: 0,0:24:10.47,0:24:11.27,Default,,0,0,0,,filled in a bit.
Dialogue: 0,0:24:11.81,0:24:13.14,Default,,0,0,0,,It's slightly less sparse than
Dialogue: 0,0:24:13.14,0:24:15.52,Default,,0,0,0,,it was, so we're only 30 times
Dialogue: 0,0:24:15.52,0:24:16.60,Default,,0,0,0,,better on the storage.
Dialogue: 0,0:24:17.45,0:24:19.09,Default,,0,0,0,,Now, to drive that point home,
Dialogue: 0,0:24:19.26,0:24:20.67,Default,,0,0,0,,we've set up a little race.
Dialogue: 0,0:24:21.20,0:24:22.75,Default,,0,0,0,,We decided we'd run the sparse
Dialogue: 0,0:24:22.75,0:24:25.56,Default,,0,0,0,,solver on a Watch and we put it
Dialogue: 0,0:24:25.69,0:24:27.67,Default,,0,0,0,,up against our best dense matrix
Dialogue: 0,0:24:27.67,0:24:30.29,Default,,0,0,0,,solver from LAPACK on a Macbook
Dialogue: 0,0:24:30.36,0:24:30.69,Default,,0,0,0,,Air.
Dialogue: 0,0:24:31.51,0:24:32.81,Default,,0,0,0,,And this is what happened.
Dialogue: 0,0:24:33.47,0:24:36.90,Default,,0,0,0,,Now, this is running at five
Dialogue: 0,0:24:36.90,0:24:38.82,Default,,0,0,0,,times real time.
Dialogue: 0,0:24:39.14,0:24:40.66,Default,,0,0,0,,And you can see that the Watch
Dialogue: 0,0:24:40.92,0:24:43.76,Default,,0,0,0,,is finished in only 16 seconds.
Dialogue: 0,0:24:43.76,0:24:44.95,Default,,0,0,0,,You got to remember while
Dialogue: 0,0:24:44.95,0:24:46.97,Default,,0,0,0,,watching this that the floating
Dialogue: 0,0:24:46.97,0:24:48.18,Default,,0,0,0,,point throughput on the MacBook
Dialogue: 0,0:24:48.18,0:24:50.47,Default,,0,0,0,,Air is about 50 times that
Dialogue: 0,0:24:50.47,0:24:51.74,Default,,0,0,0,,available on the Watch.
Dialogue: 0,0:24:52.52,0:24:56.55,Default,,0,0,0,,[ Laughter ]
Dialogue: 0,0:24:57.05,0:24:59.08,Default,,0,0,0,,Now, there's actually two phases
Dialogue: 0,0:24:59.08,0:25:00.05,Default,,0,0,0,,to this factorization in the
Dialogue: 0,0:25:00.05,0:25:00.63,Default,,0,0,0,,sparse world.
Dialogue: 0,0:25:00.99,0:25:02.60,Default,,0,0,0,,First we find where the
Dialogue: 0,0:25:02.60,0:25:03.48,Default,,0,0,0,,positions of the non-zero
Dialogue: 0,0:25:03.48,0:25:05.04,Default,,0,0,0,,entry's going to be -- that's
Dialogue: 0,0:25:05.04,0:25:05.89,Default,,0,0,0,,the symbolic phase.
Dialogue: 0,0:25:06.12,0:25:07.97,Default,,0,0,0,,Then we have a numeric phase
Dialogue: 0,0:25:08.17,0:25:09.06,Default,,0,0,0,,which calculates the actual
Dialogue: 0,0:25:09.06,0:25:09.57,Default,,0,0,0,,values.
Dialogue: 0,0:25:10.65,0:25:11.85,Default,,0,0,0,,These times are just for the
Dialogue: 0,0:25:11.85,0:25:14.44,Default,,0,0,0,,numeric phase, but the symbolic
Dialogue: 0,0:25:14.44,0:25:15.82,Default,,0,0,0,,phase only takes about two
Dialogue: 0,0:25:15.82,0:25:16.93,Default,,0,0,0,,seconds on the Watch.
Dialogue: 0,0:25:17.29,0:25:19.27,Default,,0,0,0,,So rather than 16 seconds, you
Dialogue: 0,0:25:19.27,0:25:21.05,Default,,0,0,0,,could say it takes about 18
Dialogue: 0,0:25:21.05,0:25:21.53,Default,,0,0,0,,seconds.
Dialogue: 0,0:25:21.53,0:25:22.85,Default,,0,0,0,,But if you're doing more than
Dialogue: 0,0:25:22.85,0:25:25.60,Default,,0,0,0,,one factorization on the same
Dialogue: 0,0:25:26.24,0:25:27.68,Default,,0,0,0,,pattern, you can skip that
Dialogue: 0,0:25:27.68,0:25:29.64,Default,,0,0,0,,symbolic phase on the second and
Dialogue: 0,0:25:29.64,0:25:30.53,Default,,0,0,0,,third factorization.
Dialogue: 0,0:25:31.34,0:25:32.51,Default,,0,0,0,,Even if you include that, we're
Dialogue: 0,0:25:32.51,0:25:33.92,Default,,0,0,0,,still more than 10 times faster
Dialogue: 0,0:25:33.92,0:25:35.27,Default,,0,0,0,,than the Macbook due to dense
Dialogue: 0,0:25:35.27,0:25:36.01,Default,,0,0,0,,computation.
Dialogue: 0,0:25:37.34,0:25:39.32,Default,,0,0,0,,Hopefully I've now convinced you
Dialogue: 0,0:25:39.59,0:25:40.72,Default,,0,0,0,,that it's worth using sparse
Dialogue: 0,0:25:40.72,0:25:41.35,Default,,0,0,0,,matrices.
Dialogue: 0,0:25:41.58,0:25:43.30,Default,,0,0,0,,So let's tell you how to
Dialogue: 0,0:25:43.30,0:25:44.62,Default,,0,0,0,,actually define one.
Dialogue: 0,0:25:45.44,0:25:47.48,Default,,0,0,0,,So here is a very, very small
Dialogue: 0,0:25:47.48,0:25:48.43,Default,,0,0,0,,sparse matrix.
Dialogue: 0,0:25:48.80,0:25:49.60,Default,,0,0,0,,You'll notice it's missing
Dialogue: 0,0:25:49.60,0:25:51.89,Default,,0,0,0,,entries -- those are zero.
Dialogue: 0,0:25:51.89,0:25:54.90,Default,,0,0,0,,We are going to store this using
Dialogue: 0,0:25:54.90,0:25:55.94,Default,,0,0,0,,a standard format called
Dialogue: 0,0:25:55.94,0:25:57.50,Default,,0,0,0,,compressed sparse column, which
Dialogue: 0,0:25:57.50,0:25:59.81,Default,,0,0,0,,uses these three arrays.
Dialogue: 0,0:26:01.15,0:26:02.95,Default,,0,0,0,,And we'll start off with the
Dialogue: 0,0:26:02.95,0:26:03.93,Default,,0,0,0,,rowIndices rate.
Dialogue: 0,0:26:04.19,0:26:06.68,Default,,0,0,0,,So let's put the row numbers
Dialogue: 0,0:26:07.00,0:26:08.16,Default,,0,0,0,,onto our matrix.
Dialogue: 0,0:26:09.17,0:26:10.53,Default,,0,0,0,,And we'll just copy those up
Dialogue: 0,0:26:10.66,0:26:11.82,Default,,0,0,0,,into the rowIndices array.
Dialogue: 0,0:26:12.23,0:26:14.42,Default,,0,0,0,,And let's do something similar
Dialogue: 0,0:26:14.42,0:26:15.21,Default,,0,0,0,,for the values.
Dialogue: 0,0:26:15.78,0:26:17.85,Default,,0,0,0,,You can see we got a one-to-one
Dialogue: 0,0:26:17.85,0:26:18.74,Default,,0,0,0,,correspondence here.
Dialogue: 0,0:26:19.32,0:26:21.39,Default,,0,0,0,,That first entry is in row zero
Dialogue: 0,0:26:21.39,0:26:22.39,Default,,0,0,0,,and has value two.
Dialogue: 0,0:26:23.80,0:26:26.08,Default,,0,0,0,,So let's just put on the
Dialogue: 0,0:26:26.08,0:26:28.26,Default,,0,0,0,,positions of those entries in
Dialogue: 0,0:26:28.26,0:26:29.46,Default,,0,0,0,,that rowIndices and values
Dialogue: 0,0:26:29.46,0:26:29.76,Default,,0,0,0,,array.
Dialogue: 0,0:26:30.66,0:26:31.75,Default,,0,0,0,,And the trick to compressed
Dialogue: 0,0:26:31.75,0:26:34.05,Default,,0,0,0,,sparse column is that all these
Dialogue: 0,0:26:34.05,0:26:36.11,Default,,0,0,0,,values have to occur in order of
Dialogue: 0,0:26:36.11,0:26:37.11,Default,,0,0,0,,increasing column.
Dialogue: 0,0:26:37.54,0:26:38.97,Default,,0,0,0,,All entries in column zero
Dialogue: 0,0:26:38.97,0:26:40.67,Default,,0,0,0,,actually occur before those from
Dialogue: 0,0:26:40.67,0:26:41.69,Default,,0,0,0,,column one.
Dialogue: 0,0:26:41.90,0:26:44.12,Default,,0,0,0,,And then we get to the trick to
Dialogue: 0,0:26:44.12,0:26:45.56,Default,,0,0,0,,this format, which is we're only
Dialogue: 0,0:26:45.56,0:26:47.88,Default,,0,0,0,,going to store the position of
Dialogue: 0,0:26:47.88,0:26:50.85,Default,,0,0,0,,the first entry in each column
Dialogue: 0,0:26:51.83,0:26:52.91,Default,,0,0,0,,and one additional piece of
Dialogue: 0,0:26:52.91,0:26:55.35,Default,,0,0,0,,information, the total number of
Dialogue: 0,0:26:55.35,0:26:57.45,Default,,0,0,0,,entries in the matrix.
Dialogue: 0,0:26:57.45,0:26:58.89,Default,,0,0,0,,That means that we know how long
Dialogue: 0,0:26:58.89,0:27:00.03,Default,,0,0,0,,that last column is.
Dialogue: 0,0:27:01.39,0:27:02.99,Default,,0,0,0,,If you've already using a sparse
Dialogue: 0,0:27:02.99,0:27:04.99,Default,,0,0,0,,solver, you should probably have
Dialogue: 0,0:27:04.99,0:27:06.55,Default,,0,0,0,,your data in either this format
Dialogue: 0,0:27:06.86,0:27:08.61,Default,,0,0,0,,or a coordinate format and we
Dialogue: 0,0:27:08.68,0:27:11.08,Default,,0,0,0,,provide a converter.
Dialogue: 0,0:27:11.18,0:27:12.85,Default,,0,0,0,,To use it in Accelerate, we need
Dialogue: 0,0:27:12.85,0:27:14.56,Default,,0,0,0,,to wrap it in some metadata,
Dialogue: 0,0:27:15.04,0:27:16.53,Default,,0,0,0,,just telling it how many rows,
Dialogue: 0,0:27:16.53,0:27:17.40,Default,,0,0,0,,how many columns.
Dialogue: 0,0:27:17.76,0:27:19.33,Default,,0,0,0,,And we're going to say this one
Dialogue: 0,0:27:19.33,0:27:20.64,Default,,0,0,0,,is an ordinary sparse matrix.
Dialogue: 0,0:27:20.64,0:27:22.00,Default,,0,0,0,,I've got an example of an
Dialogue: 0,0:27:22.00,0:27:24.43,Default,,0,0,0,,unordinary sparse matrix in a
Dialogue: 0,0:27:24.43,0:27:25.39,Default,,0,0,0,,couple of slides.
Dialogue: 0,0:27:26.14,0:27:27.74,Default,,0,0,0,,Now I've got my sparse matrix,
Dialogue: 0,0:27:27.87,0:27:30.23,Default,,0,0,0,,what can I do with it?
Dialogue: 0,0:27:31.43,0:27:33.39,Default,,0,0,0,,So you can do pretty much
Dialogue: 0,0:27:33.39,0:27:34.30,Default,,0,0,0,,anything you'd expect.
Dialogue: 0,0:27:34.30,0:27:36.36,Default,,0,0,0,,You can multiply a dense vector
Dialogue: 0,0:27:36.36,0:27:38.42,Default,,0,0,0,,or a dense matrix by it; you can
Dialogue: 0,0:27:38.51,0:27:39.89,Default,,0,0,0,,add two sparse matrices or
Dialogue: 0,0:27:39.89,0:27:41.38,Default,,0,0,0,,sparse vectors together; you can
Dialogue: 0,0:27:41.38,0:27:43.52,Default,,0,0,0,,permute the rows or columns; or
Dialogue: 0,0:27:43.52,0:27:45.08,Default,,0,0,0,,you can find various useful
Dialogue: 0,0:27:45.08,0:27:46.05,Default,,0,0,0,,matrix norms.
Dialogue: 0,0:27:46.77,0:27:48.00,Default,,0,0,0,,All that functionality is
Dialogue: 0,0:27:48.00,0:27:49.48,Default,,0,0,0,,provided by the Sparse BLAS,
Dialogue: 0,0:27:49.78,0:27:51.52,Default,,0,0,0,,which we introduced a few years
Dialogue: 0,0:27:51.52,0:27:51.62,Default,,0,0,0,,ago.
Dialogue: 0,0:27:52.48,0:27:53.54,Default,,0,0,0,,So what's new this time?
Dialogue: 0,0:27:54.76,0:27:56.64,Default,,0,0,0,,The ability to solve sparse
Dialogue: 0,0:27:56.64,0:28:00.85,Default,,0,0,0,,systems, that is, given a matrix
Dialogue: 0,0:28:00.85,0:28:03.60,Default,,0,0,0,,equation A times X equals B
Dialogue: 0,0:28:03.68,0:28:04.87,Default,,0,0,0,,where we know the matrix A and
Dialogue: 0,0:28:04.87,0:28:07.38,Default,,0,0,0,,to the right-hand side B, find
Dialogue: 0,0:28:07.53,0:28:09.37,Default,,0,0,0,,that vector of unknowns X.
Dialogue: 0,0:28:10.67,0:28:12.66,Default,,0,0,0,,So we got two approaches to this
Dialogue: 0,0:28:12.66,0:28:12.98,Default,,0,0,0,,for you.
Dialogue: 0,0:28:13.59,0:28:15.64,Default,,0,0,0,,The first is matrix
Dialogue: 0,0:28:15.64,0:28:16.17,Default,,0,0,0,,factorization.
Dialogue: 0,0:28:16.25,0:28:17.69,Default,,0,0,0,,This is exactly what happens in
Dialogue: 0,0:28:17.69,0:28:18.23,Default,,0,0,0,,LAPACK.
Dialogue: 0,0:28:19.09,0:28:20.40,Default,,0,0,0,,It's simple, it's accurate, it's
Dialogue: 0,0:28:20.54,0:28:21.62,Default,,0,0,0,,easy to use.
Dialogue: 0,0:28:22.45,0:28:23.92,Default,,0,0,0,,But mathematicians being
Dialogue: 0,0:28:23.92,0:28:25.40,Default,,0,0,0,,mathematicians, they came up
Dialogue: 0,0:28:25.52,0:28:26.65,Default,,0,0,0,,with a more complicated way of
Dialogue: 0,0:28:26.65,0:28:27.38,Default,,0,0,0,,doing things.
Dialogue: 0,0:28:28.70,0:28:29.95,Default,,0,0,0,,That's iterative methods.
Dialogue: 0,0:28:29.95,0:28:30.75,Default,,0,0,0,,And I'll tell you a bit more
Dialogue: 0,0:28:30.75,0:28:31.55,Default,,0,0,0,,about those later.
Dialogue: 0,0:28:32.11,0:28:35.54,Default,,0,0,0,,So now a matrix factorization.
Dialogue: 0,0:28:35.69,0:28:37.20,Default,,0,0,0,,For those of you who haven't
Dialogue: 0,0:28:37.20,0:28:39.10,Default,,0,0,0,,come across this before, we want
Dialogue: 0,0:28:39.10,0:28:41.26,Default,,0,0,0,,to take our green matrix on the
Dialogue: 0,0:28:41.26,0:28:42.93,Default,,0,0,0,,left here and factorize it into
Dialogue: 0,0:28:42.93,0:28:44.17,Default,,0,0,0,,the products of two triangular
Dialogue: 0,0:28:44.17,0:28:45.12,Default,,0,0,0,,matrices on the right.
Dialogue: 0,0:28:46.18,0:28:47.11,Default,,0,0,0,,That's because we know how to
Dialogue: 0,0:28:47.11,0:28:48.23,Default,,0,0,0,,solve a system with a triangular
Dialogue: 0,0:28:48.23,0:28:49.62,Default,,0,0,0,,matrix very well.
Dialogue: 0,0:28:50.63,0:28:52.19,Default,,0,0,0,,If we're not square, we have to
Dialogue: 0,0:28:52.19,0:28:53.38,Default,,0,0,0,,do things slightly differently;
Dialogue: 0,0:28:54.14,0:28:55.59,Default,,0,0,0,,we have to pick a rectangular
Dialogue: 0,0:28:55.59,0:28:57.66,Default,,0,0,0,,and orthogonal factor here.
Dialogue: 0,0:28:57.66,0:28:59.14,Default,,0,0,0,,And this is your QR
Dialogue: 0,0:28:59.14,0:29:00.75,Default,,0,0,0,,factorization if you've heard of
Dialogue: 0,0:29:00.75,0:29:01.47,Default,,0,0,0,,that before.
Dialogue: 0,0:29:02.53,0:29:05.28,Default,,0,0,0,,So let's see how to actually do
Dialogue: 0,0:29:05.98,0:29:06.08,Default,,0,0,0,,this.
Dialogue: 0,0:29:06.26,0:29:08.08,Default,,0,0,0,,Here is a sparse matrix
Dialogue: 0,0:29:08.21,0:29:08.69,Default,,0,0,0,,equation.
Dialogue: 0,0:29:09.87,0:29:11.35,Default,,0,0,0,,And let's define that matrix
Dialogue: 0,0:29:11.35,0:29:11.90,Default,,0,0,0,,just to begin with.
Dialogue: 0,0:29:12.57,0:29:14.59,Default,,0,0,0,,So this is going to be very
Dialogue: 0,0:29:14.59,0:29:15.90,Default,,0,0,0,,similar to what I just showed
Dialogue: 0,0:29:15.90,0:29:17.53,Default,,0,0,0,,you, except this matrix is
Dialogue: 0,0:29:17.53,0:29:17.94,Default,,0,0,0,,special.
Dialogue: 0,0:29:18.63,0:29:19.47,Default,,0,0,0,,It's symmetric.
Dialogue: 0,0:29:19.96,0:29:21.32,Default,,0,0,0,,That means that the lower
Dialogue: 0,0:29:21.32,0:29:23.43,Default,,0,0,0,,triangle is just the mirror
Dialogue: 0,0:29:23.43,0:29:24.37,Default,,0,0,0,,reflection of the other
Dialogue: 0,0:29:24.37,0:29:24.75,Default,,0,0,0,,triangle.
Dialogue: 0,0:29:24.80,0:29:27.04,Default,,0,0,0,,So we can take advantage of that
Dialogue: 0,0:29:27.04,0:29:28.38,Default,,0,0,0,,and let's only store those lower
Dialogue: 0,0:29:28.38,0:29:29.37,Default,,0,0,0,,triangle entries.
Dialogue: 0,0:29:30.49,0:29:31.97,Default,,0,0,0,,Wrap it in that metadata and
Dialogue: 0,0:29:31.97,0:29:34.61,Default,,0,0,0,,this time we're going to specify
Dialogue: 0,0:29:34.61,0:29:35.75,Default,,0,0,0,,that this is not ordinary, this
Dialogue: 0,0:29:35.75,0:29:37.09,Default,,0,0,0,,is a symmetric matrix.
Dialogue: 0,0:29:37.48,0:29:38.67,Default,,0,0,0,,And we're going to tell it that
Dialogue: 0,0:29:38.67,0:29:40.08,Default,,0,0,0,,we're passing the lower
Dialogue: 0,0:29:40.08,0:29:40.61,Default,,0,0,0,,triangle.
Dialogue: 0,0:29:40.95,0:29:41.94,Default,,0,0,0,,We could pass the upper triangle
Dialogue: 0,0:29:41.94,0:29:43.31,Default,,0,0,0,,if we wanted, we've chosen the
Dialogue: 0,0:29:43.31,0:29:44.25,Default,,0,0,0,,lower triangle here.
Dialogue: 0,0:29:45.16,0:29:46.81,Default,,0,0,0,,So we got our matrix.
Dialogue: 0,0:29:47.21,0:29:48.62,Default,,0,0,0,,Next let's look at that
Dialogue: 0,0:29:48.62,0:29:49.45,Default,,0,0,0,,right-hand side.
Dialogue: 0,0:29:50.04,0:29:51.53,Default,,0,0,0,,So this is a dense vector.
Dialogue: 0,0:29:52.61,0:29:54.46,Default,,0,0,0,,Let's just have a simple array.
Dialogue: 0,0:29:55.15,0:29:56.14,Default,,0,0,0,,Wrap it in a little bit of
Dialogue: 0,0:29:56.14,0:29:57.30,Default,,0,0,0,,metadata, telling us how long it
Dialogue: 0,0:29:57.30,0:30:00.91,Default,,0,0,0,,is, and that's how easy this is.
Dialogue: 0,0:30:01.52,0:30:03.20,Default,,0,0,0,,Which gets us to the interesting
Dialogue: 0,0:30:03.20,0:30:04.94,Default,,0,0,0,,part, how do we actually find
Dialogue: 0,0:30:05.04,0:30:08.84,Default,,0,0,0,,that vector X?
Dialogue: 0,0:30:09.06,0:30:11.02,Default,,0,0,0,,So let's define some storage to
Dialogue: 0,0:30:11.13,0:30:11.87,Default,,0,0,0,,put the answer in.
Dialogue: 0,0:30:11.87,0:30:13.74,Default,,0,0,0,,This is exactly the same as flat
Dialogue: 0,0:30:13.74,0:30:15.21,Default,,0,0,0,,dense vector B we just saw,
Dialogue: 0,0:30:15.44,0:30:16.65,Default,,0,0,0,,except we don't have to supply
Dialogue: 0,0:30:16.65,0:30:17.61,Default,,0,0,0,,any values.
Dialogue: 0,0:30:18.13,0:30:20.48,Default,,0,0,0,,Then we're going to call
Dialogue: 0,0:30:20.48,0:30:21.38,Default,,0,0,0,,SparseFactor.
Dialogue: 0,0:30:21.78,0:30:23.14,Default,,0,0,0,,And I know this matrix is
Dialogue: 0,0:30:23.14,0:30:24.88,Default,,0,0,0,,positive definite; therefore, I
Dialogue: 0,0:30:24.88,0:30:25.88,Default,,0,0,0,,can tell it use a Cholesky
Dialogue: 0,0:30:25.88,0:30:26.50,Default,,0,0,0,,factorization.
Dialogue: 0,0:30:26.65,0:30:28.52,Default,,0,0,0,,I've got a flowchart for you in
Dialogue: 0,0:30:28.52,0:30:29.61,Default,,0,0,0,,a couple of slides which tells
Dialogue: 0,0:30:29.61,0:30:30.72,Default,,0,0,0,,you how to pick a factorization
Dialogue: 0,0:30:30.72,0:30:33.05,Default,,0,0,0,,to use, but here we're using
Dialogue: 0,0:30:33.05,0:30:33.48,Default,,0,0,0,,Cholesky.
Dialogue: 0,0:30:33.89,0:30:35.65,Default,,0,0,0,,That gets us L times L transpose
Dialogue: 0,0:30:35.65,0:30:37.35,Default,,0,0,0,,factorization, which we then
Dialogue: 0,0:30:37.35,0:30:39.44,Default,,0,0,0,,feed into SparseSolve, pass that
Dialogue: 0,0:30:39.44,0:30:40.77,Default,,0,0,0,,right-hand side and the storage
Dialogue: 0,0:30:40.77,0:30:41.42,Default,,0,0,0,,we specify it.
Dialogue: 0,0:30:41.75,0:30:42.88,Default,,0,0,0,,And we get our answer.
Dialogue: 0,0:30:43.58,0:30:44.63,Default,,0,0,0,,We can put that back into the
Dialogue: 0,0:30:44.63,0:30:45.23,Default,,0,0,0,,equation.
Dialogue: 0,0:30:45.47,0:30:48.88,Default,,0,0,0,,And we can see this is correct.
Dialogue: 0,0:30:49.01,0:30:51.23,Default,,0,0,0,,So what if A is not square?
Dialogue: 0,0:30:53.36,0:30:55.14,Default,,0,0,0,,Well, this is where we have to
Dialogue: 0,0:30:55.14,0:30:56.12,Default,,0,0,0,,use that QR factorization
Dialogue: 0,0:30:56.12,0:30:57.03,Default,,0,0,0,,[inaudible] I mentioned before.
Dialogue: 0,0:30:57.03,0:30:59.35,Default,,0,0,0,,But we got two different cases
Dialogue: 0,0:30:59.35,0:30:59.55,Default,,0,0,0,,here.
Dialogue: 0,0:30:59.60,0:31:00.91,Default,,0,0,0,,It's not entirely simple.
Dialogue: 0,0:31:01.27,0:31:03.29,Default,,0,0,0,,We can be overdetermined since
Dialogue: 0,0:31:03.29,0:31:05.68,Default,,0,0,0,,we have more rows than columns.
Dialogue: 0,0:31:06.68,0:31:07.66,Default,,0,0,0,,Unless you've picked a very
Dialogue: 0,0:31:07.66,0:31:08.63,Default,,0,0,0,,special system here, that
Dialogue: 0,0:31:08.63,0:31:09.79,Default,,0,0,0,,probably means there's no
Dialogue: 0,0:31:09.79,0:31:11.55,Default,,0,0,0,,exactly correct answer.
Dialogue: 0,0:31:12.11,0:31:13.03,Default,,0,0,0,,In fact, you're in this sort of
Dialogue: 0,0:31:13.03,0:31:13.68,Default,,0,0,0,,situation.
Dialogue: 0,0:31:14.98,0:31:17.19,Default,,0,0,0,,Put a straight line through
Dialogue: 0,0:31:17.19,0:31:18.21,Default,,0,0,0,,these four points.
Dialogue: 0,0:31:20.06,0:31:22.25,Default,,0,0,0,,Clearly that's impossible, but
Dialogue: 0,0:31:22.25,0:31:22.93,Default,,0,0,0,,if you remember back to your
Dialogue: 0,0:31:22.93,0:31:24.59,Default,,0,0,0,,school days, you probably did
Dialogue: 0,0:31:24.89,0:31:26.14,Default,,0,0,0,,some least squares fitting.
Dialogue: 0,0:31:27.40,0:31:29.72,Default,,0,0,0,,We pick a line which minimizes
Dialogue: 0,0:31:29.87,0:31:31.43,Default,,0,0,0,,sum of the square of the arrows.
Dialogue: 0,0:31:31.62,0:31:32.75,Default,,0,0,0,,It's exactly what we do in this
Dialogue: 0,0:31:32.75,0:31:33.27,Default,,0,0,0,,case.
Dialogue: 0,0:31:34.08,0:31:35.30,Default,,0,0,0,,Remember we want to solve X
Dialogue: 0,0:31:35.30,0:31:35.90,Default,,0,0,0,,equals B.
Dialogue: 0,0:31:36.00,0:31:37.97,Default,,0,0,0,,So the arrow is X minus B.
Dialogue: 0,0:31:38.51,0:31:39.69,Default,,0,0,0,,Let's take the two normals out,
Dialogue: 0,0:31:39.78,0:31:41.05,Default,,0,0,0,,which is effectively the sum of
Dialogue: 0,0:31:41.05,0:31:41.94,Default,,0,0,0,,the square of the arrows in this
Dialogue: 0,0:31:42.44,0:31:45.13,Default,,0,0,0,,example, and minimize that.
Dialogue: 0,0:31:46.68,0:31:48.34,Default,,0,0,0,,If we're underdetermined, that
Dialogue: 0,0:31:48.34,0:31:49.88,Default,,0,0,0,,is, we have more columns than
Dialogue: 0,0:31:49.88,0:31:51.49,Default,,0,0,0,,rows, we're in a slightly
Dialogue: 0,0:31:51.49,0:31:52.46,Default,,0,0,0,,different situation.
Dialogue: 0,0:31:53.82,0:31:55.84,Default,,0,0,0,,It's equivalent to saying put a
Dialogue: 0,0:31:55.84,0:31:57.20,Default,,0,0,0,,line through this point.
Dialogue: 0,0:31:58.03,0:32:00.09,Default,,0,0,0,,Obviously, there's an infinite
Dialogue: 0,0:32:00.09,0:32:01.39,Default,,0,0,0,,family of lines which goes
Dialogue: 0,0:32:01.39,0:32:02.04,Default,,0,0,0,,through that point.
Dialogue: 0,0:32:02.53,0:32:04.91,Default,,0,0,0,,So how do we pick one to return
Dialogue: 0,0:32:04.91,0:32:05.50,Default,,0,0,0,,to you?
Dialogue: 0,0:32:06.48,0:32:08.54,Default,,0,0,0,,We give you the solution with
Dialogue: 0,0:32:08.54,0:32:09.06,Default,,0,0,0,,minimum norm.
Dialogue: 0,0:32:09.06,0:32:13.45,Default,,0,0,0,,Let's look at that on a code
Dialogue: 0,0:32:13.45,0:32:13.86,Default,,0,0,0,,slide.
Dialogue: 0,0:32:15.28,0:32:17.42,Default,,0,0,0,,Here it's very, very similar to
Dialogue: 0,0:32:17.42,0:32:18.62,Default,,0,0,0,,that Cholesky factorization we
Dialogue: 0,0:32:18.62,0:32:19.12,Default,,0,0,0,,saw before.
Dialogue: 0,0:32:19.66,0:32:22.36,Default,,0,0,0,,In fact, the only difference is
Dialogue: 0,0:32:22.36,0:32:23.43,Default,,0,0,0,,that we say to use a QR
Dialogue: 0,0:32:23.43,0:32:25.14,Default,,0,0,0,,factorization rather than
Dialogue: 0,0:32:25.14,0:32:25.66,Default,,0,0,0,,Cholesky.
Dialogue: 0,0:32:25.88,0:32:27.76,Default,,0,0,0,,And this will automatically pick
Dialogue: 0,0:32:27.76,0:32:28.84,Default,,0,0,0,,whether to do the least squares
Dialogue: 0,0:32:28.84,0:32:30.34,Default,,0,0,0,,or the minimum norm depending on
Dialogue: 0,0:32:30.34,0:32:32.34,Default,,0,0,0,,the dimensions of your matrix.
Dialogue: 0,0:32:32.82,0:32:34.91,Default,,0,0,0,,And I told you that we had a
Dialogue: 0,0:32:34.91,0:32:36.25,Default,,0,0,0,,flowchart for you on how to
Dialogue: 0,0:32:36.25,0:32:37.64,Default,,0,0,0,,decide which factorization to
Dialogue: 0,0:32:37.64,0:32:38.02,Default,,0,0,0,,use.
Dialogue: 0,0:32:38.60,0:32:40.31,Default,,0,0,0,,So the first question you have
Dialogue: 0,0:32:41.05,0:32:45.35,Default,,0,0,0,,to ask is: Is your matrix
Dialogue: 0,0:32:45.42,0:32:46.01,Default,,0,0,0,,symmetric?
Dialogue: 0,0:32:47.54,0:32:49.71,Default,,0,0,0,,If it isn't, you have to use the
Dialogue: 0,0:32:49.71,0:32:50.96,Default,,0,0,0,,QR factorization.
Dialogue: 0,0:32:51.56,0:32:53.08,Default,,0,0,0,,But if it is, we have another
Dialogue: 0,0:32:53.08,0:32:55.50,Default,,0,0,0,,question for you: Is your matrix
Dialogue: 0,0:32:55.50,0:32:56.27,Default,,0,0,0,,positive definite?
Dialogue: 0,0:32:56.71,0:32:57.76,Default,,0,0,0,,Now, if you don't know the
Dialogue: 0,0:32:57.76,0:33:00.42,Default,,0,0,0,,answer or if you're sure it
Dialogue: 0,0:33:00.42,0:33:02.65,Default,,0,0,0,,isn't, you can do a symmetric
Dialogue: 0,0:33:02.65,0:33:05.36,Default,,0,0,0,,indefinite factorization, LDL
Dialogue: 0,0:33:05.45,0:33:06.63,Default,,0,0,0,,transpose.
Dialogue: 0,0:33:07.25,0:33:08.64,Default,,0,0,0,,But if you know that extra bit
Dialogue: 0,0:33:08.64,0:33:09.70,Default,,0,0,0,,of information that you've got
Dialogue: 0,0:33:09.70,0:33:11.50,Default,,0,0,0,,positive definite matrix, you
Dialogue: 0,0:33:11.50,0:33:12.29,Default,,0,0,0,,can use the Cholesky
Dialogue: 0,0:33:12.29,0:33:14.21,Default,,0,0,0,,factorization L times L
Dialogue: 0,0:33:14.21,0:33:15.08,Default,,0,0,0,,transposes.
Dialogue: 0,0:33:15.93,0:33:17.41,Default,,0,0,0,,And that's all we have to tell
Dialogue: 0,0:33:17.41,0:33:18.91,Default,,0,0,0,,you on matrix factorizations.
Dialogue: 0,0:33:18.91,0:33:21.01,Default,,0,0,0,,Now, I said there was this other
Dialogue: 0,0:33:21.10,0:33:22.94,Default,,0,0,0,,technique, iterative methods.
Dialogue: 0,0:33:22.94,0:33:26.91,Default,,0,0,0,,So what is an iterative method?
Dialogue: 0,0:33:27.89,0:33:29.81,Default,,0,0,0,,Well, we pick a starting point,
Dialogue: 0,0:33:29.81,0:33:31.48,Default,,0,0,0,,our best guess at the solution
Dialogue: 0,0:33:31.48,0:33:32.57,Default,,0,0,0,,before we start.
Dialogue: 0,0:33:32.62,0:33:34.33,Default,,0,0,0,,And this can be zero if you
Dialogue: 0,0:33:34.33,0:33:35.68,Default,,0,0,0,,don't have any idea what the
Dialogue: 0,0:33:35.68,0:33:37.28,Default,,0,0,0,,actual answer is going to look
Dialogue: 0,0:33:37.28,0:33:37.54,Default,,0,0,0,,like.
Dialogue: 0,0:33:38.14,0:33:40.35,Default,,0,0,0,,And we want to get within some
Dialogue: 0,0:33:40.35,0:33:42.34,Default,,0,0,0,,small radius of our actual
Dialogue: 0,0:33:42.34,0:33:42.94,Default,,0,0,0,,solution.
Dialogue: 0,0:33:42.94,0:33:45.29,Default,,0,0,0,,And the way we do that is we
Dialogue: 0,0:33:45.29,0:33:46.65,Default,,0,0,0,,iterate through a series of
Dialogue: 0,0:33:46.65,0:33:48.68,Default,,0,0,0,,points which converge to that
Dialogue: 0,0:33:48.68,0:33:49.19,Default,,0,0,0,,solution.
Dialogue: 0,0:33:50.16,0:33:51.62,Default,,0,0,0,,Now, there's a couple of caveats
Dialogue: 0,0:33:51.62,0:33:52.38,Default,,0,0,0,,with using these.
Dialogue: 0,0:33:53.82,0:33:55.16,Default,,0,0,0,,Typically they're only going to
Dialogue: 0,0:33:55.16,0:33:56.91,Default,,0,0,0,,be faster than that matrix
Dialogue: 0,0:33:56.91,0:33:59.18,Default,,0,0,0,,factorization approach if you've
Dialogue: 0,0:33:59.18,0:34:01.29,Default,,0,0,0,,got a really, really, really big
Dialogue: 0,0:34:01.29,0:34:02.32,Default,,0,0,0,,sparse matrix.
Dialogue: 0,0:34:03.03,0:34:04.62,Default,,0,0,0,,And further, to actually get to
Dialogue: 0,0:34:04.62,0:34:06.26,Default,,0,0,0,,that performance, you need to
Dialogue: 0,0:34:06.26,0:34:07.58,Default,,0,0,0,,know a bit mathematically about
Dialogue: 0,0:34:07.58,0:34:08.15,Default,,0,0,0,,your problem.
Dialogue: 0,0:34:08.31,0:34:09.15,Default,,0,0,0,,You need something called a
Dialogue: 0,0:34:09.15,0:34:11.13,Default,,0,0,0,,preconditioner, which is a very
Dialogue: 0,0:34:11.13,0:34:12.13,Default,,0,0,0,,approximate solution.
Dialogue: 0,0:34:13.25,0:34:14.85,Default,,0,0,0,,And if you check the literature
Dialogue: 0,0:34:14.85,0:34:16.18,Default,,0,0,0,,for your field, you'll probably
Dialogue: 0,0:34:16.18,0:34:17.78,Default,,0,0,0,,find quite a number have been
Dialogue: 0,0:34:18.13,0:34:20.04,Default,,0,0,0,,derived by mathematicians.
Dialogue: 0,0:34:21.21,0:34:22.27,Default,,0,0,0,,What does this actually look
Dialogue: 0,0:34:22.27,0:34:23.05,Default,,0,0,0,,like to use?
Dialogue: 0,0:34:23.68,0:34:25.52,Default,,0,0,0,,So here's that matrix equation
Dialogue: 0,0:34:25.52,0:34:26.07,Default,,0,0,0,,we had earlier.
Dialogue: 0,0:34:26.46,0:34:27.46,Default,,0,0,0,,This time I'm going to use
Dialogue: 0,0:34:27.46,0:34:28.69,Default,,0,0,0,,iterative method to solve it.
Dialogue: 0,0:34:29.55,0:34:30.95,Default,,0,0,0,,In fact, I'm going to use
Dialogue: 0,0:34:30.95,0:34:32.11,Default,,0,0,0,,conjugate gradients.
Dialogue: 0,0:34:32.85,0:34:34.42,Default,,0,0,0,,So this is positive definite.
Dialogue: 0,0:34:35.32,0:34:38.68,Default,,0,0,0,,So we just specify to use the
Dialogue: 0,0:34:38.68,0:34:39.66,Default,,0,0,0,,conjugate gradient methods.
Dialogue: 0,0:34:39.66,0:34:40.53,Default,,0,0,0,,And you'll notice there's some
Dialogue: 0,0:34:40.53,0:34:41.65,Default,,0,0,0,,brackets ever this.
Dialogue: 0,0:34:42.74,0:34:43.67,Default,,0,0,0,,That's actually because this is
Dialogue: 0,0:34:43.67,0:34:45.13,Default,,0,0,0,,a factory function which
Dialogue: 0,0:34:45.13,0:34:46.85,Default,,0,0,0,,produces the methods and you can
Dialogue: 0,0:34:46.85,0:34:48.96,Default,,0,0,0,,specify method-specific
Dialogue: 0,0:34:48.96,0:34:50.49,Default,,0,0,0,,parameters in those brackets.
Dialogue: 0,0:34:51.22,0:34:52.15,Default,,0,0,0,,The other thing I'm going to do
Dialogue: 0,0:34:52.15,0:34:53.51,Default,,0,0,0,,is I'm going to use a diagonal
Dialogue: 0,0:34:53.51,0:34:54.07,Default,,0,0,0,,precondition.
Dialogue: 0,0:34:54.56,0:34:55.80,Default,,0,0,0,,This matrix is diagonally
Dialogue: 0,0:34:55.80,0:34:56.17,Default,,0,0,0,,dominant.
Dialogue: 0,0:34:56.17,0:34:57.49,Default,,0,0,0,,That means that the entries down
Dialogue: 0,0:34:57.49,0:34:58.72,Default,,0,0,0,,the diagonal are very large
Dialogue: 0,0:34:58.72,0:34:59.65,Default,,0,0,0,,compared to those off the
Dialogue: 0,0:34:59.65,0:35:02.01,Default,,0,0,0,,diagonal; therefore, I know this
Dialogue: 0,0:35:02.01,0:35:03.21,Default,,0,0,0,,diagonal preconditioner will
Dialogue: 0,0:35:03.21,0:35:04.15,Default,,0,0,0,,work very well.
Dialogue: 0,0:35:04.74,0:35:06.89,Default,,0,0,0,,And indeed, if we look at the
Dialogue: 0,0:35:06.89,0:35:08.54,Default,,0,0,0,,output of the algorithm, you can
Dialogue: 0,0:35:08.54,0:35:10.32,Default,,0,0,0,,see that this arrow AX minus B
Dialogue: 0,0:35:10.32,0:35:12.56,Default,,0,0,0,,is decreasing its iteration and
Dialogue: 0,0:35:12.56,0:35:13.70,Default,,0,0,0,,we get to machine precision in
Dialogue: 0,0:35:13.70,0:35:14.77,Default,,0,0,0,,four iterations.
Dialogue: 0,0:35:14.88,0:35:16.32,Default,,0,0,0,,That's because it's 4 by 4
Dialogue: 0,0:35:16.32,0:35:16.91,Default,,0,0,0,,matrix.
Dialogue: 0,0:35:17.18,0:35:18.05,Default,,0,0,0,,Mathematically, we should
Dialogue: 0,0:35:18.05,0:35:21.01,Default,,0,0,0,,converge in at most N iterations
Dialogue: 0,0:35:21.22,0:35:22.65,Default,,0,0,0,,where N is the size of matrix.
Dialogue: 0,0:35:23.53,0:35:24.83,Default,,0,0,0,,So this is behaving as expected.
Dialogue: 0,0:35:24.86,0:35:25.92,Default,,0,0,0,,But if you've got a much larger
Dialogue: 0,0:35:25.92,0:35:27.13,Default,,0,0,0,,matrix, you probably don't want
Dialogue: 0,0:35:27.13,0:35:28.68,Default,,0,0,0,,to go that many iterations,
Dialogue: 0,0:35:29.27,0:35:30.20,Default,,0,0,0,,which is why you get an
Dialogue: 0,0:35:30.20,0:35:31.19,Default,,0,0,0,,approximate solution.
Dialogue: 0,0:35:32.37,0:35:33.56,Default,,0,0,0,,And you can see you the get same
Dialogue: 0,0:35:33.56,0:35:34.29,Default,,0,0,0,,answer as before.
Dialogue: 0,0:35:35.10,0:35:37.20,Default,,0,0,0,,Now, let's say we want to solve
Dialogue: 0,0:35:37.20,0:35:38.03,Default,,0,0,0,,the least squares problem
Dialogue: 0,0:35:38.03,0:35:38.52,Default,,0,0,0,,instead.
Dialogue: 0,0:35:39.47,0:35:41.43,Default,,0,0,0,,We offer a least square solver,
Dialogue: 0,0:35:41.51,0:35:42.20,Default,,0,0,0,,which is iterative.
Dialogue: 0,0:35:42.50,0:35:43.13,Default,,0,0,0,,We don't offer an
Dialogue: 0,0:35:43.13,0:35:45.61,Default,,0,0,0,,underdetermined system solver,
Dialogue: 0,0:35:45.61,0:35:45.95,Default,,0,0,0,,however.
Dialogue: 0,0:35:46.20,0:35:47.99,Default,,0,0,0,,In that case you can just pick a
Dialogue: 0,0:35:47.99,0:35:48.96,Default,,0,0,0,,[inaudible] of zeros and call
Dialogue: 0,0:35:48.96,0:35:50.09,Default,,0,0,0,,them in solver square system
Dialogue: 0,0:35:50.09,0:35:50.56,Default,,0,0,0,,instead.
Dialogue: 0,0:35:51.48,0:35:53.92,Default,,0,0,0,,And to use this, we use the
Dialogue: 0,0:35:53.96,0:35:56.18,Default,,0,0,0,,method LSMR and a slightly
Dialogue: 0,0:35:56.18,0:35:57.81,Default,,0,0,0,,different preconditioner which
Dialogue: 0,0:35:57.81,0:35:59.49,Default,,0,0,0,,is, again, problem-specific.
Dialogue: 0,0:36:00.00,0:36:01.95,Default,,0,0,0,,And you can see that we get
Dialogue: 0,0:36:01.95,0:36:03.33,Default,,0,0,0,,there three iterations this time
Dialogue: 0,0:36:03.33,0:36:05.18,Default,,0,0,0,,because this is a 4 by 3 matrix.
Dialogue: 0,0:36:05.80,0:36:07.70,Default,,0,0,0,,But there are some very cool
Dialogue: 0,0:36:07.70,0:36:11.23,Default,,0,0,0,,things about this particular way
Dialogue: 0,0:36:11.23,0:36:11.98,Default,,0,0,0,,of doing things.
Dialogue: 0,0:36:13.45,0:36:15.65,Default,,0,0,0,,The first is that I don't
Dialogue: 0,0:36:15.65,0:36:17.00,Default,,0,0,0,,actually need my matrix
Dialogue: 0,0:36:17.00,0:36:17.61,Default,,0,0,0,,explicitly.
Dialogue: 0,0:36:18.95,0:36:20.86,Default,,0,0,0,,As long as I have a function
Dialogue: 0,0:36:21.31,0:36:22.87,Default,,0,0,0,,which performs the mathematical
Dialogue: 0,0:36:22.87,0:36:25.01,Default,,0,0,0,,operation A times X or A
Dialogue: 0,0:36:25.01,0:36:26.61,Default,,0,0,0,,transpose times X, that is, you
Dialogue: 0,0:36:26.61,0:36:28.89,Default,,0,0,0,,have an operator, I can
Dialogue: 0,0:36:28.89,0:36:30.68,Default,,0,0,0,,substitute a block of code in
Dialogue: 0,0:36:30.68,0:36:31.90,Default,,0,0,0,,place of this actual matrix
Dialogue: 0,0:36:31.90,0:36:32.38,Default,,0,0,0,,argument.
Dialogue: 0,0:36:33.48,0:36:35.50,Default,,0,0,0,,The second is you're not
Dialogue: 0,0:36:35.50,0:36:37.00,Default,,0,0,0,,restricted to using our
Dialogue: 0,0:36:37.00,0:36:37.96,Default,,0,0,0,,preconditioners.
Dialogue: 0,0:36:38.79,0:36:40.21,Default,,0,0,0,,You can write your own and just
Dialogue: 0,0:36:40.21,0:36:41.38,Default,,0,0,0,,provide a function pointer in
Dialogue: 0,0:36:41.38,0:36:41.97,Default,,0,0,0,,this argument.
Dialogue: 0,0:36:44.65,0:36:46.28,Default,,0,0,0,,Now, you're probably saying,
Dialogue: 0,0:36:46.37,0:36:47.78,Default,,0,0,0,,"How do I know which iterative
Dialogue: 0,0:36:47.78,0:36:48.37,Default,,0,0,0,,method to use?"
Dialogue: 0,0:36:48.45,0:36:49.16,Default,,0,0,0,,I've got another one of those
Dialogue: 0,0:36:49.16,0:36:49.90,Default,,0,0,0,,flowcharts for you.
Dialogue: 0,0:36:51.00,0:36:52.39,Default,,0,0,0,,This time our first question is
Dialogue: 0,0:36:52.39,0:36:54.05,Default,,0,0,0,,not whether you are symmetric
Dialogue: 0,0:36:54.05,0:36:55.37,Default,,0,0,0,,but whether you are square.
Dialogue: 0,0:36:55.85,0:36:57.22,Default,,0,0,0,,If you're not square, you're
Dialogue: 0,0:36:57.22,0:36:58.13,Default,,0,0,0,,going to have to do a least
Dialogue: 0,0:36:58.13,0:36:58.71,Default,,0,0,0,,square solve.
Dialogue: 0,0:36:59.93,0:37:01.67,Default,,0,0,0,,However, if you are, we go
Dialogue: 0,0:37:01.67,0:37:03.07,Default,,0,0,0,,straight to that question are
Dialogue: 0,0:37:03.07,0:37:04.06,Default,,0,0,0,,you positive definite?
Dialogue: 0,0:37:05.29,0:37:07.41,Default,,0,0,0,,If you're not, we have GMRES --
Dialogue: 0,0:37:07.41,0:37:08.93,Default,,0,0,0,,that will handle pretty much any
Dialogue: 0,0:37:08.93,0:37:09.87,Default,,0,0,0,,square matrix.
Dialogue: 0,0:37:10.92,0:37:12.52,Default,,0,0,0,,But if you know that extra bit
Dialogue: 0,0:37:12.52,0:37:13.86,Default,,0,0,0,,of information, you can, of
Dialogue: 0,0:37:13.86,0:37:15.32,Default,,0,0,0,,course, use the famous conjugate
Dialogue: 0,0:37:15.32,0:37:16.00,Default,,0,0,0,,gradient method.
Dialogue: 0,0:37:16.53,0:37:18.95,Default,,0,0,0,,Now, that's everything I have to
Dialogue: 0,0:37:18.95,0:37:20.48,Default,,0,0,0,,tell you today about sparse
Dialogue: 0,0:37:20.48,0:37:21.11,Default,,0,0,0,,matrices.
Dialogue: 0,0:37:22.06,0:37:23.96,Default,,0,0,0,,So we've got one thing we want
Dialogue: 0,0:37:23.96,0:37:27.40,Default,,0,0,0,,to point out, and that is that
Dialogue: 0,0:37:27.78,0:37:29.71,Default,,0,0,0,,you can now use Accelerate on
Dialogue: 0,0:37:29.97,0:37:30.43,Default,,0,0,0,,the Watch.
Dialogue: 0,0:37:30.43,0:37:31.96,Default,,0,0,0,,We have provided you that SDK.
Dialogue: 0,0:37:31.96,0:37:35.00,Default,,0,0,0,,Now, the framework has always
Dialogue: 0,0:37:35.00,0:37:35.63,Default,,0,0,0,,been there.
Dialogue: 0,0:37:35.87,0:37:36.91,Default,,0,0,0,,So it's even better.
Dialogue: 0,0:37:36.98,0:37:39.58,Default,,0,0,0,,Using today's SDK you can back
Dialogue: 0,0:37:39.69,0:37:42.17,Default,,0,0,0,,deploy to previous Watch OS's.
Dialogue: 0,0:37:42.54,0:37:44.26,Default,,0,0,0,,So that means that you get
Dialogue: 0,0:37:44.86,0:37:46.32,Default,,0,0,0,,everything that we've told you
Dialogue: 0,0:37:46.32,0:37:47.99,Default,,0,0,0,,about today on the Watch.
Dialogue: 0,0:37:48.80,0:37:51.06,Default,,0,0,0,,So let's just summarize what
Dialogue: 0,0:37:51.06,0:37:51.50,Default,,0,0,0,,that is.
Dialogue: 0,0:37:51.92,0:37:53.97,Default,,0,0,0,,By using Accelerate your code
Dialogue: 0,0:37:53.97,0:37:54.94,Default,,0,0,0,,will run faster.
Dialogue: 0,0:37:55.31,0:37:56.62,Default,,0,0,0,,It will be more energy
Dialogue: 0,0:37:56.62,0:37:57.08,Default,,0,0,0,,efficient.
Dialogue: 0,0:37:57.40,0:37:58.60,Default,,0,0,0,,It will run across all our
Dialogue: 0,0:37:58.60,0:37:59.30,Default,,0,0,0,,devices.
Dialogue: 0,0:37:59.36,0:38:00.75,Default,,0,0,0,,And at the end of the day you
Dialogue: 0,0:38:00.75,0:38:02.03,Default,,0,0,0,,have less code to maintain.
Dialogue: 0,0:38:02.49,0:38:03.68,Default,,0,0,0,,You get everything here we've
Dialogue: 0,0:38:03.68,0:38:04.63,Default,,0,0,0,,told you about today -- that
Dialogue: 0,0:38:04.63,0:38:06.25,Default,,0,0,0,,sparse solver library, the new
Dialogue: 0,0:38:06.25,0:38:09.00,Default,,0,0,0,,compression tool, changes to the
Dialogue: 0,0:38:09.66,0:38:11.36,Default,,0,0,0,,BNNS, improvements to simd, and
Dialogue: 0,0:38:11.36,0:38:12.76,Default,,0,0,0,,many more, and increased
Dialogue: 0,0:38:12.76,0:38:13.93,Default,,0,0,0,,performance across the
Dialogue: 0,0:38:13.93,0:38:14.39,Default,,0,0,0,,framework.
Dialogue: 0,0:38:16.17,0:38:17.45,Default,,0,0,0,,So if you want some more
Dialogue: 0,0:38:17.45,0:38:19.21,Default,,0,0,0,,information, including some
Dialogue: 0,0:38:19.21,0:38:20.31,Default,,0,0,0,,extensive sample code we've
Dialogue: 0,0:38:20.31,0:38:21.67,Default,,0,0,0,,developed for the sparse solver,
Dialogue: 0,0:38:21.99,0:38:22.90,Default,,0,0,0,,it's all available here.
Dialogue: 0,0:38:23.76,0:38:27.34,Default,,0,0,0,,And you may be interested in
Dialogue: 0,0:38:27.34,0:38:28.03,Default,,0,0,0,,reviewing some of these
Dialogue: 0,0:38:28.03,0:38:29.19,Default,,0,0,0,,sessions, which have already
Dialogue: 0,0:38:29.19,0:38:30.66,Default,,0,0,0,,been or going to the Metal
Dialogue: 0,0:38:30.66,0:38:32.10,Default,,0,0,0,,session this afternoon.
Dialogue: 0,0:38:33.42,0:38:34.79,Default,,0,0,0,,Thank you for your time.
Dialogue: 0,0:38:35.02,0:38:37.00,Default,,0,0,0,,[ Applause ]
