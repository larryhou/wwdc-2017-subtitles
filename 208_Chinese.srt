1
00:00:26,226 --> 00:00:27,461
大家早上好

2
00:00:27,761 --> 00:00:29,029
各位今天怎么样？

3
00:00:30,664 --> 00:00:34,134
很好 欢迎来到我们的演讲
主题是“自然语言处理”

4
00:00:34,601 --> 00:00:35,869
很高兴跟大家分享

5
00:00:35,936 --> 00:00:37,771
我们的自然语言处理API

6
00:00:38,305 --> 00:00:40,874
告诉大家
如何将这些API

7
00:00:40,941 --> 00:00:42,142
应用到你自己的应用里

8
00:00:42,910 --> 00:00:45,612
我叫维维克
与我一同演讲的

9
00:00:45,679 --> 00:00:46,847
还有我的同事道格

10
00:00:47,214 --> 00:00:49,116
如果你以为还有第三个人 没有了

11
00:00:49,349 --> 00:00:50,684
这只是我的名字太长了

12
00:00:53,687 --> 00:00:57,090
好了 开始吧
首先讲讲我们的主旨

13
00:00:58,759 --> 00:01:01,128
我们要做的
就是要让你们

14
00:01:01,261 --> 00:01:02,496
成为这场演讲的核心

15
00:01:03,931 --> 00:01:04,765
这是个应用

16
00:01:05,132 --> 00:01:07,734
这个应用可能
已发布在App Store里了

17
00:01:08,535 --> 00:01:11,071
也可能是你正在设计的应用

18
00:01:12,005 --> 00:01:14,074
又或许只是
你的一个想法

19
00:01:15,309 --> 00:01:18,078
如果你的应用
需要处理自然语言文本

20
00:01:18,612 --> 00:01:20,214
输入格式会有很多种

21
00:01:20,647 --> 00:01:23,250
比如键盘输入文字

22
00:01:23,650 --> 00:01:26,453
可识别手写文字
或者转录的讲话文本

23
00:01:27,120 --> 00:01:28,789
比如 你可能要将

24
00:01:28,856 --> 00:01:31,592
新闻或社交媒体信息收录到应用里

25
00:01:32,659 --> 00:01:36,463
或者应用在输出时
需要处理自然语言文字

26
00:01:36,563 --> 00:01:37,698
这是什么意思呢？

27
00:01:38,165 --> 00:01:40,734
就是如果用户
要在应用内生成内容

28
00:01:41,034 --> 00:01:43,136
比如在应用里写评论

29
00:01:43,504 --> 00:01:45,405
或者这是个效率类应用

30
00:01:45,472 --> 00:01:47,808
用户可以
写入新的文档

31
00:01:47,875 --> 00:01:48,976
或编辑文档

32
00:01:49,943 --> 00:01:51,578
那么处理自然语言文本时

33
00:01:51,645 --> 00:01:53,680
无论输入还是输出

34
00:01:55,582 --> 00:01:57,651
我们能利用NLP的力量

35
00:01:57,985 --> 00:02:00,888
极大提高
应用的用户体验

36
00:02:02,022 --> 00:02:03,790
当我说利用NLP的力量

37
00:02:03,857 --> 00:02:05,025
指什么呢？

38
00:02:07,060 --> 00:02:09,729
就是自然语言API

39
00:02:10,097 --> 00:02:12,466
这些自然语言处理API

40
00:02:12,533 --> 00:02:13,934
跟其他API一样

41
00:02:14,001 --> 00:02:16,136
可以驱动多个第一方应用

42
00:02:16,203 --> 00:02:18,238
可跨Apple的整个生态系统

43
00:02:18,305 --> 00:02:19,606
和所有平台

44
00:02:20,641 --> 00:02:22,576
它可以驱动
所有键盘上的东西

45
00:02:22,643 --> 00:02:25,445
比如Spotlight
Messages和Safari

46
00:02:27,014 --> 00:02:28,482
还会看到

47
00:02:28,549 --> 00:02:30,717
API对Keynote的作用

48
00:02:32,286 --> 00:02:33,654
你会了解它如何

49
00:02:34,288 --> 00:02:37,191
能明显提升用户的打字体验

50
00:02:37,991 --> 00:02:39,726
那么现在让我来设置一下

51
00:02:43,564 --> 00:02:45,899
这里我在跟朋友聊天

52
00:02:45,966 --> 00:02:48,202
规划去冰岛的行程

53
00:02:48,902 --> 00:02:51,972
我想要输入
“离开雷克雅未克的去瓦特纳冰原

54
00:02:52,039 --> 00:02:54,641
那里有冰岛和全欧洲最大的冰山”

55
00:02:55,008 --> 00:02:57,644
可惜键盘不知道我要输入什么

56
00:02:57,978 --> 00:02:59,746
它以为我要写“蝙蝠侠”

57
00:03:00,047 --> 00:03:02,049
别见怪
我也喜欢蝙蝠侠

58
00:03:02,115 --> 00:03:04,751
但我可不认为他住在雷克雅未克附近

59
00:03:05,519 --> 00:03:06,587
另一方面

60
00:03:07,354 --> 00:03:09,122
如果你在浏览文章

61
00:03:09,323 --> 00:03:12,659
寻找过有关冰岛的内容

62
00:03:12,726 --> 00:03:14,361
比如为了计划行程

63
00:03:14,795 --> 00:03:16,330
这时 就会…

64
00:03:16,396 --> 00:03:18,866
阅读大量有关冰岛的

65
00:03:19,166 --> 00:03:20,434
冰岛东岸的信息

66
00:03:20,601 --> 00:03:23,337
NPL利用机器学习的力量

67
00:03:23,403 --> 00:03:25,205
可以自动提取名字

68
00:03:25,506 --> 00:03:28,976
就像这篇文章里的
瓦特纳冰原和埃伊尔斯塔济

69
00:03:29,743 --> 00:03:32,112
然后将这些内容
记入键盘

70
00:03:32,779 --> 00:03:35,449
然后再输入这些文字

71
00:03:36,283 --> 00:03:38,952
你看到了什么？
就是刚刚读过的名字

72
00:03:40,487 --> 00:03:43,624
这都要归功于
自然语言处理API

73
00:03:44,958 --> 00:03:46,393
这几个例子

74
00:03:46,860 --> 00:03:50,163
体现了自然语言处理API
对第一方应用的作用

75
00:03:50,230 --> 00:03:52,866
但我说过
你们才是焦点

76
00:03:53,667 --> 00:03:54,635
在接下来的时间里

77
00:03:54,701 --> 00:03:57,171
我要说说
你们的想法和应用

78
00:03:59,506 --> 00:04:01,208
在座的观众们

79
00:04:01,275 --> 00:04:02,476
在我看来是不同的群体

80
00:04:02,543 --> 00:04:05,479
你们中有些人
可能每天都会用到NLP

81
00:04:05,546 --> 00:04:06,747
是NLP专家

82
00:04:07,114 --> 00:04:08,815
其他人对此可能很好奇

83
00:04:08,882 --> 00:04:10,250
因为NLP和机器学习

84
00:04:10,317 --> 00:04:11,785
是大热的流行词汇

85
00:04:11,919 --> 00:04:13,320
每个人都想了解

86
00:04:13,520 --> 00:04:15,389
并想用到自己的应用里

87
00:04:15,923 --> 00:04:18,659
所以我想有必要花一点时间

88
00:04:18,959 --> 00:04:21,094
先讲讲NLP的构成

89
00:04:21,562 --> 00:04:23,330
然后再讲API

90
00:04:24,765 --> 00:04:26,433
在我说过的高级别上

91
00:04:26,633 --> 00:04:28,035
有自然语言文本

92
00:04:28,101 --> 00:04:29,937
可以任何格式生成

93
00:04:31,839 --> 00:04:33,140
然后要做一些处理

94
00:04:33,373 --> 00:04:35,008
这就是NLP

95
00:04:35,342 --> 00:04:37,377
当然你肯定知道要做一些处理

96
00:04:37,544 --> 00:04:39,046
但处理的目的是什么？

97
00:04:40,280 --> 00:04:42,015
就是要将原文本转换为

98
00:04:42,082 --> 00:04:43,851
某种有意义的信息

99
00:04:44,785 --> 00:04:46,086
这种有意义的信息

100
00:04:46,153 --> 00:04:48,355
通常是用来提升

101
00:04:48,422 --> 00:04:49,957
用户和设备之间的互动

102
00:04:50,324 --> 00:04:51,592
或者两台设备之间的互动

103
00:04:53,160 --> 00:04:55,195
讲得更细致一些

104
00:04:56,597 --> 00:04:58,532
现在说的还是很抽象

105
00:04:58,899 --> 00:05:01,869
我就拨开如何处理的迷雾

106
00:05:02,269 --> 00:05:04,671
让大家了解NLP的基本构建块

107
00:05:04,938 --> 00:05:06,406
我们所有人

108
00:05:06,473 --> 00:05:07,574
都能够理解

109
00:05:07,908 --> 00:05:09,843
能转换为API的东西

110
00:05:10,978 --> 00:05:13,947
我们就逐个了解
NLP的基本构建块

111
00:05:14,615 --> 00:05:16,717
第一 语言识别

112
00:05:17,251 --> 00:05:18,952
语言识别的任务是什么呢？

113
00:05:19,219 --> 00:05:21,455
在对文本做任何处理之前

114
00:05:21,722 --> 00:05:24,391
你要知道文本的语言是什么

115
00:05:24,658 --> 00:05:26,426
这就是语言识别的任务

116
00:05:26,660 --> 00:05:28,428
它利用机器学习技术

117
00:05:28,595 --> 00:05:30,898
去识别一份文本的

118
00:05:31,031 --> 00:05:32,199
语言和脚本

119
00:05:33,166 --> 00:05:34,701
我这里有很多例子

120
00:05:35,102 --> 00:05:37,604
如果你输入这个字符串
第一个字符串

121
00:05:37,671 --> 00:05:38,939
它就会显示是英文

122
00:05:39,072 --> 00:05:41,808
也可以是简体中文 西班牙语

123
00:05:42,042 --> 00:05:45,012
或者印地语和德语

124
00:05:46,446 --> 00:05:48,048
那么一旦确定了文本

125
00:05:48,482 --> 00:05:50,584
就可以开始分析文本

126
00:05:50,851 --> 00:05:53,020
如果这个文本是很长一段

127
00:05:53,086 --> 00:05:54,488
比如整篇文档

128
00:05:54,855 --> 00:05:56,089
逻辑上讲

129
00:05:56,156 --> 00:05:57,624
你要将这个文本分解成

130
00:05:57,691 --> 00:05:58,759
多个有意义的片段

131
00:05:58,926 --> 00:06:01,461
有时需要分析整个文档

132
00:06:01,995 --> 00:06:04,331
通常一个文档
由多个段落组成

133
00:06:04,665 --> 00:06:07,334
所以你还可能要分析
文档中的每个段落

134
00:06:07,801 --> 00:06:09,436
你还可以分得更细

135
00:06:09,703 --> 00:06:11,471
段落由句子组成

136
00:06:11,705 --> 00:06:14,007
也可以在段落中
分析每个句子

137
00:06:14,441 --> 00:06:16,510
最后 更精细地分析

138
00:06:16,577 --> 00:06:18,846
可以是句子中的每个词

139
00:06:19,513 --> 00:06:21,181
这叫作词语切分

140
00:06:21,682 --> 00:06:23,517
那么简单举个例子

141
00:06:23,784 --> 00:06:25,352
句子级的词语切分

142
00:06:25,619 --> 00:06:26,887
以这个句子为例

143
00:06:26,954 --> 00:06:29,923
"Mr. Tim Cook presided
over the earnings report of Apple Inc."

144
00:06:30,390 --> 00:06:31,758
如果告诉机器

145
00:06:32,326 --> 00:06:34,761
一个基于规则的切分方法

146
00:06:34,828 --> 00:06:36,263
就是在每个句号那里

147
00:06:36,830 --> 00:06:38,098
切分为一个句子

148
00:06:38,866 --> 00:06:39,700
对不对？

149
00:06:39,933 --> 00:06:40,767
不对 是吧？

150
00:06:40,901 --> 00:06:42,469
你会错误地假设

151
00:06:42,536 --> 00:06:44,338
这里有三个句子

152
00:06:44,838 --> 00:06:46,106
所以 句子切分

153
00:06:46,173 --> 00:06:49,309
提供了实际的方法

154
00:06:49,676 --> 00:06:50,878
帮助断句

155
00:06:51,144 --> 00:06:52,946
这会变得更复杂

156
00:06:53,013 --> 00:06:54,414
对中文这样的语言来说

157
00:06:54,581 --> 00:06:56,316
因为它没有空白符

158
00:06:56,650 --> 00:06:58,619
只有一个字符序列

159
00:06:58,752 --> 00:07:00,854
为了让机器能

160
00:07:01,955 --> 00:07:03,423
做有意义的分析

161
00:07:03,657 --> 00:07:05,559
就要分解成词

162
00:07:05,692 --> 00:07:07,127
这就是词语切分

163
00:07:08,095 --> 00:07:12,099
假设我们对前两个基本构建块都会使用

164
00:07:12,165 --> 00:07:14,067
就是说我们知道
如何做语言识别

165
00:07:14,134 --> 00:07:15,802
如何做词语切分

166
00:07:16,270 --> 00:07:19,540
那么我们来讲讲
更为复杂的文本分析

167
00:07:20,340 --> 00:07:21,975
下一个技术

168
00:07:22,042 --> 00:07:23,243
就是词性标注

169
00:07:23,710 --> 00:07:25,679
什么是词性标注？

170
00:07:25,746 --> 00:07:26,713
很简单

171
00:07:27,614 --> 00:07:29,316
已知一个词语序列

172
00:07:29,383 --> 00:07:31,084
词性标注就是要

173
00:07:31,285 --> 00:07:33,320
给文本中的每个词

174
00:07:33,520 --> 00:07:35,022
进行词性标注

175
00:07:35,622 --> 00:07:37,257
还是看这个句子

176
00:07:37,791 --> 00:07:39,393
Tim Cook是一个人名

177
00:07:39,593 --> 00:07:40,827
presided是一个词

178
00:07:41,094 --> 00:07:44,298
over是介词
earnings是名词 等等

179
00:07:45,566 --> 00:07:47,201
那么作为应用开发者

180
00:07:47,668 --> 00:07:49,670
你也许会想这对我有什么用

181
00:07:50,337 --> 00:07:52,606
说不定你在构建一个词典应用
对不对？

182
00:07:52,906 --> 00:07:54,741
词典定义服务

183
00:07:55,209 --> 00:07:57,044
那么假设孩子阅读的时候

184
00:07:57,377 --> 00:08:00,047
想要查某个词的意思

185
00:08:00,414 --> 00:08:02,115
比如说熊这个单词

186
00:08:02,482 --> 00:08:03,450
B-E-A-R

187
00:08:03,684 --> 00:08:05,786
Bear可以是名词
也可以是动词

188
00:08:06,186 --> 00:08:07,721
那么当你点击这个词

189
00:08:08,589 --> 00:08:10,591
如果你知道
它是个实际动词

190
00:08:10,657 --> 00:08:12,726
你就可以显示
这个单词的最合适的定义

191
00:08:13,126 --> 00:08:14,027
对不对？

192
00:08:14,094 --> 00:08:16,330
我认为这就是词性标注

193
00:08:16,396 --> 00:08:18,966
能真正对用户有帮助的方法

194
00:08:20,334 --> 00:08:22,903
下一个构建块叫作词形还原

195
00:08:23,937 --> 00:08:25,172
听上去很自然语言

196
00:08:26,006 --> 00:08:27,374
我想我们可以讲得更细一点

197
00:08:28,375 --> 00:08:30,143
试着去了解什么是词形

198
00:08:30,744 --> 00:08:33,947
词有各种形态

199
00:08:34,014 --> 00:08:35,782
可以是现在时

200
00:08:35,849 --> 00:08:37,150
过去时

201
00:08:37,217 --> 00:08:38,552
或将来时

202
00:08:38,919 --> 00:08:40,587
各种形态的共同点是什么

203
00:08:41,154 --> 00:08:44,591
就是词根
词根是所有形态的共通点

204
00:08:44,992 --> 00:08:46,727
它也叫作词形

205
00:08:47,160 --> 00:08:48,629
那么请看这个例子

206
00:08:49,630 --> 00:08:52,266
你看presided这个单词
是个动词

207
00:08:53,300 --> 00:08:55,269
词根是preside

208
00:08:55,702 --> 00:08:58,672
同理 hours这个词
是个名词

209
00:08:58,872 --> 00:09:00,574
词根是hour

210
00:09:01,708 --> 00:09:04,077
这有什么重要？
因为它看上去无关紧要

211
00:09:04,144 --> 00:09:05,546
对英语这样的语言来说

212
00:09:05,746 --> 00:09:06,880
相信我 如果你们

213
00:09:06,947 --> 00:09:09,249
处理的语言形态复杂

214
00:09:09,316 --> 00:09:10,684
例如俄语或土耳其语

215
00:09:11,018 --> 00:09:12,986
词形还原就尤为重要了

216
00:09:13,487 --> 00:09:14,421
如果一种语言

217
00:09:14,488 --> 00:09:16,256
有无穷尽的词汇

218
00:09:16,557 --> 00:09:18,792
比方说 有一两百万个词

219
00:09:18,859 --> 00:09:21,195
那么分解词汇就很重要

220
00:09:21,261 --> 00:09:23,397
要将词分解为词根和词缀

221
00:09:23,697 --> 00:09:26,733
然后再运行较小的构建块

222
00:09:28,836 --> 00:09:31,538
这个拼图的最后一块

223
00:09:31,738 --> 00:09:33,273
叫作命名实体识别

224
00:09:34,241 --> 00:09:35,576
同样 听上去很复杂

225
00:09:35,642 --> 00:09:38,011
这都是NLP术语

226
00:09:38,078 --> 00:09:40,180
实体是什么？识别又是什么？等等

227
00:09:40,480 --> 00:09:43,016
还是让我们用例子来看清楚

228
00:09:43,317 --> 00:09:44,451
命名实体识别

229
00:09:44,518 --> 00:09:47,621
就是自动从文本中检测名字

230
00:09:47,988 --> 00:09:50,290
这些名字可以分为不同类别

231
00:09:50,490 --> 00:09:52,092
比如人名

232
00:09:52,159 --> 00:09:54,528
或者公司名称或地名

233
00:09:55,362 --> 00:09:58,265
在这个例子里
Tim Cook是人名

234
00:09:58,565 --> 00:10:00,267
Apple Inc是公司名称

235
00:10:00,734 --> 00:10:03,637
命名实体识别就是使用机器学习

236
00:10:03,704 --> 00:10:05,205
和语言学知识

237
00:10:05,506 --> 00:10:08,876
用这些标签自动标记文本范围

238
00:10:10,244 --> 00:10:11,845
好 等一下

239
00:10:12,179 --> 00:10:13,847
我们基本已经了解了

240
00:10:13,914 --> 00:10:17,084
NLP的基本构建块

241
00:10:17,718 --> 00:10:19,520
那么怎么完成这些任务呢？

242
00:10:20,087 --> 00:10:21,154
这就用到我们了

243
00:10:21,788 --> 00:10:24,958
我们结合了

244
00:10:25,025 --> 00:10:26,894
语言学和机器学习

245
00:10:27,027 --> 00:10:29,096
以驱动所有这些基本构建块

246
00:10:30,230 --> 00:10:34,368
所有这些构成了自然语言处理API

247
00:10:35,736 --> 00:10:37,037
是的 有些人也许会说

248
00:10:37,104 --> 00:10:39,006
“这么多信息 我都知道”

249
00:10:39,206 --> 00:10:40,941
其他人可能说
谢谢你分享这些信息

250
00:10:43,076 --> 00:10:45,345
但有人会说
够了 只要说怎么用就行了

251
00:10:46,280 --> 00:10:49,183
那么现在就来看看
怎么使用自然语言处理API

252
00:10:49,249 --> 00:10:50,250
自然语言处理API

253
00:10:50,317 --> 00:10:51,818
所有这些API

254
00:10:51,885 --> 00:10:54,388
在所有Apple平台上都配备

255
00:10:54,655 --> 00:10:56,056
通过NSLinguisticTagger

256
00:10:56,657 --> 00:10:59,293
有些人可能熟悉
NSLinguisticTagger

257
00:10:59,359 --> 00:11:01,128
也许你已经把它

258
00:11:01,228 --> 00:11:02,896
引入了你的应用

259
00:11:02,963 --> 00:11:05,265
用它做很多事情

260
00:11:05,899 --> 00:11:08,202
对不熟悉NSLinguisticTagger的人来说

261
00:11:08,368 --> 00:11:09,203
它是什么呢？

262
00:11:10,504 --> 00:11:12,072
它是foundation的一个类

263
00:11:13,607 --> 00:11:15,442
用来划分和标注文本

264
00:11:16,109 --> 00:11:18,679
我们描述的每个标签 每个任务

265
00:11:18,745 --> 00:11:21,648
从语言识别到词语切分

266
00:11:21,715 --> 00:11:23,417
到词性标注 词形还原

267
00:11:23,483 --> 00:11:27,921
命名实体识别 所有这些标签体系
都在NSLinguisticTagger

268
00:11:28,255 --> 00:11:30,190
所以如果你明确某个标签体系

269
00:11:30,390 --> 00:11:31,391
输入文本

270
00:11:31,558 --> 00:11:33,627
它就可以分析得出结果

271
00:11:34,027 --> 00:11:35,629
这就是NSLinguisticTagger的作用

272
00:11:35,963 --> 00:11:38,665
要了解更多
关于NSLinguisticTagger的信息

273
00:11:39,066 --> 00:11:41,268
我建议大家去看看开发者文档

274
00:11:41,435 --> 00:11:44,171
现在来关注一下
NSLinguisticTagger的新特性

275
00:11:45,672 --> 00:11:49,209
我们对这版NSLinguisticTagger
做了很大的改进

276
00:11:50,611 --> 00:11:52,746
第一个是标签单元

277
00:11:53,146 --> 00:11:55,249
上一版的NSLinguisticTagger

278
00:11:55,449 --> 00:11:57,484
只能分析词语

279
00:11:58,151 --> 00:12:01,488
所以如果你想要
做更复杂的分析 就像我说的

280
00:12:01,989 --> 00:12:04,758
文本可以被分解成
文档 段落

281
00:12:04,825 --> 00:12:06,493
句子和词

282
00:12:06,693 --> 00:12:10,197
只能分析词汇并不理想

283
00:12:10,264 --> 00:12:12,366
也不能满足多个任务

284
00:12:12,900 --> 00:12:16,837
新版的NSLinguisticTagger
有多个不同的单元

285
00:12:17,671 --> 00:12:19,806
可以选择单元进行分析

286
00:12:20,040 --> 00:12:23,010
分析级别可以为词语 句子

287
00:12:23,377 --> 00:12:25,579
段落 或者文档

288
00:12:26,413 --> 00:12:30,284
不是所有标签体系
都能作用于每个单元 是吧？

289
00:12:30,350 --> 00:12:34,388
如果我让你
对句子做词性标注 没有意义

290
00:12:34,521 --> 00:12:36,557
词性标注只能用于词

291
00:12:36,823 --> 00:12:40,160
所以为了找到
哪个单元对应哪种体系

292
00:12:40,327 --> 00:12:45,165
我们还需要一个 灵巧方便的API
叫作availableTagSchemes

293
00:12:45,499 --> 00:12:48,735
你要做的就是传递你感兴趣的单元

294
00:12:49,002 --> 00:12:52,439
和语言 通过结合
单元和语言

295
00:12:52,673 --> 00:12:54,608
就可以获得
所有可用标签体系了

296
00:12:55,843 --> 00:12:58,078
除了这两处改进

297
00:12:58,312 --> 00:13:02,616
我们还引入了 一个新的API
叫dominantLanguage

298
00:13:02,816 --> 00:13:04,718
如果你们觉得

299
00:13:05,552 --> 00:13:08,322
使用NSLinguisticTagger
运行语言识别

300
00:13:08,388 --> 00:13:11,692
有点困难
因为它只能分析词语

301
00:13:11,758 --> 00:13:13,360
那么如果给你一份文本

302
00:13:13,493 --> 00:13:15,929
它会对每个单词
进行语言假设

303
00:13:16,096 --> 00:13:18,065
如果要确定句子的语言

304
00:13:18,232 --> 00:13:19,266
那么就要

305
00:13:19,333 --> 00:13:21,535
在代码里做大量的表达内容

306
00:13:21,702 --> 00:13:23,070
现在这些都不用做了

307
00:13:23,136 --> 00:13:24,705
你的代码库会干净很多

308
00:13:24,938 --> 00:13:27,541
你只要调用
dominantLanguage

309
00:13:27,741 --> 00:13:30,811
传递给它一个字符串
它就能识别出文本语言

310
00:13:32,346 --> 00:13:35,048
另外 特别是对Swift 4

311
00:13:35,349 --> 00:13:36,884
我们不再需要通用字符串

312
00:13:36,950 --> 00:13:39,486
而对标签和tagSchemes
命名类型

313
00:13:41,522 --> 00:13:42,356
最后

314
00:13:42,923 --> 00:13:44,625
我们显著改进了

315
00:13:44,691 --> 00:13:47,227
NSLinguisticTagger的
底层实现

316
00:13:47,361 --> 00:13:49,229
API界面还是一样

317
00:13:49,429 --> 00:13:51,732
但是整个底层的实现

318
00:13:51,899 --> 00:13:53,634
都焕然一新

319
00:13:53,700 --> 00:13:55,536
让它具备可扩展性

320
00:13:56,270 --> 00:13:57,738
那么结果就是

321
00:13:57,804 --> 00:13:59,339
性能改善了

322
00:13:59,439 --> 00:14:00,674
准确度提高了

323
00:14:00,741 --> 00:14:03,243
也能支持更多的语言

324
00:14:05,946 --> 00:14:06,780
很好

325
00:14:06,880 --> 00:14:08,448
我们已经明白了

326
00:14:08,515 --> 00:14:11,451
NLP的基本构建块

327
00:14:12,152 --> 00:14:14,655
我们也讲了
NSLinguisticTagger

328
00:14:14,888 --> 00:14:17,191
让我们更深入地
探究一下这个API

329
00:14:17,357 --> 00:14:18,859
但我不想只演示代码

330
00:14:19,092 --> 00:14:20,327
我的演示会使用

331
00:14:20,561 --> 00:14:22,129
两个虚构的应用

332
00:14:22,229 --> 00:14:24,097
名字是Winnow和Whisk
两个W

333
00:14:24,164 --> 00:14:25,132
是个双关

334
00:14:25,599 --> 00:14:27,434
第一个应用是Winnow

335
00:14:27,901 --> 00:14:29,069
操作系统是macOS

336
00:14:29,603 --> 00:14:31,171
第二个是Whisk

337
00:14:31,572 --> 00:14:32,673
操作系统是iOS

338
00:14:32,873 --> 00:14:34,541
这两个应用都是虚拟的

339
00:14:35,742 --> 00:14:36,877
先来讲讲Winnow

340
00:14:37,611 --> 00:14:39,046
Winnow是虚拟的应用

341
00:14:39,112 --> 00:14:41,148
用描述标注图片

342
00:14:41,682 --> 00:14:45,085
我给家人 朋友和孩子
拍了许多照片

343
00:14:45,452 --> 00:14:48,355
每张图片都是一段回忆

344
00:14:48,689 --> 00:14:50,324
我想留下印记

345
00:14:50,591 --> 00:14:52,993
给图片一段描述
便于回忆

346
00:14:53,627 --> 00:14:59,900
这个印记可以是
附在图片上的录音

347
00:14:59,967 --> 00:15:02,436
或者键盘输入的文本消息

348
00:15:02,536 --> 00:15:03,904
或者是手写的便条

349
00:15:04,571 --> 00:15:05,606
Winnow要做的

350
00:15:05,672 --> 00:15:08,075
就是建一个图像库

351
00:15:08,442 --> 00:15:10,043
在拍下照片的时候

352
00:15:10,110 --> 00:15:11,745
方便添加说明

353
00:15:12,679 --> 00:15:13,847
这就是所有的说明

354
00:15:13,914 --> 00:15:16,517
描述的方法不重要

355
00:15:16,650 --> 00:15:18,252
假设这些描述

356
00:15:18,519 --> 00:15:20,888
是Winnow的一部分

357
00:15:21,622 --> 00:15:23,156
可以用不同的语言

358
00:15:23,223 --> 00:15:24,191
也可以是多语描述

359
00:15:25,225 --> 00:15:26,493
那么我们的目标

360
00:15:27,194 --> 00:15:28,996
作为应用开发者
我把它发布到

361
00:15:29,096 --> 00:15:30,964
App Store
我获得了很多关注

362
00:15:31,331 --> 00:15:32,599
我真的很高兴

363
00:15:32,666 --> 00:15:34,201
但是我还想
加入更多新功能

364
00:15:34,668 --> 00:15:36,503
首先我要给Winnow应用

365
00:15:36,570 --> 00:15:38,639
添加搜索功能

366
00:15:38,939 --> 00:15:40,507
对吧 人们喜欢搜索信息

367
00:15:40,574 --> 00:15:42,209
就是说写了这么多描述

368
00:15:42,342 --> 00:15:43,810
要怎么用呢？

369
00:15:43,977 --> 00:15:45,245
比方说 你说

370
00:15:45,379 --> 00:15:46,380
孩子的生日

371
00:15:46,446 --> 00:15:48,382
你想要看到的
是所有关于这个的照片

372
00:15:49,249 --> 00:15:50,717
所以我的第一步

373
00:15:50,784 --> 00:15:53,153
就是传递搜索实现

374
00:15:54,421 --> 00:15:57,224
我对Winnow提问
比方说hike（远足）

375
00:15:57,691 --> 00:15:59,893
很可惜 没有答案

376
00:16:01,061 --> 00:16:03,297
因为hike这个词没有出现在

377
00:16:03,630 --> 00:16:04,698
我的任何描述里

378
00:16:05,699 --> 00:16:07,534
那么我们要做的就是

379
00:16:07,601 --> 00:16:09,503
改善搜索体验
解决这个问题

380
00:16:09,703 --> 00:16:11,038
通过利用NLP的力量

381
00:16:12,906 --> 00:16:16,109
现在 我输入提问
还是hike

382
00:16:16,677 --> 00:16:21,582
我想要看到的是所有包含
相关描述的图片

383
00:16:22,049 --> 00:16:23,851
包括hike的所有词形

384
00:16:24,151 --> 00:16:26,854
所以我们看到
hiked hikes和hiking

385
00:16:27,754 --> 00:16:30,190
这些都跟hike有关

386
00:16:30,424 --> 00:16:32,292
只是用了不同的词形

387
00:16:32,359 --> 00:16:35,495
你们如果理解了演讲的前一部分

388
00:16:36,063 --> 00:16:38,131
这是什么？就是词形还原

389
00:16:38,699 --> 00:16:41,235
因为词形千变万化
词根只有一个

390
00:16:43,737 --> 00:16:47,708
现在看看
如果使用NLP API实现这些

391
00:16:48,141 --> 00:16:50,711
这里有很多图片 还有描述

392
00:16:52,045 --> 00:16:54,248
都存在Winnow里

393
00:16:57,618 --> 00:16:59,786
现在我们要在中间使用NLP

394
00:17:00,053 --> 00:17:01,154
首先要做什么？

395
00:17:01,522 --> 00:17:03,223
我们要做语言识别

396
00:17:03,790 --> 00:17:05,826
因为描述可以是不同的语言

397
00:17:06,059 --> 00:17:08,228
比方说 你的一个朋友
发给你一张带描述的照片

398
00:17:08,295 --> 00:17:10,329
来自法国
用法语写的

399
00:17:10,497 --> 00:17:12,132
好吧？现在照片在你的库里了

400
00:17:12,232 --> 00:17:13,534
现在你要查找照片

401
00:17:14,734 --> 00:17:17,538
只要完成所有描述的语言识别

402
00:17:17,671 --> 00:17:19,006
就要对文本进行词语切分

403
00:17:19,473 --> 00:17:22,576
这种切分可以
是词语 句子或者段落

404
00:17:22,709 --> 00:17:25,012
有些描述可能很长

405
00:17:25,145 --> 00:17:26,713
包含好多句子

406
00:17:29,516 --> 00:17:30,884
然后是词形标注

407
00:17:31,585 --> 00:17:33,187
最后做词形还原

408
00:17:33,520 --> 00:17:36,423
因此如果所有这些构建块
Winnow都用到了

409
00:17:36,957 --> 00:17:39,760
搜索体验也就改善了

410
00:17:41,361 --> 00:17:42,963
这是我们的UI

411
00:17:43,030 --> 00:17:45,432
一会儿我们会演示这个操作

412
00:17:45,832 --> 00:17:48,702
但先让我展示一些代码样本

413
00:17:48,769 --> 00:17:52,673
来告诉你如何轻松地把这些模块
放进你的应用

414
00:17:53,273 --> 00:17:56,243
语言识别其实就是三行代码

415
00:17:56,643 --> 00:17:58,512
首先导入Foundation

416
00:17:59,780 --> 00:18:02,616
创建一个
NSLinguisticTagger对象

417
00:18:02,816 --> 00:18:04,585
定义tagScheme

418
00:18:05,452 --> 00:18:08,322
在语言识别中 tagScheme定义为
language

419
00:18:10,023 --> 00:18:12,359
然后定义你要分析的字符串

420
00:18:12,459 --> 00:18:14,228
这个例子里 字符串是德语

421
00:18:15,696 --> 00:18:18,065
然后调出方法
dominantLanguage

422
00:18:18,131 --> 00:18:19,900
前几张幻灯片里演示过

423
00:18:20,133 --> 00:18:23,270
作用于这个对象voilà
文本语言就被识别了

424
00:18:23,604 --> 00:18:24,972
就这么简单

425
00:18:25,405 --> 00:18:27,541
简单的背后是复杂的机器学习

426
00:18:27,608 --> 00:18:28,709
各种模型

427
00:18:28,876 --> 00:18:30,377
对你而言 只要结果就好

428
00:18:30,444 --> 00:18:33,013
之后就可以继续优化应用体验

429
00:18:35,449 --> 00:18:36,683
再来看看词语切分

430
00:18:37,818 --> 00:18:40,153
同样 第一步创建

431
00:18:40,220 --> 00:18:41,922
NSLinguisticTagger对象

432
00:18:42,422 --> 00:18:44,958
但是现在tagScheme
不再是language

433
00:18:45,025 --> 00:18:47,060
而是tokenType为
tagScheme

434
00:18:49,129 --> 00:18:50,631
定义一些文本

435
00:18:52,366 --> 00:18:53,734
并设定文本范围

436
00:18:53,867 --> 00:18:56,904
NSLinguisticTagger
仍旧处理NSranges

437
00:18:56,970 --> 00:19:00,140
我们希望下一版本
能改进range范围

438
00:19:00,407 --> 00:19:02,342
但是现在就设定整个范围

439
00:19:02,476 --> 00:19:04,478
为需要分析的字符串长度

440
00:19:05,913 --> 00:19:07,814
随后定义一些选项

441
00:19:07,881 --> 00:19:11,185
这个例子里
我想忽略标点

442
00:19:11,518 --> 00:19:13,353
也忽略空白符

443
00:19:17,224 --> 00:19:19,826
最后 枚举每个单词

444
00:19:20,160 --> 00:19:22,029
在枚举每个单词的时候

445
00:19:22,429 --> 00:19:25,666
我们发现token成为了
原字符串的子字符串

446
00:19:26,166 --> 00:19:27,267
一旦有一个token

447
00:19:27,501 --> 00:19:30,504
你可以用它做任何事情

448
00:19:32,239 --> 00:19:33,740
现在看看词形还原

449
00:19:33,841 --> 00:19:35,609
这是代码样本

450
00:19:35,676 --> 00:19:37,911
你看到的图形都差不多

451
00:19:38,212 --> 00:19:41,481
同样还是创建
NSLinguisticTagger对象

452
00:19:42,115 --> 00:19:43,817
定义一个tagScheme

453
00:19:43,884 --> 00:19:45,085
这里定义为lemma

454
00:19:45,252 --> 00:19:47,087
看看之前讲的所有基本构建块

455
00:19:47,154 --> 00:19:49,089
你会发现确实如此

456
00:19:49,389 --> 00:19:52,059
这些构建块现在被译成
tagSchemes

457
00:19:53,627 --> 00:19:54,895
定义一些文本

458
00:19:56,630 --> 00:19:58,799
设置需要分析的文本范围

459
00:19:59,967 --> 00:20:01,735
同样 定义选项

460
00:20:01,802 --> 00:20:04,972
同样也是忽略标点和空白符

461
00:20:06,340 --> 00:20:08,609
最后 枚举每个单词

462
00:20:09,409 --> 00:20:11,478
枚举各个单词的时候

463
00:20:11,578 --> 00:20:12,513
我们要知道

464
00:20:12,579 --> 00:20:14,748
某个词的词根是什么

465
00:20:15,349 --> 00:20:16,383
一旦有了词根

466
00:20:16,450 --> 00:20:18,619
我们可以在其他应用中索引这个

467
00:20:18,685 --> 00:20:20,187
我们可以使用不同方法

468
00:20:21,221 --> 00:20:23,524
现在我把舞台交给道格

469
00:20:23,624 --> 00:20:27,461
为大家现场演示
Winnow的动态操作

470
00:20:27,561 --> 00:20:29,396
利用NLP的力量
有请道格

471
00:20:34,535 --> 00:20:35,636
好的 谢谢 维维克

472
00:20:35,736 --> 00:20:36,870
那么这里显示的

473
00:20:36,937 --> 00:20:39,439
是我们编写的
第一版Winnow应用

474
00:20:39,706 --> 00:20:40,908
这是个很简单的应用

475
00:20:41,175 --> 00:20:42,843
就是个图片库

476
00:20:42,976 --> 00:20:44,211
每张图片带一个描述

477
00:20:44,278 --> 00:20:47,381
有个查找域
可以搜索描述

478
00:20:47,447 --> 00:20:49,650
通过描述的词汇找到图片

479
00:20:50,184 --> 00:20:52,119
但是这一版的Winnow有个问题

480
00:20:52,786 --> 00:20:54,288
它没有任何的NLP

481
00:20:54,955 --> 00:20:57,958
所以如果输入hike这样的词
然后查找

482
00:20:58,325 --> 00:20:59,426
没有结果

483
00:20:59,893 --> 00:21:02,996
即使里面有照片
确实与hiking相关

484
00:21:03,063 --> 00:21:07,935
我输入hikes 就找到了描述里
带有hikes的图片

485
00:21:08,368 --> 00:21:09,436
输入hiking

486
00:21:09,770 --> 00:21:12,206
显示的就是描述里
带有hiking的图片

487
00:21:12,306 --> 00:21:13,140
或者hiked

488
00:21:13,807 --> 00:21:15,509
但是由于没有NLP

489
00:21:15,676 --> 00:21:18,078
应用不知道这几个词的关联

490
00:21:19,346 --> 00:21:20,714
那么我们能做什么？

491
00:21:21,315 --> 00:21:23,050
好的 先看一下代码

492
00:21:25,519 --> 00:21:29,590
这个是我们的函数
是这个应用的核心

493
00:21:30,157 --> 00:21:33,293
它要完成的任务是

494
00:21:33,360 --> 00:21:35,028
为搜索提供索引

495
00:21:35,162 --> 00:21:37,130
这个函数里有一个字符串

496
00:21:37,197 --> 00:21:39,399
可能是描述或搜索字符串

497
00:21:39,766 --> 00:21:44,671
它会转换成一系列词语
用于查找

498
00:21:45,672 --> 00:21:49,943
之所以出现这样的行为
是因为这个函数太简单了

499
00:21:50,277 --> 00:21:53,947
它只是用标准字符串方法
来写子字符串

500
00:21:54,014 --> 00:21:55,516
这里就是以词语为单位

501
00:21:55,782 --> 00:21:56,984
所以我们得到的都是词语

502
00:21:57,251 --> 00:21:58,785
这里唯一做的就是

503
00:21:58,852 --> 00:22:01,154
把它们变成小写 也就是区分大小写

504
00:22:01,488 --> 00:22:02,322
但是没有NLP

505
00:22:02,990 --> 00:22:03,991
那么就来修改吧

506
00:22:05,225 --> 00:22:06,660
我要把这个地方替换成

507
00:22:07,728 --> 00:22:11,431
你们看着很眼熟的东西
幻灯片里见过

508
00:22:12,966 --> 00:22:14,601
我要创建一个
linguisticTagger

509
00:22:14,668 --> 00:22:17,638
这里我要使用lemma language
作为Scheme

510
00:22:19,439 --> 00:22:21,074
然后在这里定义string

511
00:22:21,508 --> 00:22:23,143
这里有点别扭

512
00:22:23,544 --> 00:22:26,847
这个方法有两个选项

513
00:22:26,947 --> 00:22:29,883
第一个是language
如果已知就可以传递

514
00:22:29,983 --> 00:22:31,818
我们就会告诉tagger

515
00:22:31,885 --> 00:22:32,786
是哪种语言

516
00:22:32,853 --> 00:22:34,054
就是这样

517
00:22:34,655 --> 00:22:37,824
如果语言未知并没有传递
那么我们只要

518
00:22:38,158 --> 00:22:41,094
使用dominantLanguage
去识别语言

519
00:22:42,563 --> 00:22:44,932
然后 进行枚举

520
00:22:45,499 --> 00:22:46,800
使用lemma scheme

521
00:22:47,668 --> 00:22:51,271
这个也会
顺便完成词语切分

522
00:22:51,338 --> 00:22:52,339
得到一个token

523
00:22:52,706 --> 00:22:54,541
用它作为一个word

524
00:22:54,875 --> 00:22:56,610
如果有lemma

525
00:22:57,211 --> 00:22:59,546
就用它作为一个word

526
00:23:00,347 --> 00:23:02,416
顺便说一句 你不用记下来

527
00:23:02,482 --> 00:23:04,651
它们是样本代码 你们都能用

528
00:23:06,753 --> 00:23:08,655
那么我们来试一下

529
00:23:16,029 --> 00:23:18,665
好的 在这一版Winnow中

530
00:23:18,765 --> 00:23:21,034
如果输入hike

531
00:23:22,169 --> 00:23:24,538
显示的图片描述里
就包含了hiking

532
00:23:24,838 --> 00:23:25,739
hiked

533
00:23:26,073 --> 00:23:26,907
和hikes

534
00:23:28,075 --> 00:23:29,176
换个词试试

535
00:23:29,243 --> 00:23:30,644
试试party

536
00:23:31,612 --> 00:23:33,380
这张图带有parties

537
00:23:34,448 --> 00:23:35,849
partied 还有party

538
00:23:36,116 --> 00:23:37,518
这个还是多语言的

539
00:23:37,584 --> 00:23:41,688
我再试试法语动词
marcher 意思是走路

540
00:23:42,956 --> 00:23:46,827
你们肯定都记得
法语的动词怎么变位

541
00:23:46,894 --> 00:23:50,864
我记不住
所以我很高兴能有NLP API

542
00:23:51,298 --> 00:23:55,469
能记住这个动词的变位包括
比如 marchons

543
00:23:56,670 --> 00:23:59,072
marchais
还有marchent

544
00:23:59,540 --> 00:24:01,675
它们都被识别为一个动词的不同形态

545
00:24:01,742 --> 00:24:02,743
也能试试德语

546
00:24:03,343 --> 00:24:05,345
动词spielen意为玩耍

547
00:24:06,013 --> 00:24:08,916
找到的图片
描述里包含spielen

548
00:24:09,316 --> 00:24:11,518
还有过去时gespielt

549
00:24:11,952 --> 00:24:15,722
自然语言处理API
知道这些是同一个动词的不同形态

550
00:24:15,789 --> 00:24:17,691
它们词根相同 所以都能被识别

551
00:24:19,092 --> 00:24:20,827
这就是Winnow

552
00:24:26,300 --> 00:24:27,167
交还给你 维维克

553
00:24:28,001 --> 00:24:29,670
谢谢 道格 演示很棒

554
00:24:30,170 --> 00:24:33,774
我说过要讲两个虚拟的应用

555
00:24:33,841 --> 00:24:35,442
现在我们讲过了第一个W

556
00:24:35,509 --> 00:24:36,743
现在讲讲下一个W

557
00:24:37,110 --> 00:24:37,945
就是Whisk

558
00:24:38,979 --> 00:24:43,250
Whisk也是虚拟的应用
用来整理社交媒体信息

559
00:24:43,483 --> 00:24:47,154
我觉得这很难
因为我有好多个社交媒体账号

560
00:24:47,454 --> 00:24:49,623
我觉得很麻烦
因为要登录每个账号

561
00:24:49,690 --> 00:24:51,825
去查看消息 看看活动

562
00:24:51,892 --> 00:24:53,060
评论一大堆内容

563
00:24:53,360 --> 00:24:57,431
设想有这样一个应用
可以把所有这些集中在一起

564
00:24:57,531 --> 00:25:00,400
这就是Whisk的目的

565
00:25:00,801 --> 00:25:03,504
它收集的社交媒体信息
来自不同的地方

566
00:25:03,570 --> 00:25:05,105
不同的社交媒体账号

567
00:25:05,472 --> 00:25:08,609
然后把它们混在一起
融入一个界面

568
00:25:08,909 --> 00:25:11,645
然后只要在一个地方
就能看到所有信息

569
00:25:12,212 --> 00:25:15,282
Whisk的问题是 虽然在
App Store里 表现不错

570
00:25:15,649 --> 00:25:18,285
但可惜它到处都是

571
00:25:18,352 --> 00:25:20,854
就是说它的内容
浏览起来很麻烦

572
00:25:21,321 --> 00:25:23,590
因为有的来自Pinterest

573
00:25:23,657 --> 00:25:26,994
有的来自Facebook
还有Twitter 哪里都有

574
00:25:27,060 --> 00:25:31,999
我很想进一步 再整理Whisk
比如 提高用户参与度

575
00:25:33,033 --> 00:25:34,001
怎么做呢？

576
00:25:34,935 --> 00:25:39,439
我们想做的是在整理信息时

577
00:25:39,840 --> 00:25:42,509
Whisk会划分不同人群

578
00:25:42,576 --> 00:25:44,178
感兴趣的机构和地点

579
00:25:44,244 --> 00:25:46,647
还有订阅的内容

580
00:25:47,748 --> 00:25:48,582
如何做到？

581
00:25:48,815 --> 00:25:52,586
假设我们关注了很多文章
在Twitter上

582
00:25:52,653 --> 00:25:53,620
我关注了10篇

583
00:25:54,121 --> 00:25:56,356
我关注了Apple Music

584
00:25:56,657 --> 00:25:58,926
根据所有这些内容

585
00:25:58,992 --> 00:26:00,494
对这些信息文本

586
00:26:00,994 --> 00:26:02,563
我们可以使用NLP API

587
00:26:02,629 --> 00:26:04,164
比如命名实体识别

588
00:26:04,765 --> 00:26:07,668
自动标注
和提取实体

589
00:26:08,335 --> 00:26:09,570
在这条信息里

590
00:26:09,636 --> 00:26:12,873
蒂姆·库克和Apple
史提夫·汪达都是实体

591
00:26:13,106 --> 00:26:16,076
被自动提取出来
就通过NLP API

592
00:26:16,210 --> 00:26:17,411
完全基于机器学习

593
00:26:18,445 --> 00:26:20,214
第二个例子是法瑞尔

594
00:26:20,414 --> 00:26:21,748
法瑞尔正在访问纽约大学

595
00:26:21,815 --> 00:26:23,584
这两个实体都被提取了

596
00:26:23,851 --> 00:26:25,853
那么设想所有这些实体都可获取

597
00:26:26,053 --> 00:26:27,521
我们就能整理内容

598
00:26:27,621 --> 00:26:32,059
让Whisk的用户体验
大幅提升

599
00:26:32,125 --> 00:26:33,327
这就是它的目的

600
00:26:34,494 --> 00:26:37,664
还是这个问题 要实现这些
怎么使用NLP API？

601
00:26:38,932 --> 00:26:41,435
首先 找一些资讯

602
00:26:41,535 --> 00:26:46,006
假设某些资讯类API
给我们发送的信息

603
00:26:46,073 --> 00:26:47,407
来自不同的社交媒体账号

604
00:26:48,609 --> 00:26:50,077
只要你有资讯API

605
00:26:51,211 --> 00:26:53,247
然后都导入Whisk

606
00:26:53,647 --> 00:26:55,549
这里就要凸显NLP的作用

607
00:26:56,650 --> 00:27:00,153
你觉得第一个模块应该是什么

608
00:27:01,855 --> 00:27:03,824
没错 就是语言识别

609
00:27:03,891 --> 00:27:05,959
因为资讯可以是不同的语言

610
00:27:06,026 --> 00:27:10,397
有些资讯是用德语写的
还可能是俄语或者法语

611
00:27:10,564 --> 00:27:14,168
为了能正确分析
就要进行语言识别

612
00:27:14,968 --> 00:27:18,805
语言识别完成后
对文本进行词语切分

613
00:27:18,972 --> 00:27:21,008
可想而知 资讯可以是句子

614
00:27:21,074 --> 00:27:22,476
段落或者文档 对吧？

615
00:27:22,709 --> 00:27:24,178
所以还是要做词语切分

616
00:27:24,745 --> 00:27:28,048
最后调用命名实体提取API

617
00:27:28,248 --> 00:27:30,384
以便在文本中提取实体

618
00:27:31,218 --> 00:27:32,819
这个应用就是这样

619
00:27:33,053 --> 00:27:34,588
再看看示例代码

620
00:27:34,655 --> 00:27:37,291
也是要让你们知道这有多容易实现

621
00:27:38,926 --> 00:27:40,194
一样的形式

622
00:27:40,694 --> 00:27:43,964
先创建
NSLinguisticTagger对象

623
00:27:44,565 --> 00:27:47,201
定义tagScheme
为nameType

624
00:27:47,401 --> 00:27:48,836
我们之前用过tokenType

625
00:27:48,902 --> 00:27:51,638
用过lemma、language
现在是name type

626
00:27:52,773 --> 00:27:54,608
然后定义要分析的字符串

627
00:27:55,509 --> 00:27:57,578
定义范围为整个字符串

628
00:27:59,379 --> 00:28:00,514
然后定义选项

629
00:28:00,781 --> 00:28:02,249
如果仔细观察

630
00:28:02,516 --> 00:28:05,285
除了忽略标点和空白符

631
00:28:05,352 --> 00:28:06,286
就是之前见过的

632
00:28:06,420 --> 00:28:08,655
还多了一个选项
叫做joinedNames

633
00:28:09,156 --> 00:28:10,424
这是为什么

634
00:28:10,824 --> 00:28:12,659
名字可以有多个token

635
00:28:12,893 --> 00:28:16,730
这个例子中 蒂姆·库克
是含有两个 token的名字

636
00:28:16,864 --> 00:28:18,599
当迭代结果的时候

637
00:28:18,665 --> 00:28:21,201
我们要保证
这个被识别为一个人名

638
00:28:21,301 --> 00:28:23,637
所以我们要迭代
这个连接token

639
00:28:23,871 --> 00:28:25,606
这就是连接的意思

640
00:28:26,507 --> 00:28:29,009
然后定义我们感兴趣的标签

641
00:28:29,276 --> 00:28:32,646
这里就是personName
placeName和organizationName

642
00:28:33,447 --> 00:28:35,516
最后 你也知道枚举词语是怎么回事

643
00:28:35,716 --> 00:28:38,452
在枚举词语的时候
会获取token类型

644
00:28:38,652 --> 00:28:43,357
如果token类型是特殊标签
这让我们很感兴趣

645
00:28:44,224 --> 00:28:47,761
我们就可以获得属于这个类别的
文本范围

646
00:28:48,462 --> 00:28:50,297
现在让我们再请回道格

647
00:28:50,364 --> 00:28:53,433
用XCode
做Whisk的动态演示

648
00:28:53,901 --> 00:28:54,735
道格 交给你了

649
00:28:55,335 --> 00:28:57,471
好的 请看这里

650
00:28:57,538 --> 00:29:00,207
Whisk正在运行
至少在模拟器上

651
00:29:00,574 --> 00:29:02,209
它会显示所有资讯

652
00:29:02,342 --> 00:29:04,211
可以点进去看每一条

653
00:29:04,344 --> 00:29:05,412
但是这很无趣

654
00:29:05,646 --> 00:29:09,249
我们实际想做的 是通过命名实体
整理这些资讯

655
00:29:09,316 --> 00:29:11,084
点一下这个键

656
00:29:11,318 --> 00:29:12,819
成了！它能浏览

657
00:29:12,886 --> 00:29:16,190
并提取所有名字
可以寻找并列举这些名字

658
00:29:16,256 --> 00:29:17,558
以频率排序

659
00:29:18,225 --> 00:29:20,260
并索引全部

660
00:29:20,327 --> 00:29:22,296
那么我选蒂姆·库克

661
00:29:22,729 --> 00:29:24,665
就看到有关蒂姆·库克的全部内容

662
00:29:24,965 --> 00:29:26,366
我们找到其中一个

663
00:29:26,433 --> 00:29:27,835
这里高亮显示了

664
00:29:30,804 --> 00:29:32,005
再看另外一个

665
00:29:32,072 --> 00:29:32,940
蒂姆·库克

666
00:29:34,074 --> 00:29:37,010
再回到刚才的页面选下一个实体

667
00:29:37,644 --> 00:29:39,646
加利福尼亚 地名

668
00:29:40,214 --> 00:29:42,015
就会显示所有提到加利福尼亚的内容

669
00:29:42,683 --> 00:29:44,451
我看到了加利福尼亚

670
00:29:44,518 --> 00:29:46,453
都被找到并高亮了

671
00:29:49,456 --> 00:29:52,426
这就是Whisk

672
00:29:52,826 --> 00:29:53,694
怎么运作的呢？

673
00:29:53,861 --> 00:29:55,562
现在看看代码

674
00:29:57,097 --> 00:30:00,033
这就是Whisk的一个重要方法

675
00:30:00,167 --> 00:30:02,169
叫作extractEntities

676
00:30:02,236 --> 00:30:05,305
选一篇文本

677
00:30:05,772 --> 00:30:09,076
然后查找所有
我们想要的命名实体

678
00:30:09,643 --> 00:30:11,311
这里看着就很熟悉了

679
00:30:11,645 --> 00:30:13,013
创建一个tagger

680
00:30:13,080 --> 00:30:15,415
定义为nameType

681
00:30:16,283 --> 00:30:17,885
然后定义字符串

682
00:30:17,951 --> 00:30:19,253
再定义选项

683
00:30:19,319 --> 00:30:21,688
不要标点和空白符

684
00:30:21,755 --> 00:30:23,490
名字要连接在一起

685
00:30:23,957 --> 00:30:26,126
然后 进行枚举

686
00:30:27,160 --> 00:30:31,965
在不同的情况下
如果有名字标签

687
00:30:32,032 --> 00:30:33,934
而且是我们感兴趣的

688
00:30:34,001 --> 00:30:36,403
也就是人名 地名或者机构名称

689
00:30:36,837 --> 00:30:39,640
那么我们就
以这个token查找文本

690
00:30:40,007 --> 00:30:44,244
并在这里创建
单独的namedEntity类

691
00:30:44,545 --> 00:30:46,513
用这个token
tag和range

692
00:30:47,581 --> 00:30:49,216
所以 很简单

693
00:30:49,349 --> 00:30:50,384
这就达成了

694
00:30:50,450 --> 00:30:52,085
不需要做其他工作

695
00:30:52,152 --> 00:30:54,555
就能在文本中提取命名实体

696
00:30:56,223 --> 00:30:57,424
到你了 维维克

697
00:31:04,198 --> 00:31:06,800
很好 现在你们看到了
NLP API的动态展示

698
00:31:06,867 --> 00:31:08,468
通过这两个虚拟的应用

699
00:31:08,669 --> 00:31:12,105
我想要再深入探究下
这些API的优点

700
00:31:12,172 --> 00:31:14,107
当然你也看到它用起来很简单

701
00:31:14,174 --> 00:31:16,343
也很系统化

702
00:31:16,510 --> 00:31:17,945
形式都差不多

703
00:31:18,212 --> 00:31:20,280
但除了这些
还有其他优点吗？

704
00:31:21,048 --> 00:31:23,050
首先是相似文本处理

705
00:31:23,283 --> 00:31:24,351
这是什么意思？

706
00:31:25,118 --> 00:31:27,387
鉴于这些NLP API可以用于

707
00:31:27,454 --> 00:31:29,656
所有Apple平台
就像我说的那样

708
00:31:30,257 --> 00:31:32,059
而且作为这些API的用户

709
00:31:32,125 --> 00:31:34,528
你要保持在所有平台

710
00:31:34,595 --> 00:31:37,698
文本处理和用户体验的一致性

711
00:31:38,599 --> 00:31:41,001
另外这些API
我说过

712
00:31:41,301 --> 00:31:43,737
与第一方应用使用的API一样

713
00:31:43,904 --> 00:31:47,741
因此你的应用用户
所获得的体验

714
00:31:48,041 --> 00:31:49,409
与其他Apple应用一样

715
00:31:51,245 --> 00:31:52,779
再来讲讲第二个优点

716
00:31:53,046 --> 00:31:53,981
隐私

717
00:31:55,048 --> 00:31:57,017
所有NLP的机器学习

718
00:31:57,084 --> 00:32:00,053
如我们所讲
完全在设备中进行

719
00:32:01,288 --> 00:32:02,356
作为它的用户

720
00:32:02,422 --> 00:32:06,360
所有都在设备里 而且用户数据
也不会超出设备范围

721
00:32:06,527 --> 00:32:07,594
对你来说是好事

722
00:32:08,262 --> 00:32:09,897
对吗？
不需要云端API

723
00:32:09,963 --> 00:32:10,831
不用做任何事

724
00:32:10,898 --> 00:32:12,666
所有都在设备上完成

725
00:32:14,735 --> 00:32:16,003
除了隐私

726
00:32:16,803 --> 00:32:20,007
NSLinguisticTagger的
底层实现

727
00:32:20,073 --> 00:32:22,142
在这一版本中完全翻新

728
00:32:22,543 --> 00:32:26,113
于是极大提升了它的性能

729
00:32:26,613 --> 00:32:30,317
所以设备的代码库高度优化
可用于所有平台

730
00:32:30,450 --> 00:32:31,685
而且是多线程

731
00:32:32,119 --> 00:32:36,790
现有的 NSLinguisticTagger用户
会感觉速度有明显提升

732
00:32:37,157 --> 00:32:41,962
例如 中文的词语切分
在iOS上提速30%

733
00:32:42,029 --> 00:32:43,630
这是iPhone 7的评估结果

734
00:32:44,998 --> 00:32:48,335
命名实体识别增速80%
使用新的代码库

735
00:32:49,136 --> 00:32:52,072
对于没有使用过
NSLinguisticTagger

736
00:32:52,139 --> 00:32:55,042
的用户 这些改进
没有什么意义

737
00:32:55,108 --> 00:32:57,344
这些30%和80%都是相对的

738
00:32:58,946 --> 00:33:00,614
那么来看一下原始数字

739
00:33:00,681 --> 00:33:01,815
（TOKENS/秒 1 线程）

740
00:33:01,882 --> 00:33:06,687
我会用一条黄线代表一个线程

741
00:33:06,753 --> 00:33:10,390
那么词性标注
在iOS设备上是单线程

742
00:33:10,724 --> 00:33:13,627
每秒可处理五万个token

743
00:33:14,328 --> 00:33:17,231
都在设备上完成
在设备上进行机器学习

744
00:33:18,165 --> 00:33:21,268
命名实体识别 在另一侧

745
00:33:21,568 --> 00:33:24,004
每秒可处理四万个token

746
00:33:24,371 --> 00:33:25,939
那么想一下 一分钟

747
00:33:26,073 --> 00:33:29,309
你读过或分析过的
一篇文章平均多长？

748
00:33:29,543 --> 00:33:31,278
大约四五百字

749
00:33:31,478 --> 00:33:35,015
也就是说处理上百篇文章
提取命名实体

750
00:33:35,215 --> 00:33:37,050
在iOS设备上一秒就能完成

751
00:33:37,417 --> 00:33:38,318
这太棒了

752
00:33:38,385 --> 00:33:39,786
我们十分激动

753
00:33:46,460 --> 00:33:48,662
除了隐私和性能

754
00:33:48,729 --> 00:33:53,400
NSLinguisticTagger
还支持 很多种语言

755
00:33:53,867 --> 00:33:56,470
如果你需要对应用本地化
这就太有用了

756
00:33:57,271 --> 00:34:01,875
语言识别
支持29种脚本52种语言

757
00:34:03,744 --> 00:34:08,148
词语切分支持
所有iOS和macOS的系统语言

758
00:34:09,416 --> 00:34:13,353
词形还原和词性标注
还有命名实体识别

759
00:34:13,520 --> 00:34:15,222
支持8种语言

760
00:34:16,690 --> 00:34:20,226
除英语之外的其他语言
都在此版本中添加

761
00:34:20,327 --> 00:34:23,263
而且英语模型
也都得到了很大改进

762
00:34:23,530 --> 00:34:25,933
再来讲一讲准确度

763
00:34:26,065 --> 00:34:29,870
如果真正了解
我们的机器学习

764
00:34:29,969 --> 00:34:31,905
你看到了API的优点

765
00:34:31,972 --> 00:34:33,139
知道它运行顺畅

766
00:34:33,206 --> 00:34:34,208
使用简单

767
00:34:34,341 --> 00:34:37,277
有个大问题
这些技术准确吗？

768
00:34:37,411 --> 00:34:38,579
所以我们就看看准确度

769
00:34:38,911 --> 00:34:39,913
完美转接

770
00:34:41,681 --> 00:34:43,684
我向你们展示的这些模型

771
00:34:43,750 --> 00:34:46,853
为了简洁明了
只基于英语和西班牙语

772
00:34:47,020 --> 00:34:48,822
结果非常好

773
00:34:48,956 --> 00:34:52,391
我们的词性标注模型
无论英语还是西班牙语

774
00:34:52,458 --> 00:34:54,428
准确率都超过了90%

775
00:34:54,561 --> 00:34:56,697
这一套标记集合有15个标签

776
00:34:57,030 --> 00:34:59,933
支持NSLinguisticTagger的
具体标签

777
00:35:00,000 --> 00:35:02,736
可以在开发者文档中找到

778
00:35:03,637 --> 00:35:07,007
命名实体识别
准确率在85分左右

779
00:35:07,074 --> 00:35:08,308
这是最高水平

780
00:35:08,375 --> 00:35:12,613
同样 都是在设备上完成
使用复杂的机器学习技术

781
00:35:14,882 --> 00:35:17,484
那么在总结本场演讲之前

782
00:35:17,551 --> 00:35:21,355
我想再用几分钟讲一下
一些调式的注意事项

783
00:35:21,421 --> 00:35:23,891
现在你已经熟悉API的使用

784
00:35:23,957 --> 00:35:26,593
你肯定也会碰到一些问题

785
00:35:26,760 --> 00:35:30,998
所以我要提醒你们
就是在运行API时

786
00:35:31,064 --> 00:35:33,166
词形标注结果

787
00:35:33,233 --> 00:35:36,436
或者命名实体识别结果
可能是另外的词语

788
00:35:36,503 --> 00:35:39,540
也就是说它没授予人名或地名的标签

789
00:35:40,207 --> 00:35:42,342
这个问题的原因

790
00:35:42,409 --> 00:35:44,278
可能就是设备上没有下载模型

791
00:35:44,878 --> 00:35:45,879
什么意思呢？

792
00:35:46,513 --> 00:35:49,816
因为所有的词形标注
和命名实体识别模型

793
00:35:50,117 --> 00:35:54,087
都是无线下载
可跨所有iOS平台

794
00:35:54,388 --> 00:35:55,222
为什么呢？

795
00:35:55,556 --> 00:35:58,158
你一定多次听到过

796
00:35:58,325 --> 00:36:01,495
机器学习就是用更多数据完善模型

797
00:36:01,862 --> 00:36:03,497
所以我们要做的

798
00:36:03,797 --> 00:36:06,066
就是改进和训练模型
不断翻新

799
00:36:06,133 --> 00:36:08,702
这样模型的准确度
才会一直处于高水准

800
00:36:09,236 --> 00:36:11,205
我们这么做
是希望将模型

801
00:36:11,271 --> 00:36:14,808
通过无线更新传递给你
用最快的速度

802
00:36:15,375 --> 00:36:18,045
因此不是所有模型都安装完整

803
00:36:18,111 --> 00:36:19,780
要经过无线下载

804
00:36:20,747 --> 00:36:23,050
对于iOS系统
如何获取模型？

805
00:36:23,317 --> 00:36:25,219
在你安装某个键盘以后

806
00:36:25,285 --> 00:36:26,920
以法语键盘为例吧

807
00:36:27,154 --> 00:36:29,790
所有的法语资源
就会下载到设备上

808
00:36:29,990 --> 00:36:31,558
其他语言也一样

809
00:36:32,759 --> 00:36:34,761
第二个注意事项就是

810
00:36:35,395 --> 00:36:37,631
如果你知道
处理的是哪种语言

811
00:36:37,831 --> 00:36:39,466
你可以明确定义语言

812
00:36:39,733 --> 00:36:40,767
什么意思呢？

813
00:36:41,201 --> 00:36:43,136
以hello这个字符串为例

814
00:36:43,637 --> 00:36:47,875
如果你传递hello这个字符串
给语言识别API

815
00:36:48,141 --> 00:36:49,610
你预计会是哪种语言？

816
00:36:50,544 --> 00:36:52,713
Hello这个词
在很多语言里都有

817
00:36:52,779 --> 00:36:56,250
对吧？你其实可以更聪明地
利用这些API

818
00:36:56,316 --> 00:36:58,919
这就像是NLP和机器学习的艺术

819
00:36:59,119 --> 00:37:02,256
这些API会自动
提供很多信息

820
00:37:02,322 --> 00:37:06,026
但是你也要十分智慧地
将它应用到自己的应用里

821
00:37:06,426 --> 00:37:09,263
如果你能明确
某种情况下的语言类别

822
00:37:09,463 --> 00:37:11,365
就应该定义语言

823
00:37:11,598 --> 00:37:14,535
如果字符串很长
那就用API获取语言

824
00:37:14,701 --> 00:37:16,003
这是一种权衡

825
00:37:16,069 --> 00:37:17,037
根据应用的情况

826
00:37:17,104 --> 00:37:19,406
你可以选择想用的方式

827
00:37:20,674 --> 00:37:22,075
总结来说

828
00:37:22,776 --> 00:37:25,579
我们讲过了
自然语言处理API

829
00:37:26,380 --> 00:37:29,650
这些API可以通过
NSLinguisticTagger使用

830
00:37:30,684 --> 00:37:33,520
我们也讲了
此版本支持的新单元

831
00:37:33,720 --> 00:37:36,557
除了词语级别的枚举

832
00:37:36,623 --> 00:37:40,360
还可以枚举句子
段落和文档

833
00:37:40,460 --> 00:37:41,495
这些单元

834
00:37:41,562 --> 00:37:44,231
会越来越重要

835
00:37:44,364 --> 00:37:47,100
因为我们会不断
给API增加功能

836
00:37:48,302 --> 00:37:51,238
鉴于代码库本身的
巨大改进

837
00:37:51,572 --> 00:37:53,941
标注器的速度显著提升

838
00:37:54,408 --> 00:37:55,943
同时也提高了准确率

839
00:37:56,143 --> 00:37:58,345
还能支持更多语言

840
00:38:01,648 --> 00:38:05,052
要了解更多有关本场演讲的信息
可以观看演讲208

841
00:38:05,152 --> 00:38:06,386
可以看录音稿

842
00:38:06,453 --> 00:38:08,722
还有道格讲述的示例项目

843
00:38:08,789 --> 00:38:10,290
就是Winnow和Whisk项目

844
00:38:10,824 --> 00:38:14,294
在WWDC还有很多内容等着你们

845
00:38:14,761 --> 00:38:16,496
首先 这是一些相关的演讲

846
00:38:16,630 --> 00:38:17,497
如果你们参加了

847
00:38:17,564 --> 00:38:21,001
昨天的“Core ML”介绍讲座

848
00:38:21,335 --> 00:38:23,837
还有一个后续演讲
深度解析Core ML

849
00:38:24,137 --> 00:38:25,072
就在明天

850
00:38:25,372 --> 00:38:28,408
还有一些核心演讲
比如加速和稀疏求解器

851
00:38:28,475 --> 00:38:30,644
会讲矩阵乘法和入门级别的内容

852
00:38:31,011 --> 00:38:32,646
这场演讲在周四

853
00:38:34,414 --> 00:38:36,984
NLP对我们来说十分有趣

854
00:38:37,251 --> 00:38:39,786
在这个领域 我们投入了
大量时间和精力

855
00:38:39,853 --> 00:38:41,154
我们真的很想了解

856
00:38:41,522 --> 00:38:44,424
哪些API
会对你们有帮助？

857
00:38:44,625 --> 00:38:45,759
会为用户带来不同

858
00:38:46,159 --> 00:38:51,031
那就去解决一些问题
当然为了解决而解决 不是我们的目标

859
00:38:51,098 --> 00:38:52,799
但我们很想听到你们的声音

860
00:38:52,866 --> 00:38:54,034
获得你们的反馈

861
00:38:54,101 --> 00:38:57,104
想知道你们在文本处理上
遇到了什么问题？

862
00:38:57,271 --> 00:38:59,940
哪些API
能让你的生活更好？

863
00:39:00,374 --> 00:39:03,911
如果能给我们开发的特性
找到更好的折衷办法

864
00:39:04,278 --> 00:39:07,247
或者能帮助到你的API

865
00:39:07,581 --> 00:39:08,682
我觉得是件好事

866
00:39:08,749 --> 00:39:10,651
所以请大家尽情交流

867
00:39:10,717 --> 00:39:12,452
来告诉我们 就当实验的一部分

868
00:39:13,120 --> 00:39:16,890
讲讲你的问题
谈谈你的兴趣

869
00:39:16,957 --> 00:39:19,593
告诉我们你想要知道什么
想让我们做什么

870
00:39:19,893 --> 00:39:21,495
我们洗耳恭听

871
00:39:22,429 --> 00:39:23,263
谢谢

