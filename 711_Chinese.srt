1
00:00:26,059 --> 00:00:27,995
谢谢 欢迎参加加速演讲

2
00:00:28,061 --> 00:00:31,865
我叫Eric Bainville
我来自CoreOS向量与数值工作组

3
00:00:33,033 --> 00:00:35,969
我们工作组的任务是
维护Accelerate框架

4
00:00:36,470 --> 00:00:40,174
这是我们今天要讲的内容
首先我要介绍Accelerate

5
00:00:40,274 --> 00:00:43,010
它包含什么 如何使用它
然后结合一些示例

6
00:00:43,076 --> 00:00:45,012
我会给大家演示你为什么要用它

7
00:00:45,479 --> 00:00:49,650
我们主要关注
今年我们所做的一些新功能和新改进

8
00:00:49,716 --> 00:00:53,120
首先讲Compression
无损数据压缩库

9
00:00:53,187 --> 00:00:56,390
然后是BNNS 基本神经网络子程序

10
00:00:57,024 --> 00:00:59,960
之后我的同事Steve
将上台跟大家谈谈

11
00:01:00,027 --> 00:01:01,395
simd中的新功能

12
00:01:01,461 --> 00:01:05,199
最后我们非常亲爱的
Jonathan Hogg将上台

13
00:01:05,265 --> 00:01:07,367
跟大家介绍稀疏矩阵

14
00:01:07,501 --> 00:01:09,770
稀疏矩阵求解器

15
00:01:09,837 --> 00:01:12,673
被首次商业化了

16
00:01:12,739 --> 00:01:14,208
但让我们先从
Accelerate开始讲吧

17
00:01:15,509 --> 00:01:20,447
Accelerate是一个
低等级的系统框架

18
00:01:20,514 --> 00:01:21,682
用于CPU上的高性能基元

19
00:01:22,916 --> 00:01:25,352
实际上它无所不在

20
00:01:25,419 --> 00:01:27,855
当你占用了太多CPU时

21
00:01:28,455 --> 00:01:31,158
在Accelerate内部有许多库

22
00:01:31,225 --> 00:01:35,462
比如vImage用于图像处理
堪称图像处理方面的瑞士军刀

23
00:01:35,762 --> 00:01:40,567
我们还包括vDSP
用于DFT和FFT的信号处理

24
00:01:40,634 --> 00:01:42,636
还有vForce用于向量函数

25
00:01:43,136 --> 00:01:46,240
然后我们有许多线性代数库

26
00:01:46,306 --> 00:01:48,542
用于密集和稀疏矩阵

27
00:01:48,609 --> 00:01:51,745
那么这是用于密集向量
和矩阵的BLAS和LAPACK

28
00:01:51,812 --> 00:01:55,816
还有Sparse BLAS
和Sparse Solvers用于稀疏向量和矩阵

29
00:01:56,416 --> 00:01:59,887
去年我们还引入了
BNNS 基本神经网络子程序

30
00:01:59,953 --> 00:02:02,155
这是对我们更新的网络的支持

31
00:02:02,256 --> 00:02:07,561
这用在 比如说 Core ML
还有Vision和NLP框架中

32
00:02:08,095 --> 00:02:11,765
稍微偏离了Accelerate
但仍然由我们维护 我们有simd

33
00:02:11,832 --> 00:02:14,001
就是一个标头和函数的集合

34
00:02:14,067 --> 00:02:17,171
允许你直接与CPU向量单元通讯

35
00:02:17,905 --> 00:02:21,441
最后是Compression
一个无损数据压缩库

36
00:02:22,276 --> 00:02:23,977
如何使用Accelerate？

37
00:02:24,578 --> 00:02:27,881
你导入Accelerate
或引用Accelerate标头

38
00:02:27,948 --> 00:02:30,984
然后在你自己的集合中
链接Accelerate框架

39
00:02:31,051 --> 00:02:34,988
现在我要给你们展示几个例子
关于你为何用Accelerate？

40
00:02:35,389 --> 00:02:36,823
让我们从那个开始谈吧

41
00:02:37,057 --> 00:02:39,459
那么让我们假设
你有这个向量X 值为浮点型

42
00:02:39,526 --> 00:02:41,428
你想调整这些值

43
00:02:42,095 --> 00:02:44,831
那么你有这个调整
所以你给每一个值加倍

44
00:02:44,898 --> 00:02:48,202
并将其存储在Y向量中
那么这是个很简单的循环

45
00:02:48,602 --> 00:02:49,803
非常完美

46
00:02:50,070 --> 00:02:53,607
但其实在Accelerate中
有一个函数可以实现同样的功能

47
00:02:53,674 --> 00:02:54,775
它叫作vsmul

48
00:02:55,676 --> 00:02:58,645
那么只需要用一行代码来替换你的代码

49
00:02:58,879 --> 00:03:03,851
好处是我们为你进行了优化
可以应用于所支持的全部硬件上

50
00:03:04,117 --> 00:03:05,452
当然 我们也会替你们维护

51
00:03:05,519 --> 00:03:07,688
所以你就不再需要维护你的循环了

52
00:03:07,921 --> 00:03:10,858
当然了 它更快
正如Accelerate名字一样

53
00:03:11,258 --> 00:03:14,261
那么这对于循环来说是一个基准速度
但也会消耗能量

54
00:03:14,328 --> 00:03:18,165
这是你通过Accelerate
所得到的速度快了六倍

55
00:03:21,768 --> 00:03:25,606
并且能量消耗少了六倍 这非常重要

56
00:03:25,672 --> 00:03:26,874
让我给你看另一个例子

57
00:03:27,140 --> 00:03:30,844
那么这次我们仍然有这个数组X
我们想削减

58
00:03:30,911 --> 00:03:33,881
下限和上限之间的值并将其保存到Y中

59
00:03:34,081 --> 00:03:37,217
再一次 你可以通过写这段代码来实现
这很完美 不错

60
00:03:37,284 --> 00:03:41,922
但我们在vDSP中有一个函数
叫作vclip 可以实现同样的功能

61
00:03:41,989 --> 00:03:44,958
我们替你维护它
我们替你进行了优化

62
00:03:45,526 --> 00:03:48,262
当然了 它速度更快
它是循环的一个参考

63
00:03:48,595 --> 00:03:50,531
这是你通过Accelerate
所得到的

64
00:03:51,231 --> 00:03:54,601
速度快了八倍 并且能量消耗少了八倍

65
00:03:55,202 --> 00:03:56,270
另一个例子

66
00:03:57,571 --> 00:04:00,207
矩阵 那么假如我们有两个矩阵A和B

67
00:04:00,274 --> 00:04:02,242
你想要计算A和B的结果

68
00:04:02,309 --> 00:04:04,678
并把结果添加到C矩阵中

69
00:04:06,180 --> 00:04:08,148
听起来没那么简单 但实际上非常简单

70
00:04:08,215 --> 00:04:10,551
你只需要三行代码就可以实现
你可以看到吧

71
00:04:11,351 --> 00:04:14,288
当然在Accelerate中
我们有有一个函数可以实现

72
00:04:14,354 --> 00:04:16,757
叫作sgemm 用于Cblas

73
00:04:18,692 --> 00:04:21,461
真的 真的 你永远不希望通过写代码

74
00:04:21,528 --> 00:04:22,930
来计算矩阵向量结果

75
00:04:22,996 --> 00:04:25,465
或矩阵度量或任何与矩阵相关的东西

76
00:04:25,532 --> 00:04:27,401
你再也不想写那样的代码了

77
00:04:28,202 --> 00:04:31,205
你想调用Accelerate中的
BLAS、LAPACK或任何东西

78
00:04:31,538 --> 00:04:34,908
为什么？嗯 首先是因为
我们替你进行维护 它将会被优化

79
00:04:34,975 --> 00:04:38,545
和多线程化
可用于我们所支持的全部架构中

80
00:04:39,713 --> 00:04:42,416
这一次 这是对循环的一个参考

81
00:04:42,482 --> 00:04:46,019
这是你通过Accelerate
所得到的 我不确定你是否可以看到

82
00:04:47,588 --> 00:04:49,623
是的 速度快了100倍

83
00:04:51,925 --> 00:04:54,528
并且能量比原来节约了26倍

84
00:04:54,928 --> 00:04:56,396
这是你的电池

85
00:04:56,897 --> 00:04:59,333
好的 再讲一个例子
这次是在vImage中

86
00:04:59,399 --> 00:05:01,802
那么假如你有一个32位/像素的图像

87
00:05:01,869 --> 00:05:05,606
每个像素有四个组成成分
分别是阿尔法、红、绿和蓝

88
00:05:05,906 --> 00:05:08,609
并且你想给图像中的每个像素

89
00:05:08,675 --> 00:05:10,110
都应用一个4x4的转换矩阵

90
00:05:10,777 --> 00:05:13,380
但你可通过写代码来实现
你能在此写代码 代码很长

91
00:05:13,447 --> 00:05:15,182
但实际上 你不需要写代码

92
00:05:15,249 --> 00:05:17,651
我们在vImage中有一个函数
MatrixMultiply

93
00:05:17,718 --> 00:05:19,887
它是vImage中最常用的函数之一

94
00:05:19,953 --> 00:05:23,957
完全可以实现那个功能
并且我们尽可能地优化了它的速度

95
00:05:24,024 --> 00:05:26,026
在我们所支持的全部架构中

96
00:05:26,727 --> 00:05:30,264
最后一个例子 这是个卷积层

97
00:05:30,330 --> 00:05:33,834
这是神经网络中的主力

98
00:05:33,901 --> 00:05:35,602
卷积神经网络

99
00:05:35,869 --> 00:05:38,572
那么这个层获取输入堆栈

100
00:05:38,639 --> 00:05:42,809
就是左边显示的这个东西 是一堆图像

101
00:05:42,943 --> 00:05:46,113
它将生产输入图像堆栈
就是蓝色的这个东西

102
00:05:46,180 --> 00:05:50,117
输出中的每个像素都是协定卷积的结果

103
00:05:50,184 --> 00:05:52,019
在整个输入堆栈上

104
00:05:52,085 --> 00:05:55,656
我们给这三个中的每一个都执行一遍
就是我提到过的为了输出图像

105
00:05:55,989 --> 00:05:58,458
那么最后 那是一个六维循环

106
00:05:59,026 --> 00:06:00,994
你真的不想写这个循环了

107
00:06:01,228 --> 00:06:04,831
就算维数小 你也要把它们乘在一起

108
00:06:04,898 --> 00:06:09,203
那么这是数百万
或甚至是数十亿的浮点运算

109
00:06:10,070 --> 00:06:13,106
当然 我们为你准备了一个函数
这次是在BNNS中实现那个功能

110
00:06:13,273 --> 00:06:15,108
当你运行Core ML模型时

111
00:06:15,175 --> 00:06:17,878
我们将在这个函数中
花上大约80%的时间

112
00:06:19,012 --> 00:06:20,981
好的 那么这是几个简单的例子

113
00:06:21,048 --> 00:06:22,816
我几乎可以一直举例

114
00:06:22,883 --> 00:06:26,520
因为我们在Accelerate中
有2800多个API

115
00:06:27,054 --> 00:06:29,389
那么通常这些API中
总会有一个适合你的函数

116
00:06:29,556 --> 00:06:31,825
每次你使用
Accelerate函数时

117
00:06:32,326 --> 00:06:35,195
好处似乎你不再需要写那么多代码了

118
00:06:35,729 --> 00:06:37,030
并且我们也会替你维护

119
00:06:37,097 --> 00:06:39,933
当然了 它的速度更快 更节能

120
00:06:40,000 --> 00:06:41,468
并且它是最优化的

121
00:06:42,369 --> 00:06:45,405
在我们所支持的全部架构中
尽可能地进行了优化

122
00:06:45,472 --> 00:06:48,542
包括一些新架构
那么当我们发布新硬件时

123
00:06:48,609 --> 00:06:51,712
你的代码将从第一天开始
就尽可能快地飞速运行

124
00:06:52,646 --> 00:06:56,717
好的 这是Accelerate
让我们看看Compression

125
00:06:58,952 --> 00:07:01,688
Compression是一个
无损数据压缩库

126
00:07:01,755 --> 00:07:06,059
它是一个非常简单的API
其中包括一些很棒的压缩器

127
00:07:06,393 --> 00:07:09,062
那么这个小图表显示出了
这些选择压缩器

128
00:07:09,363 --> 00:07:12,633
在x轴上你可以看到相对压缩率

129
00:07:12,699 --> 00:07:15,002
相对于ZLIB ZLIB在中心

130
00:07:15,169 --> 00:07:18,972
y轴是压缩速度

131
00:07:19,239 --> 00:07:20,541
并不是呈指数

132
00:07:21,241 --> 00:07:25,479
那么在压缩库内部 我们有一些压缩器

133
00:07:25,913 --> 00:07:28,982
LZMA的压缩性能较好

134
00:07:29,049 --> 00:07:32,352
LZ4的优化版压缩速度快

135
00:07:33,120 --> 00:07:36,356
当然了 我们有ZLIB
以及优化了的ZLIB解码器

136
00:07:36,423 --> 00:07:42,296
还有我们自己的LZFSE 它比ZLIB
压缩的东西多一点 但速度却更快

137
00:07:42,729 --> 00:07:46,233
去年我们开源了LZFSE
是在GitHub上

138
00:07:47,668 --> 00:07:49,369
好的 现在讲API

139
00:07:50,037 --> 00:07:52,472
在压缩中有两个API

140
00:07:52,573 --> 00:07:54,007
第一个是缓冲器API

141
00:07:54,074 --> 00:07:56,643
那么就是当你压缩全部数据时使用

142
00:07:57,477 --> 00:08:01,315
你在要压缩的数据中引用一个缓冲器
你只需要调用一个函数

143
00:08:01,982 --> 00:08:04,985
提供输出缓冲器 然后就会在一个
单一调用中获得输出

144
00:08:05,052 --> 00:08:07,054
这对于编码和解码很有帮助

145
00:08:07,120 --> 00:08:11,592
如果数据很大或数据是一小块一小块的

146
00:08:11,658 --> 00:08:13,427
你就要使用一个数据流API

147
00:08:14,094 --> 00:08:18,065
在那种情况下你要创建一个数据流对象
并向其中发送数据

148
00:08:18,131 --> 00:08:19,733
然后在外部获得一个较小的数据

149
00:08:19,800 --> 00:08:23,604
你要重复调用它
直到处理完整个数据流

150
00:08:25,339 --> 00:08:30,143
这是我们提供给你的 我们改进了它
我们添加了一个压缩工具命令行

151
00:08:31,378 --> 00:08:34,847
那么你可以从命令行中
用Compression进行压缩

152
00:08:35,549 --> 00:08:38,784
好的 这是Compression
现在让我们讲BNNS

153
00:08:38,852 --> 00:08:40,654
（基本神经网络子程序 BNNS）

154
00:08:40,721 --> 00:08:43,756
正如我所说过的 这是CPU的引擎

155
00:08:44,057 --> 00:08:49,663
它支持着全部神经网络和机器学习库

156
00:08:49,830 --> 00:08:54,735
那么你几乎可以随时使用BNNS
当你用键盘输入时

157
00:08:54,801 --> 00:09:00,741
或当你运行面部识别时
全部这些应用都要使用BNNS

158
00:09:01,742 --> 00:09:04,845
BNNS为此提供了低等级的函数

159
00:09:04,912 --> 00:09:08,415
那么是卷积层、池化层

160
00:09:09,049 --> 00:09:10,517
我们还有完全连接的层

161
00:09:10,584 --> 00:09:14,621
我们还添加了独立激活层

162
00:09:14,688 --> 00:09:16,523
正是用于执行激活函数

163
00:09:16,723 --> 00:09:19,526
这些层还可以执行高效转换、

164
00:09:19,593 --> 00:09:21,195
数据类型转换

165
00:09:21,562 --> 00:09:24,565
提到了数据类型

166
00:09:24,698 --> 00:09:27,901
那么当你训练机器学习模型时

167
00:09:27,968 --> 00:09:32,472
你会得到数百万字节或上亿字节的数据

168
00:09:32,539 --> 00:09:35,342
通常是32位的浮点型数据

169
00:09:35,576 --> 00:09:37,845
这些是卷积比重等等

170
00:09:38,345 --> 00:09:42,282
你可以把这些家伙转换成较小的类型

171
00:09:42,349 --> 00:09:47,020
比如16位浮点 或甚至是8位整数
无论是否有符号

172
00:09:47,087 --> 00:09:49,890
并仍得到同样的精确度

173
00:09:49,957 --> 00:09:53,493
但是当然了
当你把32位浮点转为8位时

174
00:09:53,560 --> 00:09:55,495
你的模型就缩小了4倍

175
00:09:55,562 --> 00:09:57,164
对此你要与你的应用进行协商

176
00:09:57,231 --> 00:09:59,066
那么你要考虑到这一点

177
00:09:59,833 --> 00:10:03,470
今年 我们优化了BNNS
使其支持这些类型

178
00:10:03,770 --> 00:10:08,575
那么这是我们现在所支持的
在卷积层进行了优化

179
00:10:09,142 --> 00:10:10,210
绿色部分是新添加的

180
00:10:11,044 --> 00:10:15,315
看 我们为输入和比重
添加了fp16存储 还有int8

181
00:10:16,750 --> 00:10:20,420
这是我们对完全连接的层中
所支持的东西

182
00:10:20,487 --> 00:10:22,789
那么我们仍然支持32位

183
00:10:22,856 --> 00:10:26,260
但我们也可以采用16位
或8位输入和比重

184
00:10:27,027 --> 00:10:30,864
现在 对于激活函数 这是去年的

185
00:10:30,931 --> 00:10:34,501
今年我们又增加了一些
包括最需要的Softmax

186
00:10:34,568 --> 00:10:37,070
现在我们在BNNS中
有优化的Softmax了

187
00:10:38,038 --> 00:10:42,075
如果你把激活函数设为身份
那么你可以

188
00:10:42,142 --> 00:10:45,479
把输入和输出类型修改为不同组合

189
00:10:45,612 --> 00:10:47,481
这是我们现在所支持的

190
00:10:47,548 --> 00:10:50,551
你将从BNNS中
获得优化了的类型转换

191
00:10:51,552 --> 00:10:53,587
最后一个也同样重要 性能

192
00:10:54,821 --> 00:10:58,892
我们与Core ML团队以及
Vision和NLP团队一起努力

193
00:10:58,959 --> 00:11:01,728
优化他们平时使用最频繁的东西

194
00:11:02,596 --> 00:11:06,366
那么包括带填充的卷积

195
00:11:06,433 --> 00:11:09,970
Stride 1和2卷积以及

196
00:11:10,037 --> 00:11:14,308
较小的内核 因为新神经网络有许多层

197
00:11:14,374 --> 00:11:17,911
有较小的卷积 是3x3和1x1

198
00:11:17,978 --> 00:11:19,446
那么我们优化了这些情况

199
00:11:19,746 --> 00:11:23,383
尤其是针对3x3
我们有Winograd卷积

200
00:11:23,450 --> 00:11:27,087
要比基准实施的速度快四倍

201
00:11:27,821 --> 00:11:31,458
这就是BNNS 那么让我邀请
Steve上台 他会谈一下

202
00:11:31,525 --> 00:11:33,493
simd相关的内容 谢谢

203
00:11:37,664 --> 00:11:39,733
非常感谢Eric 谢谢大家

204
00:11:39,900 --> 00:11:41,301
Eric刚说过了 我叫Steve

205
00:11:41,368 --> 00:11:43,670
今天我要讲一下simd模块

206
00:11:43,737 --> 00:11:46,640
我不认为我能讲到全部东西
但我会讲其中一些

207
00:11:47,908 --> 00:11:50,911
simd模块位于
Accelerate外部

208
00:11:50,978 --> 00:11:53,580
它是标头和用户应用的一个小集合

209
00:11:53,747 --> 00:11:55,816
它是一个你可在Swift中
导入的模块

210
00:11:55,883 --> 00:11:59,620
大约主要有三种用例
可以驱动你使用simd

211
00:12:00,220 --> 00:12:05,626
第一个 如果你正在执行2x2、
3x3、4x4向量和矩阵算法

212
00:12:05,692 --> 00:12:07,761
就是当进行图形或集合运算时

213
00:12:07,828 --> 00:12:09,329
总能看到的那种东西

214
00:12:10,464 --> 00:12:12,966
它还提供了较大的向量类型集合

215
00:12:13,033 --> 00:12:14,968
其中有整型向量和浮点型向量

216
00:12:15,335 --> 00:12:19,206
长度最大可达64位
用于处理通用向量编程

217
00:12:19,273 --> 00:12:24,278
你可以在我们所支持的全部平台上的
我们所支持的全部架构上使用它

218
00:12:24,344 --> 00:12:28,081
非常简单 你只需要写一段代码

219
00:12:28,148 --> 00:12:29,616
就可在全部这些架构上
获得良好的向量代码集

220
00:12:30,484 --> 00:12:32,486
你要使用simd的最后一个原因是

221
00:12:32,553 --> 00:12:36,056
它是一个类型和运算的大集合

222
00:12:36,123 --> 00:12:41,261
运算是指在平台上进行3x3、
4x4运算的各种框架之间的运算

223
00:12:41,328 --> 00:12:46,166
比如SceneKit、SpriteKit、
ARKit、Vision等等这些

224
00:12:46,233 --> 00:12:49,236
你可以有许多矩阵和向量

225
00:12:49,503 --> 00:12:52,139
并且有许多simd类型可以配合使用

226
00:12:52,439 --> 00:12:54,441
我应该说尤其是SpriteKit

227
00:12:54,508 --> 00:12:56,844
或者尤其是SceneKit
今年添加了许多新东西

228
00:12:56,910 --> 00:12:58,045
那么请参看相关的演讲

229
00:12:58,111 --> 00:13:00,447
通过simd可以实现很多很棒的东西

230
00:13:00,514 --> 00:13:03,050
我要给你展示几个关于
你可以实现的功能的例子

231
00:13:04,184 --> 00:13:07,721
那么假如说你想用三维矩阵
乘以一个向量

232
00:13:07,921 --> 00:13:10,991
你可以通过BLAS实现
就是Eric刚谈到的那样

233
00:13:11,058 --> 00:13:12,025
看起来是这样的

234
00:13:12,926 --> 00:13:17,497
这没问题 但BLAS将全部参数
都作为原始指针

235
00:13:17,564 --> 00:13:19,933
那么我们必须得告诉它
这些是矩阵的维数

236
00:13:20,000 --> 00:13:22,870
这些是向量的维数 这就是内存的分配

237
00:13:22,936 --> 00:13:25,339
还有许多其它信息需要传递

238
00:13:25,706 --> 00:13:28,108
这会增加写代码的困难系数

239
00:13:28,175 --> 00:13:29,676
并且也很难读懂

240
00:13:29,877 --> 00:13:33,046
如果你还不熟悉BLAS
这里的最后一行

241
00:13:33,113 --> 00:13:35,916
很难看出它正在生产一个矩阵向量

242
00:13:35,983 --> 00:13:38,218
那么我们想要一种更简单的方式

243
00:13:39,253 --> 00:13:43,357
我们还可以用GLKit来写这个
GLKit会让它变得相当简单

244
00:13:43,423 --> 00:13:46,026
我们有三维矩阵

245
00:13:46,093 --> 00:13:47,694
和三维向量的专用类型

246
00:13:47,761 --> 00:13:51,398
我们把它叫作
GLKMatrix3MultiplyVector3函数

247
00:13:51,465 --> 00:13:53,433
很显然它是一个乘法

248
00:13:53,500 --> 00:13:56,603
但我们可以通过simd
把它变得更简单

249
00:13:57,337 --> 00:13:58,839
这是在simd中的样子

250
00:13:58,906 --> 00:14:01,775
好的？非常明确它是一个对角矩阵

251
00:14:02,075 --> 00:14:05,913
矩阵乘以向量只需要
使用乘法运算器即可

252
00:14:05,979 --> 00:14:10,150
非常好 非常简单 速度也非常快

253
00:14:10,417 --> 00:14:13,487
关于simd最重要的部分
就是作为标头内联实施

254
00:14:13,554 --> 00:14:17,457
那么这会在我的CPU上
给我提供三个向量乘法

255
00:14:17,558 --> 00:14:19,626
速度很快 不需要调用

256
00:14:19,693 --> 00:14:21,562
不需要检查参数 什么也不用做

257
00:14:21,628 --> 00:14:23,997
我就是能从这个中
获得漂亮的简单代码集

258
00:14:24,531 --> 00:14:25,899
这是一个Swift示例

259
00:14:25,966 --> 00:14:29,203
我要演示的下一个示例是在C中

260
00:14:30,237 --> 00:14:31,972
在这里 我要给你展示一个例子

261
00:14:32,039 --> 00:14:34,274
看如何用simd来写向量代码

262
00:14:34,708 --> 00:14:38,579
那么假如说我们想用指定中点

263
00:14:38,645 --> 00:14:39,813
和最大斜率计算对数曲线

264
00:14:40,080 --> 00:14:42,816
这个函数总是会出现在

265
00:14:42,883 --> 00:14:44,685
数学运算中 尤其是机器学习

266
00:14:44,751 --> 00:14:46,820
那么这是一个可以进行优化的有用函数

267
00:14:46,887 --> 00:14:48,188
我们非常关心这个

268
00:14:48,789 --> 00:14:51,725
我放在注释中的东西 在函数的主体中

269
00:14:52,092 --> 00:14:54,828
是一个典型的变量实施

270
00:14:54,895 --> 00:14:56,830
看起来非常像是一个数学运算

271
00:14:57,364 --> 00:15:01,902
但我们想同时在16浮点值上计算这个

272
00:15:01,969 --> 00:15:04,071
因为那样我们的效率更高

273
00:15:04,137 --> 00:15:06,807
这就是该simd float16
类型在函数中的功能

274
00:15:06,874 --> 00:15:09,076
它就是个16位浮点的向量

275
00:15:09,343 --> 00:15:12,346
我们要看我们是否可以实施
这个函数的主体

276
00:15:12,579 --> 00:15:14,615
那么向量代码很复杂

277
00:15:14,681 --> 00:15:17,384
所以我把这部分分成了三段

278
00:15:17,451 --> 00:15:20,220
那么我们可以单独写每一段

279
00:15:20,354 --> 00:15:22,890
让我们从第一部分开始 线性部分

280
00:15:23,290 --> 00:15:26,627
那么我们刚从向量中减去了一个标量

281
00:15:26,693 --> 00:15:28,395
我们从那个向量的每一个路径中减去它

282
00:15:28,462 --> 00:15:30,497
然后我们要用它乘以一个标量

283
00:15:30,564 --> 00:15:32,099
在simd中是什么样的？

284
00:15:33,734 --> 00:15:36,837
我们就是先做减法 在做乘法
非常非常简单

285
00:15:37,571 --> 00:15:41,441
可在C中用 可在Swift中用
可在C++中用 也可在Objective-C中用

286
00:15:41,508 --> 00:15:43,777
非常棒 看起来非常像是着色器编程

287
00:15:43,844 --> 00:15:45,045
若你曾做过着色器编程

288
00:15:45,646 --> 00:15:49,383
那么这里的这最后一段
我们有一个倒数

289
00:15:49,449 --> 00:15:52,920
再一次 同样的 我们写出了一段
非常像是数学运算的代码

290
00:15:52,986 --> 00:15:56,356
它看起来就像是调整器代码
看起来就像是我们正在做一个数学运算

291
00:15:56,757 --> 00:15:58,258
那么这中间这部分怎么样呢？

292
00:15:58,325 --> 00:15:59,860
这个稍微有点复杂

293
00:15:59,927 --> 00:16:02,262
我们在这里要做的是
对于向量中的每一个元素

294
00:16:02,329 --> 00:16:04,731
我们都想计算它的指数函数

295
00:16:04,798 --> 00:16:07,768
并把它放在结果因素的响应元素中

296
00:16:08,902 --> 00:16:12,806
我们可以用for循环来实现
这没问题 能实现

297
00:16:13,574 --> 00:16:17,744
但我们今年有了一个很棒的新功能
从根本上来说

298
00:16:17,811 --> 00:16:20,948
全部的数学函数都能在浮点向量
和双精度向量上使用

299
00:16:21,014 --> 00:16:23,550
所以是任意长度的向量
浮点向量和双精度向量

300
00:16:23,617 --> 00:16:26,987
你可调用XPath 你可调用正弦
你可调用余弦 无论什么都可以

301
00:16:27,054 --> 00:16:28,755
数学函数就是能在它们上边用了

302
00:16:28,822 --> 00:16:32,326
这是一个非常棒、非常方便的功能
当你写这种代码时

303
00:16:32,626 --> 00:16:38,398
当我在ARM上写的时候
这个要在NEON扩展中使用

304
00:16:38,465 --> 00:16:41,935
当我编译Intel时
要在AVX和SSE中使用

305
00:16:42,002 --> 00:16:45,272
那么我会在所有平台上得到
迅捷的代码 非常棒

306
00:16:45,672 --> 00:16:47,407
今年我们还有另一个很大的新功能

307
00:16:47,474 --> 00:16:50,677
是许多人要求添加的一个新功能
即四元数

308
00:16:51,011 --> 00:16:53,514
我要非常快速地介绍一下

309
00:16:53,714 --> 00:16:57,484
就是那个四元素扩展了复数

310
00:16:57,551 --> 00:16:59,319
与复数扩展实数的方式一样

311
00:17:00,621 --> 00:17:03,156
那么复数 你可能还记得在学校学过吧

312
00:17:03,223 --> 00:17:05,925
有实数和虚数

313
00:17:07,160 --> 00:17:11,999
四元数有实数 并且有三个虚数

314
00:17:12,065 --> 00:17:13,634
有时候你需要调用四元数的向量

315
00:17:13,700 --> 00:17:17,104
我妈妈总是说 如果有一个
负一的平方根那么没问题

316
00:17:17,171 --> 00:17:19,772
但有三个负一的平方根那一定很棒

317
00:17:20,641 --> 00:17:22,742
她是位聪慧的女人 你应该听她的

318
00:17:25,179 --> 00:17:28,315
有许多关于四元数的迷人的数学结构

319
00:17:28,382 --> 00:17:31,318
我们真正关心的并不是那个
我们只对一件事感兴趣

320
00:17:32,019 --> 00:17:34,721
四元数有长度的概念 跟复数一样

321
00:17:34,788 --> 00:17:37,691
你把各部分的平方数加起来
然后开平方根

322
00:17:37,758 --> 00:17:39,359
就是四元数的长度

323
00:17:39,793 --> 00:17:43,597
长度为1的四元数
我们把它叫作单位四元数

324
00:17:43,664 --> 00:17:48,602
它们有这个非常棒的属性 可以用于

325
00:17:48,669 --> 00:17:52,005
在三维空间中表示旋转

326
00:17:52,706 --> 00:17:56,577
这就是我们所关心的东西
忘了我刚才提到的其它数学算法吧

327
00:17:57,811 --> 00:18:00,214
那么我要给你看一下迅捷代码示例

328
00:18:00,480 --> 00:18:02,950
比如说我们有一个向量
是XY路径中的向量

329
00:18:03,917 --> 00:18:05,319
让我们创建一个四元数

330
00:18:05,385 --> 00:18:08,989
这是一个代表y轴旋转的四元数

331
00:18:10,457 --> 00:18:14,228
四元数作用于向量
这是simd的act函数

332
00:18:14,828 --> 00:18:18,398
它并不是乘法 当向量乘以矩阵时

333
00:18:18,465 --> 00:18:22,803
当通过矩阵旋转向量时
你只需要做乘法

334
00:18:22,870 --> 00:18:24,538
对于四元数来说 这叫作一个作用

335
00:18:24,605 --> 00:18:27,174
那么不要太关心细节

336
00:18:27,241 --> 00:18:29,142
这就是这个act函数产生的原因

337
00:18:30,110 --> 00:18:32,246
那么这是一个表示旋转的很棒的方式

338
00:18:32,679 --> 00:18:35,115
还有许多其它方式来表示旋转

339
00:18:35,182 --> 00:18:37,985
你为什么要用这个呢？
什么时候要用这个呢？

340
00:18:38,785 --> 00:18:41,622
你知道的 你可能会使用矩阵
你可能会使用欧拉角

341
00:18:41,688 --> 00:18:44,358
或偏航角/俯仰角/翻滚角
你可以使用轴和角度来表示

342
00:18:44,424 --> 00:18:45,659
有很多选择

343
00:18:45,859 --> 00:18:48,028
四元数是一个特别好的选择

344
00:18:48,095 --> 00:18:51,031
对于我将要讲的某些操作来说

345
00:18:52,566 --> 00:18:55,836
关于四元数的第一个好处就是
比矩阵占用的内存小

346
00:18:55,903 --> 00:18:59,039
这很好 非常棒

347
00:18:59,106 --> 00:19:01,175
但这并不是
我们想要使用它们的真正原因

348
00:19:01,975 --> 00:19:06,380
关于四元数更大的好处是
它们执行旋转的速度并不是很快

349
00:19:06,446 --> 00:19:09,316
你可以在这里看到只有

350
00:19:09,383 --> 00:19:12,119
使用矩阵计算旋转时的速度的三分之一

351
00:19:13,320 --> 00:19:15,656
当你想执行一系列操作时

352
00:19:15,722 --> 00:19:18,425
当你想联合旋转或想插入旋转时

353
00:19:18,492 --> 00:19:19,693
你想做那样类似的操作

354
00:19:19,760 --> 00:19:23,030
那么它们是执行
这些操作的最自然的环境

355
00:19:23,463 --> 00:19:25,566
那么当我们想把两个旋转结合在一起时

356
00:19:25,632 --> 00:19:29,203
你可看到四元数比向量和矩阵快30%

357
00:19:29,469 --> 00:19:33,207
但它们还允许我们执行一些
用矩阵很难执行的操作

358
00:19:34,474 --> 00:19:36,143
那么假如说我们想插入

359
00:19:36,210 --> 00:19:38,946
在两个不同的旋转的坐标系中执行插入

360
00:19:39,246 --> 00:19:43,116
如果用矩阵 感觉有点儿微妙
但如果用四元数 会感到非常自然

361
00:19:43,417 --> 00:19:45,219
感到很自然的原因是与

362
00:19:45,285 --> 00:19:48,255
我在屏幕右边画的这个球体有关

363
00:19:48,322 --> 00:19:51,658
你可能会说“嗯
你为什么在球体上画旋转？”

364
00:19:51,792 --> 00:19:53,193
有一个很好的理由

365
00:19:53,594 --> 00:19:57,898
你可以把四元数看做是
四维投影球体上的点

366
00:19:58,765 --> 00:20:02,536
听起来有点复杂 需要数学专业知识
但它的确是

367
00:20:02,603 --> 00:20:06,773
但在三维空间中是旋转的自然空间

368
00:20:06,840 --> 00:20:09,610
那么 当我执行操作时
在这个球体表面

369
00:20:09,676 --> 00:20:12,446
那会与你的天生直觉完全匹配

370
00:20:12,513 --> 00:20:14,515
关于旋转会发生什么

371
00:20:15,616 --> 00:20:17,417
比如说
如果我想在这之间做一个插入

372
00:20:17,484 --> 00:20:20,420
我只需要在球体上沿着大圆弧插入

373
00:20:20,487 --> 00:20:21,955
这就是该simd slerp函数

374
00:20:22,022 --> 00:20:24,491
它代表了球面线性差值

375
00:20:25,125 --> 00:20:28,562
非常简单易用
而且正好能实现你所想要实现的功能

376
00:20:29,062 --> 00:20:32,766
如果我们有一系列的点
我们想把它们插入到这之间

377
00:20:33,233 --> 00:20:36,904
我们可以重复调用slerp
来将它们插入

378
00:20:36,970 --> 00:20:39,473
但那会有一个很明显的跳跃

379
00:20:39,540 --> 00:20:41,842
在旋转中 当你转角时

380
00:20:42,809 --> 00:20:46,213
相反 我们可以使用
simd spline函数

381
00:20:46,280 --> 00:20:48,348
得到一个完全流畅的插入

382
00:20:48,415 --> 00:20:50,951
通过一系列旋转的坐标系

383
00:20:51,518 --> 00:20:55,656
在simd标头中
还有大量其它类似运算

384
00:20:55,722 --> 00:20:58,625
你可以用于执行这种类型的操作

385
00:20:58,926 --> 00:21:02,229
如果你想处理旋转
那么有相当多可用的API

386
00:21:02,296 --> 00:21:03,664
我鼓励你们自己去了解

387
00:21:04,064 --> 00:21:06,767
正如我所说的
这是开发者们最想添加的功能

388
00:21:06,834 --> 00:21:08,902
所以我鼓励你们发现漏洞并告诉我们说

389
00:21:08,969 --> 00:21:10,871
“嘿 你们还能添加这个东西吗？”

390
00:21:10,938 --> 00:21:14,107
我们一定会给你们一个满意的答案
我们喜欢从用户那儿得到未来的目标

391
00:21:14,575 --> 00:21:18,045
那么 我要把你们交给
Jonathan Hogg

392
00:21:18,111 --> 00:21:21,381
他要跟大家谈一些非常非常大的矩阵

393
00:21:27,688 --> 00:21:31,124
嗨 你们从Steve那儿
了解了simd

394
00:21:31,191 --> 00:21:34,261
这对于非常非常小的矩阵来说很棒

395
00:21:34,561 --> 00:21:38,232
我要讲一下非常大的矩阵

396
00:21:38,765 --> 00:21:41,235
但首先我要谈谈
BLAS和LAPACK

397
00:21:41,301 --> 00:21:44,204
这些是处理密集矩阵的库

398
00:21:44,271 --> 00:21:49,610
那么你可以在MacBook上
拥有最多3万或4万个列

399
00:21:50,744 --> 00:21:51,812
我们有什么？

400
00:21:52,746 --> 00:21:56,383
那么BLAS代表基础线性代数子程序

401
00:21:56,450 --> 00:21:59,887
在矩阵和向量上执行基本运算

402
00:22:00,621 --> 00:22:04,057
我们有BLAS 1 执行向量运算

403
00:22:04,124 --> 00:22:07,194
BLAS 2执行矩阵向量

404
00:22:07,261 --> 00:22:09,363
BLAS 2执行矩阵运算

405
00:22:09,663 --> 00:22:13,567
你已经从Eric那儿了解到了

406
00:22:13,634 --> 00:22:16,403
我们在矩阵相乘上的速度
比你的简单循环快100倍

407
00:22:17,204 --> 00:22:19,506
如果你想执行更复杂的运算

408
00:22:19,773 --> 00:22:21,375
那么我们有LAPACK

409
00:22:21,909 --> 00:22:26,513
这些会执行矩阵因式分解、
线性求解、找到的特征值、

410
00:22:26,580 --> 00:22:31,051
特征向量、奇异值分解等等
有很多你想要做的运算

411
00:22:32,819 --> 00:22:35,756
这就是我要告诉你的关于
密集矩阵的全部内容

412
00:22:35,822 --> 00:22:37,791
因为我们实际上想要谈谈稀疏矩阵

413
00:22:39,293 --> 00:22:41,562
什么是稀疏矩阵？

414
00:22:44,398 --> 00:22:47,401
那么James Wilkinson

415
00:22:47,467 --> 00:22:49,136
是计算数学线性代数的先驱之一

416
00:22:49,203 --> 00:22:50,337
这是他的定义

417
00:22:51,271 --> 00:22:55,609
“稀疏矩阵是
利用零对我们有用的任意矩阵”

418
00:22:57,511 --> 00:23:00,180
让我们看看稀疏矩阵实际上是什么样子

419
00:23:01,648 --> 00:23:03,817
那么这里有两个稀疏矩阵

420
00:23:03,884 --> 00:23:06,787
一个实际上是另一个的乔里斯基分解

421
00:23:07,354 --> 00:23:10,390
这里的每个像素都代表多个非零

422
00:23:11,291 --> 00:23:17,464
它们是白色的
那个像素背后的项都是零

423
00:23:17,831 --> 00:23:20,934
而蓝色的代表至少存在一个非零

424
00:23:21,001 --> 00:23:24,171
那么你可以看到
这些矩阵绝大部分是空的

425
00:23:25,138 --> 00:23:28,575
事实上 如果你要把它存储为密集矩阵

426
00:23:28,642 --> 00:23:32,679
它大约是30,000x30,000
那么它占用了6.5GB

427
00:23:33,380 --> 00:23:39,386
如果我们把它存储为稀疏矩阵
我们占用的内存比原来小了260倍

428
00:23:39,453 --> 00:23:41,188
只有26MB

429
00:23:41,288 --> 00:23:44,424
如果我们想用这个矩阵

430
00:23:44,491 --> 00:23:49,730
乘以一个向量 我们所需要的浮点运算
比原来几乎少了200倍

431
00:23:50,564 --> 00:23:52,432
但如果我们想执行一个更复杂的运算

432
00:23:52,499 --> 00:23:54,868
比如因式分解这个矩阵

433
00:23:56,503 --> 00:24:00,607
那更棒了 至少是在浮点运算中更棒了

434
00:24:00,841 --> 00:24:05,078
要因式分解这个矩阵

435
00:24:05,145 --> 00:24:06,513
我们所需要的浮点运算减少了2000倍

436
00:24:07,447 --> 00:24:09,683
而密集矩阵仍然是一样的大小

437
00:24:09,750 --> 00:24:11,418
因子也替代了一点儿

438
00:24:11,685 --> 00:24:13,687
它比原来稍微密集一点儿

439
00:24:13,754 --> 00:24:16,790
那马我们减少了30倍的内存

440
00:24:17,758 --> 00:24:20,794
现在 要把那个点指回去
我们设置了一个竞赛

441
00:24:21,361 --> 00:24:26,200
我们决定在Watch上运行
稀疏求解器 并将其与

442
00:24:26,266 --> 00:24:30,938
Macbook Air上LAPACK中的
最棒的密集矩阵求解器相对比

443
00:24:31,505 --> 00:24:32,973
情况就是这样的

444
00:24:35,008 --> 00:24:38,812
现在 这个的实际运行速度快5倍

445
00:24:39,012 --> 00:24:43,684
你可以看到Watch
仅在16秒钟就完成了

446
00:24:44,084 --> 00:24:45,953
你要记住 在看这个时

447
00:24:46,019 --> 00:24:50,090
MacBook Air上的浮点

448
00:24:50,157 --> 00:24:51,892
比Watch上可用的浮点要多50倍

449
00:24:56,797 --> 00:25:00,868
现在对于稀疏矩阵来说
因式分解其实有两个阶段

450
00:25:00,934 --> 00:25:04,671
第一 我们发现非零项的位置

451
00:25:04,738 --> 00:25:05,939
这是象征阶段

452
00:25:06,006 --> 00:25:09,877
然后我们有一个数值阶段
是计算实际的值

453
00:25:10,544 --> 00:25:12,946
这些时间只是数值阶段的时间

454
00:25:13,714 --> 00:25:16,917
但象征阶段在Watch上
只用了大约两秒钟

455
00:25:17,217 --> 00:25:21,488
那么与其说是16秒
不如说是大约18秒

456
00:25:21,555 --> 00:25:25,425
但如果你在同样的模式上
执行一次以上的因式分解

457
00:25:26,460 --> 00:25:30,531
你可以在第二个和第三个因式分解上
跳过那个象征阶段

458
00:25:31,231 --> 00:25:33,867
即便你执行象征阶段
我们仍比Macbook速度快10倍

459
00:25:33,934 --> 00:25:36,103
因为MacBook执行的是密集计算

460
00:25:37,571 --> 00:25:41,441
我希望我说服了你们
稀疏矩阵是很值得一用的

461
00:25:41,508 --> 00:25:44,611
那么让我来谈谈如何定义稀疏矩阵

462
00:25:45,412 --> 00:25:48,415
那么这是一个非常非常小的稀疏矩阵

463
00:25:48,682 --> 00:25:52,252
你会注意到它的项有缺失
那些都是零

464
00:25:52,953 --> 00:25:55,789
我们要使用一种标准格式把它存起来

465
00:25:55,856 --> 00:26:00,160
叫作压缩稀疏列 使用这三个数组

466
00:26:01,295 --> 00:26:04,064
我们要从rowIndices率开始

467
00:26:04,131 --> 00:26:08,168
那么让我们把行数添加到矩阵中

468
00:26:09,169 --> 00:26:11,805
我们只需把那些复制到
rowIndices数组中即可

469
00:26:12,940 --> 00:26:15,242
那么值的处理也类似

470
00:26:16,376 --> 00:26:18,745
你可以看到我们这里是一一对应的

471
00:26:19,213 --> 00:26:22,382
第一个项是第零行 值为二

472
00:26:23,750 --> 00:26:27,888
那么让我们把这些项的位置放到

473
00:26:27,955 --> 00:26:30,090
那个rowIndices和值数组中

474
00:26:30,591 --> 00:26:33,060
压缩稀疏列的一个技巧是

475
00:26:33,126 --> 00:26:37,097
全部这些值必须按照
增加的列的顺序产生

476
00:26:37,598 --> 00:26:41,702
第零列的全部项实际上
比第一列的项发生的时间早

477
00:26:42,769 --> 00:26:44,738
那么我们还有一个关于这种格式的技巧

478
00:26:44,805 --> 00:26:46,707
即我们只需要存储

479
00:26:46,773 --> 00:26:50,844
每列中第一项的位置

480
00:26:51,745 --> 00:26:57,251
和一条额外的信息
即矩阵中项的总数量

481
00:26:57,317 --> 00:27:00,020
意思就是我们知道最后一列是多长

482
00:27:01,288 --> 00:27:05,259
如果你曾经使用过稀疏求解器
你很可能会有

483
00:27:05,325 --> 00:27:07,628
这种格式或坐标格式的数据

484
00:27:07,694 --> 00:27:09,029
并且我们提供转换器

485
00:27:11,164 --> 00:27:14,902
要在Accelerate中使用
我们需要把它包在一些元数据中

486
00:27:14,968 --> 00:27:17,404
只是告诉它有多少行 有多少列

487
00:27:17,671 --> 00:27:20,440
我们要表明这是一个普通的稀疏矩阵

488
00:27:20,507 --> 00:27:25,379
稍后我要展示一个异常稀疏矩阵的例子

489
00:27:26,513 --> 00:27:29,249
现在我有了我的稀疏矩阵
我能用它做什么呢？

490
00:27:31,351 --> 00:27:34,087
那么你可以做很多你所期待的任何运算

491
00:27:34,154 --> 00:27:37,858
你可以乘以一个密集向量或密集矩阵

492
00:27:37,925 --> 00:27:40,928
你可以同时增加两个
稀疏矩阵或稀疏向量

493
00:27:40,994 --> 00:27:43,197
你可以变换行或列

494
00:27:43,263 --> 00:27:46,033
或你可以寻找各种有用的矩阵范数

495
00:27:46,700 --> 00:27:49,603
这些功能都是
由Sparse BLAS提供的

496
00:27:49,670 --> 00:27:53,540
是我们几年前引入的
那么这次有什么改进呢？

497
00:27:53,607 --> 00:27:54,908
（求解）

498
00:27:54,975 --> 00:27:57,544
求解稀疏系统的能力

499
00:27:58,679 --> 00:28:05,185
就是假设矩阵方程A乘以X等于B
矩阵A

500
00:28:05,252 --> 00:28:09,456
和右边的B已知
那么我们就能算出未知X的向量

501
00:28:10,591 --> 00:28:13,493
那么我们为你们提供了两种方法

502
00:28:14,027 --> 00:28:18,532
第一种方式是矩阵因式分解
这正是在LAPACK中所发生的

503
00:28:18,966 --> 00:28:21,702
非常简单 非常精确 很容易上手

504
00:28:22,336 --> 00:28:24,805
但数学家就是数学家

505
00:28:24,872 --> 00:28:27,474
他们提出了更复杂的方式

506
00:28:28,675 --> 00:28:29,877
就是迭代法

507
00:28:29,943 --> 00:28:31,979
稍后我会详细讲一下迭代法

508
00:28:33,313 --> 00:28:35,883
那么我们的矩阵因式分解

509
00:28:35,949 --> 00:28:38,385
对于你们从来没听说过
矩阵因式分解的人来说

510
00:28:38,452 --> 00:28:42,556
我们要对左边的这个绿色矩阵
进行因式分解

511
00:28:42,623 --> 00:28:45,425
把它分解到右边的两个三角矩阵中

512
00:28:46,126 --> 00:28:47,628
这是因为我们非常了解

513
00:28:47,694 --> 00:28:49,630
如何求解一个有三角矩阵的系统

514
00:28:50,564 --> 00:28:53,433
若我们不是正方形
我们所采取的方式就稍微有点不一样了

515
00:28:54,034 --> 00:28:58,005
我们得从这里选择一个矩形和正交因子

516
00:28:58,071 --> 00:29:01,575
这是你的QR因式分解
如果你之前听说过的话

517
00:29:02,476 --> 00:29:04,778
那么让我们看看到底该怎么做

518
00:29:06,213 --> 00:29:09,049
这是一个系数矩阵等式

519
00:29:09,783 --> 00:29:12,186
一开始让我们先定义那个矩阵

520
00:29:13,554 --> 00:29:15,923
那么这与我刚展示给你们的非常相似

521
00:29:15,989 --> 00:29:19,459
除了这个矩阵有点特殊外 它是对称的

522
00:29:19,860 --> 00:29:23,864
意思就是靠下的三角形就是

523
00:29:23,931 --> 00:29:26,967
另一个三角形的镜反射
那么我们可以利用一下这个

524
00:29:27,034 --> 00:29:29,369
让我们只存储靠下的三角形的项

525
00:29:30,404 --> 00:29:34,575
把它包在元数据中
并且这一次我们要指定

526
00:29:34,641 --> 00:29:37,077
它不是普通矩阵 它是一个对称矩阵

527
00:29:37,377 --> 00:29:40,781
我们要告诉它我们要传递靠下的三角形

528
00:29:40,848 --> 00:29:42,683
如果我们想
我们也可传递靠上的三角形

529
00:29:42,749 --> 00:29:44,518
但在这里我们选择靠下的三角形

530
00:29:45,152 --> 00:29:49,456
那么我们得到了我们的矩阵
接下来让我们看看右手边

531
00:29:49,990 --> 00:29:54,461
那么这是一个密集向量
让我们把它们放在一个简单的数组中

532
00:29:55,028 --> 00:29:57,898
用一些元数据把它包起来
这些元数据会告诉我们它有多长

533
00:29:57,965 --> 00:30:00,367
以及它是如何简单

534
00:30:01,768 --> 00:30:06,006
这就把我们带到了最有意思的部分
我们到底要如何找到那个向量X呢？

535
00:30:08,976 --> 00:30:12,179
那么让我们定义一些存储
可以把答案存起来

536
00:30:12,246 --> 00:30:15,282
这与我们刚看到的那个
密集矢量B是一模一样的

537
00:30:15,349 --> 00:30:17,818
除了我们不需要提供任何值以外

538
00:30:19,353 --> 00:30:21,388
然后我们要调用
SparseFactor

539
00:30:21,688 --> 00:30:23,957
我知道这个矩阵是正定的；

540
00:30:24,024 --> 00:30:26,593
因此 我可以告诉它使用乔里斯基分解

541
00:30:26,994 --> 00:30:29,563
稍后我会给你们看一个流程图 告诉你

542
00:30:29,630 --> 00:30:33,734
如何选择一种因式分解
但在这里我们要使用乔里斯基分解

543
00:30:33,800 --> 00:30:36,637
那就为我们提供了
L乘以L转置矩阵分解

544
00:30:36,703 --> 00:30:38,906
然后我们进入
SparseSolve中

545
00:30:38,972 --> 00:30:41,575
传入右手边的那个
和我们给它指定的存储

546
00:30:41,642 --> 00:30:45,312
然后我们就得到了答案
我们可以把它放回等式中

547
00:30:45,379 --> 00:30:47,414
我们可以看到这是正确的

548
00:30:48,916 --> 00:30:51,218
那么如果A不是正方形会怎么样呢？

549
00:30:53,554 --> 00:30:56,757
嗯 这时候我们就不得不使用
那个QR因式分解[听不清]

550
00:30:56,823 --> 00:30:59,426
我之前提到过
但我们在这里有两种不同的情况

551
00:30:59,493 --> 00:31:00,894
并不完全是那么简单

552
00:31:01,161 --> 00:31:05,666
我们可以多因素决定
因为我们的行数比列数多

553
00:31:06,567 --> 00:31:08,335
除非你选择了一个非常特殊的系统

554
00:31:08,402 --> 00:31:11,538
那很可能意味着没有完全正确的答案

555
00:31:12,105 --> 00:31:14,074
事实上你就处于这种情况下

556
00:31:15,209 --> 00:31:18,212
用一条直线把这四个点连起来

557
00:31:20,314 --> 00:31:21,748
很明显这是不可能的

558
00:31:21,815 --> 00:31:23,584
但若你还记得上学时
老师教的东西

559
00:31:23,650 --> 00:31:26,119
你很可能会执行一些最小二乘方拟合

560
00:31:27,888 --> 00:31:31,558
我们选择了一条箭头平方总和最小的线

561
00:31:31,625 --> 00:31:33,360
这即我们在该情况下
所采取的措施

562
00:31:33,961 --> 00:31:37,965
还记得吧 我们要求解Ax等于B
那么箭头是X减去B

563
00:31:38,398 --> 00:31:41,168
让我们把两个常量拿出来
其实是本例中箭头的平方总和

564
00:31:41,235 --> 00:31:44,805
并求它的最小值

565
00:31:46,907 --> 00:31:50,711
如果我们还不确定
也就是说我们的列数比行数多

566
00:31:50,777 --> 00:31:52,713
我们的情况就稍微不一样了

567
00:31:53,714 --> 00:31:57,451
那等同于画一条线穿过这个点

568
00:31:58,252 --> 00:32:02,222
很明显 有无限多条线可以穿过那个点

569
00:32:02,422 --> 00:32:05,726
那么我们要如何选择一条线
并返回给你呢？

570
00:32:06,360 --> 00:32:09,663
我们给你提供一个最小范数

571
00:32:12,099 --> 00:32:14,268
让我们看看代码

572
00:32:15,502 --> 00:32:19,439
它非常非常类似于
我们之前看过的乔里斯基分解

573
00:32:19,640 --> 00:32:22,843
事实上唯一的不同点是
我们[听不清]要使用

574
00:32:22,910 --> 00:32:25,712
一个QR分解 而不是乔里斯基分解

575
00:32:25,779 --> 00:32:28,649
这将自动选择是否执行最小平方

576
00:32:28,715 --> 00:32:32,352
或最小范数 根据你矩阵的维数

577
00:32:33,320 --> 00:32:35,222
并且我告诉过你我们有一个流程图

578
00:32:35,289 --> 00:32:38,458
可以让你了解如何决定
使用哪种因式分解

579
00:32:38,525 --> 00:32:41,695
那么你要提出的第一个问题是：

580
00:32:44,498 --> 00:32:46,266
“你的矩阵对称吗？”

581
00:32:47,434 --> 00:32:50,971
如果不对称 你就要使用QR分解

582
00:32:51,438 --> 00:32:54,308
如果对称 那么还有另一个问题：

583
00:32:54,741 --> 00:32:56,543
“你的矩阵是正定的吗？”

584
00:32:56,610 --> 00:33:01,882
现在如果你不知道答案
或你不确定它不是 你可以执行

585
00:33:01,949 --> 00:33:06,620
对称不定分解 LDL转置

586
00:33:07,154 --> 00:33:09,223
但如果你稍微知道一点其它信息

587
00:33:09,289 --> 00:33:11,225
比如你有一个正定矩阵

588
00:33:11,291 --> 00:33:15,229
你可以使用乔里斯基分解
L乘以L转置

589
00:33:15,829 --> 00:33:18,765
这就是我们要谈的关于
矩阵因式分解的全部内容

590
00:33:18,832 --> 00:33:23,270
现在 我说过还有另一种技术 迭代法

591
00:33:25,305 --> 00:33:27,107
那么什么是迭代法？

592
00:33:27,875 --> 00:33:29,510
我们选择一个起点

593
00:33:29,576 --> 00:33:32,546
是我们猜测的最佳答案
在我们开始之前

594
00:33:33,146 --> 00:33:35,282
这可以是零 如果你没有任何想法的话

595
00:33:35,349 --> 00:33:37,684
对于[听不清]答案会是什么的想法

596
00:33:38,018 --> 00:33:43,156
我们想把这个点放在
真实答案的一个小半径内

597
00:33:43,690 --> 00:33:47,261
我们的实现方式是通过
一系列的点进行迭代

598
00:33:47,327 --> 00:33:49,496
这就会收敛到那个答案

599
00:33:50,063 --> 00:33:52,699
现在对于使用这些方法
有一些注意事项

600
00:33:53,734 --> 00:33:58,672
一般来说 如果你有一个
非常非常非常大的稀疏矩阵

601
00:33:58,739 --> 00:34:02,409
这种方法的速度
才会比矩阵因式分解方法快

602
00:34:02,976 --> 00:34:05,779
此外 要实际获取那种性能

603
00:34:05,846 --> 00:34:08,148
你需要了解关于
那个问题的一些数学算法

604
00:34:08,215 --> 00:34:10,050
你需要一个叫作预处理器的东西

605
00:34:10,117 --> 00:34:12,119
它是一个非常近似的答案

606
00:34:13,152 --> 00:34:15,621
如果你查看你所在领域的文献

607
00:34:15,688 --> 00:34:20,027
你很可能会发现有许多
都是从数学家那儿衍生出来的

608
00:34:21,128 --> 00:34:23,096
这到底要怎么用呢？

609
00:34:23,597 --> 00:34:26,300
那么这是我们之前看的那个矩阵方程

610
00:34:26,366 --> 00:34:29,002
这一次 我要使用迭代法来求解它

611
00:34:29,436 --> 00:34:32,105
事实上 我要使用共轭梯度

612
00:34:33,139 --> 00:34:34,641
这是正定的

613
00:34:35,242 --> 00:34:39,612
我们只需要指定
使用共轭梯度法即可

614
00:34:39,679 --> 00:34:42,049
你会注意到那儿有一个括号

615
00:34:42,549 --> 00:34:44,818
那其实是因为这是一个工厂函数

616
00:34:44,885 --> 00:34:47,821
它生产方法 你可以在这些括号中指定

617
00:34:47,888 --> 00:34:50,724
方法专用的参数

618
00:34:51,123 --> 00:34:51,992
我要做的另一件事就是

619
00:34:52,059 --> 00:34:54,293
使用一个对角线预处理器

620
00:34:54,360 --> 00:34:55,996
这个矩阵是个对角优势矩阵

621
00:34:56,063 --> 00:34:58,565
意思是对角线上的项远远大于

622
00:34:58,632 --> 00:35:00,534
那些不在对角线上的项；

623
00:35:00,601 --> 00:35:02,769
因此 我就知道这个对角线预处理器

624
00:35:02,836 --> 00:35:04,338
应该会很好用

625
00:35:04,638 --> 00:35:08,141
确实 如果我们看一下算法的输出

626
00:35:08,208 --> 00:35:10,143
你可以看到这个箭头AX减去B

627
00:35:10,210 --> 00:35:14,781
是递减的[听不清] 并且我们在
四次迭代中得到了机器精确度

628
00:35:15,082 --> 00:35:18,752
这是因为它是个4x4矩阵
从数学角度来说 我们应该

629
00:35:18,819 --> 00:35:22,656
最多收敛N次迭代
而N就是那个矩阵的大小

630
00:35:23,423 --> 00:35:26,093
那么这跟我们预期的一样
但如果你一个更大的矩阵

631
00:35:26,159 --> 00:35:28,896
你和可能不想执行那么多次迭代

632
00:35:29,229 --> 00:35:31,465
这也是为什么你会获得
一个近似答案的原因

633
00:35:32,266 --> 00:35:34,401
且你可以看到我们
得到了与之前一样的答案

634
00:35:35,135 --> 00:35:38,872
现在假设我们想求解那个
最小平方的问题

635
00:35:39,373 --> 00:35:42,309
我们提供了一个最小平方求解器
是迭代求解器

636
00:35:42,376 --> 00:35:46,013
然而 我们没有提供不定系统求解器

637
00:35:46,079 --> 00:35:48,916
在那种情况下
你只需要选择[听不清]即可

638
00:35:48,982 --> 00:35:50,918
在求解器正方系统中

639
00:35:51,385 --> 00:35:57,424
要使用这个 我们需使用LSMR方法
和一个稍微不一样的预处理器

640
00:35:57,491 --> 00:36:00,027
这个预处理器
是专门用来处理这个问题的

641
00:36:00,093 --> 00:36:01,995
你可以看到

642
00:36:02,062 --> 00:36:05,165
这次我们进行了三次迭代
因为这是一个4x3矩阵

643
00:36:05,699 --> 00:36:12,272
但关于这种实现方式
我们还有一些非常酷的东西

644
00:36:13,340 --> 00:36:17,845
首先是很明显
我实际上不需要我的矩阵

645
00:36:18,912 --> 00:36:23,383
只要我有一个
能执行数学运算的函数即可

646
00:36:23,450 --> 00:36:27,855
A乘以X或A转置乘以X
那就是我们有一个运算符

647
00:36:28,422 --> 00:36:32,726
我可以替换一个
替换了这个矩阵参数的代码块

648
00:36:33,460 --> 00:36:37,965
第二个是你可以使用无限个预处理器

649
00:36:38,699 --> 00:36:42,202
你可以写自己的预处理器
或在这个参数中提供一个函数指针

650
00:36:44,838 --> 00:36:46,173
现在你很可能会说

651
00:36:46,240 --> 00:36:48,342
“该如何了解要使用哪种迭代方法？”

652
00:36:48,408 --> 00:36:50,711
我这里有另外一个流程图

653
00:36:50,878 --> 00:36:53,881
这一次我们的第一个问题不是
是否对称了

654
00:36:53,947 --> 00:36:56,884
而是是否为正方形 如果不是正方形

655
00:36:56,950 --> 00:36:59,152
你就要执行最小二乘方求解

656
00:36:59,820 --> 00:37:02,723
然而 如果是
我们可以直接回答这个问题

657
00:37:02,789 --> 00:37:04,358
“你是正定的吗？”

658
00:37:05,192 --> 00:37:07,227
如果不是 我们就用GMRES

659
00:37:07,294 --> 00:37:09,863
它会处理很多任意正方形矩阵

660
00:37:10,797 --> 00:37:13,967
但如果你了解更多一点儿信息
你可以 当然了

661
00:37:14,034 --> 00:37:16,136
使用著名的共轭梯度法

662
00:37:17,471 --> 00:37:21,408
现在这就是我今天要跟大家
分享的关于稀疏矩阵的全部内容

663
00:37:21,975 --> 00:37:24,745
那么我们有一点要指出来

664
00:37:26,313 --> 00:37:30,284
就是你现在可以在Watch上
使用Accelerate了

665
00:37:30,350 --> 00:37:35,455
我们提供了那个SDK
现在框架会一直在那儿

666
00:37:35,789 --> 00:37:40,394
甚至会更棒 使用今天谈到的SDK
你可以重新部署

667
00:37:40,460 --> 00:37:45,599
之前的Watch OS上的东西
那么意味着你可以

668
00:37:45,666 --> 00:37:48,302
在Watch上应用我们今天
跟你们分享的全部功能

669
00:37:49,503 --> 00:37:51,772
那么让我们总结一下

670
00:37:51,839 --> 00:37:54,942
通过使用Accelerate
你的代码会运行更迅捷

671
00:37:55,209 --> 00:37:59,279
它会更节能
它能在我们的全部设备上运行

672
00:37:59,479 --> 00:38:02,316
到头来你也不需要维护那么多的代码了

673
00:38:02,382 --> 00:38:04,318
这是我们今天跟大家分享的全部内容：

674
00:38:04,384 --> 00:38:07,387
稀疏求解器库、新压缩工具、

675
00:38:07,988 --> 00:38:10,991
BNNS的变更、simd的改进

676
00:38:11,058 --> 00:38:13,293
以及更多 还有针对框架

677
00:38:13,360 --> 00:38:14,695
增强的性能

678
00:38:16,063 --> 00:38:18,232
如果你想了解更多信息

679
00:38:18,298 --> 00:38:21,835
引用我们针对稀疏求解器
开发的大量示例代码

680
00:38:21,902 --> 00:38:23,337
你可以从这里找到

681
00:38:25,239 --> 00:38:28,275
你可能对这些演讲感兴趣

682
00:38:28,342 --> 00:38:32,312
有些已经结束了或即将开始
今天下午就有一场Metal演讲

683
00:38:33,313 --> 00:38:34,548
谢谢大家的参与

