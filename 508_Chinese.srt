1
00:00:25,292 --> 00:00:26,360
谢谢

2
00:00:28,262 --> 00:00:31,131
我叫Etienne
今天我很高兴能来这里

3
00:00:31,198 --> 00:00:37,204
与大家分享如何使用深度
来给你的图片应用新的效果

4
00:00:39,540 --> 00:00:43,043
首先我们要看什么是深度
以及它是什么样子的

5
00:00:43,710 --> 00:00:47,581
然后我们要看如何
从图像文件中加载和读取深度

6
00:00:48,582 --> 00:00:52,352
然后我们要给你展示一些示例效果

7
00:00:52,419 --> 00:00:54,121
都是可以通过深度实现的

8
00:00:55,122 --> 00:00:57,691
我们可以总结一下如何保存深度数据

9
00:00:58,692 --> 00:01:00,260
好的 那么让我们开始吧

10
00:01:01,528 --> 00:01:02,596
什么是深度？

11
00:01:03,997 --> 00:01:08,202
那么要回答那个问题
让我们从如何捕捉深度开始讲

12
00:01:10,904 --> 00:01:17,511
深度只能从iPhone 7+上
和iOS 11上捕捉到

13
00:01:20,047 --> 00:01:22,850
iPhone 7+
有一个双摄像头系统

14
00:01:22,916 --> 00:01:27,487
可以用于同时捕捉同一场景的两个图像

15
00:01:27,554 --> 00:01:29,089
焦距也相同

16
00:01:30,424 --> 00:01:34,561
这两个图像之间的不同点叫作视差

17
00:01:36,463 --> 00:01:39,333
那么视差是视差效应的一个度量

18
00:01:39,399 --> 00:01:44,304
它衡量距离摄像头较近的对象
趋向于如何移动

19
00:01:45,038 --> 00:01:48,876
更多地从一个图像转换到另一个图像

20
00:01:49,776 --> 00:01:51,211
一旦我们了解了视差

21
00:01:51,278 --> 00:01:54,781
我们就可以通过简单的公式计算深度

22
00:01:55,516 --> 00:01:57,651
深度是视差分之一

23
00:01:59,520 --> 00:02:02,890
那么在接下来的演讲中 我们要

24
00:02:02,956 --> 00:02:06,827
在深度数据的广义定义下
谈谈深度或视差

25
00:02:06,960 --> 00:02:12,866
但请记住它们非常类似
并且一个是另一个的倒数

26
00:02:14,668 --> 00:02:17,538
要了解更多关于如何捕捉深度的信息

27
00:02:17,604 --> 00:02:21,909
我推荐你参看昨天举办的

28
00:02:21,975 --> 00:02:23,076
在iPhone摄影中捕捉深度演讲

29
00:02:24,611 --> 00:02:25,445
好的

30
00:02:26,980 --> 00:02:29,850
那么现在我们知道了
深度和视差的样子…

31
00:02:30,651 --> 00:02:33,187
抱歉 现在我们了解了
什么是深度和视差

32
00:02:33,253 --> 00:02:35,689
让我们在实际中看一看
它是什么样子的

33
00:02:35,756 --> 00:02:36,590
为此

34
00:02:36,657 --> 00:02:39,693
我要邀请我的同事Craig上台
给你们演示一下

35
00:02:39,860 --> 00:02:40,694
Craig

36
00:02:47,367 --> 00:02:48,569
谢谢 Etienne

37
00:02:49,503 --> 00:02:53,473
我们在这里看到的是一个
用iPhone 7+捕捉到的图像

38
00:02:55,309 --> 00:02:57,044
这是它的视差图

39
00:02:58,212 --> 00:02:59,046
我们已经了解到

40
00:02:59,112 --> 00:03:04,384
视差是指我们通过iPhone 7+
的双摄像头系统

41
00:03:04,451 --> 00:03:07,955
捕捉到的两个对应点之间的距离

42
00:03:09,122 --> 00:03:15,629
明亮区域距离摄像头更近
对应较高的视差值

43
00:03:15,696 --> 00:03:18,966
而深色区域距离摄像头稍远

44
00:03:19,032 --> 00:03:21,368
对应较低的视差值

45
00:03:22,903 --> 00:03:24,505
那么让我们返回到图像

46
00:03:25,205 --> 00:03:27,307
再次查看视差图

47
00:03:27,875 --> 00:03:30,410
我们可以放大一个区域

48
00:03:30,611 --> 00:03:33,347
但我们对于这种应用还有一个技巧

49
00:03:34,781 --> 00:03:38,519
如果我拖动我的手指
我们可以看到3D效果的数据

50
00:03:43,790 --> 00:03:45,893
我们可以放大仔细看一下

51
00:03:46,293 --> 00:03:49,029
可用数据的范围

52
00:03:49,096 --> 00:03:52,165
我们可以一直旋转并再次查看

53
00:03:53,100 --> 00:03:56,770
甚至可以切换回覆盖在
视差图顶部的图像数据

54
00:03:59,540 --> 00:04:01,375
那么让我们来看另一张图像

55
00:04:03,544 --> 00:04:05,412
这是一些漂亮的花

56
00:04:06,780 --> 00:04:09,416
当我放大并旋转时

57
00:04:10,050 --> 00:04:13,787
你可以看到我们需要用一些数据
填充这些多边形

58
00:04:13,854 --> 00:04:17,089
所以我们需要获取图像值
并把它们填充到那儿

59
00:04:17,958 --> 00:04:20,793
这就表明了一个事实 即深度数据

60
00:04:20,861 --> 00:04:25,265
并不是一个很好的表达
对于重现一个完全的3D场景

61
00:04:25,332 --> 00:04:28,135
但这个视图看起来仍然很有意思

62
00:04:29,469 --> 00:04:32,239
同时需要注意 视差图

63
00:04:32,306 --> 00:04:34,975
是一个比完整图像分辨率低的图

64
00:04:35,442 --> 00:04:38,045
视差图大约是50万像素

65
00:04:38,111 --> 00:04:40,280
而图像是1200万像素

66
00:04:41,815 --> 00:04:46,053
我们用SceneKit创建该应用
它让这种实施变得非常简单

67
00:04:46,386 --> 00:04:51,491
我们获取一个网格
然后转换了至高点的z位置

68
00:04:51,558 --> 00:04:55,295
因此较明亮的像素值距离摄像头更近

69
00:04:55,796 --> 00:04:57,898
同时我们也规范化和重新绘制了数据

70
00:04:57,965 --> 00:05:00,467
从而使我们可以以3D查看

71
00:05:02,603 --> 00:05:04,238
我们再来看一张图像

72
00:05:05,138 --> 00:05:08,675
在这张图像上 如果我们看一下
它的视差图会感到很有意思

73
00:05:08,742 --> 00:05:11,378
我们放大并稍微移动一点

74
00:05:11,445 --> 00:05:14,381
我们看到这里有一些明显的平面
需要处理

75
00:05:15,716 --> 00:05:18,318
那么为此 我们可能就有了这个想法

76
00:05:18,385 --> 00:05:21,021
即也许我们在为了获取
更戏剧性的效果而过滤它之前

77
00:05:21,088 --> 00:05:23,490
就量化深度数据或为其设置一个
临界线可能是个好主意

78
00:05:24,358 --> 00:05:27,728
为此 我要把舞台交还给
Etienne

79
00:05:34,535 --> 00:05:35,502
谢谢 Craig

80
00:05:38,205 --> 00:05:41,275
好的 那么现在我们
已经看到了深度和视差的样子

81
00:05:41,341 --> 00:05:45,012
我们可以用那个数据来应用
哪种效果呢？

82
00:05:45,445 --> 00:05:46,547
那么让我们来看一下

83
00:05:47,014 --> 00:05:50,384
这是一张示例图像及其视差图

84
00:05:52,686 --> 00:05:55,522
我们可以应用的一种效果是
深度模糊效果

85
00:05:55,589 --> 00:05:59,293
这是你可以通过纵向模式的摄像头

86
00:05:59,359 --> 00:06:01,328
实现的一个效果

87
00:06:03,730 --> 00:06:07,267
我们可以更有创造力一些 这是一个

88
00:06:07,334 --> 00:06:10,270
给背景和前景应用不同效果的示例

89
00:06:10,537 --> 00:06:12,739
在这里我们遣散了背景

90
00:06:12,806 --> 00:06:15,409
而给前景增加了色饱和度

91
00:06:15,475 --> 00:06:17,244
以突出显示这些花

92
00:06:19,379 --> 00:06:21,448
我们甚至可以做得更好

93
00:06:21,515 --> 00:06:25,752
那么在这里我们实际上认为
背景中的像素

94
00:06:25,819 --> 00:06:27,354
与深度是成比例的

95
00:06:28,355 --> 00:06:31,158
那么这只是几个例子

96
00:06:31,225 --> 00:06:34,494
帮助你大概了解一下
如何使用那个数据

97
00:06:34,928 --> 00:06:38,432
稍后我们会讲如何实现

98
00:06:40,133 --> 00:06:41,635
现在让我们看看谁能使用那个深度

99
00:06:42,636 --> 00:06:46,206
嗯 当然了 如果你正在编辑一个应用

100
00:06:46,273 --> 00:06:49,576
你现在可以使用深度来创建新的效果

101
00:06:49,643 --> 00:06:52,145
并给图像应用新的效果

102
00:06:52,913 --> 00:06:56,884
但如果你是一个摄像头应用
你还可以选择捕捉深度

103
00:06:57,384 --> 00:07:01,588
并给图像应用第一个深度效果

104
00:07:01,655 --> 00:07:04,091
例如你自己的深度模糊效果 比如说

105
00:07:05,559 --> 00:07:06,860
如果你是一个共享应用

106
00:07:06,927 --> 00:07:09,263
你可能还想利用深度

107
00:07:09,463 --> 00:07:13,200
来应用很酷的效果 在共享图像之前

108
00:07:14,735 --> 00:07:15,569
好的

109
00:07:15,903 --> 00:07:17,738
但在我们应用任何效果之前

110
00:07:17,804 --> 00:07:21,842
让我们看看如何读取深度数据
并把它加载到内存中

111
00:07:23,977 --> 00:07:25,179
那么让我们来看一下

112
00:07:25,946 --> 00:07:30,250
深度数据保存在图像文件中
与图像数据一起保存

113
00:07:30,317 --> 00:07:33,053
在一个叫作辅助数据的区域

114
00:07:34,988 --> 00:07:39,059
请注意系统中的[听不清]值图像

115
00:07:39,126 --> 00:07:41,662
比如UI图像和[听不清]图像
或[听不清]图像

116
00:07:41,728 --> 00:07:43,697
不包含深度信息

117
00:07:44,131 --> 00:07:47,701
你需要获取图像文件
以便读取深度数据

118
00:07:48,035 --> 00:07:49,570
那么让我们看看要如何实现

119
00:07:50,103 --> 00:07:51,738
如果你用的是PhotoKit

120
00:07:52,439 --> 00:07:54,908
有好几种获取图像文件的方式

121
00:07:55,542 --> 00:08:00,347
你可能用的是PH Content Editing输入
比如说

122
00:08:00,414 --> 00:08:02,015
这是如何向

123
00:08:02,082 --> 00:08:05,085
Content Editing输入
请求特定PHAsset的方式

124
00:08:05,853 --> 00:08:10,591
你可以用那种方式从Content Editing
输入中获取图像文件URL

125
00:08:12,960 --> 00:08:15,295
你还可能使用了
PH Image Manager

126
00:08:15,829 --> 00:08:18,899
你可以要求
PH Image Manager

127
00:08:18,966 --> 00:08:21,602
请求特定资产的图像数据

128
00:08:21,668 --> 00:08:26,340
那将给你返回一个数据对象
包含文件数据

129
00:08:27,875 --> 00:08:28,709
好的

130
00:08:29,243 --> 00:08:33,145
那么现在我们获取了一个文件
让我们看看它是否包含深度数据

131
00:08:33,212 --> 00:08:35,448
那么我们要使用ImageIO来查看

132
00:08:37,618 --> 00:08:40,988
从我们在图像文件中
创建的图像源开始看

133
00:08:42,256 --> 00:08:47,060
然后复制图像源属性

134
00:08:47,628 --> 00:08:51,431
这将给你返回一个词典 跟这个类似

135
00:08:52,533 --> 00:08:57,271
你要查看那个词典中的
kCKImage

136
00:08:57,337 --> 00:08:58,338
属性辅助数据键

137
00:08:58,405 --> 00:09:02,776
那个键的存在就是告诉你
你正在查看的图像文件

138
00:09:02,843 --> 00:09:04,411
包含辅助数据

139
00:09:05,279 --> 00:09:09,516
你可以查看数据类型
在这里你可以看到它的视差

140
00:09:09,583 --> 00:09:10,784
也可以是深度

141
00:09:11,618 --> 00:09:15,556
这里需要注意一点
即深度数据的维数

142
00:09:15,689 --> 00:09:19,493
比全尺寸图像的维数要小

143
00:09:20,160 --> 00:09:22,496
这是一个由iPhone 7+
捕捉的图像

144
00:09:22,563 --> 00:09:25,132
全尺寸图像是1200万像素

145
00:09:25,199 --> 00:09:29,903
深度数据可能小于100万像素

146
00:09:32,406 --> 00:09:33,407
好的

147
00:09:34,107 --> 00:09:36,877
那么现在我们知道我们有一个
带深度数据的文件

148
00:09:36,944 --> 00:09:39,279
让我们看看
我们要如何读取它[听不清]

149
00:09:43,483 --> 00:09:47,321
那么是这样的
我们从文件中的辅助数据开始

150
00:09:48,021 --> 00:09:50,290
然后我们创建一个AV深度数据对象

151
00:09:50,357 --> 00:09:53,327
它是深度数据的新内存表达

152
00:09:54,328 --> 00:09:58,165
我们可以从那个对象中
获取一个CV像素缓存

153
00:09:58,232 --> 00:10:00,133
它包含深度数据

154
00:10:01,268 --> 00:10:04,538
像素缓存是数据的一个单通道

155
00:10:05,038 --> 00:10:07,708
包含深度或视差

156
00:10:08,242 --> 00:10:11,478
是16位或32位的浮点值

157
00:10:14,281 --> 00:10:16,783
好的 那么让我们看看
如何在代码中实现

158
00:10:18,218 --> 00:10:20,120
我们从[听不清]开始

159
00:10:21,522 --> 00:10:26,360
接下来我们要复制
图像的[听不清]辅助数据

160
00:10:26,426 --> 00:10:30,163
那么为此 我们要请求一个
特定的辅助数据类型

161
00:10:30,264 --> 00:10:32,266
在这里我们请求的是视差

162
00:10:32,833 --> 00:10:37,104
这会给我们返回一个词典
其中包含辅助数据

163
00:10:38,005 --> 00:10:39,506
它还可以返回空

164
00:10:39,706 --> 00:10:41,942
那就表示图像文件

165
00:10:42,009 --> 00:10:46,980
不包含那种特定类型的辅助数据

166
00:10:47,047 --> 00:10:51,185
所以这是另一种查看文件
是否包含深度数据的方式

167
00:10:53,520 --> 00:10:58,091
接下来我们要从辅助数据中
创建一个AVDepth数据对象

168
00:10:58,258 --> 00:11:00,894
就是我们从ImageIO中
得到的表达

169
00:11:01,995 --> 00:11:05,098
并且那个AVDepth数据包含
你所请求的一对属性

170
00:11:05,165 --> 00:11:09,436
比如 你可以查看它的原生数据类型

171
00:11:09,837 --> 00:11:12,206
这是你可以查看的一个像素格式

172
00:11:12,272 --> 00:11:14,608
并且如果它不是你想要的格式

173
00:11:14,675 --> 00:11:18,979
你还可以把它转换为新的像素格式

174
00:11:19,046 --> 00:11:23,417
那么比如说 在这里我们请求
显示视差的16位浮点值

175
00:11:23,483 --> 00:11:27,254
因为我们也许会在GPU上使用视差图
比如说

176
00:11:27,788 --> 00:11:32,259
这将会返回一个正确格式的
新AV深度数据对象

177
00:11:32,659 --> 00:11:35,629
那么一旦你得到了
满意的深度数据对象

178
00:11:35,696 --> 00:11:40,133
你就可以使用深度数据图属性
获取一个CV像素缓存

179
00:11:41,301 --> 00:11:43,837
一旦你得到了CV像素缓存
你可以直接使用它

180
00:11:43,904 --> 00:11:46,607
或你可以通过Metal
或Core Image使用它

181
00:11:47,508 --> 00:11:49,443
如果你通过
Core Image使用它

182
00:11:49,510 --> 00:11:53,981
有一个便利的方式可以把深度数据
直接加载到CI图像中

183
00:11:54,047 --> 00:11:55,382
这是实现方式

184
00:11:55,949 --> 00:11:59,186
当你从文件内容中创建CI图像时

185
00:11:59,253 --> 00:12:01,121
你现在可以制定一个新选项

186
00:12:01,188 --> 00:12:06,293
比如kCCGCIImage
辅助深度或视差

187
00:12:06,360 --> 00:12:12,900
以指示CI加载深度图像
而不是常规图像

188
00:12:14,101 --> 00:12:15,802
一旦你得到了深度图像

189
00:12:16,637 --> 00:12:19,506
你总是可以返回到AV深度数据对象

190
00:12:19,573 --> 00:12:21,675
通过调用其深度数据属性

191
00:12:23,277 --> 00:12:25,479
请记住你总是能在

192
00:12:25,679 --> 00:12:29,917
视差和深度之间来回转换
通过便利的UCI过滤器

193
00:12:29,983 --> 00:12:32,219
比如CI Depth To Disparity

194
00:12:34,087 --> 00:12:34,922
好的

195
00:12:35,255 --> 00:12:40,460
那么现在我们已经从文件中
把深度数据读取到了图像中

196
00:12:40,661 --> 00:12:46,266
我们还需要几个步骤
在我们开始编辑它之前

197
00:12:47,367 --> 00:12:51,505
你还记得吧
深度数据的分辨率比图像低

198
00:12:51,605 --> 00:12:54,408
那么你要做的第一件事就是

199
00:12:54,474 --> 00:12:58,278
把它的分辨率调整为
你要处理的图像的分辨率

200
00:12:58,612 --> 00:13:01,515
有好几种方式可以实现
那么让我们来看一下

201
00:13:02,883 --> 00:13:06,153
这是我们的示例图像及其视差图

202
00:13:06,486 --> 00:13:10,490
那么如果我们调整它
假设调整这里的这个很小的部分

203
00:13:10,824 --> 00:13:12,326
使用近邻取样

204
00:13:12,593 --> 00:13:14,628
你可以看到它非常非常像素化

205
00:13:14,695 --> 00:13:15,696
那么至少

206
00:13:15,762 --> 00:13:19,066
你要应用线性取样
来获得更平滑的结果

207
00:13:19,933 --> 00:13:22,369
你还可以给
CI BiCubicScale Transform

208
00:13:22,436 --> 00:13:28,308
使用新的CI过滤器
来获取一个更加平滑的结果

209
00:13:28,942 --> 00:13:32,579
然而请注意深度数据不是颜色数据

210
00:13:32,880 --> 00:13:35,949
那么除了平滑 也许你还希望

211
00:13:36,016 --> 00:13:40,320
实际尽可能多地保存图像的具体信息

212
00:13:40,387 --> 00:13:43,724
以便深度数据更加匹配图像数据

213
00:13:43,790 --> 00:13:46,527
你可以通过一个便利的CI过滤器实现
叫作

214
00:13:46,593 --> 00:13:48,962
CI Edge Preserve
Upsample Filter

215
00:13:49,930 --> 00:13:55,802
这个过滤器可以上去样深度数据并尝试

216
00:13:55,869 --> 00:13:58,071
从彩色图像中保存边缘

217
00:14:00,207 --> 00:14:01,208
好的

218
00:14:01,775 --> 00:14:05,345
哦 还有一点你需要注意

219
00:14:06,046 --> 00:14:08,515
对于全部重新取样操作

220
00:14:08,582 --> 00:14:10,918
我们建议你使用视差而不是深度

221
00:14:10,984 --> 00:14:13,921
因为你会得到更好的结果

222
00:14:15,055 --> 00:14:15,889
好的

223
00:14:16,290 --> 00:14:19,193
你可能还想做几件事

224
00:14:20,160 --> 00:14:24,831
你可能想计算
深度数据的最小和最大值

225
00:14:26,733 --> 00:14:29,469
因为有很多时候你需要了解这些值

226
00:14:29,536 --> 00:14:32,739
以便获得你想要应用的特定效果

227
00:14:34,808 --> 00:14:38,579
同时请记住深度数据不是
0和1之间的规范值

228
00:14:38,645 --> 00:14:44,985
比如 视差值可以从0
意思是无穷大

229
00:14:45,452 --> 00:14:52,025
到大于1
对于距离摄像头不到1米的对象来说

230
00:14:53,126 --> 00:14:53,961
好的

231
00:14:56,029 --> 00:14:59,233
你可以做的另一件事就是
规范化深度数据

232
00:14:59,299 --> 00:15:00,501
一旦你知道了最小和最大值

233
00:15:00,567 --> 00:15:04,037
你就可以把深度数据或视差数据
规范化到0和1之间

234
00:15:04,104 --> 00:15:07,774
这非常便利 首先要让它可视化

235
00:15:07,841 --> 00:15:11,478
但你还可以

236
00:15:11,545 --> 00:15:14,481
在各种不同的场景间
应用一致的深度效果

237
00:15:14,748 --> 00:15:17,651
好的 那么现在我们
已经读取了我们的深度数据

238
00:15:17,718 --> 00:15:21,388
并做好进行编辑的准备了
我们可以开始过滤它了

239
00:15:23,190 --> 00:15:24,258
那么在这部分

240
00:15:24,324 --> 00:15:28,795
我们要展示一些
你可以实施的深度效果的例子

241
00:15:29,229 --> 00:15:31,465
我们要从简单的背景效果开始

242
00:15:31,532 --> 00:15:35,269
你可以通过内嵌的
Core Image过滤器实现

243
00:15:36,436 --> 00:15:40,140
然后我们要展示一些自定义深度效果

244
00:15:40,207 --> 00:15:42,476
你可以使用自定义
CI[听不清]代码实现

245
00:15:44,211 --> 00:15:47,080
然后我们要给你展示
如何应用你自己的深度模糊效果

246
00:15:47,147 --> 00:15:48,916
通过一个全新的CI过滤器

247
00:15:49,716 --> 00:15:50,717
最后

248
00:15:50,784 --> 00:15:55,522
我们要给你展示如何使用深度
创建一个全新的3D效果

249
00:15:55,589 --> 00:15:58,659
那么让我们从第一个开始讲
为此 我要邀请

250
00:15:58,725 --> 00:16:01,128
我的同事Stephen上台进行演示

251
00:16:01,395 --> 00:16:02,329
Stephen

252
00:16:07,167 --> 00:16:08,235
谢谢Etienne

253
00:16:08,635 --> 00:16:10,304
大家早上好 我叫Stephen

254
00:16:10,370 --> 00:16:14,875
现在Etienne已经给大家展示了
如何加载和准备你的深度数据

255
00:16:15,409 --> 00:16:18,912
深度数据
我很高兴能来这里给你们展示

256
00:16:18,979 --> 00:16:24,651
如何使用深度在你的图像上
实现一些新的和有意思的效果

257
00:16:25,385 --> 00:16:27,354
那么我们要看一个演示

258
00:16:29,957 --> 00:16:30,924
好的

259
00:16:31,358 --> 00:16:35,796
我们在这里看到的是
我在Photos应用中

260
00:16:36,129 --> 00:16:38,532
并且我要进入这里的编辑
编辑这张图像

261
00:16:38,599 --> 00:16:44,538
那么这里所实施的效果
是一种图片编辑扩展

262
00:16:47,574 --> 00:16:50,210
现在我们不看半成品了

263
00:16:50,911 --> 00:16:52,779
我们正在看的是原始图像

264
00:16:53,347 --> 00:16:54,448
没有经过任何编辑

265
00:16:54,515 --> 00:16:56,783
我要继续并打开效果

266
00:16:57,651 --> 00:17:00,888
你所看到的是我给图像应用了稀释效果

267
00:17:00,954 --> 00:17:02,956
但只给背景区域应用了这种效果

268
00:17:04,057 --> 00:17:07,394
我可以选择应用一种不同的背景效果

269
00:17:07,461 --> 00:17:09,896
在本例中 我选择了一个白化图像

270
00:17:10,230 --> 00:17:13,967
也许我并不是非常满意

271
00:17:14,034 --> 00:17:16,936
那个临界线是在背景和前景之间

272
00:17:17,003 --> 00:17:20,007
所以我可以通过轻触选择一个新临界线

273
00:17:20,674 --> 00:17:23,076
这都是基于深度数据实现的

274
00:17:24,411 --> 00:17:25,913
让我把它还原回来

275
00:17:25,979 --> 00:17:29,082
你可以清楚地看到

276
00:17:29,149 --> 00:17:31,952
在你认为是背景和前景之间
有一个非常尖锐的分界线

277
00:17:32,119 --> 00:17:34,121
实际上在两者之间有一个很窄的区域

278
00:17:34,188 --> 00:17:36,657
我们在两者之间稍微做了一点调配

279
00:17:36,857 --> 00:17:39,660
我可以控制那个混合区域的大小

280
00:17:40,360 --> 00:17:43,297
我可以通过缩放进行调整

281
00:17:43,363 --> 00:17:47,434
你可以看到它看起来像是一个
很漂亮的白雾效果

282
00:17:49,169 --> 00:17:53,740
我们已经通过使用混合遮罩
实现了这种效果

283
00:17:54,007 --> 00:17:56,343
让我给你展示一下
我们的混合遮罩是什么样的

284
00:17:57,544 --> 00:18:01,181
混合遮罩的黑色区域对应的是背景图像

285
00:18:01,248 --> 00:18:02,616
而纯白色对应的是前景

286
00:18:02,683 --> 00:18:05,752
然后它们之间的所有东西就是
我们给这两者之间所做的混合

287
00:18:06,186 --> 00:18:09,389
那么这是那个混合遮罩
随着我的缩放看起来的效果

288
00:18:09,656 --> 00:18:12,392
我们调整了那个混合的尺寸和斜率

289
00:18:13,594 --> 00:18:15,229
好的 让我们回到原始图像

290
00:18:15,362 --> 00:18:17,698
你们中有很多人都知道有许多内嵌的

291
00:18:17,764 --> 00:18:20,868
有意思的Core Image过滤器
我们可以选择应用

292
00:18:21,068 --> 00:18:22,669
我要给你展示一些其它的工具

293
00:18:22,736 --> 00:18:25,405
这是一个六边形像素化过滤器

294
00:18:26,707 --> 00:18:28,208
以及一个运动模糊过滤器

295
00:18:29,643 --> 00:18:34,014
假设我很满意
我就把它存到我的图库中

296
00:18:34,481 --> 00:18:37,184
好的 现在让我们谈谈
我们是如何实现的

297
00:18:41,588 --> 00:18:43,023
正如我所提到的

298
00:18:44,191 --> 00:18:47,261
我们通过创建混合遮罩
实现了这个效果

299
00:18:47,461 --> 00:18:50,030
那么我现在就谈谈我们
是如何创建那个混合遮罩的

300
00:18:50,097 --> 00:18:53,901
基本理念就是我们要把
规范化的视差值映射

301
00:18:54,067 --> 00:18:57,504
到0和1之间以便进行遮罩

302
00:18:58,572 --> 00:19:03,043
那么我们希望视差值高的区域
能在混合遮罩中映射为1

303
00:19:03,110 --> 00:19:05,379
这对应的是前景

304
00:19:06,413 --> 00:19:09,449
而视差值低的区域映射为0

305
00:19:09,516 --> 00:19:11,118
这对应的是背景区域

306
00:19:11,185 --> 00:19:15,322
然后中间的全部视差值
都与线性斜坡混合在一起

307
00:19:16,990 --> 00:19:18,959
创建这个混合遮罩的第一步

308
00:19:19,026 --> 00:19:23,830
就是在前景和后景之间选择临界线

309
00:19:24,464 --> 00:19:26,366
那么当用户轻触图像时

310
00:19:27,868 --> 00:19:30,604
我们要做的就是针对同一个位置

311
00:19:30,671 --> 00:19:31,972
取规范化视差图的样本

312
00:19:32,439 --> 00:19:36,310
并将其作为前景和背景之间的临界线

313
00:19:37,544 --> 00:19:40,214
现在我将展示这部分的代码

314
00:19:41,782 --> 00:19:44,451
这都是通过内嵌Core Image
过滤器实现的

315
00:19:44,518 --> 00:19:46,420
那么我首先要给你展示的是

316
00:19:46,486 --> 00:19:48,789
CI Area Min
Max Red过滤器

317
00:19:49,923 --> 00:19:52,759
这个过滤器
当你把它渲染到单像素中时

318
00:19:53,393 --> 00:19:56,330
它会返回图像的最大值和最小值

319
00:19:56,396 --> 00:19:58,332
在你所指定的范围内

320
00:19:58,398 --> 00:20:01,935
在这里我们传入了
用户轻触的那个小矩形区域

321
00:20:03,136 --> 00:20:06,573
关于这条线你需要注意的另一件事就是
在我们应用效果之前

322
00:20:06,707 --> 00:20:08,475
我们要锁住视差图

323
00:20:08,542 --> 00:20:11,678
以确保如果用户轻触图像的边缘区域

324
00:20:11,745 --> 00:20:14,381
我们不会取边界之外的任何清晰像素

325
00:20:15,883 --> 00:20:19,820
这行代码是我们只需要
分配一个4-字节缓存

326
00:20:19,887 --> 00:20:21,755
足够存储单像素即可

327
00:20:22,589 --> 00:20:24,858
并且我们会渲染到
这行代码的那个像素中

328
00:20:25,325 --> 00:20:27,794
请注意 我们传入了空
作为我们的颜色空间

329
00:20:27,861 --> 00:20:32,432
这就会告诉Core Image
我们不希望它执行任何的颜色管理

330
00:20:34,268 --> 00:20:35,169
最终

331
00:20:35,235 --> 00:20:38,772
我们从像素的绿色通道
读取最大视差值

332
00:20:39,139 --> 00:20:43,443
然后把它除以255
重新映射到0到1的范围内

333
00:20:46,780 --> 00:20:50,417
用户能控制的另外一个输入是尺寸
和混合区域的斜率

334
00:20:50,484 --> 00:20:53,187
那么用户缩放视图时

335
00:20:53,921 --> 00:20:56,423
我们会相应地调整尺寸和斜率

336
00:20:58,258 --> 00:21:05,199
这个映像是通过应用CI Color Matrix
过滤器得到的结果

337
00:21:05,265 --> 00:21:06,600
那么我稍后会展示给你看

338
00:21:06,767 --> 00:21:09,803
然后我们还应用了一个
CI Color Clamp

339
00:21:09,870 --> 00:21:14,208
以确保值保留在0到1的范围内

340
00:21:15,309 --> 00:21:16,376
那么这是代码

341
00:21:16,643 --> 00:21:19,379
首先我们应用CR Color Matrix过滤器

342
00:21:19,713 --> 00:21:24,218
它的输入基本上就是斜率和偏差

343
00:21:24,284 --> 00:21:26,854
是由用户通过轻触和缩放所选择的

344
00:21:27,454 --> 00:21:31,725
然后这一行代码中 我们应用了
CI Color Clamp过滤器

345
00:21:35,195 --> 00:21:37,764
现在我们已建好混合遮罩
余下的操作就很直接简单了

346
00:21:37,831 --> 00:21:40,634
你在左边看到的是原始图像

347
00:21:40,701 --> 00:21:44,271
你在右边看到的是给背景
应用了效果的图像

348
00:21:45,806 --> 00:21:48,342
当我们给原始图像应用混合遮罩时

349
00:21:49,076 --> 00:21:50,611
背景区域会消失

350
00:21:50,677 --> 00:21:53,714
当我们把它与背景图像混合在一起时

351
00:21:53,780 --> 00:21:55,082
我们就得到了最终的效果

352
00:21:55,649 --> 00:21:57,217
又是代码

353
00:21:59,386 --> 00:22:01,522
这是我们应用背景过滤器的位置

354
00:22:02,222 --> 00:22:04,358
你可以选择任意一款过滤器

355
00:22:04,424 --> 00:22:07,127
有许多内嵌的Core Image
你可以写你自己的

356
00:22:08,328 --> 00:22:11,131
然后我们应用了
CI Blend With Mask过滤器

357
00:22:11,665 --> 00:22:17,437
传入了背景图像和遮罩

358
00:22:18,071 --> 00:22:21,108
这就是我们如何实现这个效果的

359
00:22:21,175 --> 00:22:25,012
使用了一组内嵌
Core Image过滤器

360
00:22:25,579 --> 00:22:29,383
接下来我要给你们展示另一个演示

361
00:22:32,186 --> 00:22:38,292
之前的那个演示
我们简介使用了深度数据 对吧？

362
00:22:38,358 --> 00:22:40,928
我们用它来创建混合遮罩

363
00:22:41,295 --> 00:22:46,033
对于这个演示
我们要更为直接地使用视差

364
00:22:48,769 --> 00:22:52,406
我要打开这另一个编辑扩展给你们看

365
00:22:52,706 --> 00:22:54,474
好的 我们还是在Photos中

366
00:22:55,042 --> 00:22:57,211
让我们选择这下一个扩展

367
00:22:58,512 --> 00:22:59,379
好了

368
00:22:59,913 --> 00:23:02,583
原始图像 没有进行过任何编辑

369
00:23:03,150 --> 00:23:05,018
底部有一个滑块

370
00:23:05,419 --> 00:23:06,687
我现在要开始移动它了

371
00:23:06,753 --> 00:23:11,859
你可以看到背景逐渐变成了黑色

372
00:23:11,925 --> 00:23:14,294
只给我们留下了这个
突出显示的前景人物

373
00:23:14,528 --> 00:23:17,898
这是个很不错的效果
你不这么认为吗？

374
00:23:18,465 --> 00:23:23,237
让我们把它保存到图库中
让我来告诉你这是如何实现的

375
00:23:23,604 --> 00:23:26,340
我们所要做的是映射规范化的视差值

376
00:23:26,406 --> 00:23:30,277
为一个调节值 稍后直接用于像素上

377
00:23:31,211 --> 00:23:36,650
对于这种特定的效果 我们通过一个

378
00:23:36,717 --> 00:23:38,485
指数函数来映射视差值

379
00:23:38,719 --> 00:23:39,987
当我们开始时

380
00:23:40,420 --> 00:23:44,725
我们就把规范化的视差值提高到0

381
00:23:44,791 --> 00:23:48,562
那会把全部比例因子映射为1

382
00:23:48,896 --> 00:23:50,964
不会在输出图像中生产任何效果

383
00:23:52,199 --> 00:23:55,002
当我们移动滑块把值提高到1时

384
00:23:55,068 --> 00:23:57,504
这与通过深度的倒数
调整我们的像素强度

385
00:23:57,571 --> 00:24:02,543
所实现的是一样的效果

386
00:24:03,677 --> 00:24:06,380
因为我们正在直接调整视差

387
00:24:08,015 --> 00:24:09,283
效果变得更有意思了

388
00:24:09,349 --> 00:24:11,852
随着我们把它提高到越来越高的值

389
00:24:12,152 --> 00:24:12,986
正如你所看到的

390
00:24:13,053 --> 00:24:16,356
曲线的形状变了 在前景和背景之间

391
00:24:16,423 --> 00:24:18,025
有了一个更明显的区分

392
00:24:18,392 --> 00:24:20,861
后台迅速就变成了黑色

393
00:24:23,130 --> 00:24:26,600
那么我只需要一张幻灯片
就能给你展示这种效果的代码

394
00:24:26,700 --> 00:24:30,304
我们把这种效果作为一个自定义
CI Color Kernel实施

395
00:24:30,437 --> 00:24:31,972
关于使用自定义
CI Color Kernel

396
00:24:32,039 --> 00:24:34,274
有一些值得一提的好处

397
00:24:34,441 --> 00:24:35,909
其中一个就是性能

398
00:24:35,976 --> 00:24:39,980
如果你能按照自定义
CI Color Kernel表达效果

399
00:24:40,047 --> 00:24:42,015
Core Image就可以优化它

400
00:24:42,082 --> 00:24:44,718
通过把你的内核连接到其渲染曲线图中

401
00:24:45,552 --> 00:24:51,558
从而跳过任何潜在的消耗大的中间图像

402
00:24:52,926 --> 00:24:55,095
另外一个好处是

403
00:24:55,162 --> 00:24:59,399
Core Image
允许我们传入多个输入图像

404
00:24:59,466 --> 00:25:01,902
而Core Image
将会自动为我们取样

405
00:25:01,969 --> 00:25:05,472
并传入这些样本值
作为我们的内核函数的参数

406
00:25:05,539 --> 00:25:06,673
你可以在这里看到

407
00:25:06,740 --> 00:25:09,877
第一个参数是来自原始图像的样本

408
00:25:09,943 --> 00:25:12,379
第二个参数是来自
规范化视差图的样本

409
00:25:12,446 --> 00:25:16,183
然后第三个参数是由用户
通过移动滑块所选择的值

410
00:25:17,351 --> 00:25:19,186
对于规范化视差
我们要做的第一件事就是

411
00:25:19,253 --> 00:25:21,722
提高它的值 正如我所提到过的一样

412
00:25:21,955 --> 00:25:23,724
那就给我们提供了比例因子

413
00:25:24,558 --> 00:25:28,195
然后我们把比例因子
应用到像素的强度中

414
00:25:28,262 --> 00:25:30,297
同时保留原始阿尔法值

415
00:25:32,099 --> 00:25:34,668
这最后一行是Swift代码

416
00:25:35,369 --> 00:25:38,705
图解说明了我们要如何把我们的自定义
内核应用到原始图像中

417
00:25:38,772 --> 00:25:41,441
一旦从你刚在上边看到的源代码中
把它构建出来

418
00:25:41,508 --> 00:25:45,279
我们传入我们的图像范围以及参数列表

419
00:25:45,345 --> 00:25:48,882
在这里 这些是原始图像、
规范化的视差图

420
00:25:48,949 --> 00:25:50,484
和由用户所选择的值

421
00:25:50,551 --> 00:25:53,320
请注意这些参数一一对应

422
00:25:53,387 --> 00:25:56,123
我们的内核署名中定义有参数

423
00:25:57,624 --> 00:25:58,792
好的 就是这样

424
00:25:58,859 --> 00:26:01,828
我刚给你展示了如何使用自定义
CI Color Kernel

425
00:26:01,895 --> 00:26:04,698
来做出这个非常漂亮的暗化背景效果

426
00:26:05,465 --> 00:26:06,900
希望这可以给你一些提示

427
00:26:06,967 --> 00:26:09,703
关于你可以用自定义
CI Color Kernel

428
00:26:09,770 --> 00:26:12,072
结合深度可以生产哪些漂亮的效果

429
00:26:12,306 --> 00:26:14,308
现在我要邀请我们的同事Alex上台

430
00:26:14,374 --> 00:26:17,611
他会给大家展示
Core Image中的新功能

431
00:26:18,278 --> 00:26:19,146
Alex

432
00:26:24,585 --> 00:26:25,686
谢谢Stephen

433
00:26:26,386 --> 00:26:27,454
大家早上好

434
00:26:27,888 --> 00:26:31,091
我是Alexandre Naaman

435
00:26:31,158 --> 00:26:33,861
今天我要跟大家讲一个
新的Core Image过滤器

436
00:26:34,828 --> 00:26:38,932
在iOS 10中
使用iPhone 7+

437
00:26:39,099 --> 00:26:42,803
你可以使用深度功能捕捉图像

438
00:26:42,870 --> 00:26:45,506
通过摄像头应用和竖屏模式

439
00:26:46,540 --> 00:26:50,711
现在 在iOS 11和
Mac OS High Sierra中

440
00:26:51,144 --> 00:26:52,913
我们改进了这些功能

441
00:26:53,313 --> 00:26:55,816
你可以使用一模一样的算法

442
00:26:55,883 --> 00:26:59,086
通过一个叫作CI Depth Blur Effect的
新Core Image过滤器

443
00:26:59,786 --> 00:27:03,290
那么现在让我们尝试一下
切换到一个演示中

444
00:27:03,757 --> 00:27:05,359
看看实际是如何实现的

445
00:27:07,594 --> 00:27:09,930
哇 好的

446
00:27:09,997 --> 00:27:12,332
在这里我们有一个资产
一张带有深度数据的照片

447
00:27:12,399 --> 00:27:15,702
我们看到的图像
没有应用过任何过滤器

448
00:27:18,405 --> 00:27:20,040
如果我轻触一次

449
00:27:20,307 --> 00:27:23,076
我们可以看到视差数据是什么样子的

450
00:27:23,544 --> 00:27:26,213
我要再轻触一次
我们会返回到主图像

451
00:27:26,280 --> 00:27:27,648
如果我再轻触一次

452
00:27:28,048 --> 00:27:30,651
我们就会看到
当我们把这两个图像结合

453
00:27:30,717 --> 00:27:33,020
新的CI Depth
Blur Effect过滤器

454
00:27:33,086 --> 00:27:34,855
创建新渲染结果的效果

455
00:27:34,922 --> 00:27:36,590
我们应该看到背景模糊了

456
00:27:36,924 --> 00:27:37,758
哇

457
00:27:39,493 --> 00:27:43,997
那么除了这样应用过滤器

458
00:27:44,064 --> 00:27:46,700
我们还可以设置许多可调的参数

459
00:27:46,767 --> 00:27:48,535
在这个应用内部

460
00:27:48,602 --> 00:27:51,471
我所进行的设置是它会响应一些手势

461
00:27:51,538 --> 00:27:54,508
那么如果我现在 比如说缩放

462
00:27:54,775 --> 00:27:57,110
我们可以动态地修改光圈

463
00:27:57,544 --> 00:28:01,248
并得到一个新的模拟效果
那么我们可以模拟任意镜头孔径

464
00:28:01,315 --> 00:28:03,250
非常简单

465
00:28:05,786 --> 00:28:08,755
我在这个应用中设置的另一个手势是

466
00:28:08,822 --> 00:28:12,726
当我们轻触不同的位置时
它会修改焦点框

467
00:28:12,793 --> 00:28:16,063
那么我们现在可以看到光圈是非常大的

468
00:28:16,129 --> 00:28:18,232
只有前边的这位美女在焦点框中

469
00:28:18,298 --> 00:28:21,702
但如果我轻触左边的美女
她会立即出现在焦点框中

470
00:28:21,768 --> 00:28:23,537
背景变得稍微不那么模糊了

471
00:28:23,637 --> 00:28:25,873
右边的帅哥仍然有一点模糊

472
00:28:25,939 --> 00:28:29,109
我现在可以轻触他 再次修改焦点框

473
00:28:29,910 --> 00:28:34,681
现在他们三个都在焦点框中了
背景仍然模糊

474
00:28:35,849 --> 00:28:39,753
现在我们已经完成了演示
让我们看看这是如何实现的…

475
00:28:42,523 --> 00:28:43,524
看一下代码

476
00:28:46,894 --> 00:28:47,761
好的

477
00:28:50,697 --> 00:28:52,032
那么正如我所提到的

478
00:28:52,900 --> 00:28:56,503
在底层CI Depth Blur Effect
其实只有两个输入：

479
00:28:56,637 --> 00:28:59,039
输入图像和输入视差图

480
00:28:59,106 --> 00:29:02,509
通过这两个图像
Core Image会为你提取许多元数据

481
00:29:02,743 --> 00:29:07,915
应应用效果 以便渲染一个新图像

482
00:29:12,052 --> 00:29:12,886
然而在内部

483
00:29:12,953 --> 00:29:15,923
你可以设置许多参数
正如我之前提到过的那样

484
00:29:16,056 --> 00:29:17,558
我们已知道你可设置输入图像

485
00:29:17,624 --> 00:29:19,226
和输入视差图像

486
00:29:19,293 --> 00:29:21,929
在我们之前看到过的那种应用的示例中

487
00:29:23,497 --> 00:29:27,301
当我们轻触时
我们就设置了输入焦点框

488
00:29:28,202 --> 00:29:32,906
然后随着我们缩放 我们就设置了光圈

489
00:29:33,540 --> 00:29:37,144
那么现在我们从概念上
有了一个如何实现的想法

490
00:29:37,211 --> 00:29:40,380
让我们看看这是如何在代码中实现的

491
00:29:41,348 --> 00:29:45,185
实际上只有这一张幻灯片上有代码

492
00:29:45,252 --> 00:29:46,954
你可想而知它的使用有多么简单

493
00:29:47,554 --> 00:29:48,956
正如我们之前所看到的

494
00:29:49,289 --> 00:29:51,892
你可以非常简便地通过URL
加载CI Image

495
00:29:51,959 --> 00:29:53,493
这就提供了主图像

496
00:29:53,560 --> 00:29:55,529
然后为了获得视差图

497
00:29:55,596 --> 00:29:57,698
你所要做的就是使用那同一个URL

498
00:29:57,764 --> 00:30:02,469
并请求辅助视差信息

499
00:30:02,536 --> 00:30:05,205
通过词典选项
正如Etienne之前所提到的那样

500
00:30:06,273 --> 00:30:10,777
一旦我们得到了两个图像
我们就可以创建过滤器

501
00:30:11,144 --> 00:30:13,714
我们可以通过CI Depth
Blur Effect实现

502
00:30:13,780 --> 00:30:15,582
然后我们指定我们的两个图像

503
00:30:16,750 --> 00:30:17,951
一旦完成后

504
00:30:18,285 --> 00:30:21,788
我们就可以请求通过
.outputImage输出图像

505
00:30:21,855 --> 00:30:25,726
我们有一个新CI Image
我们可以以任意一种方式进行渲染

506
00:30:25,993 --> 00:30:27,194
有一点很重要

507
00:30:27,261 --> 00:30:29,997
CI Image其实只是
如何渲染的一个方法

508
00:30:30,063 --> 00:30:32,099
那么这其实是一个非常轻量级的对象

509
00:30:34,568 --> 00:30:36,904
在我们之前看到过的那种应用的示例中

510
00:30:37,437 --> 00:30:40,607
为了渲染新效果我们所要做的就是

511
00:30:40,807 --> 00:30:42,176
修改两个值

512
00:30:42,242 --> 00:30:44,578
那么在本例中 我们修改了输入光圈

513
00:30:44,645 --> 00:30:47,214
我们通过调用过滤器
setValue forKey实现

514
00:30:48,182 --> 00:30:52,819
并制定一个1到22之间的浮点值
以创建一个新的模拟光圈

515
00:30:53,353 --> 00:30:55,489
并且我们指定了一个新的焦点框

516
00:30:55,556 --> 00:30:58,659
就是我们想要聚焦的位置
通过输入焦点框键

517
00:30:58,725 --> 00:31:04,665
对应的是一个较低的基于左侧的拥有
规范化坐标的焦点框

518
00:31:06,200 --> 00:31:07,367
一旦完成这两件事

519
00:31:07,434 --> 00:31:09,703
我们可以请求过滤器提供新的输出图像

520
00:31:10,037 --> 00:31:13,774
然后按照我们的意愿进行渲染

521
00:31:16,143 --> 00:31:16,977
现在正如我提到的

522
00:31:17,044 --> 00:31:18,979
CoreImage通过检验元数据

523
00:31:19,046 --> 00:31:21,148
替你做了许多工作

524
00:31:21,515 --> 00:31:23,417
然而 你可以做一些工作

525
00:31:24,151 --> 00:31:28,422
以便进一步改善
我们没有为你自动进行的渲染

526
00:31:28,889 --> 00:31:32,392
这些与寻找面部特征有关

527
00:31:33,227 --> 00:31:36,697
为此 你可以使用我们的那个

528
00:31:36,763 --> 00:31:37,731
新视野框架

529
00:31:37,798 --> 00:31:41,435
那么通过视野框架
你可以获得左眼位置、

530
00:31:41,502 --> 00:31:45,806
右眼位置、鼻子位置和下巴位置

531
00:31:45,873 --> 00:31:49,743
你最多可以指定四张脸

532
00:31:49,810 --> 00:31:52,112
在CI Depth
Blur Effect内部使用

533
00:31:52,713 --> 00:31:55,682
在这张图像的示例中 因为有三张脸

534
00:31:55,749 --> 00:32:01,088
我们实际上要指定六个浮点值
到一个CI向量中

535
00:32:01,154 --> 00:32:03,490
并对我们所找到的每个特征进行设置

536
00:32:04,391 --> 00:32:07,594
有[听不清]
所以应该是xy、xy、xy

537
00:32:12,499 --> 00:32:14,168
接下来我要谈的是

538
00:32:14,234 --> 00:32:18,472
处理不同大小的渲染输出

539
00:32:21,775 --> 00:32:25,179
即使输入非常大 1200万像素

540
00:32:25,245 --> 00:32:27,648
有时候你并不总是渲染整张图像

541
00:32:27,981 --> 00:32:29,883
你可能希望下取样输出

542
00:32:30,517 --> 00:32:33,520
你的最初反应可能是下取样

543
00:32:33,720 --> 00:32:35,889
下取样CI Depth
Blur Effect的结果

544
00:32:35,956 --> 00:32:37,524
但这其实并不是很有效率

545
00:32:37,591 --> 00:32:40,794
因为从计算方面来讲CI Depth
Blur Effect代价非常昂贵

546
00:32:41,128 --> 00:32:44,698
相反 下取样输入会更有意义

547
00:32:45,966 --> 00:32:48,969
如果你这样做了 我们就可以利用

548
00:32:49,036 --> 00:32:52,372
输入图像较小的事实
并实施一些优化

549
00:32:53,373 --> 00:32:56,176
然而 为此你的确需要设置另一个参数

550
00:32:56,243 --> 00:32:57,845
叫作Input
Scale Factor

551
00:32:58,745 --> 00:33:01,882
那么在本例中
如果我们想从图像中下取样2个样本

552
00:33:01,949 --> 00:33:04,451
我们可以把输入比率因子设置为0.5

553
00:33:04,518 --> 00:33:08,021
这样做可以确保我们
从图像中适当地进行取样

554
00:33:08,088 --> 00:33:11,625
并考虑到其它效果 比如图像中的噪音

555
00:33:14,628 --> 00:33:17,531
关于使用CI Depth
Blur Effect

556
00:33:17,764 --> 00:33:20,901
我还想提其它几点 都很重要
你需要记住

557
00:33:21,502 --> 00:33:25,906
首先是当你创建你的CI情境时

558
00:33:26,306 --> 00:33:28,175
就是你要使用这些过滤器的情境

559
00:33:28,242 --> 00:33:31,245
你需要确保你使用的是
半浮点型中间体

560
00:33:31,311 --> 00:33:36,817
你可以通过把kCI Context Working
Format指定为RWAH实现

561
00:33:38,252 --> 00:33:42,089
在MacOS上这是默认的
但在iOS上我们默认使用8位浮点

562
00:33:42,155 --> 00:33:45,158
如果你不这样做
你将看到数据会被截掉一部分

563
00:33:45,225 --> 00:33:48,228
因为视差数据的范围扩展了

564
00:33:48,395 --> 00:33:49,630
如果不指定这个

565
00:33:49,696 --> 00:33:51,598
它会被截掉一部分
而结果看起来该不会很好

566
00:33:51,665 --> 00:33:53,567
所以当你使用这个过滤器时

567
00:33:53,634 --> 00:33:55,102
记得这样做非常重要

568
00:33:57,471 --> 00:33:59,506
正如我之前提到过的

569
00:34:00,174 --> 00:34:03,644
CI Depth Blur
Effect将自动在过滤器上设置

570
00:34:03,710 --> 00:34:06,246
许多属性

571
00:34:06,313 --> 00:34:10,117
为此 它将检验来自主图像的元数据

572
00:34:11,217 --> 00:34:16,690
以及存在于辅助图像内部的数据

573
00:34:16,757 --> 00:34:18,425
所以尝试把它

574
00:34:18,492 --> 00:34:20,393
保留在你的管道中很重要

575
00:34:20,460 --> 00:34:23,764
Core Image
将尽自己一切努力实现

576
00:34:23,830 --> 00:34:25,264
但在使用这个过滤器时

577
00:34:25,331 --> 00:34:26,567
你需要记住几点

578
00:34:26,632 --> 00:34:28,902
Etienne稍后会跟你们谈谈如何确保

579
00:34:28,969 --> 00:34:31,205
实现这个 当你保存图像时

580
00:34:33,674 --> 00:34:34,574
好的

581
00:34:34,641 --> 00:34:37,578
嗯 我今天要跟你们谈的
需要做的最后一件事

582
00:34:37,643 --> 00:34:41,681
与CI Depth Blur
Effect的某些内部构件有关

583
00:34:42,449 --> 00:34:45,385
今天我们已经提到好多次了

584
00:34:45,819 --> 00:34:49,723
主图像和视差图的分辨率差别很大

585
00:34:49,790 --> 00:34:51,058
现在内部

586
00:34:52,359 --> 00:34:56,362
Core Image将
上取样视差图到一个指定的点

587
00:34:56,429 --> 00:34:59,233
以便达到最终的结果

588
00:35:01,001 --> 00:35:04,071
这个区域是我们感觉
如果你有额外的处理时间

589
00:35:04,137 --> 00:35:06,607
你可能也许会做一些
不一样的效果的地方

590
00:35:06,840 --> 00:35:09,710
也许会采用
Etienne刚才提到的那几种方法

591
00:35:10,911 --> 00:35:13,647
那几乎总结了我要告诉你的一切

592
00:35:13,714 --> 00:35:15,749
关于使用CI Depth
Blur Effect

593
00:35:15,816 --> 00:35:18,485
我希望你们都开始
把它应用到你们的应用中

594
00:35:18,552 --> 00:35:20,487
那么我要把舞台交还给Etienne

595
00:35:20,554 --> 00:35:21,588
非常感谢

596
00:35:23,357 --> 00:35:24,191
谢谢Alex

597
00:35:27,227 --> 00:35:30,330
好的 那么目前我们已经看了一些
很有意思、很酷的新效果

598
00:35:30,397 --> 00:35:32,666
你可以使用深度数据来实现

599
00:35:33,200 --> 00:35:36,236
但深度数据其实是用作一个遮罩

600
00:35:36,303 --> 00:35:40,007
用于给图像的不同部分
应用不同的效果

601
00:35:40,340 --> 00:35:43,143
那么现在
我要给你们讲一些不一样的东西

602
00:35:44,378 --> 00:35:47,681
就是实际上把深度用作第三维度

603
00:35:48,382 --> 00:35:51,218
这就给你提供了你可以使用这个数据

604
00:35:51,285 --> 00:35:53,520
应用哪些新的创造性效果的概念

605
00:35:53,954 --> 00:35:57,891
关于这一点
我要邀请Stephen上台来谈谈

606
00:35:57,958 --> 00:35:58,792
Stephen

607
00:36:03,463 --> 00:36:04,398
谢谢 Etienne

608
00:36:05,499 --> 00:36:06,400
很高兴我又回来了

609
00:36:06,466 --> 00:36:08,335
我现在要展示给你的是

610
00:36:09,136 --> 00:36:11,438
一个真实的3D效果

611
00:36:12,940 --> 00:36:16,343
我们要展示给你的这种特定的效果
叫作滑动变焦

612
00:36:16,410 --> 00:36:19,213
你们种很可能有很多人
已经很熟悉滑动变焦了

613
00:36:19,279 --> 00:36:21,448
特别是如果你看过恐怖电影的话

614
00:36:22,015 --> 00:36:24,017
但为了让每个人都了解

615
00:36:24,284 --> 00:36:27,821
我要给你展示一个小动画
关于滑动变焦是怎么回事

616
00:36:28,121 --> 00:36:29,756
那么你在这里看到的

617
00:36:30,490 --> 00:36:33,026
是一个由三个球体组成的场景

618
00:36:33,727 --> 00:36:36,697
摄像头正在前后滑动

619
00:36:37,030 --> 00:36:40,167
它的这种滑动方式

620
00:36:40,234 --> 00:36:42,669
同时也约束了视野

621
00:36:42,769 --> 00:36:47,040
因此焦面中间的灰色球体

622
00:36:47,174 --> 00:36:49,910
在输出图像中几乎保持了同样的大小

623
00:36:49,977 --> 00:36:53,213
在整个效果过程中 你可以在右边看到

624
00:36:53,280 --> 00:36:55,582
场景中的其它东西都在移动

625
00:36:55,649 --> 00:36:57,484
由于视角效果

626
00:36:58,785 --> 00:37:00,320
那么让我们来看一下

627
00:37:00,888 --> 00:37:02,990
让我们切换到设备上

628
00:37:03,557 --> 00:37:04,591
完美

629
00:37:05,826 --> 00:37:06,793
好的

630
00:37:09,196 --> 00:37:12,299
让我打开滑动变焦编辑扩展

631
00:37:14,401 --> 00:37:15,802
我现要让你们的注意力

632
00:37:15,869 --> 00:37:18,705
集中到图像中间的花丛上

633
00:37:18,772 --> 00:37:20,941
它们是在焦面上

634
00:37:21,508 --> 00:37:23,577
那么我开始移动摄像头

635
00:37:25,479 --> 00:37:29,650
你可以看到整个滑动变焦效果

636
00:37:30,217 --> 00:37:32,586
特别是当我把摄像头拉到这个方向时

637
00:37:32,653 --> 00:37:35,455
你实际上可以看到
这个效果的真3D性质

638
00:37:35,522 --> 00:37:38,592
前景中的花其实是弹出来一样

639
00:37:38,659 --> 00:37:42,429
而背景看起来像是逐渐减弱
或逐渐从摄像头的位置拉开

640
00:37:42,963 --> 00:37:45,599
你还可以看到我们参与的痕迹
当然了

641
00:37:45,666 --> 00:37:46,633
其中一个就是

642
00:37:46,700 --> 00:37:50,938
你在背景周围所看到的黑色像素

643
00:37:51,538 --> 00:37:54,875
这是由于摄像头的当前配置

644
00:37:54,942 --> 00:37:58,278
是虚拟摄像头 它的视野

645
00:37:58,412 --> 00:38:01,281
比捕捉这张图像的iPhone要宽

646
00:38:01,915 --> 00:38:05,052
所以虚拟摄像头看到的场景

647
00:38:05,118 --> 00:38:07,521
比iPhone捕捉图像时
看到的场景要多

648
00:38:07,654 --> 00:38:10,157
所以我们就把那些像素填充为黑色

649
00:38:10,891 --> 00:38:14,761
类似地 你所看到的前景花丛中的拉伸

650
00:38:14,828 --> 00:38:17,764
和花后面绿叶的拉伸
都是由于这个摄像头

651
00:38:17,831 --> 00:38:20,200
是虚拟摄像头的原因 曝光了

652
00:38:20,267 --> 00:38:23,036
在iPhone捕捉图像时
不可见的部分场景

653
00:38:24,404 --> 00:38:28,175
要解决这些问题
你可以采取的一个策略是

654
00:38:28,675 --> 00:38:30,911
设置一个新的焦面

655
00:38:31,245 --> 00:38:34,948
那么现在我轻触了一下前景中的黄花

656
00:38:35,015 --> 00:38:37,150
位于图像的右下角

657
00:38:37,451 --> 00:38:39,720
我把它设为焦面

658
00:38:39,853 --> 00:38:42,956
现在随着我以这个方向移动摄像头
你可以看到

659
00:38:43,790 --> 00:38:45,826
没有任何黑色像素进入视野

660
00:38:45,893 --> 00:38:50,430
当然了 如果我再次以这个方向
移动摄像头 它们再次进入视野了

661
00:38:50,597 --> 00:38:53,066
那种3D效果真的非常强大

662
00:38:55,269 --> 00:38:58,372
相应地 我可以轻触图像的背景区域

663
00:38:58,438 --> 00:39:01,141
比如你在右上角看到的树

664
00:39:01,742 --> 00:39:04,745
并且当我现在以这个方向拉动摄像头时

665
00:39:06,146 --> 00:39:09,750
真的产生了一种非常漂亮的突显效果

666
00:39:09,816 --> 00:39:12,319
突显了中间的花丛

667
00:39:12,753 --> 00:39:14,421
那么现在让我们看一下

668
00:39:14,488 --> 00:39:17,524
由于这个问题的真3D性质

669
00:39:18,492 --> 00:39:21,528
我们要通过Metal来看
作为一个真3D工具

670
00:39:21,628 --> 00:39:25,332
来获得这种效果 来生产这种效果

671
00:39:25,432 --> 00:39:29,036
在Metal中我们可以
非常快速地打开并启动我们的系统

672
00:39:29,102 --> 00:39:31,405
因为它替我们做了全部的工作

673
00:39:32,105 --> 00:39:33,740
基本上来说 我们所需要做的

674
00:39:34,775 --> 00:39:37,911
首先构建一个

675
00:39:38,011 --> 00:39:40,013
映像到图像上的三角网格

676
00:39:40,080 --> 00:39:43,217
跟你在演讲一开始看到的

677
00:39:43,283 --> 00:39:44,885
Craig的Depth Explorer
演示非常类似

678
00:39:45,485 --> 00:39:50,991
我们让图像在原点居中

679
00:39:52,192 --> 00:39:53,927
Metal还可以让我们

680
00:39:53,994 --> 00:39:57,231
编码它的管道的几个阶段

681
00:39:57,297 --> 00:39:59,099
其中一个是顶点着色器

682
00:39:59,166 --> 00:40:02,269
顶点着色器的作用是可以我们

683
00:40:02,336 --> 00:40:05,372
以某种方式处理场景中的几何结构

684
00:40:06,340 --> 00:40:08,642
我们还可以编码片段着色器

685
00:40:08,709 --> 00:40:14,314
这样我们可以在输出中
给每个像素生产一个颜色

686
00:40:15,782 --> 00:40:18,418
我们可以把全部这个
3D Metal渲染恢复到

687
00:40:18,485 --> 00:40:23,023
Core Image管道中 通过使用
CI Image Processor Kernel

688
00:40:25,359 --> 00:40:27,995
那么这是顶点着色器的代码

689
00:40:30,163 --> 00:40:33,166
顶点着色器的作用是
处理几何结构

690
00:40:33,233 --> 00:40:35,269
它一次只能处理一个顶点

691
00:40:35,335 --> 00:40:38,438
那么我们获取到原始网格的一个顶点
作为输入

692
00:40:38,872 --> 00:40:41,008
然后我们会在输出中生产一些新东西

693
00:40:41,074 --> 00:40:47,314
在顶点着色器中我们要做的第一件事
就是在那个顶点对深度取样

694
00:40:47,748 --> 00:40:50,918
就是你在这里看到的这行代码
我们把它存在一个叫作z的变量中

695
00:40:50,984 --> 00:40:53,587
将会在这个着色器中多次使用

696
00:40:54,254 --> 00:40:57,891
首先是用在这里的这行
有魔力的代码行中

697
00:40:57,958 --> 00:41:00,360
这行代码就是每个年轻的工程师

698
00:41:00,427 --> 00:41:02,229
在成长过程中梦想着他们将来
有一天能写出来的那种代码

699
00:41:02,296 --> 00:41:04,431
因为这是我们进行数学运算的代码

700
00:41:05,632 --> 00:41:10,170
在这个方程式中有三个变量作为输入

701
00:41:10,771 --> 00:41:13,073
一个是深度 就是我们刚才取样的深度

702
00:41:13,140 --> 00:41:15,542
其它两个与焦面的用户输入

703
00:41:15,609 --> 00:41:19,112
和摄像头的配置一致

704
00:41:20,380 --> 00:41:26,687
这会生产一个比例因子
我们可以应用到顶点中

705
00:41:27,621 --> 00:41:29,523
我们是在这行代码中实现的

706
00:41:29,723 --> 00:41:31,892
我们可以给它应用一个比例因子

707
00:41:32,025 --> 00:41:35,696
因为顶点是围绕原点居中的

708
00:41:35,762 --> 00:41:39,066
那么这个比例因子的作用是移动顶点

709
00:41:39,132 --> 00:41:43,036
放射状地远离中心或朝图像中心移动

710
00:41:43,337 --> 00:41:46,907
这就是生产三维错觉的代码

711
00:41:48,375 --> 00:41:50,511
一旦我们转换了我们的顶点位置

712
00:41:50,577 --> 00:41:53,180
我们就把它输出到这里的新输出顶点中

713
00:41:53,447 --> 00:41:56,250
并保存原始深度值z

714
00:41:56,316 --> 00:41:57,384
这非常重要

715
00:41:57,451 --> 00:42:00,721
因为它会被传到Metal的
z缓存机器中

716
00:42:00,821 --> 00:42:02,756
然后那会替我们做正确的操作

717
00:42:02,823 --> 00:42:06,059
随着像素在输出中移动
并开始相互重叠

718
00:42:07,828 --> 00:42:11,765
同时我们会输出原始顶点的纹理坐标

719
00:42:12,199 --> 00:42:14,268
片段着色器会使用这个坐标

720
00:42:14,601 --> 00:42:15,669
我现在就展示给你看

721
00:42:17,871 --> 00:42:22,276
请记住片段着色器的作用是
做出颜色像素输出

722
00:42:23,243 --> 00:42:29,082
因为Metal替我们插入了
全部这些纹理坐标

723
00:42:29,416 --> 00:42:33,153
我们在片段着色器中所要做的就是
对原始图像取样

724
00:42:33,320 --> 00:42:35,255
在插入的纹理坐标处

725
00:42:35,889 --> 00:42:38,559
就是这样 这就是你需要看的全部代码

726
00:42:38,792 --> 00:42:40,327
为了实施滑动变焦效果

727
00:42:40,661 --> 00:42:42,829
我希望这会给你们提供一些想法

728
00:42:42,896 --> 00:42:45,265
关于用它

729
00:42:45,332 --> 00:42:48,202
来生产你自己的
全新自定义3D效果的新方向

730
00:42:48,268 --> 00:42:50,737
我们非常激动地期待看到你们的产品

731
00:42:51,004 --> 00:42:56,476
现在我要把舞台交还给Etienne

732
00:43:02,182 --> 00:43:03,050
谢谢Stephen

733
00:43:04,151 --> 00:43:05,018
好的

734
00:43:05,085 --> 00:43:09,289
那么现在我们已经给图像
应用了各种新效果

735
00:43:09,356 --> 00:43:11,525
我们还需要做一步操作

736
00:43:11,625 --> 00:43:13,627
就是保存你的深度数据

737
00:43:16,430 --> 00:43:19,900
那么你应该总是保留深度数据

738
00:43:20,467 --> 00:43:24,872
对吧？那样你的用户就可以使用
其它与你的应用类似的应用

739
00:43:24,938 --> 00:43:27,875
在你的图像效果的顶层来实施
他们自己的深度效果

740
00:43:28,609 --> 00:43:30,644
即便你不使用深度数据

741
00:43:30,711 --> 00:43:34,314
你也应该总是保留它
如果它存在于原始图像中的话

742
00:43:35,682 --> 00:43:39,386
那将真的确保你的用户
获得尽可能好的体验

743
00:43:40,087 --> 00:43:42,422
然而 当你保存深度数据时

744
00:43:42,489 --> 00:43:45,893
一定要匹配图像数据的几何结构

745
00:43:46,660 --> 00:43:48,829
如果你不想正确地应用几何结构

746
00:43:49,029 --> 00:43:51,798
深度数据将永远与图像数据不匹配

747
00:43:51,865 --> 00:43:54,668
因此应用在它顶层的进一步的深度效果

748
00:43:54,735 --> 00:43:56,236
也永远不能很好地实现

749
00:43:57,137 --> 00:44:00,274
那么让我们看一下这种几何转换

750
00:44:00,340 --> 00:44:02,776
是如何应用到深度数据上的

751
00:44:04,878 --> 00:44:07,381
一种很常见的操作是定向

752
00:44:07,548 --> 00:44:10,050
你要经常处理竖屏图像

753
00:44:10,117 --> 00:44:13,954
而那其实是在横屏模式下拍摄的
并且有一个[听不清]定向

754
00:44:14,988 --> 00:44:17,424
那么深度数据可能看起来像这样

755
00:44:17,491 --> 00:44:21,295
那么你也希望确保定向深度数据

756
00:44:21,361 --> 00:44:23,230
那么一定要确保应用定向

757
00:44:23,964 --> 00:44:27,668
另一个很常见的操作是剪裁 对吧？

758
00:44:27,901 --> 00:44:32,239
一定要确保你剪裁深度数据以进行匹配

759
00:44:33,540 --> 00:44:35,642
现在你可能有了一个更高级的转换

760
00:44:35,709 --> 00:44:37,211
你可能也想应用到图像上

761
00:44:37,511 --> 00:44:40,047
比如[听不清]转换 就像这个一样

762
00:44:40,814 --> 00:44:43,450
好的 或者也许你有一个
自定义[听不清]转换

763
00:44:43,517 --> 00:44:47,087
比如视角转换 或也许甚至是3D转换

764
00:44:47,154 --> 00:44:49,623
就像我们在滑动变焦演示中
看到的那个一样

765
00:44:50,924 --> 00:44:54,561
在任何情况下
你也想给深度数据应用同样的转换

766
00:44:54,628 --> 00:44:56,864
以便它能完美地匹配图像数据

767
00:44:59,566 --> 00:45:00,400
好的

768
00:45:00,467 --> 00:45:02,269
那么这里要记住的关键点是

769
00:45:02,336 --> 00:45:03,804
以深度数据的原生分辨率

770
00:45:03,871 --> 00:45:06,573
应用你的转换

771
00:45:07,474 --> 00:45:09,476
那么你想调整你的转换参数

772
00:45:09,543 --> 00:45:13,480
从全尺寸图像
转换到深度图像的那个尺寸

773
00:45:17,117 --> 00:45:18,285
否则 好的

774
00:45:18,352 --> 00:45:20,754
你将实现错误的转换

775
00:45:20,821 --> 00:45:24,858
然后深度图像不再匹配图像了

776
00:45:24,958 --> 00:45:26,093
我说的是输出图像

777
00:45:27,261 --> 00:45:30,163
另一件需要注意的事就是
深度数据不是颜色数据

778
00:45:30,230 --> 00:45:32,733
那么当你渲染新的深度图像时

779
00:45:32,799 --> 00:45:35,802
确保不要给它应用任何一种颜色匹配

780
00:45:38,205 --> 00:45:39,106
好的

781
00:45:39,773 --> 00:45:43,911
那么现在 我们已经看到了
我们可以给深度数据应用哪些转换

782
00:45:43,977 --> 00:45:46,847
我们可以把它渲染到一个
新的CV像素缓存中

783
00:45:47,347 --> 00:45:49,683
一旦我们拥有一个新的CV像素缓存

784
00:45:49,883 --> 00:45:52,286
我们就可以从中创建一个
新的深度数据对象

785
00:45:52,352 --> 00:45:53,220
这是实现方式

786
00:45:53,453 --> 00:45:55,989
我们从原始深度数据对象着手

787
00:45:56,223 --> 00:45:59,059
然后我们通过替换Depth Data Map
来编码Depth Data

788
00:45:59,126 --> 00:46:01,662
并且我们传入所有新渲染的深度缓存

789
00:46:02,362 --> 00:46:05,165
现在返回了一个新的AV深度数据对象

790
00:46:05,232 --> 00:46:08,902
我们可以把它存到我们的输出图像中

791
00:46:09,236 --> 00:46:12,539
让我们看看如何
使用Image IO写深度数据

792
00:46:14,808 --> 00:46:19,479
我们从未我们的输出文件
创建的图像目的地着手

793
00:46:20,781 --> 00:46:22,816
在这里我们请求JPEG格式

794
00:46:22,883 --> 00:46:26,153
那么请注意 并不是指来自于那个
[听不清]深度的所有图片

795
00:46:26,220 --> 00:46:27,588
而是JPEG

796
00:46:28,488 --> 00:46:31,625
接下来我们要把我们的输出图像
添加到图像目的地

797
00:46:33,760 --> 00:46:37,698
然后我们向要存储到
图像中的所有深度数据对象请求

798
00:46:37,764 --> 00:46:39,499
词典表达

799
00:46:39,566 --> 00:46:42,002
表达要存储在文件中的辅助数据

800
00:46:42,369 --> 00:46:45,305
那么这将会给词典返回辅助数据

801
00:46:45,372 --> 00:46:49,009
以及要存储的辅助数据类型 以供参考

802
00:46:49,910 --> 00:46:53,847
然后我们请求CG图像目的地
添加那个辅助数据

803
00:46:53,914 --> 00:46:56,183
传递类型和词典

804
00:46:56,850 --> 00:47:00,487
最后我们所要做的就是
调用CG图像目的地结束

805
00:47:00,554 --> 00:47:02,189
以在磁盘中写入这一切

806
00:47:03,690 --> 00:47:05,893
如果你正在用Core Image

807
00:47:05,959 --> 00:47:10,764
有一个很便利的实现方式

808
00:47:10,831 --> 00:47:16,069
那么如果你正在用CI情境
[听不清]JPEG 带有图像表达

809
00:47:16,136 --> 00:47:18,438
直接表达一个特定的CI图像

810
00:47:18,505 --> 00:47:21,375
以便渲染并保存到一个JPEG文件

811
00:47:21,575 --> 00:47:25,779
你现在可能可以使用一个选项键传递

812
00:47:25,846 --> 00:47:29,016
还有一个你想要存起来作为
那个文件的一部分的深度数据对象

813
00:47:30,651 --> 00:47:31,685
更棒的是

814
00:47:32,686 --> 00:47:36,223
如果你有一个带深度图像的图像

815
00:47:36,290 --> 00:47:38,659
假设你给它应用了一种转换或什么东西

816
00:47:38,825 --> 00:47:44,398
你还可以把它指定为
那个方法的一个选项

817
00:47:44,464 --> 00:47:49,336
从而Core Image既会渲染
常规图像又会渲染深度图像

818
00:47:49,403 --> 00:47:53,207
并把一切都保存到文件中
这只需要一次调用

819
00:47:53,273 --> 00:47:54,408
非常方便

820
00:47:55,542 --> 00:47:59,479
那么就是这样 这就结束了我们这场
用深度编辑图像的演讲

821
00:48:00,080 --> 00:48:02,082
那么让我们回顾一下
我们今天学到的内容

822
00:48:03,116 --> 00:48:07,221
我们了解了什么是深度以及深度
和视差分别是什么样子的

823
00:48:09,089 --> 00:48:12,559
我们了解了如何读取
和准备深度数据用于编辑

824
00:48:13,560 --> 00:48:17,364
然后我们了解了

825
00:48:17,431 --> 00:48:20,501
给图像应用新深度效果的几种方式

826
00:48:20,567 --> 00:48:25,005
第一个是背景效果 使用内嵌的
Core Image过滤器

827
00:48:25,272 --> 00:48:29,343
然后我们有一个自定义暗化效果使用
一个自定义Core Image内核

828
00:48:29,943 --> 00:48:33,413
然后我们给你展示了
如何应用你自己的深度效果

829
00:48:33,480 --> 00:48:35,782
使用一个新CI过滤器

830
00:48:36,550 --> 00:48:41,588
然后我们了解了如何使用
深度创建全新的3D效果

831
00:48:42,489 --> 00:48:44,491
我们希望这场演讲可以激励你

832
00:48:44,558 --> 00:48:46,960
在你自己的应用中使用深度数据

833
00:48:47,027 --> 00:48:49,329
且我几乎迫不及待要看到
你们所做出的效果了

834
00:48:49,863 --> 00:48:51,198
要获取更多信息

835
00:48:51,265 --> 00:48:53,333
请参看developer.apple.com

836
00:48:54,568 --> 00:48:56,370
我们还有一些相关的演讲

837
00:48:56,703 --> 00:48:59,306
今天晚些时候有一场关于

838
00:48:59,373 --> 00:49:01,308
“Core Image新进展”
的演讲

839
00:49:01,375 --> 00:49:03,710
我们强烈推荐你们参加这场演讲

840
00:49:03,844 --> 00:49:04,711
去看看

841
00:49:04,778 --> 00:49:08,148
昨天还有几场演讲

842
00:49:08,215 --> 00:49:09,650
讲的是Photo Kit

843
00:49:09,716 --> 00:49:13,487
以及如何用iPhone捕捉深度

844
00:49:14,087 --> 00:49:17,457
就这样了
我希望你们享受WWDC剩下的大会

845
00:49:17,524 --> 00:49:18,458
非常感谢

