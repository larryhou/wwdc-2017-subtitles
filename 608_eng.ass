[Script Info]
; Script generated by FFmpeg/Lavc57.89.100
ScriptType: v4.00+
PlayResX: 384
PlayResY: 288

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,16,&Hffffff,&Hffffff,&H0,&H0,0,0,0,0,100,100,0,0,1,1,0,2,10,10,10,0

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:30.08,0:00:32.01,Default,,0,0,0,,welcome to our talk on using
Dialogue: 0,0:00:32.01,0:00:32.95,Default,,0,0,0,,Metal 2 for Compute.
Dialogue: 0,0:00:33.89,0:00:35.30,Default,,0,0,0,,My name is Anna Tikhonova.
Dialogue: 0,0:00:35.30,0:00:36.69,Default,,0,0,0,,I'm an engineer on the GPU
Dialogue: 0,0:00:36.69,0:00:37.98,Default,,0,0,0,,Software Team, so let's begin.
Dialogue: 0,0:00:42.16,0:00:44.05,Default,,0,0,0,,The Metal 2 echo system is so
Dialogue: 0,0:00:44.05,0:00:45.84,Default,,0,0,0,,much more than the Metal API and
Dialogue: 0,0:00:45.84,0:00:46.36,Default,,0,0,0,,the language.
Dialogue: 0,0:00:46.80,0:00:48.95,Default,,0,0,0,,We also have the GPU Tools and
Dialogue: 0,0:00:48.95,0:00:50.34,Default,,0,0,0,,we have the MetalKit and Metal
Dialogue: 0,0:00:50.34,0:00:51.59,Default,,0,0,0,,Performance Shaders frameworks.
Dialogue: 0,0:00:53.01,0:00:54.15,Default,,0,0,0,,You might know Metal as this
Dialogue: 0,0:00:54.50,0:00:56.38,Default,,0,0,0,,great technology for developing
Dialogue: 0,0:00:56.38,0:00:57.57,Default,,0,0,0,,high-end games and graphics.
Dialogue: 0,0:00:58.40,0:00:59.62,Default,,0,0,0,,But it can also be used for
Dialogue: 0,0:00:59.62,0:01:00.51,Default,,0,0,0,,Compute processing.
Dialogue: 0,0:01:01.63,0:01:02.81,Default,,0,0,0,,In fact, the Compute side of
Dialogue: 0,0:01:02.81,0:01:04.62,Default,,0,0,0,,Metal is so powerful and
Dialogue: 0,0:01:04.62,0:01:06.53,Default,,0,0,0,,flexible that the Metal
Dialogue: 0,0:01:06.53,0:01:08.20,Default,,0,0,0,,Performance Shaders framework is
Dialogue: 0,0:01:08.20,0:01:09.33,Default,,0,0,0,,built completely on top of
Dialogue: 0,0:01:09.41,0:01:09.76,Default,,0,0,0,,Compute.
Dialogue: 0,0:01:11.03,0:01:12.49,Default,,0,0,0,,And in this session, we'll talk
Dialogue: 0,0:01:12.49,0:01:14.08,Default,,0,0,0,,about what's new in the Metal
Dialogue: 0,0:01:14.08,0:01:15.18,Default,,0,0,0,,Performance Shaders framework.
Dialogue: 0,0:01:17.96,0:01:19.60,Default,,0,0,0,,We introduced the Metal
Dialogue: 0,0:01:19.60,0:01:21.03,Default,,0,0,0,,Performers Shaders framework, or
Dialogue: 0,0:01:21.03,0:01:22.76,Default,,0,0,0,,MPS in 2015.
Dialogue: 0,0:01:23.49,0:01:24.55,Default,,0,0,0,,And the videos of our past
Dialogue: 0,0:01:24.55,0:01:25.92,Default,,0,0,0,,sessions are available on our
Dialogue: 0,0:01:25.92,0:01:28.91,Default,,0,0,0,,developer website.
Dialogue: 0,0:01:29.27,0:01:30.69,Default,,0,0,0,,MPS uses the compute power of
Dialogue: 0,0:01:30.69,0:01:33.45,Default,,0,0,0,,the GPU to bring GPU accelerated
Dialogue: 0,0:01:33.45,0:01:33.82,Default,,0,0,0,,primitives.
Dialogue: 0,0:01:34.29,0:01:35.89,Default,,0,0,0,,For image processing, linear
Dialogue: 0,0:01:35.93,0:01:37.42,Default,,0,0,0,,algebra and machine learning.
Dialogue: 0,0:01:39.15,0:01:40.42,Default,,0,0,0,,The framework is optimized for
Dialogue: 0,0:01:40.42,0:01:42.34,Default,,0,0,0,,iOS and we're happy to announce
Dialogue: 0,0:01:42.34,0:01:44.10,Default,,0,0,0,,that this year we're also
Dialogue: 0,0:01:44.10,0:01:44.84,Default,,0,0,0,,bringing MPS to the Mac.
Dialogue: 0,0:01:45.52,0:01:49.79,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:01:50.29,0:01:50.72,Default,,0,0,0,,Thank you.
Dialogue: 0,0:01:51.93,0:01:53.37,Default,,0,0,0,,The entire feature set is
Dialogue: 0,0:01:53.37,0:01:55.62,Default,,0,0,0,,available in both iOS and macOS.
Dialogue: 0,0:01:55.62,0:01:58.48,Default,,0,0,0,,So let's begin with a quick
Dialogue: 0,0:01:58.48,0:02:00.34,Default,,0,0,0,,update on our image processing
Dialogue: 0,0:02:00.34,0:02:00.69,Default,,0,0,0,,support.
Dialogue: 0,0:02:02.05,0:02:03.87,Default,,0,0,0,,So here's a list of all of the
Dialogue: 0,0:02:03.87,0:02:05.58,Default,,0,0,0,,primitives for image processing
Dialogue: 0,0:02:05.70,0:02:07.49,Default,,0,0,0,,that we had available in iOS 10.
Dialogue: 0,0:02:08.11,0:02:09.68,Default,,0,0,0,,So there's Convolution, Gaussian
Dialogue: 0,0:02:09.68,0:02:11.59,Default,,0,0,0,,Blur, Lanczos Resampling, just
Dialogue: 0,0:02:11.59,0:02:12.20,Default,,0,0,0,,to name a few.
Dialogue: 0,0:02:13.13,0:02:14.73,Default,,0,0,0,,They're all now available in
Dialogue: 0,0:02:14.73,0:02:15.00,Default,,0,0,0,,macOS.
Dialogue: 0,0:02:16.15,0:02:17.66,Default,,0,0,0,,And this year we're bringing you
Dialogue: 0,0:02:17.66,0:02:18.93,Default,,0,0,0,,four new image processing
Dialogue: 0,0:02:18.93,0:02:19.34,Default,,0,0,0,,primitives.
Dialogue: 0,0:02:20.47,0:02:21.82,Default,,0,0,0,,The Image Keypoints primitive
Dialogue: 0,0:02:22.21,0:02:24.32,Default,,0,0,0,,can be used -- is often used in
Dialogue: 0,0:02:24.32,0:02:26.26,Default,,0,0,0,,computer vision algorithms such
Dialogue: 0,0:02:26.26,0:02:28.60,Default,,0,0,0,,as image stabilization and
Dialogue: 0,0:02:28.60,0:02:29.93,Default,,0,0,0,,Bilinear Rescale, Image
Dialogue: 0,0:02:29.93,0:02:31.73,Default,,0,0,0,,Statistics, and Element-wise
Dialogue: 0,0:02:31.73,0:02:33.25,Default,,0,0,0,,Arithmetic Operators, are
Dialogue: 0,0:02:33.33,0:02:34.83,Default,,0,0,0,,commonly used to pre-process
Dialogue: 0,0:02:34.83,0:02:35.16,Default,,0,0,0,,images.
Dialogue: 0,0:02:35.47,0:02:36.39,Default,,0,0,0,,For example, in machine
Dialogue: 0,0:02:36.39,0:02:36.66,Default,,0,0,0,,learning.
Dialogue: 0,0:02:37.56,0:02:38.93,Default,,0,0,0,,And the arithmetic filters also
Dialogue: 0,0:02:38.93,0:02:40.45,Default,,0,0,0,,support broadcasting operations.
Dialogue: 0,0:02:41.26,0:02:42.72,Default,,0,0,0,,Which, for example, allow you to
Dialogue: 0,0:02:42.72,0:02:44.77,Default,,0,0,0,,add a 2D image or the 1D image.
Dialogue: 0,0:02:46.18,0:02:48.41,Default,,0,0,0,,So that's it for our very quick
Dialogue: 0,0:02:48.41,0:02:49.61,Default,,0,0,0,,update on image processing.
Dialogue: 0,0:02:49.99,0:02:51.29,Default,,0,0,0,,And now let's talk about the new
Dialogue: 0,0:02:51.29,0:02:52.39,Default,,0,0,0,,Linear Algebra operations.
Dialogue: 0,0:02:54.29,0:02:55.69,Default,,0,0,0,,Without support, Matrix
Dialogue: 0,0:02:55.69,0:02:57.44,Default,,0,0,0,,Multiplication, Matrix Vector
Dialogue: 0,0:02:57.44,0:02:59.74,Default,,0,0,0,,Multiplication, and Triangular
Dialogue: 0,0:03:00.08,0:03:01.87,Default,,0,0,0,,Matrix Factorization and Linear
Dialogue: 0,0:03:01.87,0:03:02.31,Default,,0,0,0,,Solvers.
Dialogue: 0,0:03:05.36,0:03:06.38,Default,,0,0,0,,To support Linear Algebra
Dialogue: 0,0:03:06.38,0:03:09.26,Default,,0,0,0,,operations, we now have multiple
Dialogue: 0,0:03:09.26,0:03:10.36,Default,,0,0,0,,new data representations.
Dialogue: 0,0:03:11.07,0:03:13.08,Default,,0,0,0,,First, we have the MPSVector
Dialogue: 0,0:03:13.08,0:03:15.19,Default,,0,0,0,,object which interprets the data
Dialogue: 0,0:03:15.19,0:03:16.50,Default,,0,0,0,,in a metal buffer as a
Dialogue: 0,0:03:16.50,0:03:17.42,Default,,0,0,0,,one-dimensional array.
Dialogue: 0,0:03:19.11,0:03:21.51,Default,,0,0,0,,And we have an MPSMatrix object
Dialogue: 0,0:03:22.08,0:03:23.28,Default,,0,0,0,,which interprets the data in a
Dialogue: 0,0:03:23.28,0:03:24.89,Default,,0,0,0,,metal buffer as a rectangular
Dialogue: 0,0:03:24.89,0:03:25.16,Default,,0,0,0,,array.
Dialogue: 0,0:03:25.89,0:03:27.66,Default,,0,0,0,,And MPS matrices are in role
Dialogue: 0,0:03:27.66,0:03:28.18,Default,,0,0,0,,major order.
Dialogue: 0,0:03:28.96,0:03:30.17,Default,,0,0,0,,And you can think of both
Dialogue: 0,0:03:30.17,0:03:32.96,Default,,0,0,0,,MPSVectors and MPSMatrices as
Dialogue: 0,0:03:33.46,0:03:34.74,Default,,0,0,0,,wrappers around user data
Dialogue: 0,0:03:34.74,0:03:35.10,Default,,0,0,0,,buffers.
Dialogue: 0,0:03:37.44,0:03:39.30,Default,,0,0,0,,And we also support a temporary
Dialogue: 0,0:03:39.30,0:03:40.93,Default,,0,0,0,,variance of MPSMatrix.
Dialogue: 0,0:03:42.30,0:03:45.20,Default,,0,0,0,,MPS images -- temporary images
Dialogue: 0,0:03:45.20,0:03:47.06,Default,,0,0,0,,and MPSTemporaryMatrices are
Dialogue: 0,0:03:47.06,0:03:48.67,Default,,0,0,0,,allocated from a Metal heap
Dialogue: 0,0:03:48.91,0:03:49.96,Default,,0,0,0,,associated with a command
Dialogue: 0,0:03:49.96,0:03:50.22,Default,,0,0,0,,buffer.
Dialogue: 0,0:03:50.77,0:03:51.86,Default,,0,0,0,,And they are called temporary
Dialogue: 0,0:03:52.23,0:03:54.07,Default,,0,0,0,,because their lifespan is
Dialogue: 0,0:03:54.22,0:03:56.00,Default,,0,0,0,,limited to the lifetime of the
Dialogue: 0,0:03:56.00,0:03:56.52,Default,,0,0,0,,command buffer.
Dialogue: 0,0:03:57.55,0:03:58.87,Default,,0,0,0,,And we recommend you use
Dialogue: 0,0:03:58.90,0:04:00.18,Default,,0,0,0,,temporary images and matrices
Dialogue: 0,0:04:00.64,0:04:02.53,Default,,0,0,0,,for most of your intermediate
Dialogue: 0,0:04:03.01,0:04:03.21,Default,,0,0,0,,storage.
Dialogue: 0,0:04:04.32,0:04:07.42,Default,,0,0,0,,Both MPSVector and MPSMatrix
Dialogue: 0,0:04:07.58,0:04:09.12,Default,,0,0,0,,support a number of input types.
Dialogue: 0,0:04:09.65,0:04:11.60,Default,,0,0,0,,We support single-precision and
Dialogue: 0,0:04:11.60,0:04:14.24,Default,,0,0,0,,half-precision input types and a
Dialogue: 0,0:04:14.24,0:04:15.27,Default,,0,0,0,,floating-point input types.
Dialogue: 0,0:04:15.76,0:04:17.70,Default,,0,0,0,,And 16-bits and 8-bit signed
Dialogue: 0,0:04:17.99,0:04:19.13,Default,,0,0,0,,integer input types.
Dialogue: 0,0:04:21.02,0:04:22.14,Default,,0,0,0,,And now let's take a look at how
Dialogue: 0,0:04:22.14,0:04:24.45,Default,,0,0,0,,we can create an MPSVector of
Dialogue: 0,0:04:24.54,0:04:24.89,Default,,0,0,0,,size N.
Dialogue: 0,0:04:24.89,0:04:26.86,Default,,0,0,0,,So if you don't already have a
Dialogue: 0,0:04:26.86,0:04:28.35,Default,,0,0,0,,Metal buffer, you need to create
Dialogue: 0,0:04:28.35,0:04:28.61,Default,,0,0,0,,one.
Dialogue: 0,0:04:29.67,0:04:30.67,Default,,0,0,0,,And then you need to create a
Dialogue: 0,0:04:30.67,0:04:31.69,Default,,0,0,0,,descriptor for your vector.
Dialogue: 0,0:04:32.53,0:04:34.55,Default,,0,0,0,,And note here that you specify
Dialogue: 0,0:04:34.73,0:04:36.09,Default,,0,0,0,,the length of the vector.
Dialogue: 0,0:04:36.67,0:04:38.15,Default,,0,0,0,,That's because the vector can be
Dialogue: 0,0:04:38.15,0:04:39.95,Default,,0,0,0,,made from a portion of the
Dialogue: 0,0:04:39.95,0:04:40.93,Default,,0,0,0,,original Metal buffer.
Dialogue: 0,0:04:41.72,0:04:43.24,Default,,0,0,0,,And other related offsets can be
Dialogue: 0,0:04:43.24,0:04:44.56,Default,,0,0,0,,set in a kernel that will use
Dialogue: 0,0:04:44.56,0:04:45.02,Default,,0,0,0,,this vector.
Dialogue: 0,0:04:46.00,0:04:47.41,Default,,0,0,0,,And then the last step is
Dialogue: 0,0:04:47.47,0:04:49.59,Default,,0,0,0,,creating a vector from the
Dialogue: 0,0:04:49.59,0:04:50.91,Default,,0,0,0,,buffer with a descriptor.
Dialogue: 0,0:04:52.97,0:04:53.98,Default,,0,0,0,,And now let's take a look at how
Dialogue: 0,0:04:53.98,0:04:56.26,Default,,0,0,0,,you can create an MPSMatrix with
Dialogue: 0,0:04:56.33,0:04:57.91,Default,,0,0,0,,M rows and N columns.
Dialogue: 0,0:04:59.52,0:05:00.91,Default,,0,0,0,,So it's very similar to the way
Dialogue: 0,0:05:00.91,0:05:02.92,Default,,0,0,0,,you would create MPSVector, but
Dialogue: 0,0:05:02.92,0:05:04.01,Default,,0,0,0,,there's just a few things we
Dialogue: 0,0:05:04.01,0:05:04.73,Default,,0,0,0,,want to mention.
Dialogue: 0,0:05:06.18,0:05:08.26,Default,,0,0,0,,We provide a convenient API that
Dialogue: 0,0:05:08.26,0:05:09.61,Default,,0,0,0,,you can use to find the
Dialogue: 0,0:05:09.61,0:05:11.97,Default,,0,0,0,,recommended bytes per row value
Dialogue: 0,0:05:12.56,0:05:13.76,Default,,0,0,0,,for sizing your Metal buffers.
Dialogue: 0,0:05:14.67,0:05:15.72,Default,,0,0,0,,And if you choose to use the
Dialogue: 0,0:05:15.80,0:05:17.25,Default,,0,0,0,,API, this is how you would
Dialogue: 0,0:05:17.25,0:05:18.82,Default,,0,0,0,,create a metal buffer with this
Dialogue: 0,0:05:18.82,0:05:19.60,Default,,0,0,0,,recommended value.
Dialogue: 0,0:05:20.60,0:05:22.11,Default,,0,0,0,,And using this API is completely
Dialogue: 0,0:05:22.11,0:05:24.42,Default,,0,0,0,,optional, but recommended for
Dialogue: 0,0:05:24.42,0:05:25.14,Default,,0,0,0,,better performance.
Dialogue: 0,0:05:25.99,0:05:27.16,Default,,0,0,0,,And then the rest is simple.
Dialogue: 0,0:05:28.26,0:05:29.36,Default,,0,0,0,,You create a descriptor for your
Dialogue: 0,0:05:29.36,0:05:30.89,Default,,0,0,0,,matrix, and then you create a
Dialogue: 0,0:05:30.89,0:05:32.35,Default,,0,0,0,,matrix with a descriptor.
Dialogue: 0,0:05:34.94,0:05:36.51,Default,,0,0,0,,And now that we talked about the
Dialogue: 0,0:05:36.51,0:05:37.81,Default,,0,0,0,,data presentations, now let's
Dialogue: 0,0:05:37.81,0:05:39.05,Default,,0,0,0,,talk about the primitives.
Dialogue: 0,0:05:39.90,0:05:41.18,Default,,0,0,0,,So for Matrix-Matrix and
Dialogue: 0,0:05:41.18,0:05:43.14,Default,,0,0,0,,Matrix-Vector multiplication our
Dialogue: 0,0:05:43.14,0:05:44.59,Default,,0,0,0,,API is modeled after the
Dialogue: 0,0:05:44.59,0:05:46.04,Default,,0,0,0,,standard BLAS GEMM and GEMV
Dialogue: 0,0:05:46.04,0:05:46.77,Default,,0,0,0,,interfaces.
Dialogue: 0,0:05:47.65,0:05:48.85,Default,,0,0,0,,And for triangular matrix
Dialogue: 0,0:05:48.85,0:05:50.20,Default,,0,0,0,,vectorization and linear
Dialogue: 0,0:05:50.20,0:05:52.22,Default,,0,0,0,,solvers, our API is modeled
Dialogue: 0,0:05:52.22,0:05:53.25,Default,,0,0,0,,after standard LAPACK
Dialogue: 0,0:05:53.25,0:05:54.92,Default,,0,0,0,,decomposition and solve
Dialogue: 0,0:05:54.92,0:05:55.49,Default,,0,0,0,,interfaces.
Dialogue: 0,0:05:55.85,0:05:57.04,Default,,0,0,0,,So if you're familiar with those
Dialogue: 0,0:05:57.04,0:05:59.11,Default,,0,0,0,,interfaces our API will look
Dialogue: 0,0:05:59.11,0:06:00.53,Default,,0,0,0,,very familiar to you as well.
Dialogue: 0,0:06:02.58,0:06:04.22,Default,,0,0,0,,And now let's take a look at a
Dialogue: 0,0:06:04.22,0:06:05.55,Default,,0,0,0,,very simple code example.
Dialogue: 0,0:06:05.84,0:06:07.54,Default,,0,0,0,,So we'll be doing matrix
Dialogue: 0,0:06:07.54,0:06:09.00,Default,,0,0,0,,multiplication and computing
Dialogue: 0,0:06:09.00,0:06:10.43,Default,,0,0,0,,just C = A times B.
Dialogue: 0,0:06:10.43,0:06:12.72,Default,,0,0,0,,So first we need to create our
Dialogue: 0,0:06:12.72,0:06:14.48,Default,,0,0,0,,matrices A, B and C.
Dialogue: 0,0:06:14.71,0:06:15.65,Default,,0,0,0,,But I know you know how to do
Dialogue: 0,0:06:15.65,0:06:16.79,Default,,0,0,0,,this, I showed you in a previous
Dialogue: 0,0:06:16.84,0:06:18.31,Default,,0,0,0,,slide, so let's move on.
Dialogue: 0,0:06:19.34,0:06:21.12,Default,,0,0,0,,Now we want to run matrix
Dialogue: 0,0:06:21.12,0:06:22.60,Default,,0,0,0,,multiplication on the GPU.
Dialogue: 0,0:06:23.89,0:06:25.39,Default,,0,0,0,,So first we do our usual Metal
Dialogue: 0,0:06:25.47,0:06:27.45,Default,,0,0,0,,setup to getting a device, a
Dialogue: 0,0:06:27.45,0:06:29.08,Default,,0,0,0,,command queue, and a command
Dialogue: 0,0:06:29.08,0:06:29.36,Default,,0,0,0,,buffer.
Dialogue: 0,0:06:29.36,0:06:31.77,Default,,0,0,0,,And then we need to create our
Dialogue: 0,0:06:31.85,0:06:33.19,Default,,0,0,0,,matrix multiplication kernel.
Dialogue: 0,0:06:33.77,0:06:35.20,Default,,0,0,0,,And note here that you specify
Dialogue: 0,0:06:35.20,0:06:36.30,Default,,0,0,0,,the size of the result.
Dialogue: 0,0:06:36.83,0:06:38.22,Default,,0,0,0,,That's because this kernel can
Dialogue: 0,0:06:38.22,0:06:39.90,Default,,0,0,0,,operate on subregions of
Dialogue: 0,0:06:39.90,0:06:40.44,Default,,0,0,0,,matrices.
Dialogue: 0,0:06:41.07,0:06:45.58,Default,,0,0,0,,And then we encode this kernel
Dialogue: 0,0:06:45.66,0:06:47.06,Default,,0,0,0,,to the GPU and tell it to start
Dialogue: 0,0:06:47.06,0:06:47.48,Default,,0,0,0,,doing the work.
Dialogue: 0,0:06:47.48,0:06:51.04,Default,,0,0,0,,And we already have sample code
Dialogue: 0,0:06:51.04,0:06:52.35,Default,,0,0,0,,from Matrix multiplication
Dialogue: 0,0:06:52.59,0:06:53.91,Default,,0,0,0,,available on our developer
Dialogue: 0,0:06:53.91,0:06:56.10,Default,,0,0,0,,website, and the sample code for
Dialogue: 0,0:06:56.10,0:06:57.90,Default,,0,0,0,,triangular matrix vectorization
Dialogue: 0,0:06:58.21,0:06:59.56,Default,,0,0,0,,and solving a system of linear
Dialogue: 0,0:06:59.56,0:07:00.99,Default,,0,0,0,,equations is coming very soon.
Dialogue: 0,0:07:03.03,0:07:05.53,Default,,0,0,0,,So that's it for our -- for the
Dialogue: 0,0:07:05.76,0:07:07.03,Default,,0,0,0,,linear algebra operations.
Dialogue: 0,0:07:07.39,0:07:09.00,Default,,0,0,0,,Let's now move on to the next
Dialogue: 0,0:07:09.00,0:07:10.76,Default,,0,0,0,,topic, which is Accelerating
Dialogue: 0,0:07:10.76,0:07:12.16,Default,,0,0,0,,Machine Learning Primitives on
Dialogue: 0,0:07:12.16,0:07:12.64,Default,,0,0,0,,the GPU.
Dialogue: 0,0:07:14.12,0:07:16.25,Default,,0,0,0,,There are a number of
Dialogue: 0,0:07:16.25,0:07:17.91,Default,,0,0,0,,machine-learning related talks
Dialogue: 0,0:07:17.91,0:07:19.16,Default,,0,0,0,,at WWDC this year.
Dialogue: 0,0:07:19.46,0:07:20.35,Default,,0,0,0,,And we are a part of the
Dialogue: 0,0:07:20.35,0:07:21.42,Default,,0,0,0,,machine-learning community.
Dialogue: 0,0:07:22.31,0:07:23.59,Default,,0,0,0,,And this slide shows the overall
Dialogue: 0,0:07:23.59,0:07:24.21,Default,,0,0,0,,architecture.
Dialogue: 0,0:07:25.09,0:07:26.61,Default,,0,0,0,,So as an application developer,
Dialogue: 0,0:07:26.82,0:07:27.88,Default,,0,0,0,,you can add machine learning
Dialogue: 0,0:07:27.88,0:07:28.82,Default,,0,0,0,,functionality to your
Dialogue: 0,0:07:28.82,0:07:30.96,Default,,0,0,0,,applications by using high-level
Dialogue: 0,0:07:31.00,0:07:32.86,Default,,0,0,0,,domain-specific frameworks such
Dialogue: 0,0:07:32.86,0:07:34.46,Default,,0,0,0,,as division framework and the
Dialogue: 0,0:07:34.46,0:07:35.57,Default,,0,0,0,,natural language processing
Dialogue: 0,0:07:35.62,0:07:37.50,Default,,0,0,0,,framework, which rely on the
Dialogue: 0,0:07:37.50,0:07:38.37,Default,,0,0,0,,Core ML framework.
Dialogue: 0,0:07:39.22,0:07:40.38,Default,,0,0,0,,And the Core ML framework is
Dialogue: 0,0:07:40.45,0:07:42.32,Default,,0,0,0,,powered by the accelerates
Dialogue: 0,0:07:42.32,0:07:44.08,Default,,0,0,0,,framework BNNS primitives on the
Dialogue: 0,0:07:44.08,0:07:44.61,Default,,0,0,0,,CPU.
Dialogue: 0,0:07:45.07,0:07:46.18,Default,,0,0,0,,And by the machine learning --
Dialogue: 0,0:07:47.07,0:07:49.05,Default,,0,0,0,,and by the Metal Performance
Dialogue: 0,0:07:49.05,0:07:51.95,Default,,0,0,0,,Shaders framework on the GPU.
Dialogue: 0,0:07:51.95,0:07:52.71,Default,,0,0,0,,But if you're writing an
Dialogue: 0,0:07:52.71,0:07:54.56,Default,,0,0,0,,application that uses Metal,
Dialogue: 0,0:07:54.91,0:07:56.05,Default,,0,0,0,,then you can use the MPS
Dialogue: 0,0:07:56.05,0:07:58.18,Default,,0,0,0,,framework directly and I will
Dialogue: 0,0:07:58.18,0:07:59.39,Default,,0,0,0,,show you how in this session.
Dialogue: 0,0:08:01.67,0:08:02.68,Default,,0,0,0,,So let's start with what are we
Dialogue: 0,0:08:02.74,0:08:03.49,Default,,0,0,0,,talking about here?
Dialogue: 0,0:08:04.25,0:08:05.12,Default,,0,0,0,,What is deep learning?
Dialogue: 0,0:08:05.37,0:08:06.24,Default,,0,0,0,,What is Machine learning?
Dialogue: 0,0:08:07.69,0:08:08.77,Default,,0,0,0,,So imagine that this is you.
Dialogue: 0,0:08:08.77,0:08:11.44,Default,,0,0,0,,And when you see an image, you
Dialogue: 0,0:08:11.44,0:08:13.08,Default,,0,0,0,,know immediately what's depicted
Dialogue: 0,0:08:13.08,0:08:13.32,Default,,0,0,0,,on it.
Dialogue: 0,0:08:13.42,0:08:13.96,Default,,0,0,0,,It's a panda.
Dialogue: 0,0:08:14.94,0:08:16.69,Default,,0,0,0,,But now think about all of the
Dialogue: 0,0:08:16.69,0:08:18.01,Default,,0,0,0,,images on your iPhone.
Dialogue: 0,0:08:18.60,0:08:20.21,Default,,0,0,0,,Or all of those pictures in your
Dialogue: 0,0:08:20.21,0:08:21.00,Default,,0,0,0,,family albums.
Dialogue: 0,0:08:21.61,0:08:22.65,Default,,0,0,0,,Or all of the images on the
Dialogue: 0,0:08:22.65,0:08:22.97,Default,,0,0,0,,internet.
Dialogue: 0,0:08:23.82,0:08:27.10,Default,,0,0,0,,No human can possibly -- can
Dialogue: 0,0:08:27.10,0:08:28.82,Default,,0,0,0,,classify these many images.
Dialogue: 0,0:08:29.09,0:08:30.51,Default,,0,0,0,,But deep-learning algorithms is
Dialogue: 0,0:08:30.51,0:08:32.06,Default,,0,0,0,,designed specifically to do
Dialogue: 0,0:08:32.06,0:08:32.20,Default,,0,0,0,,that.
Dialogue: 0,0:08:33.19,0:08:34.42,Default,,0,0,0,,They can be used for sifting
Dialogue: 0,0:08:34.42,0:08:35.58,Default,,0,0,0,,through large amounts of data
Dialogue: 0,0:08:36.02,0:08:37.87,Default,,0,0,0,,and answering questions such as
Dialogue: 0,0:08:38.00,0:08:41.68,Default,,0,0,0,,what is in this image?
Dialogue: 0,0:08:42.24,0:08:43.31,Default,,0,0,0,,Deep learning algorithms have
Dialogue: 0,0:08:43.41,0:08:43.91,Default,,0,0,0,,two phases.
Dialogue: 0,0:08:44.21,0:08:45.16,Default,,0,0,0,,Training and inference.
Dialogue: 0,0:08:45.43,0:08:46.43,Default,,0,0,0,,So let's talk about training
Dialogue: 0,0:08:46.43,0:08:46.74,Default,,0,0,0,,first.
Dialogue: 0,0:08:47.95,0:08:49.25,Default,,0,0,0,,And let's actually use an
Dialogue: 0,0:08:49.25,0:08:49.68,Default,,0,0,0,,example.
Dialogue: 0,0:08:49.68,0:08:51.33,Default,,0,0,0,,Let's train a system to classify
Dialogue: 0,0:08:51.33,0:08:51.72,Default,,0,0,0,,images.
Dialogue: 0,0:08:52.59,0:08:53.54,Default,,0,0,0,,So the training system to
Dialogue: 0,0:08:53.54,0:08:56.70,Default,,0,0,0,,classify images, for example, if
Dialogue: 0,0:08:56.70,0:08:58.07,Default,,0,0,0,,you want to have it recognize
Dialogue: 0,0:08:58.13,0:08:58.54,Default,,0,0,0,,animals.
Dialogue: 0,0:08:58.97,0:09:00.52,Default,,0,0,0,,Like, to have it recognize cats,
Dialogue: 0,0:09:00.52,0:09:02.13,Default,,0,0,0,,you need to feed this system a
Dialogue: 0,0:09:02.56,0:09:04.20,Default,,0,0,0,,large number of labeled images
Dialogue: 0,0:09:04.20,0:09:06.13,Default,,0,0,0,,of cats and then rabbits, and
Dialogue: 0,0:09:06.13,0:09:07.34,Default,,0,0,0,,all the other animals that you
Dialogue: 0,0:09:07.34,0:09:08.41,Default,,0,0,0,,want your system to be able to
Dialogue: 0,0:09:08.41,0:09:08.87,Default,,0,0,0,,recognize.
Dialogue: 0,0:09:10.55,0:09:12.32,Default,,0,0,0,,And this training step is a
Dialogue: 0,0:09:12.32,0:09:13.92,Default,,0,0,0,,one-time computationally
Dialogue: 0,0:09:13.92,0:09:16.48,Default,,0,0,0,,expensive and labor-intensive
Dialogue: 0,0:09:16.57,0:09:16.79,Default,,0,0,0,,step.
Dialogue: 0,0:09:17.90,0:09:19.08,Default,,0,0,0,,And it's usually done offline.
Dialogue: 0,0:09:19.70,0:09:20.90,Default,,0,0,0,,But the results of this training
Dialogue: 0,0:09:20.90,0:09:22.34,Default,,0,0,0,,phase is trained parameters
Dialogue: 0,0:09:23.31,0:09:24.66,Default,,0,0,0,,which are required for the next
Dialogue: 0,0:09:24.66,0:09:25.86,Default,,0,0,0,,phase, the inference phase.
Dialogue: 0,0:09:26.91,0:09:28.10,Default,,0,0,0,,This is when your system is
Dialogue: 0,0:09:28.19,0:09:30.16,Default,,0,0,0,,presented with a new image that
Dialogue: 0,0:09:30.16,0:09:31.74,Default,,0,0,0,,it has never seen before and it
Dialogue: 0,0:09:31.74,0:09:33.19,Default,,0,0,0,,needs to classify, this is a
Dialogue: 0,0:09:33.19,0:09:33.40,Default,,0,0,0,,cap.
Dialogue: 0,0:09:35.13,0:09:37.02,Default,,0,0,0,,We provide view acceleration for
Dialogue: 0,0:09:37.02,0:09:38.31,Default,,0,0,0,,the second phase; the inference
Dialogue: 0,0:09:38.31,0:09:38.53,Default,,0,0,0,,phase.
Dialogue: 0,0:09:39.10,0:09:40.97,Default,,0,0,0,,Specifically, last year we
Dialogue: 0,0:09:40.97,0:09:42.94,Default,,0,0,0,,talked about the building blocks
Dialogue: 0,0:09:43.06,0:09:44.30,Default,,0,0,0,,for building convolutional
Dialogue: 0,0:09:44.30,0:09:45.72,Default,,0,0,0,,neural networks on the GPU for
Dialogue: 0,0:09:45.72,0:09:46.15,Default,,0,0,0,,inference.
Dialogue: 0,0:09:48.47,0:09:50.18,Default,,0,0,0,,So before we move onto any of
Dialogue: 0,0:09:50.18,0:09:51.97,Default,,0,0,0,,the new features for machine
Dialogue: 0,0:09:51.97,0:09:52.83,Default,,0,0,0,,learning that we brought you
Dialogue: 0,0:09:52.86,0:09:53.94,Default,,0,0,0,,this year, we are going to
Dialogue: 0,0:09:53.94,0:09:55.14,Default,,0,0,0,,review some of the core
Dialogue: 0,0:09:55.14,0:09:56.89,Default,,0,0,0,,information that was covered in
Dialogue: 0,0:09:56.89,0:09:58.15,Default,,0,0,0,,our last year's presentation.
Dialogue: 0,0:09:58.74,0:10:00.42,Default,,0,0,0,,Such as, what are convolutional
Dialogue: 0,0:10:00.42,0:10:00.97,Default,,0,0,0,,neural networks?
Dialogue: 0,0:10:02.40,0:10:04.33,Default,,0,0,0,,And once we do that then we can
Dialogue: 0,0:10:04.33,0:10:06.06,Default,,0,0,0,,talk about the new primitives
Dialogue: 0,0:10:06.11,0:10:06.84,Default,,0,0,0,,that we've added for
Dialogue: 0,0:10:06.84,0:10:07.91,Default,,0,0,0,,convolutional neural networks
Dialogue: 0,0:10:07.97,0:10:09.43,Default,,0,0,0,,this year, and then we'll
Dialogue: 0,0:10:09.43,0:10:11.15,Default,,0,0,0,,introduce the new, easy-to-use
Dialogue: 0,0:10:11.52,0:10:12.64,Default,,0,0,0,,neural network graph API.
Dialogue: 0,0:10:13.17,0:10:14.75,Default,,0,0,0,,And our last topic will be
Dialogue: 0,0:10:14.75,0:10:15.73,Default,,0,0,0,,recurrent neural networks.
Dialogue: 0,0:10:18.61,0:10:20.98,Default,,0,0,0,,So let's go into our recap.
Dialogue: 0,0:10:21.11,0:10:22.07,Default,,0,0,0,,So what are convolutional neural
Dialogue: 0,0:10:22.07,0:10:22.37,Default,,0,0,0,,networks?
Dialogue: 0,0:10:24.45,0:10:25.58,Default,,0,0,0,,Convolutional neural networks
Dialogue: 0,0:10:25.58,0:10:27.43,Default,,0,0,0,,are biologically inspired and
Dialogue: 0,0:10:27.43,0:10:28.84,Default,,0,0,0,,designed to resemble the visual
Dialogue: 0,0:10:28.84,0:10:29.25,Default,,0,0,0,,cortex.
Dialogue: 0,0:10:29.80,0:10:31.41,Default,,0,0,0,,So let's think about how our
Dialogue: 0,0:10:31.41,0:10:33.08,Default,,0,0,0,,brain processes visual inputs.
Dialogue: 0,0:10:34.26,0:10:35.64,Default,,0,0,0,,The first hierarchy of neurons
Dialogue: 0,0:10:35.74,0:10:37.06,Default,,0,0,0,,that receive information in the
Dialogue: 0,0:10:37.06,0:10:39.40,Default,,0,0,0,,visual cortex is sensitive to
Dialogue: 0,0:10:39.40,0:10:40.79,Default,,0,0,0,,specific edges and blobs of
Dialogue: 0,0:10:40.89,0:10:41.20,Default,,0,0,0,,color.
Dialogue: 0,0:10:42.37,0:10:43.47,Default,,0,0,0,,While the brain region's further
Dialogue: 0,0:10:43.47,0:10:45.97,Default,,0,0,0,,down the visual pipeline respond
Dialogue: 0,0:10:45.97,0:10:47.60,Default,,0,0,0,,to more complex structures such
Dialogue: 0,0:10:47.60,0:10:49.37,Default,,0,0,0,,as faces of our friends or kinds
Dialogue: 0,0:10:49.37,0:10:50.17,Default,,0,0,0,,of animals like cats.
Dialogue: 0,0:10:51.00,0:10:53.65,Default,,0,0,0,,So in a similar way, CNNs are
Dialogue: 0,0:10:53.65,0:10:55.84,Default,,0,0,0,,organized into a hierarchy of
Dialogue: 0,0:10:55.84,0:10:58.18,Default,,0,0,0,,layers where high-level features
Dialogue: 0,0:10:58.30,0:10:59.84,Default,,0,0,0,,are derived from low-level
Dialogue: 0,0:10:59.84,0:11:00.25,Default,,0,0,0,,features.
Dialogue: 0,0:11:01.16,0:11:02.52,Default,,0,0,0,,So the first few layers in your
Dialogue: 0,0:11:02.52,0:11:04.57,Default,,0,0,0,,network respond to low-level
Dialogue: 0,0:11:04.57,0:11:06.77,Default,,0,0,0,,features like edges and blobs of
Dialogue: 0,0:11:06.83,0:11:07.20,Default,,0,0,0,,color.
Dialogue: 0,0:11:07.89,0:11:10.65,Default,,0,0,0,,While subsequent layers respond
Dialogue: 0,0:11:10.77,0:11:12.52,Default,,0,0,0,,to progressively more complex
Dialogue: 0,0:11:12.62,0:11:14.89,Default,,0,0,0,,features such as faces.
Dialogue: 0,0:11:16.11,0:11:17.41,Default,,0,0,0,,And I keep saying features.
Dialogue: 0,0:11:17.85,0:11:19.56,Default,,0,0,0,,So think of a feature as a
Dialogue: 0,0:11:19.56,0:11:21.18,Default,,0,0,0,,filter that filters your input
Dialogue: 0,0:11:21.18,0:11:22.71,Default,,0,0,0,,data; that particular feature.
Dialogue: 0,0:11:25.32,0:11:26.91,Default,,0,0,0,,And here's a list of all of the
Dialogue: 0,0:11:26.98,0:11:28.08,Default,,0,0,0,,CNN primitives that we had
Dialogue: 0,0:11:28.08,0:11:29.36,Default,,0,0,0,,available in iOS 10.
Dialogue: 0,0:11:29.76,0:11:31.81,Default,,0,0,0,,And in this recap I will be just
Dialogue: 0,0:11:31.81,0:11:33.69,Default,,0,0,0,,talking about the core
Dialogue: 0,0:11:34.18,0:11:35.15,Default,,0,0,0,,convolution layer.
Dialogue: 0,0:11:35.22,0:11:36.43,Default,,0,0,0,,The core building block of a
Dialogue: 0,0:11:36.55,0:11:36.76,Default,,0,0,0,,CNN.
Dialogue: 0,0:11:36.76,0:11:39.05,Default,,0,0,0,,And the rest of these primitives
Dialogue: 0,0:11:39.11,0:11:40.91,Default,,0,0,0,,are covered in great detail in
Dialogue: 0,0:11:40.91,0:11:42.27,Default,,0,0,0,,our presentation -- in our
Dialogue: 0,0:11:42.27,0:11:43.08,Default,,0,0,0,,documentation.
Dialogue: 0,0:11:43.20,0:11:44.57,Default,,0,0,0,,So Pooling, Fully-Connected and
Dialogue: 0,0:11:44.62,0:11:45.16,Default,,0,0,0,,SoftMax.
Dialogue: 0,0:11:45.75,0:11:46.86,Default,,0,0,0,,You can find information on
Dialogue: 0,0:11:46.86,0:11:47.06,Default,,0,0,0,,those.
Dialogue: 0,0:11:48.63,0:11:50.39,Default,,0,0,0,,So let's talk about the core
Dialogue: 0,0:11:50.39,0:11:51.19,Default,,0,0,0,,building block.
Dialogue: 0,0:11:52.60,0:11:54.22,Default,,0,0,0,,So the function of this core
Dialogue: 0,0:11:54.22,0:11:56.20,Default,,0,0,0,,convolution layer is to
Dialogue: 0,0:11:56.20,0:11:57.77,Default,,0,0,0,,recognize features in the input
Dialogue: 0,0:11:57.77,0:11:58.91,Default,,0,0,0,,data and it's called a
Dialogue: 0,0:11:58.91,0:12:01.08,Default,,0,0,0,,convolution layer because it
Dialogue: 0,0:12:01.13,0:12:02.58,Default,,0,0,0,,performs a convolution on its
Dialogue: 0,0:12:02.58,0:12:02.85,Default,,0,0,0,,input.
Dialogue: 0,0:12:03.92,0:12:05.25,Default,,0,0,0,,So let's recall how regular
Dialogue: 0,0:12:05.25,0:12:06.08,Default,,0,0,0,,convolution works.
Dialogue: 0,0:12:06.91,0:12:08.15,Default,,0,0,0,,You have your inputs, your
Dialogue: 0,0:12:08.19,0:12:09.37,Default,,0,0,0,,outputs and the filter.
Dialogue: 0,0:12:10.37,0:12:12.39,Default,,0,0,0,,And to convole a filter with the
Dialogue: 0,0:12:12.39,0:12:14.51,Default,,0,0,0,,input data you need to multiply
Dialogue: 0,0:12:14.76,0:12:16.63,Default,,0,0,0,,each value in your filter with
Dialogue: 0,0:12:16.63,0:12:18.45,Default,,0,0,0,,the value in the input data and
Dialogue: 0,0:12:18.45,0:12:19.69,Default,,0,0,0,,combine that information to
Dialogue: 0,0:12:19.69,0:12:21.11,Default,,0,0,0,,compute a single output value.
Dialogue: 0,0:12:22.05,0:12:23.54,Default,,0,0,0,,And you do the same for the rest
Dialogue: 0,0:12:23.64,0:12:25.17,Default,,0,0,0,,of the output pixels.
Dialogue: 0,0:12:27.60,0:12:29.86,Default,,0,0,0,,And now the convolution layer is
Dialogue: 0,0:12:29.86,0:12:31.61,Default,,0,0,0,,a generalization of regular
Dialogue: 0,0:12:31.61,0:12:32.23,Default,,0,0,0,,convolution.
Dialogue: 0,0:12:32.40,0:12:34.67,Default,,0,0,0,,It allows you to have multiple
Dialogue: 0,0:12:34.67,0:12:35.14,Default,,0,0,0,,filters.
Dialogue: 0,0:12:35.53,0:12:37.54,Default,,0,0,0,,So you have as many filters as
Dialogue: 0,0:12:37.54,0:12:38.92,Default,,0,0,0,,you have output channels -- or
Dialogue: 0,0:12:38.92,0:12:39.82,Default,,0,0,0,,16 in this case.
Dialogue: 0,0:12:41.67,0:12:43.05,Default,,0,0,0,,And these are the filters which
Dialogue: 0,0:12:43.05,0:12:44.66,Default,,0,0,0,,are going to be filtering input
Dialogue: 0,0:12:44.66,0:12:46.01,Default,,0,0,0,,data for particular features.
Dialogue: 0,0:12:47.73,0:12:49.02,Default,,0,0,0,,Now imagine that you're working
Dialogue: 0,0:12:49.02,0:12:50.27,Default,,0,0,0,,with RGB data.
Dialogue: 0,0:12:50.36,0:12:52.19,Default,,0,0,0,,So you actually have three
Dialogue: 0,0:12:52.19,0:12:53.27,Default,,0,0,0,,channels in your input.
Dialogue: 0,0:12:54.16,0:12:56.28,Default,,0,0,0,,And just because how CNNs work,
Dialogue: 0,0:12:56.48,0:12:58.82,Default,,0,0,0,,this means you need three sets
Dialogue: 0,0:12:58.89,0:13:00.16,Default,,0,0,0,,of 16 filters.
Dialogue: 0,0:13:00.87,0:13:02.58,Default,,0,0,0,,One set for each input channel.
Dialogue: 0,0:13:03.86,0:13:05.92,Default,,0,0,0,,And then these filters are
Dialogue: 0,0:13:05.92,0:13:07.30,Default,,0,0,0,,applied to the input data
Dialogue: 0,0:13:08.49,0:13:09.04,Default,,0,0,0,,separately.
Dialogue: 0,0:13:09.04,0:13:10.82,Default,,0,0,0,,And then the final step combines
Dialogue: 0,0:13:10.82,0:13:12.39,Default,,0,0,0,,all of this information to
Dialogue: 0,0:13:12.39,0:13:13.80,Default,,0,0,0,,compute a single output pixel.
Dialogue: 0,0:13:15.52,0:13:17.16,Default,,0,0,0,,So that's it for our recap of
Dialogue: 0,0:13:17.16,0:13:18.01,Default,,0,0,0,,the convolution layer.
Dialogue: 0,0:13:18.54,0:13:19.53,Default,,0,0,0,,Now let's talk about the new
Dialogue: 0,0:13:19.58,0:13:20.85,Default,,0,0,0,,primitives we've added for
Dialogue: 0,0:13:20.85,0:13:22.03,Default,,0,0,0,,convolutional neural networks.
Dialogue: 0,0:13:22.12,0:13:25.18,Default,,0,0,0,,So as you can see, we've added
Dialogue: 0,0:13:25.18,0:13:25.69,Default,,0,0,0,,quite a few.
Dialogue: 0,0:13:27.74,0:13:29.10,Default,,0,0,0,,And I'll be talking about the
Dialogue: 0,0:13:29.10,0:13:31.48,Default,,0,0,0,,ones highlighted in yellow, but
Dialogue: 0,0:13:31.48,0:13:33.21,Default,,0,0,0,,the rest of them like L2Norm
Dialogue: 0,0:13:33.26,0:13:34.69,Default,,0,0,0,,Pooling, Resampling,
Dialogue: 0,0:13:34.69,0:13:36.09,Default,,0,0,0,,Up-sampling, they will all be
Dialogue: 0,0:13:36.09,0:13:37.40,Default,,0,0,0,,covered in our documentation.
Dialogue: 0,0:13:39.29,0:13:40.99,Default,,0,0,0,,So let's talk about updates to
Dialogue: 0,0:13:40.99,0:13:42.79,Default,,0,0,0,,our core convolution layer.
Dialogue: 0,0:13:43.92,0:13:45.15,Default,,0,0,0,,We used to support only single
Dialogue: 0,0:13:45.19,0:13:46.72,Default,,0,0,0,,precision floating-point weight
Dialogue: 0,0:13:46.72,0:13:47.03,Default,,0,0,0,,types.
Dialogue: 0,0:13:47.47,0:13:49.08,Default,,0,0,0,,And now to help you reduce the
Dialogue: 0,0:13:49.08,0:13:51.13,Default,,0,0,0,,memory footprint and to prove
Dialogue: 0,0:13:51.13,0:13:51.97,Default,,0,0,0,,the performance of your
Dialogue: 0,0:13:51.97,0:13:52.33,Default,,0,0,0,,networks.
Dialogue: 0,0:13:52.88,0:13:54.55,Default,,0,0,0,,We also support half-precision
Dialogue: 0,0:13:54.55,0:13:56.47,Default,,0,0,0,,floating points, 8-bit integer,
Dialogue: 0,0:13:56.81,0:13:58.08,Default,,0,0,0,,and binary weight types.
Dialogue: 0,0:13:59.50,0:14:01.01,Default,,0,0,0,,We used to support only standard
Dialogue: 0,0:14:01.01,0:14:02.68,Default,,0,0,0,,convolution and now we also
Dialogue: 0,0:14:02.74,0:14:03.93,Default,,0,0,0,,support binary and XNOR
Dialogue: 0,0:14:03.93,0:14:04.65,Default,,0,0,0,,convolution.
Dialogue: 0,0:14:04.99,0:14:06.10,Default,,0,0,0,,Dilated convolution.
Dialogue: 0,0:14:06.10,0:14:08.41,Default,,0,0,0,,Sub-pixel convolution and
Dialogue: 0,0:14:08.41,0:14:09.37,Default,,0,0,0,,convolution transpose
Dialogue: 0,0:14:09.37,0:14:10.00,Default,,0,0,0,,operations.
Dialogue: 0,0:14:11.06,0:14:12.16,Default,,0,0,0,,And many of these are
Dialogue: 0,0:14:12.16,0:14:13.72,Default,,0,0,0,,orthogonal, so you can even have
Dialogue: 0,0:14:14.01,0:14:15.95,Default,,0,0,0,,dilated sub-pixel convolution if
Dialogue: 0,0:14:15.95,0:14:16.28,Default,,0,0,0,,you want.
Dialogue: 0,0:14:17.71,0:14:18.49,Default,,0,0,0,,So let's go through them
Dialogue: 0,0:14:18.49,0:14:19.05,Default,,0,0,0,,one-by-one.
Dialogue: 0,0:14:20.81,0:14:22.22,Default,,0,0,0,,Binary and XNOR convolution
Dialogue: 0,0:14:22.26,0:14:24.28,Default,,0,0,0,,perform the same exact operation
Dialogue: 0,0:14:24.31,0:14:26.34,Default,,0,0,0,,as regular convolution but they
Dialogue: 0,0:14:26.34,0:14:28.02,Default,,0,0,0,,do so with improved performance
Dialogue: 0,0:14:28.48,0:14:29.57,Default,,0,0,0,,and great space savings.
Dialogue: 0,0:14:30.02,0:14:31.73,Default,,0,0,0,,So in regular convolution, you
Dialogue: 0,0:14:31.73,0:14:33.55,Default,,0,0,0,,may have floating point inputs
Dialogue: 0,0:14:33.85,0:14:35.17,Default,,0,0,0,,and floating point weights.
Dialogue: 0,0:14:36.04,0:14:37.45,Default,,0,0,0,,What binary convolution allow
Dialogue: 0,0:14:37.52,0:14:39.24,Default,,0,0,0,,you to do is to use your
Dialogue: 0,0:14:39.24,0:14:41.27,Default,,0,0,0,,full-sized input with binary
Dialogue: 0,0:14:41.27,0:14:41.49,Default,,0,0,0,,weights.
Dialogue: 0,0:14:42.42,0:14:44.78,Default,,0,0,0,,And for XNOR convolution the
Dialogue: 0,0:14:44.78,0:14:46.71,Default,,0,0,0,,first thing that happens is that
Dialogue: 0,0:14:47.23,0:14:48.63,Default,,0,0,0,,your input is first converted to
Dialogue: 0,0:14:48.63,0:14:50.83,Default,,0,0,0,,binary so that both your inputs
Dialogue: 0,0:14:51.18,0:14:52.40,Default,,0,0,0,,and the weights are binary.
Dialogue: 0,0:14:53.48,0:14:55.29,Default,,0,0,0,,In regular convolution, the
Dialogue: 0,0:14:55.29,0:14:57.07,Default,,0,0,0,,input has to be multiplied with
Dialogue: 0,0:14:57.11,0:14:57.45,Default,,0,0,0,,the weights.
Dialogue: 0,0:14:57.89,0:14:59.88,Default,,0,0,0,,And for XNOR convolution the
Dialogue: 0,0:14:59.88,0:15:01.81,Default,,0,0,0,,separation becomes a simple XNOR
Dialogue: 0,0:15:01.81,0:15:02.34,Default,,0,0,0,,operation.
Dialogue: 0,0:15:04.75,0:15:06.07,Default,,0,0,0,,And now let's talk about dilated
Dialogue: 0,0:15:06.07,0:15:06.66,Default,,0,0,0,,convolution.
Dialogue: 0,0:15:07.63,0:15:09.00,Default,,0,0,0,,So we already know how regular
Dialogue: 0,0:15:09.00,0:15:09.79,Default,,0,0,0,,convolution works.
Dialogue: 0,0:15:10.49,0:15:12.40,Default,,0,0,0,,You need to apply a filter to
Dialogue: 0,0:15:12.40,0:15:13.66,Default,,0,0,0,,the input data to compute a
Dialogue: 0,0:15:13.66,0:15:14.71,Default,,0,0,0,,single output value.
Dialogue: 0,0:15:17.53,0:15:18.79,Default,,0,0,0,,But say you're working on an
Dialogue: 0,0:15:18.79,0:15:21.74,Default,,0,0,0,,algorithm that requires global
Dialogue: 0,0:15:21.74,0:15:24.85,Default,,0,0,0,,integration of a wider context
Dialogue: 0,0:15:25.22,0:15:26.17,Default,,0,0,0,,of your input data.
Dialogue: 0,0:15:26.82,0:15:28.47,Default,,0,0,0,,So instead of a 3 by 3 kernel,
Dialogue: 0,0:15:28.54,0:15:30.50,Default,,0,0,0,,you may be using a 5 by 5 kernel
Dialogue: 0,0:15:31.74,0:15:32.48,Default,,0,0,0,,to look out further.
Dialogue: 0,0:15:33.03,0:15:33.67,Default,,0,0,0,,But that's a lot more
Dialogue: 0,0:15:33.67,0:15:34.76,Default,,0,0,0,,computationally expensive.
Dialogue: 0,0:15:35.26,0:15:37.27,Default,,0,0,0,,What you can do instead is use
Dialogue: 0,0:15:37.27,0:15:39.05,Default,,0,0,0,,dilated convolutions which
Dialogue: 0,0:15:39.05,0:15:43.21,Default,,0,0,0,,allows you to -- which allows
Dialogue: 0,0:15:43.21,0:15:45.26,Default,,0,0,0,,you to use dilation factors to
Dialogue: 0,0:15:45.26,0:15:46.84,Default,,0,0,0,,introduce gaps into your
Dialogue: 0,0:15:46.84,0:15:48.84,Default,,0,0,0,,convolution kernel so that
Dialogue: 0,0:15:48.84,0:15:50.58,Default,,0,0,0,,you're still using just a 3 by 3
Dialogue: 0,0:15:50.58,0:15:52.68,Default,,0,0,0,,kernel, but you can look out
Dialogue: 0,0:15:52.68,0:15:53.02,Default,,0,0,0,,further.
Dialogue: 0,0:15:55.00,0:15:55.88,Default,,0,0,0,,And now let's talk about
Dialogue: 0,0:15:55.95,0:15:57.27,Default,,0,0,0,,subluxal convolution and
Dialogue: 0,0:15:57.27,0:15:58.85,Default,,0,0,0,,convolution transpose primitive;
Dialogue: 0,0:15:59.77,0:16:01.27,Default,,0,0,0,,very commonly used for image
Dialogue: 0,0:16:01.27,0:16:01.84,Default,,0,0,0,,upscaling.
Dialogue: 0,0:16:03.07,0:16:04.13,Default,,0,0,0,,And let's think about how
Dialogue: 0,0:16:04.18,0:16:05.37,Default,,0,0,0,,upscaling usually works.
Dialogue: 0,0:16:05.46,0:16:07.46,Default,,0,0,0,,So you have your input data and
Dialogue: 0,0:16:07.52,0:16:09.20,Default,,0,0,0,,you want to upscale it by a
Dialogue: 0,0:16:09.20,0:16:09.96,Default,,0,0,0,,factor of 2.
Dialogue: 0,0:16:12.34,0:16:13.38,Default,,0,0,0,,So you won't -- you have some
Dialogue: 0,0:16:13.38,0:16:14.57,Default,,0,0,0,,missing pixels to compute.
Dialogue: 0,0:16:15.22,0:16:16.54,Default,,0,0,0,,And usually upscaling is the
Dialogue: 0,0:16:16.54,0:16:18.16,Default,,0,0,0,,fixed operation with a constant
Dialogue: 0,0:16:18.16,0:16:18.61,Default,,0,0,0,,filter.
Dialogue: 0,0:16:18.77,0:16:20.34,Default,,0,0,0,,So for example how would a box
Dialogue: 0,0:16:20.34,0:16:22.34,Default,,0,0,0,,filter help you to upscale this
Dialogue: 0,0:16:22.39,0:16:22.76,Default,,0,0,0,,image?
Dialogue: 0,0:16:23.42,0:16:25.15,Default,,0,0,0,,So the box filter, which is take
Dialogue: 0,0:16:25.32,0:16:28.01,Default,,0,0,0,,the known pixels and copy the
Dialogue: 0,0:16:28.01,0:16:29.33,Default,,0,0,0,,known data into the missing
Dialogue: 0,0:16:29.33,0:16:30.79,Default,,0,0,0,,location to get you upscaled
Dialogue: 0,0:16:30.79,0:16:31.22,Default,,0,0,0,,results.
Dialogue: 0,0:16:33.33,0:16:35.20,Default,,0,0,0,,For sub-pixel convolution, your
Dialogue: 0,0:16:35.20,0:16:36.65,Default,,0,0,0,,filters are not constant.
Dialogue: 0,0:16:36.98,0:16:38.23,Default,,0,0,0,,Your filters are learned from
Dialogue: 0,0:16:38.23,0:16:38.63,Default,,0,0,0,,the data.
Dialogue: 0,0:16:38.77,0:16:40.29,Default,,0,0,0,,They are your trained parameters
Dialogue: 0,0:16:40.72,0:16:41.79,Default,,0,0,0,,that you get from the training
Dialogue: 0,0:16:41.79,0:16:42.91,Default,,0,0,0,,step where the system was
Dialogue: 0,0:16:42.99,0:16:45.11,Default,,0,0,0,,trained to do this task; to do
Dialogue: 0,0:16:45.11,0:16:45.95,Default,,0,0,0,,image upscaling.
Dialogue: 0,0:16:47.09,0:16:49.18,Default,,0,0,0,,So for 2x upscaling you get 4
Dialogue: 0,0:16:49.24,0:16:49.69,Default,,0,0,0,,filters.
Dialogue: 0,0:16:49.81,0:16:51.66,Default,,0,0,0,,For 4x upscaling you get 16
Dialogue: 0,0:16:51.66,0:16:52.66,Default,,0,0,0,,filters and so on.
Dialogue: 0,0:16:53.57,0:16:55.45,Default,,0,0,0,,So for our 2x upscaling we get
Dialogue: 0,0:16:55.45,0:16:57.46,Default,,0,0,0,,our 4 filters and we apply them
Dialogue: 0,0:16:57.46,0:16:58.17,Default,,0,0,0,,to the input data.
Dialogue: 0,0:16:58.17,0:17:00.22,Default,,0,0,0,,And then the output of that
Dialogue: 0,0:17:00.22,0:17:02.08,Default,,0,0,0,,operation is reshuffled to get
Dialogue: 0,0:17:02.08,0:17:03.48,Default,,0,0,0,,your final full-resolution
Dialogue: 0,0:17:03.48,0:17:03.86,Default,,0,0,0,,image.
Dialogue: 0,0:17:04.93,0:17:06.45,Default,,0,0,0,,And now let's talk about how the
Dialogue: 0,0:17:06.45,0:17:08.08,Default,,0,0,0,,convolution transpose primitive
Dialogue: 0,0:17:08.16,0:17:09.54,Default,,0,0,0,,can be used to upscale images.
Dialogue: 0,0:17:10.44,0:17:12.03,Default,,0,0,0,,So we have our inputs and we
Dialogue: 0,0:17:12.03,0:17:13.47,Default,,0,0,0,,still have to compute our
Dialogue: 0,0:17:13.47,0:17:14.15,Default,,0,0,0,,missing data.
Dialogue: 0,0:17:14.95,0:17:16.67,Default,,0,0,0,,So the way that this primitive
Dialogue: 0,0:17:17.16,0:17:18.62,Default,,0,0,0,,computes the missing data is
Dialogue: 0,0:17:18.62,0:17:19.59,Default,,0,0,0,,that it applies a kind of
Dialogue: 0,0:17:19.59,0:17:21.30,Default,,0,0,0,,convolution pass to this
Dialogue: 0,0:17:21.30,0:17:23.17,Default,,0,0,0,,intermediate result with gaps to
Dialogue: 0,0:17:23.17,0:17:24.60,Default,,0,0,0,,compute each output pixel.
Dialogue: 0,0:17:25.19,0:17:27.32,Default,,0,0,0,,So that's how you get your
Dialogue: 0,0:17:27.36,0:17:28.26,Default,,0,0,0,,upscaled output.
Dialogue: 0,0:17:31.14,0:17:32.22,Default,,0,0,0,,And now we're going to show you
Dialogue: 0,0:17:32.22,0:17:33.56,Default,,0,0,0,,how you can use these new
Dialogue: 0,0:17:33.56,0:17:35.05,Default,,0,0,0,,convolution primitives to
Dialogue: 0,0:17:35.05,0:17:36.63,Default,,0,0,0,,implement a real-world network.
Dialogue: 0,0:17:37.10,0:17:38.61,Default,,0,0,0,,So we took this colorization
Dialogue: 0,0:17:38.61,0:17:41.49,Default,,0,0,0,,network that takes black and
Dialogue: 0,0:17:41.49,0:17:42.89,Default,,0,0,0,,white images as input and
Dialogue: 0,0:17:42.89,0:17:44.36,Default,,0,0,0,,produces colorized images.
Dialogue: 0,0:17:44.36,0:17:47.16,Default,,0,0,0,,And this particular network uses
Dialogue: 0,0:17:47.24,0:17:48.43,Default,,0,0,0,,the dilated convolution
Dialogue: 0,0:17:48.43,0:17:50.40,Default,,0,0,0,,primitive to integrate wider
Dialogue: 0,0:17:50.40,0:17:52.30,Default,,0,0,0,,global context quicker.
Dialogue: 0,0:17:52.93,0:17:54.76,Default,,0,0,0,,And it uses the convolution
Dialogue: 0,0:17:54.76,0:17:56.73,Default,,0,0,0,,transpose primitive to upscale
Dialogue: 0,0:17:56.73,0:17:57.78,Default,,0,0,0,,the results of the network.
Dialogue: 0,0:18:00.17,0:18:01.28,Default,,0,0,0,,And now let's look at this
Dialogue: 0,0:18:01.67,0:18:03.97,Default,,0,0,0,,colorization network in action.
Dialogue: 0,0:18:10.23,0:18:11.47,Default,,0,0,0,,So in this demo we have a
Dialogue: 0,0:18:11.47,0:18:12.89,Default,,0,0,0,,collection of black and white
Dialogue: 0,0:18:12.89,0:18:14.05,Default,,0,0,0,,images like this image of a
Dialogue: 0,0:18:14.05,0:18:14.41,Default,,0,0,0,,lion.
Dialogue: 0,0:18:15.05,0:18:16.42,Default,,0,0,0,,And as soon as I tap on this
Dialogue: 0,0:18:16.42,0:18:17.80,Default,,0,0,0,,image, the colorization network
Dialogue: 0,0:18:17.80,0:18:20.05,Default,,0,0,0,,will run right here live on the
Dialogue: 0,0:18:20.05,0:18:21.13,Default,,0,0,0,,device, and we'll see a
Dialogue: 0,0:18:21.13,0:18:21.95,Default,,0,0,0,,colorized image.
Dialogue: 0,0:18:23.91,0:18:25.46,Default,,0,0,0,,And let's try another example
Dialogue: 0,0:18:25.46,0:18:27.05,Default,,0,0,0,,for this beautiful snowy
Dialogue: 0,0:18:27.05,0:18:27.62,Default,,0,0,0,,mountain.
Dialogue: 0,0:18:28.84,0:18:30.04,Default,,0,0,0,,And now we see it in color.
Dialogue: 0,0:18:31.59,0:18:33.76,Default,,0,0,0,,And this beautiful lovely image
Dialogue: 0,0:18:33.76,0:18:35.02,Default,,0,0,0,,of a dad and a daughter playing
Dialogue: 0,0:18:35.02,0:18:35.37,Default,,0,0,0,,guitar.
Dialogue: 0,0:18:35.37,0:18:37.39,Default,,0,0,0,,And now you can see them playing
Dialogue: 0,0:18:37.39,0:18:38.03,Default,,0,0,0,,guitar in color.
Dialogue: 0,0:18:39.52,0:18:40.90,Default,,0,0,0,,And I really like this one, the
Dialogue: 0,0:18:40.90,0:18:42.31,Default,,0,0,0,,brown bear walking in the
Dialogue: 0,0:18:42.36,0:18:42.70,Default,,0,0,0,,forest.
Dialogue: 0,0:18:42.70,0:18:43.76,Default,,0,0,0,,So I think this network does
Dialogue: 0,0:18:43.79,0:18:45.15,Default,,0,0,0,,just a really wonderful job.
Dialogue: 0,0:18:46.89,0:18:48.73,Default,,0,0,0,,Okay. So that's it for the live
Dialogue: 0,0:18:48.73,0:18:48.92,Default,,0,0,0,,demo.
Dialogue: 0,0:18:49.52,0:18:54.69,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:18:55.19,0:18:55.80,Default,,0,0,0,,Thank you so much.
Dialogue: 0,0:18:57.77,0:18:59.22,Default,,0,0,0,,So we've added all of these new
Dialogue: 0,0:18:59.22,0:19:01.46,Default,,0,0,0,,convolution CNN primitives, but
Dialogue: 0,0:19:01.46,0:19:02.06,Default,,0,0,0,,that's not all.
Dialogue: 0,0:19:02.98,0:19:04.67,Default,,0,0,0,,We also went back and improved
Dialogue: 0,0:19:04.67,0:19:06.05,Default,,0,0,0,,the performance of some of the
Dialogue: 0,0:19:06.21,0:19:07.94,Default,,0,0,0,,core CNN kernels that were
Dialogue: 0,0:19:07.94,0:19:09.65,Default,,0,0,0,,available to you in iOS 10.
Dialogue: 0,0:19:10.41,0:19:11.78,Default,,0,0,0,,So this chart will show the
Dialogue: 0,0:19:11.81,0:19:13.85,Default,,0,0,0,,performance of the Inception-v3
Dialogue: 0,0:19:13.85,0:19:15.39,Default,,0,0,0,,network, which is a commonly
Dialogue: 0,0:19:15.39,0:19:16.94,Default,,0,0,0,,used network for image
Dialogue: 0,0:19:17.06,0:19:17.55,Default,,0,0,0,,recognition.
Dialogue: 0,0:19:18.76,0:19:20.40,Default,,0,0,0,,So it shows the performance of
Dialogue: 0,0:19:20.40,0:19:22.20,Default,,0,0,0,,this network in iOS 11.
Dialogue: 0,0:19:22.20,0:19:23.79,Default,,0,0,0,,And as you can see, we're
Dialogue: 0,0:19:23.79,0:19:25.87,Default,,0,0,0,,bringing you at least 20 percent
Dialogue: 0,0:19:25.87,0:19:27.55,Default,,0,0,0,,performance improvement across
Dialogue: 0,0:19:27.76,0:19:28.70,Default,,0,0,0,,different iOS hardware.
Dialogue: 0,0:19:30.41,0:19:33.79,Default,,0,0,0,,And now let's talk about the new
Dialogue: 0,0:19:33.79,0:19:37.10,Default,,0,0,0,,neural network graph API.
Dialogue: 0,0:19:37.72,0:19:40.04,Default,,0,0,0,,the neural networks are commonly
Dialogue: 0,0:19:40.04,0:19:41.42,Default,,0,0,0,,described using a graph
Dialogue: 0,0:19:41.42,0:19:42.48,Default,,0,0,0,,abstraction like this
Dialogue: 0,0:19:42.48,0:19:43.51,Default,,0,0,0,,visualization of the
Dialogue: 0,0:19:43.51,0:19:44.62,Default,,0,0,0,,Inception-v3 network.
Dialogue: 0,0:19:44.62,0:19:46.70,Default,,0,0,0,,And we're now allowing to do
Dialogue: 0,0:19:46.70,0:19:48.71,Default,,0,0,0,,just this using the new graph
Dialogue: 0,0:19:48.71,0:19:48.97,Default,,0,0,0,,API.
Dialogue: 0,0:19:50.45,0:19:51.56,Default,,0,0,0,,So let's zoom in on one of these
Dialogue: 0,0:19:51.56,0:19:53.19,Default,,0,0,0,,inception modules.
Dialogue: 0,0:19:54.68,0:19:56.50,Default,,0,0,0,,You have filter nodes which
Dialogue: 0,0:19:56.50,0:19:58.18,Default,,0,0,0,,describe the operations that you
Dialogue: 0,0:19:58.18,0:19:59.22,Default,,0,0,0,,can perform on your data.
Dialogue: 0,0:19:59.53,0:20:01.15,Default,,0,0,0,,Such as convolution, pooling,
Dialogue: 0,0:20:01.15,0:20:01.57,Default,,0,0,0,,etcetera.
Dialogue: 0,0:20:02.56,0:20:04.32,Default,,0,0,0,,And you have image nodes which
Dialogue: 0,0:20:04.32,0:20:05.74,Default,,0,0,0,,describe how the data flows
Dialogue: 0,0:20:05.79,0:20:06.55,Default,,0,0,0,,between these different
Dialogue: 0,0:20:06.55,0:20:07.10,Default,,0,0,0,,operations.
Dialogue: 0,0:20:07.83,0:20:11.31,Default,,0,0,0,,So why did we add this new graph
Dialogue: 0,0:20:11.31,0:20:11.56,Default,,0,0,0,,API?
Dialogue: 0,0:20:11.93,0:20:13.16,Default,,0,0,0,,Well because it's easy to use.
Dialogue: 0,0:20:13.69,0:20:14.66,Default,,0,0,0,,You get this compact
Dialogue: 0,0:20:14.66,0:20:16.12,Default,,0,0,0,,representation of your entire
Dialogue: 0,0:20:16.12,0:20:18.33,Default,,0,0,0,,network and you can save it to
Dialogue: 0,0:20:18.33,0:20:20.36,Default,,0,0,0,,disk and restore it, and that
Dialogue: 0,0:20:20.47,0:20:21.55,Default,,0,0,0,,works across platforms.
Dialogue: 0,0:20:23.17,0:20:24.43,Default,,0,0,0,,You only need to initialize the
Dialogue: 0,0:20:24.43,0:20:26.37,Default,,0,0,0,,graph once and then you can
Dialogue: 0,0:20:26.37,0:20:27.72,Default,,0,0,0,,reuse it for multiple input
Dialogue: 0,0:20:27.72,0:20:28.11,Default,,0,0,0,,images.
Dialogue: 0,0:20:29.52,0:20:31.48,Default,,0,0,0,,And you can execute the entire
Dialogue: 0,0:20:31.48,0:20:34.06,Default,,0,0,0,,graph on the GPU with a single
Dialogue: 0,0:20:34.06,0:20:34.35,Default,,0,0,0,,call.
Dialogue: 0,0:20:36.28,0:20:37.54,Default,,0,0,0,,There are no intermediate images
Dialogue: 0,0:20:37.54,0:20:39.20,Default,,0,0,0,,for you to manage, you just need
Dialogue: 0,0:20:39.20,0:20:40.76,Default,,0,0,0,,to take care of your input and
Dialogue: 0,0:20:40.76,0:20:41.04,Default,,0,0,0,,output.
Dialogue: 0,0:20:42.15,0:20:45.02,Default,,0,0,0,,Internally we use Metal heaps to
Dialogue: 0,0:20:45.02,0:20:46.80,Default,,0,0,0,,make sure that the memory
Dialogue: 0,0:20:46.80,0:20:47.92,Default,,0,0,0,,footprint of all your
Dialogue: 0,0:20:47.92,0:20:49.51,Default,,0,0,0,,intermediate images is as small
Dialogue: 0,0:20:49.51,0:20:50.13,Default,,0,0,0,,as possible.
Dialogue: 0,0:20:50.61,0:20:51.30,Default,,0,0,0,,For example, for the
Dialogue: 0,0:20:51.30,0:20:53.38,Default,,0,0,0,,Inception-v3 network this means
Dialogue: 0,0:20:53.83,0:20:56.86,Default,,0,0,0,,5x memory savings and 10x viewer
Dialogue: 0,0:20:56.86,0:20:58.50,Default,,0,0,0,,allocations, which I think is
Dialogue: 0,0:20:58.56,0:20:59.26,Default,,0,0,0,,pretty impressive.
Dialogue: 0,0:21:00.84,0:21:02.93,Default,,0,0,0,,So as I said, the graph does all
Dialogue: 0,0:21:02.93,0:21:03.96,Default,,0,0,0,,the groundwork for you.
Dialogue: 0,0:21:04.32,0:21:05.65,Default,,0,0,0,,It takes care of creating
Dialogue: 0,0:21:05.85,0:21:06.85,Default,,0,0,0,,intermediate images.
Dialogue: 0,0:21:07.00,0:21:08.71,Default,,0,0,0,,It takes care of sizing them.
Dialogue: 0,0:21:09.30,0:21:11.09,Default,,0,0,0,,It also -- it even sizes your
Dialogue: 0,0:21:11.09,0:21:11.37,Default,,0,0,0,,outputs.
Dialogue: 0,0:21:11.79,0:21:12.77,Default,,0,0,0,,It takes care of the padding
Dialogue: 0,0:21:12.77,0:21:13.41,Default,,0,0,0,,policies.
Dialogue: 0,0:21:13.80,0:21:15.02,Default,,0,0,0,,It takes care of censoring.
Dialogue: 0,0:21:15.43,0:21:17.52,Default,,0,0,0,,So in short, it's a lot less
Dialogue: 0,0:21:17.57,0:21:19.41,Default,,0,0,0,,code for you to write and a lot
Dialogue: 0,0:21:19.49,0:21:20.75,Default,,0,0,0,,fewer bugs for you to write as
Dialogue: 0,0:21:20.75,0:21:20.96,Default,,0,0,0,,well.
Dialogue: 0,0:21:21.96,0:21:24.07,Default,,0,0,0,,And when I say less code, I mean
Dialogue: 0,0:21:24.60,0:21:25.38,Default,,0,0,0,,a lot less code.
Dialogue: 0,0:21:26.21,0:21:27.91,Default,,0,0,0,,So last year we released this
Dialogue: 0,0:21:28.00,0:21:30.73,Default,,0,0,0,,Metal recognition sample that
Dialogue: 0,0:21:30.73,0:21:32.04,Default,,0,0,0,,uses the Inception-v3 network
Dialogue: 0,0:21:32.04,0:21:33.29,Default,,0,0,0,,for image recognition.
Dialogue: 0,0:21:34.33,0:21:36.03,Default,,0,0,0,,And we took that sample and
Dialogue: 0,0:21:36.03,0:21:37.58,Default,,0,0,0,,converted it to use the new
Dialogue: 0,0:21:37.81,0:21:40.04,Default,,0,0,0,,graph API and found that we had
Dialogue: 0,0:21:40.04,0:21:41.96,Default,,0,0,0,,to write four times less code.
Dialogue: 0,0:21:42.36,0:21:43.96,Default,,0,0,0,,And that's pretty much the same
Dialogue: 0,0:21:43.96,0:21:45.85,Default,,0,0,0,,number of lines as Python code
Dialogue: 0,0:21:46.23,0:21:47.92,Default,,0,0,0,,you would have to write in the
Dialogue: 0,0:21:47.92,0:21:48.89,Default,,0,0,0,,open-source sensor flow
Dialogue: 0,0:21:48.89,0:21:50.44,Default,,0,0,0,,framework to implement the same
Dialogue: 0,0:21:50.44,0:21:50.85,Default,,0,0,0,,network.
Dialogue: 0,0:21:51.48,0:21:52.96,Default,,0,0,0,,And we just want to mention that
Dialogue: 0,0:21:52.96,0:21:54.05,Default,,0,0,0,,we will be releasing this
Dialogue: 0,0:21:54.09,0:21:57.20,Default,,0,0,0,,updated sample code -- updated
Dialogue: 0,0:21:57.20,0:21:58.35,Default,,0,0,0,,example as sample code.
Dialogue: 0,0:21:59.03,0:22:01.80,Default,,0,0,0,,And now having all this
Dialogue: 0,0:22:01.80,0:22:03.28,Default,,0,0,0,,information about your entire
Dialogue: 0,0:22:03.28,0:22:06.12,Default,,0,0,0,,network allows us to deliver the
Dialogue: 0,0:22:06.12,0:22:07.96,Default,,0,0,0,,best performance across
Dialogue: 0,0:22:08.11,0:22:08.87,Default,,0,0,0,,different views.
Dialogue: 0,0:22:09.34,0:22:10.95,Default,,0,0,0,,We make it easy for your to
Dialogue: 0,0:22:10.95,0:22:12.77,Default,,0,0,0,,parallelize between the CPU and
Dialogue: 0,0:22:12.77,0:22:13.21,Default,,0,0,0,,the GPU.
Dialogue: 0,0:22:13.98,0:22:15.88,Default,,0,0,0,,so as the graph is executing --
Dialogue: 0,0:22:16.33,0:22:18.08,Default,,0,0,0,,as the GPU is executing the
Dialogue: 0,0:22:18.08,0:22:19.99,Default,,0,0,0,,graph of one input image, the
Dialogue: 0,0:22:19.99,0:22:21.69,Default,,0,0,0,,CPU can already prepare to
Dialogue: 0,0:22:21.69,0:22:22.78,Default,,0,0,0,,execute the graph for a
Dialogue: 0,0:22:22.78,0:22:23.72,Default,,0,0,0,,different input image.
Dialogue: 0,0:22:25.18,0:22:26.61,Default,,0,0,0,,We can also fuse graph nodes
Dialogue: 0,0:22:26.68,0:22:28.45,Default,,0,0,0,,together like the convolution
Dialogue: 0,0:22:28.86,0:22:29.97,Default,,0,0,0,,and neuron nodes.
Dialogue: 0,0:22:31.86,0:22:33.75,Default,,0,0,0,,And we can execute graph nodes
Dialogue: 0,0:22:33.75,0:22:34.39,Default,,0,0,0,,concurrently.
Dialogue: 0,0:22:34.39,0:22:36.26,Default,,0,0,0,,So if we look at this inception
Dialogue: 0,0:22:36.26,0:22:38.06,Default,,0,0,0,,module again, you can see that
Dialogue: 0,0:22:38.06,0:22:39.89,Default,,0,0,0,,there are multiple rows of these
Dialogue: 0,0:22:39.89,0:22:41.39,Default,,0,0,0,,nodes that can be executed
Dialogue: 0,0:22:41.46,0:22:43.04,Default,,0,0,0,,completely independently of each
Dialogue: 0,0:22:43.04,0:22:43.24,Default,,0,0,0,,other.
Dialogue: 0,0:22:44.18,0:22:45.49,Default,,0,0,0,,And of course the output of
Dialogue: 0,0:22:45.49,0:22:47.33,Default,,0,0,0,,these independent executions
Dialogue: 0,0:22:47.93,0:22:49.22,Default,,0,0,0,,need to be concatenated via
Dialogue: 0,0:22:49.22,0:22:50.22,Default,,0,0,0,,concatenation nodes.
Dialogue: 0,0:22:51.21,0:22:52.66,Default,,0,0,0,,And the graph is smart enough to
Dialogue: 0,0:22:52.66,0:22:54.28,Default,,0,0,0,,optimize those away as well.
Dialogue: 0,0:22:54.89,0:22:57.71,Default,,0,0,0,,And now let's take a look at how
Dialogue: 0,0:22:57.71,0:22:59.59,Default,,0,0,0,,you can use the new graph API.
Dialogue: 0,0:23:00.30,0:23:02.18,Default,,0,0,0,,So this is the code for creating
Dialogue: 0,0:23:02.18,0:23:04.13,Default,,0,0,0,,a convolution node using the
Dialogue: 0,0:23:04.13,0:23:04.65,Default,,0,0,0,,graph API.
Dialogue: 0,0:23:05.83,0:23:07.26,Default,,0,0,0,,So it takes an image as source
Dialogue: 0,0:23:08.23,0:23:09.49,Default,,0,0,0,,and it also has weights.
Dialogue: 0,0:23:09.49,0:23:10.93,Default,,0,0,0,,So let's talk about weights for
Dialogue: 0,0:23:10.93,0:23:11.18,Default,,0,0,0,,a minute.
Dialogue: 0,0:23:13.06,0:23:14.26,Default,,0,0,0,,Neural networks keep growing
Dialogue: 0,0:23:14.26,0:23:15.40,Default,,0,0,0,,larger and larger in size.
Dialogue: 0,0:23:16.14,0:23:17.74,Default,,0,0,0,,And if you have many convolution
Dialogue: 0,0:23:17.74,0:23:19.35,Default,,0,0,0,,nodes in your networks, that
Dialogue: 0,0:23:19.35,0:23:21.44,Default,,0,0,0,,means that the overall size of
Dialogue: 0,0:23:21.50,0:23:22.47,Default,,0,0,0,,the weights for your entire
Dialogue: 0,0:23:22.47,0:23:23.62,Default,,0,0,0,,network could be quite
Dialogue: 0,0:23:23.62,0:23:24.25,Default,,0,0,0,,considerable.
Dialogue: 0,0:23:25.22,0:23:27.02,Default,,0,0,0,,And to help with that we've
Dialogue: 0,0:23:27.02,0:23:30.13,Default,,0,0,0,,added a convolution data source
Dialogue: 0,0:23:30.19,0:23:31.30,Default,,0,0,0,,protocol that you can implement
Dialogue: 0,0:23:31.66,0:23:33.19,Default,,0,0,0,,and it provides just in time
Dialogue: 0,0:23:33.61,0:23:35.04,Default,,0,0,0,,loading and purging of weights
Dialogue: 0,0:23:35.08,0:23:35.28,Default,,0,0,0,,data.
Dialogue: 0,0:23:36.30,0:23:40.05,Default,,0,0,0,,So the idea is that the weights
Dialogue: 0,0:23:40.05,0:23:41.55,Default,,0,0,0,,for your entire network do not
Dialogue: 0,0:23:41.55,0:23:43.20,Default,,0,0,0,,have to be loaded in memory all
Dialogue: 0,0:23:43.20,0:23:44.09,Default,,0,0,0,,at the same time.
Dialogue: 0,0:23:44.63,0:23:45.96,Default,,0,0,0,,They also do not have to be
Dialogue: 0,0:23:45.96,0:23:46.89,Default,,0,0,0,,loaded in advance.
Dialogue: 0,0:23:48.40,0:23:49.66,Default,,0,0,0,,To help minimize the memory
Dialogue: 0,0:23:49.66,0:23:51.56,Default,,0,0,0,,footprint, when we initialize
Dialogue: 0,0:23:51.56,0:23:53.14,Default,,0,0,0,,the graph and we process a
Dialogue: 0,0:23:53.14,0:23:54.52,Default,,0,0,0,,particular convolution layer,
Dialogue: 0,0:23:55.10,0:23:56.13,Default,,0,0,0,,we'll load the weights for that
Dialogue: 0,0:23:56.13,0:23:57.73,Default,,0,0,0,,convolution layer and then we
Dialogue: 0,0:23:57.86,0:23:59.49,Default,,0,0,0,,purge them before we move on to
Dialogue: 0,0:23:59.49,0:24:00.73,Default,,0,0,0,,the next convolution layer.
Dialogue: 0,0:24:02.23,0:24:03.59,Default,,0,0,0,,What you have to do is to
Dialogue: 0,0:24:03.59,0:24:05.15,Default,,0,0,0,,implement this initialization
Dialogue: 0,0:24:05.15,0:24:06.92,Default,,0,0,0,,method which just knows where
Dialogue: 0,0:24:06.92,0:24:08.38,Default,,0,0,0,,the data is but it doesn't
Dialogue: 0,0:24:08.38,0:24:09.09,Default,,0,0,0,,actually load it.
Dialogue: 0,0:24:10.10,0:24:11.26,Default,,0,0,0,,And then when the graph calls
Dialogue: 0,0:24:11.26,0:24:13.27,Default,,0,0,0,,the load function that alerts
Dialogue: 0,0:24:13.27,0:24:14.85,Default,,0,0,0,,you that the weights need to be
Dialogue: 0,0:24:14.85,0:24:15.24,Default,,0,0,0,,loaded.
Dialogue: 0,0:24:15.37,0:24:16.55,Default,,0,0,0,,And then when the purge function
Dialogue: 0,0:24:16.55,0:24:18.17,Default,,0,0,0,,is called by the graph then you
Dialogue: 0,0:24:18.17,0:24:19.32,Default,,0,0,0,,can release the weights.
Dialogue: 0,0:24:21.59,0:24:22.53,Default,,0,0,0,,And now let's build a graph.
Dialogue: 0,0:24:23.45,0:24:24.93,Default,,0,0,0,,So here we're implementing this
Dialogue: 0,0:24:24.93,0:24:26.12,Default,,0,0,0,,makeGraph function.
Dialogue: 0,0:24:26.60,0:24:28.37,Default,,0,0,0,,And on the left you can see all
Dialogue: 0,0:24:28.37,0:24:29.64,Default,,0,0,0,,the nodes that make up our
Dialogue: 0,0:24:29.64,0:24:30.83,Default,,0,0,0,,network that we need to build.
Dialogue: 0,0:24:31.26,0:24:32.93,Default,,0,0,0,,So then we create the nodes.
Dialogue: 0,0:24:33.23,0:24:34.45,Default,,0,0,0,,So we create the convolution
Dialogue: 0,0:24:34.45,0:24:34.84,Default,,0,0,0,,node.
Dialogue: 0,0:24:35.02,0:24:35.62,Default,,0,0,0,,The pooling node.
Dialogue: 0,0:24:35.62,0:24:37.46,Default,,0,0,0,,And then the rest of the nodes.
Dialogue: 0,0:24:37.76,0:24:38.61,Default,,0,0,0,,So we have the nodes.
Dialogue: 0,0:24:38.61,0:24:40.23,Default,,0,0,0,,How do we connect them into a
Dialogue: 0,0:24:40.23,0:24:40.45,Default,,0,0,0,,graph?
Dialogue: 0,0:24:41.65,0:24:43.19,Default,,0,0,0,,So we just take the result image
Dialogue: 0,0:24:43.19,0:24:44.99,Default,,0,0,0,,of one node and pass it as a
Dialogue: 0,0:24:45.07,0:24:46.52,Default,,0,0,0,,source image to the next node.
Dialogue: 0,0:24:46.52,0:24:48.11,Default,,0,0,0,,And then we have our graph.
Dialogue: 0,0:24:49.74,0:24:51.24,Default,,0,0,0,,And now let's run it on the GPU.
Dialogue: 0,0:24:51.91,0:24:54.07,Default,,0,0,0,,So first we do our usual Metal
Dialogue: 0,0:24:54.07,0:24:54.46,Default,,0,0,0,,setup.
Dialogue: 0,0:24:54.89,0:24:56.02,Default,,0,0,0,,We initialize the graph.
Dialogue: 0,0:24:56.68,0:24:58.17,Default,,0,0,0,,We take care of our input data
Dialogue: 0,0:24:58.87,0:25:01.07,Default,,0,0,0,,and then we encode the graph to
Dialogue: 0,0:25:01.07,0:25:01.51,Default,,0,0,0,,the GPU.
Dialogue: 0,0:25:02.28,0:25:04.03,Default,,0,0,0,,And the data in the output image
Dialogue: 0,0:25:04.56,0:25:06.55,Default,,0,0,0,,will be -- the output image will
Dialogue: 0,0:25:06.55,0:25:08.47,Default,,0,0,0,,be populated with data when the
Dialogue: 0,0:25:08.47,0:25:09.58,Default,,0,0,0,,command buffer completes.
Dialogue: 0,0:25:10.09,0:25:11.53,Default,,0,0,0,,And then we have an option to
Dialogue: 0,0:25:11.53,0:25:13.00,Default,,0,0,0,,wait for the GPU to finish.
Dialogue: 0,0:25:13.41,0:25:14.69,Default,,0,0,0,,But we don't want you to do
Dialogue: 0,0:25:14.69,0:25:14.96,Default,,0,0,0,,that.
Dialogue: 0,0:25:15.89,0:25:17.51,Default,,0,0,0,,When this happens the CPU is
Dialogue: 0,0:25:17.51,0:25:19.25,Default,,0,0,0,,waiting for the GPU to finish
Dialogue: 0,0:25:19.84,0:25:21.49,Default,,0,0,0,,before it can start encoding the
Dialogue: 0,0:25:21.49,0:25:22.85,Default,,0,0,0,,next run of the graph.
Dialogue: 0,0:25:23.49,0:25:25.26,Default,,0,0,0,,And this introduces bubbles into
Dialogue: 0,0:25:25.26,0:25:26.27,Default,,0,0,0,,your pipeline, which can
Dialogue: 0,0:25:26.53,0:25:28.04,Default,,0,0,0,,adversely affect performance.
Dialogue: 0,0:25:29.82,0:25:30.69,Default,,0,0,0,,So what we want you to do
Dialogue: 0,0:25:30.69,0:25:32.61,Default,,0,0,0,,instead is to use the new
Dialogue: 0,0:25:32.61,0:25:34.60,Default,,0,0,0,,asynchronous executeAsync API.
Dialogue: 0,0:25:35.43,0:25:37.90,Default,,0,0,0,,So with this API your Metal
Dialogue: 0,0:25:37.97,0:25:39.44,Default,,0,0,0,,setup is even smaller.
Dialogue: 0,0:25:39.63,0:25:41.08,Default,,0,0,0,,So you just need to get the
Dialogue: 0,0:25:41.08,0:25:41.74,Default,,0,0,0,,Metal device.
Dialogue: 0,0:25:42.14,0:25:43.10,Default,,0,0,0,,Then you still need to
Dialogue: 0,0:25:43.10,0:25:44.02,Default,,0,0,0,,initialize your graph.
Dialogue: 0,0:25:44.06,0:25:46.43,Default,,0,0,0,,Prepare the input data and then
Dialogue: 0,0:25:46.43,0:25:47.86,Default,,0,0,0,,you executeAsync call.
Dialogue: 0,0:25:49.59,0:25:52.38,Default,,0,0,0,,It returns immediately and then
Dialogue: 0,0:25:52.38,0:25:54.22,Default,,0,0,0,,the output image will be ready
Dialogue: 0,0:25:55.20,0:25:56.24,Default,,0,0,0,,when this code inside the
Dialogue: 0,0:25:56.24,0:25:57.09,Default,,0,0,0,,closure executes.
Dialogue: 0,0:25:57.80,0:25:59.06,Default,,0,0,0,,But in the meantime, you don't
Dialogue: 0,0:25:59.06,0:26:00.14,Default,,0,0,0,,have to wait for the GPU to
Dialogue: 0,0:26:00.31,0:26:02.06,Default,,0,0,0,,finish, you can already proceed
Dialogue: 0,0:26:02.06,0:26:03.68,Default,,0,0,0,,with a coding and new GPU task.
Dialogue: 0,0:26:04.40,0:26:07.24,Default,,0,0,0,,And this way the CPU and the GPU
Dialogue: 0,0:26:07.24,0:26:08.85,Default,,0,0,0,,are executing concurrently.
Dialogue: 0,0:26:09.41,0:26:10.32,Default,,0,0,0,,There are no bubbles in your
Dialogue: 0,0:26:10.32,0:26:12.76,Default,,0,0,0,,pipeline and they're both
Dialogue: 0,0:26:12.76,0:26:14.38,Default,,0,0,0,,utilized to full capacity.
Dialogue: 0,0:26:16.76,0:26:19.00,Default,,0,0,0,,Okay. And now I will do a live
Dialogue: 0,0:26:19.00,0:26:21.11,Default,,0,0,0,,demo that demonstrates the
Dialogue: 0,0:26:21.15,0:26:22.85,Default,,0,0,0,,performance difference between
Dialogue: 0,0:26:22.97,0:26:24.53,Default,,0,0,0,,the synchronous and asynchronous
Dialogue: 0,0:26:24.53,0:26:24.79,Default,,0,0,0,,APIs.
Dialogue: 0,0:26:24.79,0:26:27.58,Default,,0,0,0,,And this demo will be using the
Dialogue: 0,0:26:27.58,0:26:29.58,Default,,0,0,0,,Inception-v3 network for image
Dialogue: 0,0:26:29.58,0:26:30.12,Default,,0,0,0,,recognition.
Dialogue: 0,0:26:30.52,0:26:30.81,Default,,0,0,0,,All right.
Dialogue: 0,0:26:31.14,0:26:32.73,Default,,0,0,0,,So I will be starting with
Dialogue: 0,0:26:32.73,0:26:34.42,Default,,0,0,0,,synchronous API and here we're
Dialogue: 0,0:26:34.42,0:26:35.71,Default,,0,0,0,,detecting a water bottle.
Dialogue: 0,0:26:35.71,0:26:38.28,Default,,0,0,0,,And we're getting about 50
Dialogue: 0,0:26:38.28,0:26:41.76,Default,,0,0,0,,milliseconds per second per
Dialogue: 0,0:26:41.76,0:26:42.60,Default,,0,0,0,,image on average.
Dialogue: 0,0:26:42.83,0:26:44.07,Default,,0,0,0,,And now I will switch to the
Dialogue: 0,0:26:44.07,0:26:44.96,Default,,0,0,0,,asynchronous API.
Dialogue: 0,0:26:44.96,0:26:47.59,Default,,0,0,0,,And now we're getting about 36
Dialogue: 0,0:26:47.59,0:26:49.55,Default,,0,0,0,,milliseconds per image on
Dialogue: 0,0:26:49.55,0:26:49.94,Default,,0,0,0,,average.
Dialogue: 0,0:26:49.94,0:26:51.66,Default,,0,0,0,,So that's pretty good
Dialogue: 0,0:26:51.69,0:26:52.67,Default,,0,0,0,,performance improvement.
Dialogue: 0,0:26:54.78,0:26:55.07,Default,,0,0,0,,All right.
Dialogue: 0,0:26:55.20,0:26:56.44,Default,,0,0,0,,So that's it for the live demo.
Dialogue: 0,0:26:58.52,0:27:04.02,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:27:04.52,0:27:04.88,Default,,0,0,0,,Thank you.
Dialogue: 0,0:27:06.57,0:27:07.66,Default,,0,0,0,,Okay. Now that we've talked
Dialogue: 0,0:27:07.66,0:27:08.63,Default,,0,0,0,,about the new neural network
Dialogue: 0,0:27:08.63,0:27:10.93,Default,,0,0,0,,graph API and I showed you how
Dialogue: 0,0:27:10.96,0:27:12.72,Default,,0,0,0,,easy it is to use and what great
Dialogue: 0,0:27:12.72,0:27:14.02,Default,,0,0,0,,performance you can achieve with
Dialogue: 0,0:27:14.02,0:27:16.09,Default,,0,0,0,,it, let's now switch gears and
Dialogue: 0,0:27:16.09,0:27:17.17,Default,,0,0,0,,talk about recurrent neural
Dialogue: 0,0:27:17.17,0:27:17.57,Default,,0,0,0,,networks.
Dialogue: 0,0:27:19.42,0:27:20.39,Default,,0,0,0,,So what are recurrent neural
Dialogue: 0,0:27:20.39,0:27:20.79,Default,,0,0,0,,networks?
Dialogue: 0,0:27:23.41,0:27:25.46,Default,,0,0,0,,So one disadvantage of CNNs is
Dialogue: 0,0:27:25.46,0:27:27.28,Default,,0,0,0,,their inability to remember
Dialogue: 0,0:27:27.31,0:27:28.33,Default,,0,0,0,,anything that happened in the
Dialogue: 0,0:27:28.33,0:27:28.47,Default,,0,0,0,,past.
Dialogue: 0,0:27:29.46,0:27:31.23,Default,,0,0,0,,They can take one image as input
Dialogue: 0,0:27:31.90,0:27:33.93,Default,,0,0,0,,and generate a single output
Dialogue: 0,0:27:34.45,0:27:36.32,Default,,0,0,0,,such as the set of probabilities
Dialogue: 0,0:27:36.36,0:27:37.40,Default,,0,0,0,,of what is depicted in the
Dialogue: 0,0:27:37.40,0:27:37.84,Default,,0,0,0,,image.
Dialogue: 0,0:27:39.06,0:27:41.02,Default,,0,0,0,,RNNs on the other hand have
Dialogue: 0,0:27:41.02,0:27:41.45,Default,,0,0,0,,memory.
Dialogue: 0,0:27:42.35,0:27:43.47,Default,,0,0,0,,And they're good at operating on
Dialogue: 0,0:27:43.55,0:27:44.07,Default,,0,0,0,,sequences.
Dialogue: 0,0:27:44.54,0:27:48.26,Default,,0,0,0,,So they can take one input such
Dialogue: 0,0:27:48.26,0:27:49.58,Default,,0,0,0,,as a set of probabilities of
Dialogue: 0,0:27:49.64,0:27:51.02,Default,,0,0,0,,what is depicted in the image
Dialogue: 0,0:27:51.62,0:27:52.97,Default,,0,0,0,,and generate a sequence of
Dialogue: 0,0:27:53.04,0:27:53.37,Default,,0,0,0,,outputs.
Dialogue: 0,0:27:53.37,0:27:56.20,Default,,0,0,0,,So a sequence of words that make
Dialogue: 0,0:27:56.20,0:27:57.59,Default,,0,0,0,,up a caption for this image.
Dialogue: 0,0:27:59.42,0:28:01.72,Default,,0,0,0,,They can also take a sequence of
Dialogue: 0,0:28:01.81,0:28:03.51,Default,,0,0,0,,inputs such as a sentence in
Dialogue: 0,0:28:03.51,0:28:06.63,Default,,0,0,0,,English and generate a sequence
Dialogue: 0,0:28:06.63,0:28:08.51,Default,,0,0,0,,of outputs such as the same
Dialogue: 0,0:28:08.67,0:28:09.95,Default,,0,0,0,,sentence translated to a
Dialogue: 0,0:28:09.95,0:28:12.38,Default,,0,0,0,,different language like Russian
Dialogue: 0,0:28:12.47,0:28:13.06,Default,,0,0,0,,or Finnish.
Dialogue: 0,0:28:13.37,0:28:16.36,Default,,0,0,0,,And we support a number of
Dialogue: 0,0:28:16.36,0:28:17.76,Default,,0,0,0,,different of variants of RNNs.
Dialogue: 0,0:28:18.59,0:28:20.15,Default,,0,0,0,,The single gate RNN, the long
Dialogue: 0,0:28:20.15,0:28:22.16,Default,,0,0,0,,short-term memory RNN or LSTM,
Dialogue: 0,0:28:22.60,0:28:24.59,Default,,0,0,0,,and multiple variants of LSTMs.
Dialogue: 0,0:28:24.87,0:28:26.34,Default,,0,0,0,,The GRU and the MGU.
Dialogue: 0,0:28:27.77,0:28:29.34,Default,,0,0,0,,So let's talk about the simplest
Dialogue: 0,0:28:29.37,0:28:31.33,Default,,0,0,0,,kind of RNN, the single gate
Dialogue: 0,0:28:31.33,0:28:31.53,Default,,0,0,0,,RNN.
Dialogue: 0,0:28:33.67,0:28:34.97,Default,,0,0,0,,the single gate RNN has a
Dialogue: 0,0:28:34.97,0:28:37.01,Default,,0,0,0,,recurrent unit which enables the
Dialogue: 0,0:28:37.07,0:28:38.68,Default,,0,0,0,,previous output over RNN to
Dialogue: 0,0:28:39.00,0:28:40.35,Default,,0,0,0,,affect the output of the
Dialogue: 0,0:28:40.41,0:28:41.85,Default,,0,0,0,,subsequent iterations of the
Dialogue: 0,0:28:41.85,0:28:42.41,Default,,0,0,0,,same RNN.
Dialogue: 0,0:28:43.61,0:28:45.50,Default,,0,0,0,,But the single gate RNNs are not
Dialogue: 0,0:28:45.55,0:28:47.47,Default,,0,0,0,,powerful enough to carry on
Dialogue: 0,0:28:47.47,0:28:48.75,Default,,0,0,0,,important information for many
Dialogue: 0,0:28:48.75,0:28:49.29,Default,,0,0,0,,iterations.
Dialogue: 0,0:28:50.14,0:28:51.68,Default,,0,0,0,,Because the current output of an
Dialogue: 0,0:28:51.79,0:28:53.98,Default,,0,0,0,,RNN -- of the single gate RNN is
Dialogue: 0,0:28:53.98,0:28:55.00,Default,,0,0,0,,also its current state.
Dialogue: 0,0:28:55.00,0:28:55.98,Default,,0,0,0,,There's nothing else there.
Dialogue: 0,0:28:57.15,0:28:59.43,Default,,0,0,0,,The solution to this is the long
Dialogue: 0,0:28:59.48,0:29:01.60,Default,,0,0,0,,short-term memory RNN or LSTM.
Dialogue: 0,0:29:02.38,0:29:03.91,Default,,0,0,0,,It's built from single gate RNNs
Dialogue: 0,0:29:03.91,0:29:06.25,Default,,0,0,0,,and it has an internal memory
Dialogue: 0,0:29:06.25,0:29:06.51,Default,,0,0,0,,cell.
Dialogue: 0,0:29:07.44,0:29:08.86,Default,,0,0,0,,And a certain combination of
Dialogue: 0,0:29:08.96,0:29:10.60,Default,,0,0,0,,gates control how the
Dialogue: 0,0:29:10.60,0:29:13.11,Default,,0,0,0,,information flows inside LSTM.
Dialogue: 0,0:29:13.44,0:29:15.02,Default,,0,0,0,,And what is stored and not
Dialogue: 0,0:29:15.14,0:29:16.27,Default,,0,0,0,,stored in the memory cell.
Dialogue: 0,0:29:16.85,0:29:19.66,Default,,0,0,0,,So let's take a look at the
Dialogue: 0,0:29:19.66,0:29:21.32,Default,,0,0,0,,architecture of LSTM in more
Dialogue: 0,0:29:21.32,0:29:21.78,Default,,0,0,0,,detail.
Dialogue: 0,0:29:22.21,0:29:25.25,Default,,0,0,0,,As I said, the most important
Dialogue: 0,0:29:25.36,0:29:27.85,Default,,0,0,0,,entity inside LSTM is the memory
Dialogue: 0,0:29:27.89,0:29:30.41,Default,,0,0,0,,cell which is updated in every
Dialogue: 0,0:29:30.48,0:29:31.54,Default,,0,0,0,,duration of LSTM.
Dialogue: 0,0:29:31.54,0:29:33.43,Default,,0,0,0,,So you can think of each
Dialogue: 0,0:29:33.85,0:29:35.25,Default,,0,0,0,,iteration of LSTM is this
Dialogue: 0,0:29:35.31,0:29:37.46,Default,,0,0,0,,transition between the old and
Dialogue: 0,0:29:37.46,0:29:38.02,Default,,0,0,0,,new memory.
Dialogue: 0,0:29:38.68,0:29:40.79,Default,,0,0,0,,And now let's talk about the
Dialogue: 0,0:29:40.82,0:29:41.04,Default,,0,0,0,,gates.
Dialogue: 0,0:29:41.57,0:29:43.38,Default,,0,0,0,,So first there is a forget gate
Dialogue: 0,0:29:44.22,0:29:45.88,Default,,0,0,0,,which decides what to keep and
Dialogue: 0,0:29:45.88,0:29:47.21,Default,,0,0,0,,what not to keep from old
Dialogue: 0,0:29:47.21,0:29:47.57,Default,,0,0,0,,memory.
Dialogue: 0,0:29:48.97,0:29:50.46,Default,,0,0,0,,And then there are the inputs
Dialogue: 0,0:29:50.46,0:29:51.84,Default,,0,0,0,,and the cell gates and their
Dialogue: 0,0:29:51.84,0:29:54.00,Default,,0,0,0,,combined contribution determines
Dialogue: 0,0:29:54.07,0:29:55.79,Default,,0,0,0,,what from the current input will
Dialogue: 0,0:29:55.79,0:29:56.94,Default,,0,0,0,,affect the new memory.
Dialogue: 0,0:29:56.94,0:29:59.14,Default,,0,0,0,,And then the combination of all
Dialogue: 0,0:29:59.14,0:30:00.87,Default,,0,0,0,,of these three gates is combined
Dialogue: 0,0:30:01.23,0:30:04.60,Default,,0,0,0,,to update the memory cell.
Dialogue: 0,0:30:05.70,0:30:07.58,Default,,0,0,0,,And finally, there is the output
Dialogue: 0,0:30:07.63,0:30:09.66,Default,,0,0,0,,gate which determines what from
Dialogue: 0,0:30:09.66,0:30:11.98,Default,,0,0,0,,the previous inputs the -- the
Dialogue: 0,0:30:12.48,0:30:14.08,Default,,0,0,0,,previous output, the current
Dialogue: 0,0:30:14.08,0:30:16.13,Default,,0,0,0,,inputs and the new memory will
Dialogue: 0,0:30:16.13,0:30:17.94,Default,,0,0,0,,affect the output of LSTM.
Dialogue: 0,0:30:19.20,0:30:20.63,Default,,0,0,0,,So now that you know what LSTM
Dialogue: 0,0:30:20.63,0:30:22.21,Default,,0,0,0,,is made up of, let's take a look
Dialogue: 0,0:30:22.21,0:30:24.01,Default,,0,0,0,,at how you can create one using
Dialogue: 0,0:30:24.01,0:30:24.58,Default,,0,0,0,,our framework.
Dialogue: 0,0:30:25.62,0:30:27.54,Default,,0,0,0,,So first you create a descriptor
Dialogue: 0,0:30:27.76,0:30:28.58,Default,,0,0,0,,for the LSTM.
Dialogue: 0,0:30:29.15,0:30:31.31,Default,,0,0,0,,And then you need to initialize
Dialogue: 0,0:30:31.53,0:30:31.88,Default,,0,0,0,,the gates.
Dialogue: 0,0:30:32.44,0:30:33.68,Default,,0,0,0,,So what controls the gates?
Dialogue: 0,0:30:33.68,0:30:35.15,Default,,0,0,0,,So what controls the gates with
Dialogue: 0,0:30:35.31,0:30:36.16,Default,,0,0,0,,-- what controls how they
Dialogue: 0,0:30:36.16,0:30:37.76,Default,,0,0,0,,operate is the trained
Dialogue: 0,0:30:37.76,0:30:38.39,Default,,0,0,0,,parameters.
Dialogue: 0,0:30:39.15,0:30:40.16,Default,,0,0,0,,The ones that come from the
Dialogue: 0,0:30:40.16,0:30:41.73,Default,,0,0,0,,training step where you train a
Dialogue: 0,0:30:41.73,0:30:43.53,Default,,0,0,0,,system to do a particular task.
Dialogue: 0,0:30:45.57,0:30:47.50,Default,,0,0,0,,And there are multiple gates for
Dialogue: 0,0:30:47.50,0:30:48.59,Default,,0,0,0,,you to initialize as you can
Dialogue: 0,0:30:48.65,0:30:49.86,Default,,0,0,0,,see, but we're only showing two
Dialogue: 0,0:30:49.86,0:30:52.36,Default,,0,0,0,,initializations just to be
Dialogue: 0,0:30:52.36,0:30:52.73,Default,,0,0,0,,brief.
Dialogue: 0,0:30:53.21,0:30:54.34,Default,,0,0,0,,And as you can see, we're also
Dialogue: 0,0:30:54.34,0:30:56.05,Default,,0,0,0,,using a data source provider.
Dialogue: 0,0:30:56.05,0:30:57.45,Default,,0,0,0,,The same one I showed you before
Dialogue: 0,0:30:57.56,0:30:58.61,Default,,0,0,0,,to initialize the weights.
Dialogue: 0,0:30:59.66,0:31:01.54,Default,,0,0,0,,And the next step is to create
Dialogue: 0,0:31:01.54,0:31:03.61,Default,,0,0,0,,our LSTM layer and now we want
Dialogue: 0,0:31:03.61,0:31:04.88,Default,,0,0,0,,to run it on the GPU.
Dialogue: 0,0:31:06.59,0:31:08.65,Default,,0,0,0,,So we need to create our arrays
Dialogue: 0,0:31:08.65,0:31:10.98,Default,,0,0,0,,that will hold the input and
Dialogue: 0,0:31:10.98,0:31:13.24,Default,,0,0,0,,output for the sequence of the
Dialogue: 0,0:31:13.24,0:31:14.27,Default,,0,0,0,,LSTM executions.
Dialogue: 0,0:31:14.89,0:31:16.08,Default,,0,0,0,,And then we encode the sequence
Dialogue: 0,0:31:16.08,0:31:16.72,Default,,0,0,0,,to the GPU.
Dialogue: 0,0:31:17.42,0:31:19.45,Default,,0,0,0,,And here we're showing you the
Dialogue: 0,0:31:19.67,0:31:21.55,Default,,0,0,0,,-- a matrix-based RNN, but we
Dialogue: 0,0:31:21.55,0:31:22.65,Default,,0,0,0,,just want to mention that we
Dialogue: 0,0:31:22.69,0:31:25.73,Default,,0,0,0,,also support RNNs that operate
Dialogue: 0,0:31:25.73,0:31:27.64,Default,,0,0,0,,on MPS images via convolutions.
Dialogue: 0,0:31:30.18,0:31:31.22,Default,,0,0,0,,And now let's take a look at an
Dialogue: 0,0:31:31.22,0:31:32.02,Default,,0,0,0,,actual example.
Dialogue: 0,0:31:32.60,0:31:34.37,Default,,0,0,0,,So we'll use image captioning as
Dialogue: 0,0:31:34.37,0:31:35.71,Default,,0,0,0,,an example of using LSTM.
Dialogue: 0,0:31:36.73,0:31:38.57,Default,,0,0,0,,So as you recall, I told you
Dialogue: 0,0:31:38.90,0:31:40.65,Default,,0,0,0,,that deep learning algorithms
Dialogue: 0,0:31:40.65,0:31:42.08,Default,,0,0,0,,have two phases.
Dialogue: 0,0:31:42.35,0:31:43.32,Default,,0,0,0,,The training phase and the
Dialogue: 0,0:31:43.32,0:31:44.03,Default,,0,0,0,,inference phase.
Dialogue: 0,0:31:44.82,0:31:46.82,Default,,0,0,0,,So to train a system to caption
Dialogue: 0,0:31:46.82,0:31:49.20,Default,,0,0,0,,images you need to feed it a
Dialogue: 0,0:31:49.20,0:31:51.06,Default,,0,0,0,,large number of images with
Dialogue: 0,0:31:51.06,0:31:52.36,Default,,0,0,0,,human-generated captions.
Dialogue: 0,0:31:53.84,0:31:56.61,Default,,0,0,0,,So what does this system have?
Dialogue: 0,0:31:56.66,0:31:57.69,Default,,0,0,0,,Like what is it made out of?
Dialogue: 0,0:31:58.54,0:32:02.02,Default,,0,0,0,,So this system has a CNN and a
Dialogue: 0,0:32:02.02,0:32:03.91,Default,,0,0,0,,RNN working together to generate
Dialogue: 0,0:32:03.91,0:32:04.35,Default,,0,0,0,,captions.
Dialogue: 0,0:32:04.75,0:32:07.32,Default,,0,0,0,,The CNN is used to figure out
Dialogue: 0,0:32:07.32,0:32:09.32,Default,,0,0,0,,what's depicted in the image and
Dialogue: 0,0:32:09.32,0:32:10.89,Default,,0,0,0,,then the RNN is used to generate
Dialogue: 0,0:32:10.96,0:32:11.81,Default,,0,0,0,,the actual caption.
Dialogue: 0,0:32:13.26,0:32:15.08,Default,,0,0,0,,And the output of that process
Dialogue: 0,0:32:15.16,0:32:17.01,Default,,0,0,0,,is the trained parameters which
Dialogue: 0,0:32:17.01,0:32:19.04,Default,,0,0,0,,are required for the next step,
Dialogue: 0,0:32:20.19,0:32:20.89,Default,,0,0,0,,the inference step.
Dialogue: 0,0:32:21.68,0:32:25.61,Default,,0,0,0,,So in the inference phase, the
Dialogue: 0,0:32:25.66,0:32:27.77,Default,,0,0,0,,trained parameters control both
Dialogue: 0,0:32:27.77,0:32:29.83,Default,,0,0,0,,the operation of the CNN layers
Dialogue: 0,0:32:29.83,0:32:31.87,Default,,0,0,0,,and the operation of the RNN
Dialogue: 0,0:32:31.87,0:32:32.15,Default,,0,0,0,,gates.
Dialogue: 0,0:32:33.21,0:32:37.28,Default,,0,0,0,,And then for each image it's
Dialogue: 0,0:32:37.34,0:32:39.17,Default,,0,0,0,,processed by both the CNN and
Dialogue: 0,0:32:39.45,0:32:41.33,Default,,0,0,0,,the RNN to generate a caption.
Dialogue: 0,0:32:42.22,0:32:43.25,Default,,0,0,0,,So we already know a good
Dialogue: 0,0:32:43.25,0:32:44.64,Default,,0,0,0,,network for figuring out what's
Dialogue: 0,0:32:44.71,0:32:45.82,Default,,0,0,0,,depicted in the image.
Dialogue: 0,0:32:46.09,0:32:47.51,Default,,0,0,0,,It's the Inception-v3 network,
Dialogue: 0,0:32:47.88,0:32:48.63,Default,,0,0,0,,so we'll use that.
Dialogue: 0,0:32:49.19,0:32:50.46,Default,,0,0,0,,And we just talked about LSTMs,
Dialogue: 0,0:32:50.46,0:32:52.24,Default,,0,0,0,,so let's use that to generate
Dialogue: 0,0:32:52.45,0:32:53.04,Default,,0,0,0,,our caption.
Dialogue: 0,0:32:54.00,0:32:56.46,Default,,0,0,0,,And the caption generation phase
Dialogue: 0,0:32:57.27,0:32:58.18,Default,,0,0,0,,-- the caption generation
Dialogue: 0,0:32:58.18,0:32:59.73,Default,,0,0,0,,process also has two phases.
Dialogue: 0,0:33:00.01,0:33:02.21,Default,,0,0,0,,So first we have the LSTM
Dialogue: 0,0:33:02.49,0:33:03.65,Default,,0,0,0,,initialization phase.
Dialogue: 0,0:33:04.85,0:33:06.13,Default,,0,0,0,,So we run our Inception-v3
Dialogue: 0,0:33:06.13,0:33:08.62,Default,,0,0,0,,network and we actually run all
Dialogue: 0,0:33:08.62,0:33:10.50,Default,,0,0,0,,of the layers except the very
Dialogue: 0,0:33:10.50,0:33:11.99,Default,,0,0,0,,last SoftMax layer.
Dialogue: 0,0:33:12.24,0:33:13.39,Default,,0,0,0,,And the output of that is a
Dialogue: 0,0:33:13.39,0:33:15.02,Default,,0,0,0,,feature vector which has
Dialogue: 0,0:33:15.02,0:33:16.20,Default,,0,0,0,,information about what is
Dialogue: 0,0:33:16.20,0:33:17.23,Default,,0,0,0,,depicted in the image.
Dialogue: 0,0:33:17.91,0:33:19.02,Default,,0,0,0,,And then we take that feature
Dialogue: 0,0:33:19.02,0:33:20.57,Default,,0,0,0,,vector and convert it to a
Dialogue: 0,0:33:20.57,0:33:23.25,Default,,0,0,0,,compact representation that's
Dialogue: 0,0:33:23.25,0:33:24.29,Default,,0,0,0,,required by LSTM.
Dialogue: 0,0:33:24.29,0:33:26.60,Default,,0,0,0,,And then run that through LSTM
Dialogue: 0,0:33:26.95,0:33:27.75,Default,,0,0,0,,to initialize it.
Dialogue: 0,0:33:28.74,0:33:30.47,Default,,0,0,0,,And then once we have our
Dialogue: 0,0:33:30.47,0:33:32.44,Default,,0,0,0,,initialized LSTM, then we're
Dialogue: 0,0:33:32.44,0:33:33.59,Default,,0,0,0,,ready for the next phase.
Dialogue: 0,0:33:34.61,0:33:36.07,Default,,0,0,0,,Our actual caption generation
Dialogue: 0,0:33:36.07,0:33:36.38,Default,,0,0,0,,phase.
Dialogue: 0,0:33:38.12,0:33:39.68,Default,,0,0,0,,And we start this process by
Dialogue: 0,0:33:39.68,0:33:41.37,Default,,0,0,0,,passing in a special sentence
Dialogue: 0,0:33:41.44,0:33:44.03,Default,,0,0,0,,start ID token to our LSTM.
Dialogue: 0,0:33:44.24,0:33:45.05,Default,,0,0,0,,And the output of that
Dialogue: 0,0:33:45.05,0:33:46.76,Default,,0,0,0,,operations is a sequence of
Dialogue: 0,0:33:46.76,0:33:50.01,Default,,0,0,0,,words which are, you know, the
Dialogue: 0,0:33:50.01,0:33:51.28,Default,,0,0,0,,words that are connected to what
Dialogue: 0,0:33:51.28,0:33:52.67,Default,,0,0,0,,is depicted in the image.
Dialogue: 0,0:33:53.53,0:33:55.81,Default,,0,0,0,,And then we pass those words to
Dialogue: 0,0:33:55.81,0:33:57.23,Default,,0,0,0,,a SoftMax layer which computes
Dialogue: 0,0:33:57.23,0:33:58.80,Default,,0,0,0,,probabilities for these words.
Dialogue: 0,0:33:59.33,0:34:01.18,Default,,0,0,0,,And we pick the three best ones.
Dialogue: 0,0:34:01.33,0:34:03.28,Default,,0,0,0,,And these three best words are
Dialogue: 0,0:34:03.28,0:34:05.82,Default,,0,0,0,,also our one-word partial
Dialogue: 0,0:34:05.82,0:34:07.55,Default,,0,0,0,,captions for a particular image.
Dialogue: 0,0:34:08.13,0:34:09.73,Default,,0,0,0,,So we take those words and pass
Dialogue: 0,0:34:09.81,0:34:11.86,Default,,0,0,0,,them to the next situation of
Dialogue: 0,0:34:11.95,0:34:15.05,Default,,0,0,0,,LSTM which function is to now
Dialogue: 0,0:34:15.10,0:34:16.89,Default,,0,0,0,,come up with three best two-word
Dialogue: 0,0:34:16.92,0:34:19.22,Default,,0,0,0,,captions for our image and so
Dialogue: 0,0:34:19.22,0:34:19.39,Default,,0,0,0,,on.
Dialogue: 0,0:34:19.47,0:34:21.42,Default,,0,0,0,,We execute for N iterations
Dialogue: 0,0:34:21.89,0:34:23.08,Default,,0,0,0,,until we reach a stopping
Dialogue: 0,0:34:23.08,0:34:25.60,Default,,0,0,0,,condition, which is when we
Dialogue: 0,0:34:25.63,0:34:27.12,Default,,0,0,0,,either reach the maximum number
Dialogue: 0,0:34:27.12,0:34:28.97,Default,,0,0,0,,of words that we want to be in
Dialogue: 0,0:34:28.97,0:34:30.86,Default,,0,0,0,,our caption, or when the
Dialogue: 0,0:34:30.86,0:34:32.14,Default,,0,0,0,,probabilities evolving the newly
Dialogue: 0,0:34:32.14,0:34:33.91,Default,,0,0,0,,generating captions drop to 0.
Dialogue: 0,0:34:34.99,0:34:36.00,Default,,0,0,0,,So I know this is still pretty
Dialogue: 0,0:34:36.00,0:34:36.51,Default,,0,0,0,,abstract.
Dialogue: 0,0:34:36.85,0:34:39.01,Default,,0,0,0,,So let's look at the output of
Dialogue: 0,0:34:39.39,0:34:42.27,Default,,0,0,0,,LSTM -- of an actual output of
Dialogue: 0,0:34:42.33,0:34:44.56,Default,,0,0,0,,LSTM for several iterations for
Dialogue: 0,0:34:44.56,0:34:45.55,Default,,0,0,0,,a particular image.
Dialogue: 0,0:34:46.22,0:34:49.79,Default,,0,0,0,,So in this image we have, you
Dialogue: 0,0:34:49.79,0:34:51.64,Default,,0,0,0,,know, our surfer riding a wave.
Dialogue: 0,0:34:51.64,0:34:53.15,Default,,0,0,0,,And we want to compute the top
Dialogue: 0,0:34:53.15,0:34:54.67,Default,,0,0,0,,three captions for this image.
Dialogue: 0,0:34:55.70,0:34:57.29,Default,,0,0,0,,And in the first iteration of
Dialogue: 0,0:34:57.37,0:34:59.94,Default,,0,0,0,,LSTM we generate three best
Dialogue: 0,0:34:59.94,0:35:00.31,Default,,0,0,0,,words.
Dialogue: 0,0:35:02.34,0:35:04.45,Default,,0,0,0,,So -- which are our best
Dialogue: 0,0:35:04.45,0:35:05.69,Default,,0,0,0,,one-word captions for this
Dialogue: 0,0:35:05.69,0:35:06.00,Default,,0,0,0,,image.
Dialogue: 0,0:35:06.51,0:35:07.60,Default,,0,0,0,,So "man", "a", and "the".
Dialogue: 0,0:35:08.32,0:35:10.60,Default,,0,0,0,,And the word "a" has the highest
Dialogue: 0,0:35:10.60,0:35:11.19,Default,,0,0,0,,probability.
Dialogue: 0,0:35:11.94,0:35:13.55,Default,,0,0,0,,So we take these three words and
Dialogue: 0,0:35:13.55,0:35:15.20,Default,,0,0,0,,we pass them to the next
Dialogue: 0,0:35:15.20,0:35:16.44,Default,,0,0,0,,iteration of LSTM.
Dialogue: 0,0:35:17.17,0:35:19.36,Default,,0,0,0,,And in this iteration, for every
Dialogue: 0,0:35:19.36,0:35:21.42,Default,,0,0,0,,one of these three starter
Dialogue: 0,0:35:22.44,0:35:24.42,Default,,0,0,0,,words, LSTM generates three new
Dialogue: 0,0:35:24.42,0:35:26.03,Default,,0,0,0,,words that have the highest
Dialogue: 0,0:35:26.03,0:35:28.50,Default,,0,0,0,,probability of following each
Dialogue: 0,0:35:28.50,0:35:29.61,Default,,0,0,0,,one of these starter words.
Dialogue: 0,0:35:30.67,0:35:31.97,Default,,0,0,0,,Right? So we have three new
Dialogue: 0,0:35:31.97,0:35:33.56,Default,,0,0,0,,words to follow the word "man".
Dialogue: 0,0:35:33.95,0:35:35.26,Default,,0,0,0,,Three new words to follow the
Dialogue: 0,0:35:35.26,0:35:37.77,Default,,0,0,0,,word "a", and three new words to
Dialogue: 0,0:35:37.83,0:35:38.98,Default,,0,0,0,,follow the word "the".
Dialogue: 0,0:35:40.69,0:35:42.30,Default,,0,0,0,,And now as you can see, each one
Dialogue: 0,0:35:42.30,0:35:44.49,Default,,0,0,0,,of these two-word captions also
Dialogue: 0,0:35:44.49,0:35:45.49,Default,,0,0,0,,have a probability.
Dialogue: 0,0:35:46.03,0:35:47.87,Default,,0,0,0,,And because the word "a" had
Dialogue: 0,0:35:47.94,0:35:49.29,Default,,0,0,0,,such a high probability in the
Dialogue: 0,0:35:49.29,0:35:53.37,Default,,0,0,0,,first iteration, then the
Dialogue: 0,0:35:53.37,0:35:54.65,Default,,0,0,0,,captions that start with the
Dialogue: 0,0:35:54.65,0:35:56.43,Default,,0,0,0,,word "a" in the second iteration
Dialogue: 0,0:35:56.48,0:35:58.16,Default,,0,0,0,,also end up having the highest
Dialogue: 0,0:35:58.16,0:35:58.80,Default,,0,0,0,,probability.
Dialogue: 0,0:35:58.90,0:36:00.92,Default,,0,0,0,,Why? Because the probability of
Dialogue: 0,0:36:00.92,0:36:02.51,Default,,0,0,0,,a two-word caption is just a
Dialogue: 0,0:36:02.54,0:36:04.52,Default,,0,0,0,,product of the probabilities of
Dialogue: 0,0:36:04.52,0:36:05.71,Default,,0,0,0,,the words that make up that
Dialogue: 0,0:36:05.71,0:36:06.01,Default,,0,0,0,,caption.
Dialogue: 0,0:36:07.12,0:36:08.89,Default,,0,0,0,,So that's how we get these three
Dialogue: 0,0:36:08.89,0:36:09.40,Default,,0,0,0,,best ones.
Dialogue: 0,0:36:09.70,0:36:11.23,Default,,0,0,0,,And then we take them and we
Dialogue: 0,0:36:11.23,0:36:12.84,Default,,0,0,0,,move on to the next iteration.
Dialogue: 0,0:36:13.19,0:36:14.41,Default,,0,0,0,,And in the next iteration we
Dialogue: 0,0:36:14.41,0:36:15.94,Default,,0,0,0,,just add one more word to our
Dialogue: 0,0:36:15.94,0:36:17.54,Default,,0,0,0,,captions so that we have
Dialogue: 0,0:36:17.85,0:36:18.81,Default,,0,0,0,,three-word captions.
Dialogue: 0,0:36:19.21,0:36:20.00,Default,,0,0,0,,And then we compute the
Dialogue: 0,0:36:20.00,0:36:21.84,Default,,0,0,0,,probabilities of those captions
Dialogue: 0,0:36:21.84,0:36:22.89,Default,,0,0,0,,and pick the best three.
Dialogue: 0,0:36:23.94,0:36:25.11,Default,,0,0,0,,And we move on to the next
Dialogue: 0,0:36:25.11,0:36:27.03,Default,,0,0,0,,iteration where we just end up
Dialogue: 0,0:36:27.03,0:36:28.75,Default,,0,0,0,,adding one more word to our
Dialogue: 0,0:36:28.75,0:36:29.19,Default,,0,0,0,,caption.
Dialogue: 0,0:36:29.19,0:36:30.57,Default,,0,0,0,,So we have four-word captions.
Dialogue: 0,0:36:30.98,0:36:31.88,Default,,0,0,0,,And then we compute the
Dialogue: 0,0:36:31.93,0:36:33.19,Default,,0,0,0,,probabilities of all these
Dialogue: 0,0:36:33.24,0:36:34.55,Default,,0,0,0,,captions and pick the best
Dialogue: 0,0:36:34.61,0:36:34.82,Default,,0,0,0,,three.
Dialogue: 0,0:36:36.18,0:36:37.31,Default,,0,0,0,,And so on -- I think you get the
Dialogue: 0,0:36:37.31,0:36:37.65,Default,,0,0,0,,idea.
Dialogue: 0,0:36:37.87,0:36:38.94,Default,,0,0,0,,Let's just skip to the end.
Dialogue: 0,0:36:39.30,0:36:41.42,Default,,0,0,0,,So in the end, we get our three
Dialogue: 0,0:36:41.42,0:36:43.51,Default,,0,0,0,,top captions for this particular
Dialogue: 0,0:36:43.51,0:36:43.94,Default,,0,0,0,,image.
Dialogue: 0,0:36:43.94,0:36:45.91,Default,,0,0,0,,And the best one is a man riding
Dialogue: 0,0:36:45.91,0:36:47.43,Default,,0,0,0,,a wave on top of a surfboard,
Dialogue: 0,0:36:47.66,0:36:48.62,Default,,0,0,0,,which I think it's pretty close.
Dialogue: 0,0:36:50.97,0:36:52.35,Default,,0,0,0,,So -- [applause] and let's now
Dialogue: 0,0:36:52.35,0:36:52.73,Default,,0,0,0,,do a demo.
Dialogue: 0,0:36:53.51,0:36:55.51,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:36:58.48,0:37:00.12,Default,,0,0,0,,So now we'll do a demo of this
Dialogue: 0,0:37:00.61,0:37:02.21,Default,,0,0,0,,-- of the captioning network.
Dialogue: 0,0:37:03.35,0:37:04.86,Default,,0,0,0,,So we have a collection of
Dialogue: 0,0:37:04.86,0:37:07.16,Default,,0,0,0,,images here, and as soon as I
Dialogue: 0,0:37:07.16,0:37:09.04,Default,,0,0,0,,tap on an image then the CNN
Dialogue: 0,0:37:09.14,0:37:10.83,Default,,0,0,0,,will run to determine what is
Dialogue: 0,0:37:10.83,0:37:12.53,Default,,0,0,0,,depicted in the image.
Dialogue: 0,0:37:12.53,0:37:14.05,Default,,0,0,0,,And then the RNN will run to
Dialogue: 0,0:37:14.05,0:37:15.23,Default,,0,0,0,,generate the actual caption.
Dialogue: 0,0:37:15.36,0:37:16.04,Default,,0,0,0,,So let's try it out.
Dialogue: 0,0:37:17.83,0:37:19.45,Default,,0,0,0,,>> A man riding a wave on top of
Dialogue: 0,0:37:19.45,0:37:19.77,Default,,0,0,0,,a surfboard.
Dialogue: 0,0:37:19.77,0:37:22.36,Default,,0,0,0,,>> So we already know this.
Dialogue: 0,0:37:23.53,0:37:24.57,Default,,0,0,0,,Now let's try another image.
Dialogue: 0,0:37:25.00,0:37:26.54,Default,,0,0,0,,>> An old truck is parked in the
Dialogue: 0,0:37:26.54,0:37:27.11,Default,,0,0,0,,field.
Dialogue: 0,0:37:27.63,0:37:28.94,Default,,0,0,0,,>> So the network actually knows
Dialogue: 0,0:37:28.98,0:37:30.36,Default,,0,0,0,,that it's an old truck and that
Dialogue: 0,0:37:30.36,0:37:31.79,Default,,0,0,0,,it's parked and not moving,
Dialogue: 0,0:37:31.97,0:37:33.34,Default,,0,0,0,,which I think is pretty
Dialogue: 0,0:37:33.56,0:37:34.16,Default,,0,0,0,,impressive.
Dialogue: 0,0:37:34.79,0:37:35.66,Default,,0,0,0,,Now let's try one more.
Dialogue: 0,0:37:37.03,0:37:38.50,Default,,0,0,0,,>> A black and white dog laying
Dialogue: 0,0:37:38.50,0:37:39.09,Default,,0,0,0,,in the grass.
Dialogue: 0,0:37:39.80,0:37:40.90,Default,,0,0,0,,>> So the network knows that
Dialogue: 0,0:37:40.90,0:37:42.18,Default,,0,0,0,,it's a black and white dog and
Dialogue: 0,0:37:42.18,0:37:43.64,Default,,0,0,0,,that it's laying in the grass,
Dialogue: 0,0:37:44.33,0:37:45.11,Default,,0,0,0,,not running.
Dialogue: 0,0:37:45.24,0:37:46.36,Default,,0,0,0,,Not walking.
Dialogue: 0,0:37:46.73,0:37:47.88,Default,,0,0,0,,Not sitting.
Dialogue: 0,0:37:48.34,0:37:50.27,Default,,0,0,0,,Laying in the grass.
Dialogue: 0,0:37:50.77,0:37:52.80,Default,,0,0,0,,So pretty cool.
Dialogue: 0,0:37:53.52,0:37:57.79,Default,,0,0,0,,[ Applause ]
Dialogue: 0,0:37:58.29,0:37:58.73,Default,,0,0,0,,Thank you.
Dialogue: 0,0:37:59.31,0:38:01.17,Default,,0,0,0,,And on this note, let's go to
Dialogue: 0,0:38:01.24,0:38:01.59,Default,,0,0,0,,the summary.
Dialogue: 0,0:38:02.07,0:38:03.54,Default,,0,0,0,,So in this session we talked
Dialogue: 0,0:38:03.54,0:38:05.25,Default,,0,0,0,,about all of the new primitives
Dialogue: 0,0:38:05.28,0:38:07.01,Default,,0,0,0,,that we added to the MPS
Dialogue: 0,0:38:07.34,0:38:08.21,Default,,0,0,0,,framework this year.
Dialogue: 0,0:38:08.59,0:38:10.24,Default,,0,0,0,,We've expanded our support for
Dialogue: 0,0:38:10.24,0:38:12.39,Default,,0,0,0,,image processing primitives and
Dialogue: 0,0:38:12.79,0:38:13.74,Default,,0,0,0,,for convolutional neural
Dialogue: 0,0:38:13.74,0:38:14.14,Default,,0,0,0,,networks.
Dialogue: 0,0:38:15.01,0:38:16.60,Default,,0,0,0,,And we've added support for
Dialogue: 0,0:38:16.60,0:38:18.89,Default,,0,0,0,,linear algebra and recurrent
Dialogue: 0,0:38:18.89,0:38:22.23,Default,,0,0,0,,neural networks.
Dialogue: 0,0:38:23.10,0:38:24.67,Default,,0,0,0,,the framework is optimized for
Dialogue: 0,0:38:24.67,0:38:26.15,Default,,0,0,0,,iOS, as I told you, and now
Dialogue: 0,0:38:26.60,0:38:29.23,Default,,0,0,0,,these primitives are also all
Dialogue: 0,0:38:29.23,0:38:30.02,Default,,0,0,0,,available on the Mac.
Dialogue: 0,0:38:31.12,0:38:32.42,Default,,0,0,0,,We also talked about the new
Dialogue: 0,0:38:32.42,0:38:34.68,Default,,0,0,0,,neural network graph API and we
Dialogue: 0,0:38:34.68,0:38:36.41,Default,,0,0,0,,showed you how easy it is to
Dialogue: 0,0:38:36.41,0:38:38.34,Default,,0,0,0,,use, to build and execute your
Dialogue: 0,0:38:38.34,0:38:39.67,Default,,0,0,0,,networks on the GPU.
Dialogue: 0,0:38:40.43,0:38:42.19,Default,,0,0,0,,And that it makes it possible
Dialogue: 0,0:38:42.19,0:38:43.59,Default,,0,0,0,,for us to deliver the best
Dialogue: 0,0:38:43.67,0:38:45.35,Default,,0,0,0,,performance for your networks
Dialogue: 0,0:38:45.35,0:38:46.34,Default,,0,0,0,,across the different GPUs.
Dialogue: 0,0:38:46.34,0:38:49.78,Default,,0,0,0,,And we would love to see you use
Dialogue: 0,0:38:49.78,0:38:51.98,Default,,0,0,0,,all of this new functionality to
Dialogue: 0,0:38:51.98,0:38:53.53,Default,,0,0,0,,create a really great apps and
Dialogue: 0,0:38:53.53,0:38:55.84,Default,,0,0,0,,tell us about it.
Dialogue: 0,0:38:56.12,0:38:57.30,Default,,0,0,0,,So please check out the related
Dialogue: 0,0:38:57.30,0:38:58.86,Default,,0,0,0,,Metal 2 sessions and the
Dialogue: 0,0:38:58.86,0:39:01.19,Default,,0,0,0,,sessions on the core ML and
Dialogue: 0,0:39:01.68,0:39:03.01,Default,,0,0,0,,Accelerate and Vision
Dialogue: 0,0:39:03.01,0:39:03.49,Default,,0,0,0,,Frameworks.
Dialogue: 0,0:39:04.72,0:39:06.04,Default,,0,0,0,,And for more information about
Dialogue: 0,0:39:06.10,0:39:07.64,Default,,0,0,0,,this session and for links of
Dialogue: 0,0:39:07.71,0:39:09.94,Default,,0,0,0,,sample code, please check out
Dialogue: 0,0:39:09.99,0:39:11.43,Default,,0,0,0,,this link on our developer
Dialogue: 0,0:39:11.43,0:39:14.28,Default,,0,0,0,,website and thank you so much
Dialogue: 0,0:39:14.28,0:39:15.64,Default,,0,0,0,,for coming, and have a great
Dialogue: 0,0:39:15.64,0:39:15.85,Default,,0,0,0,,WWDC.
Dialogue: 0,0:39:16.52,0:39:20.50,Default,,0,0,0,,[ Applause ]
