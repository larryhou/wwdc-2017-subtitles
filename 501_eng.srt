1
00:00:30,856 --> 00:00:31,806
Good afternoon, everyone.

2
00:00:32,546 --> 00:00:34,146
Welcome to the session "What's

3
00:00:34,146 --> 00:00:35,166
New in Audio?"

4
00:00:36,156 --> 00:00:37,486
I'm Akshatha Nagesh, from the

5
00:00:37,486 --> 00:00:39,786
Audio Team, and today, I would

6
00:00:39,786 --> 00:00:41,626
like to share with you all the

7
00:00:41,626 --> 00:00:43,706
new, exciting features we have

8
00:00:43,706 --> 00:00:45,606
in audio in this year's OS

9
00:00:45,606 --> 00:00:45,996
releases.

10
00:00:46,636 --> 00:00:49,906
I'll begin with a quick overview

11
00:00:50,076 --> 00:00:50,956
of the audio stack.

12
00:00:52,216 --> 00:00:54,126
Audio frameworks offer a wide

13
00:00:54,276 --> 00:00:56,426
variety of APIs, and our main

14
00:00:56,426 --> 00:00:58,556
goal is to help you deliver an

15
00:00:58,556 --> 00:01:00,436
exceptional audio experience to

16
00:01:00,436 --> 00:01:01,826
the end user, through your apps.

17
00:01:03,326 --> 00:01:04,946
At the top, we have the AV

18
00:01:04,946 --> 00:01:06,826
foundation framework, with APIs

19
00:01:06,826 --> 00:01:09,576
like AVAudioSession, Engine,

20
00:01:09,826 --> 00:01:11,756
Player, Recorder, etcetera.

21
00:01:12,736 --> 00:01:14,486
And these APIs cater to the

22
00:01:14,486 --> 00:01:16,086
needs of most of the apps.

23
00:01:17,216 --> 00:01:18,426
But if you wanted to further

24
00:01:18,426 --> 00:01:20,496
customize the experience, you

25
00:01:20,496 --> 00:01:22,196
could use our other frameworks

26
00:01:22,196 --> 00:01:24,546
and APIs like AUAudioUnits,

27
00:01:24,756 --> 00:01:26,696
Audio Codecs, in Audio Toolbox

28
00:01:26,696 --> 00:01:28,926
framework, Code Mini framework,

29
00:01:29,396 --> 00:01:31,366
AudioHAL framework, etcetera.

30
00:01:32,786 --> 00:01:34,266
In our last year's talk here at

31
00:01:34,266 --> 00:01:36,676
WWDC, we did a walkthrough of

32
00:01:36,726 --> 00:01:38,526
all these APIs and more,

33
00:01:38,776 --> 00:01:39,626
throughout the stack.

34
00:01:40,106 --> 00:01:41,856
And I highly encourage you to

35
00:01:41,886 --> 00:01:43,086
check that out.

36
00:01:43,796 --> 00:01:45,496
Now, let's see what's on the

37
00:01:45,496 --> 00:01:46,486
agenda for today.

38
00:01:47,076 --> 00:01:49,526
We will see the new features

39
00:01:49,526 --> 00:01:51,396
we've added in some of these

40
00:01:51,396 --> 00:01:53,646
APIs, starting with the ones in

41
00:01:53,646 --> 00:01:54,806
AVFoundation framework.

42
00:01:55,506 --> 00:01:56,596
And that includes,

43
00:01:56,596 --> 00:01:58,846
AVAudioEngine, AVAudioSession,

44
00:01:59,206 --> 00:02:00,776
and the enhancements we have in

45
00:02:00,776 --> 00:02:02,876
AVFoundation on watchOS 4.

46
00:02:04,236 --> 00:02:06,276
Later on, we'll move over to the

47
00:02:06,276 --> 00:02:08,175
Audio Toolbox world, and see the

48
00:02:08,175 --> 00:02:10,786
enhancements in AUAudioUnits and

49
00:02:10,786 --> 00:02:11,636
Audio Formats.

50
00:02:12,376 --> 00:02:13,966
And finally, we'll wrap up

51
00:02:14,056 --> 00:02:15,786
today's session with an update

52
00:02:15,946 --> 00:02:17,336
on Inter-Device Audio Mode.

53
00:02:18,776 --> 00:02:20,906
We also have a few demos along

54
00:02:20,906 --> 00:02:22,876
the way, to show you many of

55
00:02:22,876 --> 00:02:25,126
these new features in action.

56
00:02:25,996 --> 00:02:27,266
So, let's begin with

57
00:02:27,306 --> 00:02:28,446
AVAudioEngine.

58
00:02:29,896 --> 00:02:31,746
And here's a quick recap of the

59
00:02:31,746 --> 00:02:32,106
API.

60
00:02:33,246 --> 00:02:35,436
AVAudioEngine is a powerful

61
00:02:35,436 --> 00:02:37,926
Objective-C and Swift based API

62
00:02:37,926 --> 00:02:38,186
set.

63
00:02:38,946 --> 00:02:40,676
And the main goal of this API,

64
00:02:41,046 --> 00:02:42,996
is to simplify dealing with real

65
00:02:42,996 --> 00:02:45,306
time audio, and to make it

66
00:02:45,306 --> 00:02:46,816
really easy for you to write

67
00:02:46,936 --> 00:02:49,336
code to perform various audio

68
00:02:49,336 --> 00:02:50,906
tasks, ranging from simple

69
00:02:50,906 --> 00:02:53,026
playback, to recording, to even

70
00:02:53,056 --> 00:02:54,596
complex tasks like audio

71
00:02:54,596 --> 00:02:56,956
processing, mixing, and even 3D

72
00:02:56,956 --> 00:02:57,996
audio specialization.

73
00:02:59,136 --> 00:03:00,626
And again, in our previous

74
00:03:00,626 --> 00:03:03,866
year's talk here at WWDC, we

75
00:03:03,866 --> 00:03:05,956
have covered this API in detail.

76
00:03:06,306 --> 00:03:08,046
So, please check those out if

77
00:03:08,046 --> 00:03:09,876
you're not familiar with this

78
00:03:10,416 --> 00:03:10,516
API.

79
00:03:11,376 --> 00:03:13,566
The Engine manages a graph of

80
00:03:13,626 --> 00:03:15,736
nodes, and a node is the basic

81
00:03:15,736 --> 00:03:17,126
building block of the Engine.

82
00:03:18,076 --> 00:03:19,826
So, here's a sample Engine setup

83
00:03:20,116 --> 00:03:21,636
and this is a classic karaoke

84
00:03:21,636 --> 00:03:22,186
example.

85
00:03:22,186 --> 00:03:24,286
As you can see, there are

86
00:03:24,286 --> 00:03:25,896
various nodes connected

87
00:03:25,896 --> 00:03:27,496
together, to form the processing

88
00:03:27,496 --> 00:03:27,816
graph.

89
00:03:28,986 --> 00:03:31,346
We have the InputNode that is

90
00:03:31,346 --> 00:03:33,146
implicitly connected to the

91
00:03:33,496 --> 00:03:34,866
[inaudible] and is capturing

92
00:03:35,006 --> 00:03:35,776
user's voice.

93
00:03:36,726 --> 00:03:38,286
This is being processed through

94
00:03:38,286 --> 00:03:39,856
an EffectNode which could be for

95
00:03:39,856 --> 00:03:42,326
example, an EQ.

96
00:03:42,326 --> 00:03:43,926
We also have something called a

97
00:03:44,086 --> 00:03:45,296
[inaudible] on the InputNode

98
00:03:45,686 --> 00:03:47,026
through which we could be

99
00:03:47,106 --> 00:03:48,826
analyzing user's voice to see

100
00:03:48,826 --> 00:03:50,646
how he's performing, and based

101
00:03:50,646 --> 00:03:52,296
on that, we could be playing out

102
00:03:52,296 --> 00:03:53,366
some cues to the user through a

103
00:03:53,576 --> 00:03:54,416
PlayerNode.

104
00:03:55,796 --> 00:03:57,206
And we have another PlayerNode

105
00:03:57,356 --> 00:03:58,716
that is playing the backing

106
00:03:58,716 --> 00:04:00,406
track as the user is singing.

107
00:04:00,736 --> 00:04:03,456
All of these signals are mixed

108
00:04:03,456 --> 00:04:05,536
together, in a MixerNode and

109
00:04:05,536 --> 00:04:07,386
finally, given to the OutputNode

110
00:04:07,666 --> 00:04:09,066
which plays it out through the

111
00:04:09,066 --> 00:04:09,786
output hardware.

112
00:04:10,896 --> 00:04:13,386
This is a simple example of the

113
00:04:13,386 --> 00:04:15,466
engine setup, but with all the

114
00:04:15,466 --> 00:04:16,866
nodes and the features the

115
00:04:16,866 --> 00:04:18,606
Engine actually offers, you

116
00:04:18,606 --> 00:04:20,326
could build a lot more complex

117
00:04:20,396 --> 00:04:21,856
processing graph, based on your

118
00:04:21,976 --> 00:04:22,676
app's needs.

119
00:04:23,446 --> 00:04:25,656
So, that was a recap of the

120
00:04:25,656 --> 00:04:26,206
Engine.

121
00:04:26,336 --> 00:04:27,976
Now, let's see what's new in the

122
00:04:27,976 --> 00:04:29,006
Engine this year.

123
00:04:30,356 --> 00:04:31,956
We have a couple of new modes,

124
00:04:32,316 --> 00:04:34,226
namely the Manual Rendering Mode

125
00:04:34,436 --> 00:04:36,546
and Auto Shutdown Mode, and

126
00:04:36,546 --> 00:04:38,146
also, we have some enhancements

127
00:04:38,146 --> 00:04:40,326
in AVAudioPlayerNode, related to

128
00:04:40,326 --> 00:04:41,636
the file and buffer completion

129
00:04:41,636 --> 00:04:42,216
callbacks.

130
00:04:43,246 --> 00:04:44,916
We'll see each of these, one by

131
00:04:44,916 --> 00:04:46,896
one, starting with the Manual

132
00:04:47,156 --> 00:04:48,406
Rendering Mode.

133
00:04:50,656 --> 00:04:52,506
So, this is the karaoke example

134
00:04:52,506 --> 00:04:53,356
that we just saw.

135
00:04:54,486 --> 00:04:56,536
And as you can see, the Input

136
00:04:56,536 --> 00:04:58,136
and the OutputNodes here, are

137
00:04:58,206 --> 00:05:00,226
connected to the audio hardware,

138
00:05:00,676 --> 00:05:02,056
and hence, the Engine

139
00:05:02,246 --> 00:05:03,816
automatically renders in real

140
00:05:03,816 --> 00:05:03,936
time.

141
00:05:03,936 --> 00:05:07,406
The IO here is driven by the

142
00:05:07,406 --> 00:05:07,886
hardware.

143
00:05:08,846 --> 00:05:10,956
But what if you wanted the

144
00:05:10,956 --> 00:05:12,676
Engine to render, not to the

145
00:05:12,676 --> 00:05:13,846
device, but to the app?

146
00:05:14,626 --> 00:05:16,626
And say, at the rate faster than

147
00:05:16,626 --> 00:05:16,886
real time?

148
00:05:18,496 --> 00:05:19,946
So, here is Manual Rendering

149
00:05:19,946 --> 00:05:21,606
Mode which enables you to do

150
00:05:21,606 --> 00:05:21,886
that.

151
00:05:23,236 --> 00:05:24,986
And as you can see, under this

152
00:05:24,986 --> 00:05:26,466
mode, the Input and the

153
00:05:26,466 --> 00:05:27,836
OutputNodes, will not be

154
00:05:27,836 --> 00:05:29,666
connected to any audio device,

155
00:05:30,436 --> 00:05:32,546
and the app will be responsible

156
00:05:32,546 --> 00:05:33,826
for pulling the Engine for

157
00:05:33,906 --> 00:05:36,436
Output and to provide the Input

158
00:05:36,666 --> 00:05:38,146
to the Engine which will be

159
00:05:38,216 --> 00:05:39,776
optionally through the InputNode

160
00:05:40,286 --> 00:05:41,846
or PlayerNode, etcetera.

161
00:05:43,046 --> 00:05:45,526
So, the app drives the IO in

162
00:05:45,526 --> 00:05:46,556
Manual Rendering Mode.

163
00:05:47,056 --> 00:05:50,476
We have two variants under

164
00:05:50,476 --> 00:05:51,336
Manual Rendering.

165
00:05:51,826 --> 00:05:53,796
That is the Offline and Real

166
00:05:53,796 --> 00:05:55,546
Time Manual Rendering Modes.

167
00:05:56,086 --> 00:05:57,356
And again, we'll see each of

168
00:05:57,356 --> 00:05:59,756
these in detail and also, later

169
00:05:59,756 --> 00:06:01,416
in this section, I'll show you a

170
00:06:01,416 --> 00:06:03,366
demo of the Offline Manual

171
00:06:03,366 --> 00:06:04,056
Rendering Mode.

172
00:06:04,476 --> 00:06:09,266
Under the Offline Manual

173
00:06:09,266 --> 00:06:11,586
Rendering Mode, the Engine and

174
00:06:11,676 --> 00:06:13,396
all the nodes in your processing

175
00:06:13,396 --> 00:06:15,266
graph, operate under no

176
00:06:15,266 --> 00:06:16,426
deadlines or real-time

177
00:06:16,426 --> 00:06:17,106
constraints.

178
00:06:18,126 --> 00:06:19,866
And because of this flexibility,

179
00:06:20,186 --> 00:06:22,476
a node may choose to say use a

180
00:06:22,476 --> 00:06:24,346
more expensive signal processing

181
00:06:24,346 --> 00:06:26,816
algorithm when it's offline, or

182
00:06:27,156 --> 00:06:28,826
a node for example, a player

183
00:06:28,826 --> 00:06:30,826
node, may choose to block on the

184
00:06:30,826 --> 00:06:32,806
render thread, until all the

185
00:06:32,806 --> 00:06:34,446
data that it needs as input,

186
00:06:34,676 --> 00:06:35,366
becomes ready.

187
00:06:36,586 --> 00:06:38,306
But these things may not -- will

188
00:06:38,306 --> 00:06:40,106
not happen with the nodes are

189
00:06:40,106 --> 00:06:41,696
actually rendering in real time,

190
00:06:42,066 --> 00:06:43,026
as we'll see soon.

191
00:06:43,276 --> 00:06:46,406
So, let's consider a simple

192
00:06:46,406 --> 00:06:48,576
example where we could use the

193
00:06:48,576 --> 00:06:49,926
offline mode.

194
00:06:51,236 --> 00:06:53,906
So, here's an example where an

195
00:06:53,906 --> 00:06:55,986
app wants to process the audio

196
00:06:55,986 --> 00:06:57,216
data in a source file.

197
00:06:57,216 --> 00:06:59,396
I'll place some effects onto

198
00:06:59,396 --> 00:07:01,256
that data, and dump the process

199
00:07:01,286 --> 00:07:03,056
output to a destination file.

200
00:07:03,586 --> 00:07:05,886
As you can see, there is no

201
00:07:05,886 --> 00:07:07,616
rendering to the device involved

202
00:07:07,696 --> 00:07:07,886
here.

203
00:07:08,226 --> 00:07:10,276
And hence, the app can now use

204
00:07:10,276 --> 00:07:12,586
the Engine in the offline mode.

205
00:07:13,516 --> 00:07:15,006
So, it could set up a very

206
00:07:15,006 --> 00:07:17,056
simple graph in the Engine, like

207
00:07:17,056 --> 00:07:17,416
this.

208
00:07:18,056 --> 00:07:20,126
It could use the PlayerNode to

209
00:07:20,126 --> 00:07:21,376
read the data from the source

210
00:07:21,376 --> 00:07:23,576
file, process it through an

211
00:07:23,576 --> 00:07:24,816
EffectNode, which could be for

212
00:07:24,816 --> 00:07:26,856
example a [inaudible], and then,

213
00:07:27,106 --> 00:07:28,236
pull the data out of the

214
00:07:28,236 --> 00:07:30,166
OutputNode and drive the process

215
00:07:30,166 --> 00:07:31,726
data into a destination file.

216
00:07:32,916 --> 00:07:34,736
And we will soon see a demo of

217
00:07:34,736 --> 00:07:36,926
this exact setup in a couple of

218
00:07:36,926 --> 00:07:38,016
slides.

219
00:07:38,886 --> 00:07:42,096
There are many more applications

220
00:07:42,266 --> 00:07:43,536
where you can use the offline

221
00:07:43,536 --> 00:07:43,766
mode.

222
00:07:44,416 --> 00:07:45,536
And some of these are listed

223
00:07:45,596 --> 00:07:45,746
here.

224
00:07:46,586 --> 00:07:48,436
Apart from post-processing of

225
00:07:48,476 --> 00:07:49,696
audio files that I just

226
00:07:49,696 --> 00:07:51,666
mentioned, you could also use

227
00:07:51,666 --> 00:07:54,086
offline mode to say mix audio

228
00:07:54,086 --> 00:07:54,476
files.

229
00:07:55,556 --> 00:07:57,686
You could use it for offline

230
00:07:57,686 --> 00:07:59,646
processing using a very CPU

231
00:07:59,646 --> 00:08:01,246
intensive or a higher quality

232
00:08:01,346 --> 00:08:02,806
algorithm, which may not be

233
00:08:02,806 --> 00:08:04,346
feasible to use in real time.

234
00:08:05,386 --> 00:08:06,936
Or simply, you could use the

235
00:08:06,936 --> 00:08:09,496
offline mode, to test, debug, or

236
00:08:09,636 --> 00:08:11,756
tune your live Engine setup.

237
00:08:12,306 --> 00:08:15,766
So, that concludes the offline

238
00:08:15,766 --> 00:08:17,486
mode and as promised, I'll show

239
00:08:17,486 --> 00:08:20,936
you a demo of this in action.

240
00:08:21,886 --> 00:08:27,056
Alright so, what I have here is

241
00:08:27,056 --> 00:08:28,126
an [inaudible] Playground.

242
00:08:29,136 --> 00:08:31,776
And this is the example where we

243
00:08:31,776 --> 00:08:33,486
will post-process the audio data

244
00:08:33,596 --> 00:08:36,126
in a source file, apply a

245
00:08:36,366 --> 00:08:37,226
[inaudible] effect on the data,

246
00:08:37,635 --> 00:08:39,186
and dump the output into a

247
00:08:39,186 --> 00:08:40,076
destination file.

248
00:08:40,645 --> 00:08:42,876
I have some code snippets here

249
00:08:42,876 --> 00:08:43,936
and [inaudible] on [inaudible].

250
00:08:44,076 --> 00:08:47,326
So, the first thing I do here,

251
00:08:48,466 --> 00:08:51,716
is set up the Engine to render

252
00:08:51,956 --> 00:08:53,706
in a live mode to the device,

253
00:08:53,706 --> 00:08:55,976
just to see how the source file

254
00:08:55,976 --> 00:08:58,536
sounds without having added any

255
00:08:58,536 --> 00:08:59,826
effect to it.

256
00:09:01,516 --> 00:09:04,506
So, I'm first opening up the

257
00:09:04,506 --> 00:09:06,176
source file, which I want to

258
00:09:06,226 --> 00:09:06,486
read.

259
00:09:07,116 --> 00:09:10,706
And then, I'm creating and

260
00:09:10,706 --> 00:09:11,816
configuring my Engine.

261
00:09:12,506 --> 00:09:14,546
So, I have an Engine and a

262
00:09:14,706 --> 00:09:15,536
PlayerNode.

263
00:09:16,486 --> 00:09:17,836
And I'm going to take the player

264
00:09:18,296 --> 00:09:19,676
to the main mixer node of the

265
00:09:19,676 --> 00:09:21,406
Engine, which is implicitly

266
00:09:21,436 --> 00:09:24,206
connected to the OutputNode of

267
00:09:25,356 --> 00:09:25,726
the Engine.

268
00:09:25,726 --> 00:09:27,006
Then I'm scheduling the source

269
00:09:27,006 --> 00:09:28,766
file that I have on the player

270
00:09:28,976 --> 00:09:30,176
so that it can read the data

271
00:09:30,176 --> 00:09:30,976
from the source file.

272
00:09:31,686 --> 00:09:34,116
And then I'm starting the Engine

273
00:09:34,116 --> 00:09:34,996
and starting the player.

274
00:09:35,866 --> 00:09:37,216
So, as I mentioned, the Engine

275
00:09:37,216 --> 00:09:38,966
is now in a live mode, and this

276
00:09:38,966 --> 00:09:41,256
will render to the device.

277
00:09:41,636 --> 00:09:43,476
So, let's see how the source

278
00:09:43,476 --> 00:09:45,416
file sounds without any effects.

279
00:09:46,516 --> 00:09:54,716
[ Music ]

280
00:09:55,216 --> 00:09:56,776
Okay, so that's how the source

281
00:09:56,776 --> 00:09:59,146
file sounds like.

282
00:09:59,236 --> 00:10:01,586
So, now what I'll do is, add a

283
00:10:01,586 --> 00:10:04,096
reverb effect to process the

284
00:10:04,096 --> 00:10:04,366
data.

285
00:10:05,516 --> 00:10:07,156
So, I'll remove the player to

286
00:10:07,156 --> 00:10:09,406
main mixer connection, and I'll

287
00:10:09,506 --> 00:10:10,736
insert the reverb.

288
00:10:11,806 --> 00:10:13,406
So, here I've created a reverb

289
00:10:14,196 --> 00:10:16,026
and I'm setting the parameters

290
00:10:16,026 --> 00:10:16,596
of the reverb.

291
00:10:16,796 --> 00:10:18,926
And in this example, I'm using a

292
00:10:18,926 --> 00:10:22,096
factory preset and wetDryMix of

293
00:10:22,396 --> 00:10:23,206
70%.

294
00:10:24,106 --> 00:10:25,176
And then I'm inserting the

295
00:10:25,176 --> 00:10:27,436
reverb in the playback part in

296
00:10:27,436 --> 00:10:28,816
between the player and the main

297
00:10:28,816 --> 00:10:29,196
mixer.

298
00:10:30,386 --> 00:10:32,786
So, now if I run the example, we

299
00:10:32,786 --> 00:10:34,886
can see how the processed output

300
00:10:34,976 --> 00:10:36,426
will sound like.

301
00:10:37,516 --> 00:10:45,816
[ Music ]

302
00:10:46,316 --> 00:10:48,776
Okay, so now at this point, if I

303
00:10:48,776 --> 00:10:50,386
want, I could go ahead and tune

304
00:10:50,386 --> 00:10:51,916
my reverb parameter so that it

305
00:10:51,916 --> 00:10:53,326
sounds exactly as I want.

306
00:10:53,786 --> 00:10:55,026
So, suppose I'm happy with all

307
00:10:55,026 --> 00:10:56,736
the parameters and then now I

308
00:10:56,736 --> 00:10:58,136
want to completely export my

309
00:10:58,136 --> 00:10:59,686
source file into a destination

310
00:10:59,686 --> 00:10:59,906
file.

311
00:11:00,306 --> 00:11:01,546
And this is where the offline

312
00:11:01,546 --> 00:11:02,526
mode comes into picture.

313
00:11:03,876 --> 00:11:07,246
So, what I'll first do is, I'll

314
00:11:07,246 --> 00:11:08,806
enable -- I'll switch the Engine

315
00:11:08,806 --> 00:11:10,026
from the live mode to the

316
00:11:10,026 --> 00:11:10,646
offline mode.

317
00:11:10,646 --> 00:11:17,816
So, what I've done here is I'm

318
00:11:18,076 --> 00:11:22,126
calling an Enable Manual

319
00:11:22,416 --> 00:11:24,466
Rendering Mode API, and I'm

320
00:11:24,466 --> 00:11:26,056
saying, "It needs to be the

321
00:11:26,056 --> 00:11:27,236
offline variant of it."

322
00:11:28,256 --> 00:11:30,156
I'm specifying a format of the

323
00:11:30,216 --> 00:11:31,956
output which I want the Engine

324
00:11:32,086 --> 00:11:32,706
to give me.

325
00:11:33,236 --> 00:11:34,696
And this is, in this example,

326
00:11:34,696 --> 00:11:36,256
same as the format of the input.

327
00:11:36,716 --> 00:11:39,056
And then I'm specifying a

328
00:11:39,056 --> 00:11:40,336
certain maximum number of

329
00:11:40,336 --> 00:11:42,526
frames, which is the maximum

330
00:11:42,666 --> 00:11:43,836
number of frames that you will

331
00:11:43,836 --> 00:11:45,786
ever ask the Engine to render in

332
00:11:45,786 --> 00:11:47,056
a single rendered call.

333
00:11:47,696 --> 00:11:49,476
And in this example, the value's

334
00:11:49,476 --> 00:11:50,536
4096.

335
00:11:50,756 --> 00:11:52,556
But you can configure this as

336
00:11:52,556 --> 00:11:52,966
you wish.

337
00:11:53,516 --> 00:11:57,576
So, now if I go ahead and run

338
00:11:58,086 --> 00:11:59,836
this example, nothing will

339
00:11:59,836 --> 00:12:01,536
happen because the Engine is now

340
00:12:01,536 --> 00:12:03,186
in the offline mode, and it's

341
00:12:03,186 --> 00:12:04,066
ready to render.

342
00:12:04,356 --> 00:12:05,586
But of course, it's waiting for

343
00:12:05,586 --> 00:12:08,016
the app to pull the Engine for

344
00:12:08,016 --> 00:12:08,466
output.

345
00:12:09,556 --> 00:12:11,816
So, what we'll do next is to

346
00:12:11,816 --> 00:12:13,296
actually pull the Engine for

347
00:12:13,296 --> 00:12:13,776
output.

348
00:12:16,636 --> 00:12:18,466
So, here I'm creating an output

349
00:12:18,466 --> 00:12:21,586
file to which I want to dump the

350
00:12:21,586 --> 00:12:22,296
process data.

351
00:12:22,956 --> 00:12:26,326
And I'm creating an output

352
00:12:26,326 --> 00:12:28,706
buffer to which I'll ask the

353
00:12:28,706 --> 00:12:30,666
Engine to render sequentially in

354
00:12:30,706 --> 00:12:31,696
every rendered call.

355
00:12:32,676 --> 00:12:34,326
And the format of this buffer is

356
00:12:34,326 --> 00:12:35,766
the same format that as I

357
00:12:35,766 --> 00:12:37,616
mentioned, when enabling the

358
00:12:37,616 --> 00:12:38,536
offline mode.

359
00:12:39,046 --> 00:12:42,206
And then comes the rendered loop

360
00:12:42,396 --> 00:12:44,236
where I'll [inaudible] pull the

361
00:12:44,236 --> 00:12:45,496
engine for output.

362
00:12:46,216 --> 00:12:47,676
Now, in this example, I have a

363
00:12:47,676 --> 00:12:49,006
source file which is about three

364
00:12:49,006 --> 00:12:49,816
minutes long.

365
00:12:50,556 --> 00:12:52,026
So, I really don't want to

366
00:12:52,026 --> 00:12:54,076
allocate a huge output buffer

367
00:12:54,246 --> 00:12:55,846
and ask the Engine to render the

368
00:12:55,846 --> 00:12:57,516
entire three minutes of data in

369
00:12:57,516 --> 00:12:58,486
a single rendered call.

370
00:12:58,996 --> 00:13:00,596
And that's why what I'm doing is

371
00:13:00,676 --> 00:13:02,756
allocating an output buffer of a

372
00:13:02,756 --> 00:13:05,206
very reasonable size, but

373
00:13:05,206 --> 00:13:05,986
[inaudible] pulling the Engine

374
00:13:05,986 --> 00:13:07,836
for output into the same buffer,

375
00:13:07,836 --> 00:13:09,266
and then dumping the output to

376
00:13:09,266 --> 00:13:10,186
the destination file.

377
00:13:10,676 --> 00:13:13,786
So, in every iteration, I'll

378
00:13:13,786 --> 00:13:16,216
decide the number of frames to

379
00:13:16,216 --> 00:13:17,336
render in this particular

380
00:13:17,366 --> 00:13:17,906
rendered call.

381
00:13:18,566 --> 00:13:20,266
And I call the rendered offline

382
00:13:20,416 --> 00:13:21,176
[inaudible] around the Engine,

383
00:13:21,326 --> 00:13:23,076
asking it to render those many

384
00:13:23,076 --> 00:13:24,636
number of frames, and giving it

385
00:13:24,636 --> 00:13:26,456
the output buffer that we just

386
00:13:26,456 --> 00:13:26,986
allocated.

387
00:13:27,916 --> 00:13:29,466
And depending on the status, if

388
00:13:29,466 --> 00:13:32,086
it rendered success, the data

389
00:13:32,086 --> 00:13:33,706
was rendered successfully and I

390
00:13:33,706 --> 00:13:35,506
can go ahead and drag the data

391
00:13:35,616 --> 00:13:37,896
into my output file, and in case

392
00:13:37,896 --> 00:13:39,146
it rendered an error, then

393
00:13:39,146 --> 00:13:40,496
something went wrong, so you can

394
00:13:40,496 --> 00:13:42,886
check the error code for more

395
00:13:42,886 --> 00:13:43,456
information.

396
00:13:44,636 --> 00:13:45,686
So, finally, when the

397
00:13:45,686 --> 00:13:47,316
rendering's done, I'll stop the

398
00:13:47,316 --> 00:13:49,276
player and I'll stop the Engine.

399
00:13:50,146 --> 00:13:51,476
So, now if I go ahead and run

400
00:13:51,476 --> 00:13:53,536
this example, the entire source

401
00:13:53,536 --> 00:13:55,066
file will get exported and the

402
00:13:55,066 --> 00:13:56,376
data will be dumped into the

403
00:13:56,376 --> 00:13:57,196
destination file.

404
00:13:57,876 --> 00:14:02,596
So, let's do that.

405
00:14:02,816 --> 00:14:04,366
Okay, so as you may have

406
00:14:04,366 --> 00:14:06,736
observed, the three-minute

407
00:14:07,036 --> 00:14:09,566
length long source file got

408
00:14:09,566 --> 00:14:11,266
rendered into an output file,

409
00:14:11,746 --> 00:14:13,106
way faster than real time.

410
00:14:13,486 --> 00:14:14,646
And that is one of the main

411
00:14:14,646 --> 00:14:15,866
applications of the offline

412
00:14:15,866 --> 00:14:16,416
rendering mode.

413
00:14:17,416 --> 00:14:19,796
So, what we'll do next is again,

414
00:14:19,796 --> 00:14:21,916
listen to the source file, and

415
00:14:23,046 --> 00:14:25,396
the destination file, and make

416
00:14:25,396 --> 00:14:28,946
sure that the data was indeed

417
00:14:29,006 --> 00:14:29,396
processed.

418
00:14:30,116 --> 00:14:31,636
So, that is my source file.

419
00:14:33,146 --> 00:14:35,216
And this is my destination file.

420
00:14:35,796 --> 00:14:40,636
So, first we'll listen to the

421
00:14:40,636 --> 00:14:41,866
source file.

422
00:14:42,516 --> 00:14:48,766
[ Music ]

423
00:14:49,266 --> 00:14:51,786
So, as you saw, it is pretty

424
00:14:51,786 --> 00:14:52,156
dry.

425
00:14:53,096 --> 00:14:54,946
And now, the processed file.

426
00:14:55,516 --> 00:15:03,746
[ Music ]

427
00:15:04,246 --> 00:15:06,156
Okay, so as expected, the

428
00:15:06,186 --> 00:15:07,876
processed data has reverb effect

429
00:15:07,876 --> 00:15:08,426
added to it.

430
00:15:09,746 --> 00:15:12,066
So, that concludes the offline

431
00:15:12,066 --> 00:15:13,446
rendering demo.

432
00:15:13,616 --> 00:15:15,316
And I'll switch back to the

433
00:15:16,086 --> 00:15:16,246
slides.

434
00:15:19,516 --> 00:15:24,666
[ Applause ]

435
00:15:25,166 --> 00:15:26,136
So, as I mentioned, there are

436
00:15:26,136 --> 00:15:27,606
many more applications to the

437
00:15:27,756 --> 00:15:28,526
rendering mode.

438
00:15:28,976 --> 00:15:31,446
And I'm also happy to announce

439
00:15:31,506 --> 00:15:33,856
that the sample code for this

440
00:15:33,906 --> 00:15:35,676
example, is already available on

441
00:15:35,676 --> 00:15:37,316
our Sessions Homepage, and we'll

442
00:15:37,316 --> 00:15:39,336
show you a link to that homepage

443
00:15:39,336 --> 00:15:40,426
at the end of presentation.

444
00:15:42,436 --> 00:15:44,356
Now, going to the second variant

445
00:15:44,356 --> 00:15:45,606
of the Manual Rendering Mode.

446
00:15:46,396 --> 00:15:47,746
The real time Manual Entering

447
00:15:47,746 --> 00:15:47,916
Mode.

448
00:15:48,696 --> 00:15:50,516
As the name itself suggests,

449
00:15:50,626 --> 00:15:52,556
under this mode, the Engine and

450
00:15:52,556 --> 00:15:53,966
all the nodes in your processing

451
00:15:53,966 --> 00:15:55,836
graph, assume that they are

452
00:15:55,886 --> 00:15:57,276
rendering under a real-time

453
00:15:57,346 --> 00:15:57,886
context.

454
00:15:58,376 --> 00:15:59,736
And hence, the they honor the

455
00:15:59,776 --> 00:16:01,026
real-time constraints.

456
00:16:01,766 --> 00:16:03,756
That is, they will not make any

457
00:16:03,756 --> 00:16:05,776
kind of a blocking calls on the

458
00:16:05,806 --> 00:16:06,396
render thread.

459
00:16:07,046 --> 00:16:08,556
For example, they will not call

460
00:16:08,556 --> 00:16:09,556
any libdispatch.

461
00:16:10,146 --> 00:16:12,036
They will not allocate memory or

462
00:16:12,076 --> 00:16:13,416
wait to block on a mutex.

463
00:16:14,346 --> 00:16:15,836
And because of this constraint,

464
00:16:16,106 --> 00:16:17,916
suppose the input data for node

465
00:16:18,046 --> 00:16:19,396
is not ready in time.

466
00:16:20,016 --> 00:16:22,046
A node has no other choice, but

467
00:16:22,046 --> 00:16:23,756
the say, "Drop the data for that

468
00:16:23,796 --> 00:16:25,516
particular render cycle, or

469
00:16:25,746 --> 00:16:27,406
assume zeros and proceed."

470
00:16:29,696 --> 00:16:31,486
Now, let's see where you would

471
00:16:31,486 --> 00:16:32,826
use the Engine in the real-time

472
00:16:32,826 --> 00:16:34,546
Manual Rendering Mode.

473
00:16:35,236 --> 00:16:37,436
Suppose you have a custom AU

474
00:16:37,436 --> 00:16:38,086
audio unit.

475
00:16:38,986 --> 00:16:41,286
That is, in the live playback

476
00:16:41,376 --> 00:16:43,456
part, and within the internal

477
00:16:43,456 --> 00:16:45,116
render block of your audio unit,

478
00:16:45,416 --> 00:16:46,836
you would like to process the

479
00:16:46,836 --> 00:16:48,386
data that is going through,

480
00:16:48,736 --> 00:16:50,746
using some other audio unit or

481
00:16:50,796 --> 00:16:52,066
audio units.

482
00:16:52,906 --> 00:16:54,996
In that case, you can set up the

483
00:16:54,996 --> 00:16:57,316
Engine to use those other audio

484
00:16:57,316 --> 00:16:59,716
units and process the data in

485
00:16:59,716 --> 00:17:01,186
the real-time Manual Rendering

486
00:17:01,726 --> 00:17:01,826
Mode.

487
00:17:02,596 --> 00:17:04,236
The second example would be,

488
00:17:04,366 --> 00:17:05,746
suppose you wanted to process

489
00:17:05,746 --> 00:17:07,415
the audio data that belongs to a

490
00:17:07,415 --> 00:17:09,286
movie or video, as it is

491
00:17:09,286 --> 00:17:10,636
streaming or playing back.

492
00:17:11,526 --> 00:17:12,516
Because this happens in the

493
00:17:12,516 --> 00:17:14,016
real-time, you could use the

494
00:17:14,016 --> 00:17:15,656
Engine in real-time Manual

495
00:17:15,656 --> 00:17:17,306
Rendering Mode, to do that audio

496
00:17:17,306 --> 00:17:17,846
processing.

497
00:17:18,516 --> 00:17:19,986
And now, let's consider the

498
00:17:19,986 --> 00:17:22,386
second use case and see how to

499
00:17:22,386 --> 00:17:24,756
set up and use the Engine both

500
00:17:24,756 --> 00:17:26,445
as an example an in code.

501
00:17:27,106 --> 00:17:30,926
So, here's the app that's

502
00:17:30,926 --> 00:17:33,416
receiving input movie stream,

503
00:17:33,596 --> 00:17:35,236
and displaying back in

504
00:17:35,236 --> 00:17:37,046
real-time, say to a TV.

505
00:17:37,656 --> 00:17:39,016
But what it wants to do is

506
00:17:39,236 --> 00:17:42,406
process the audio data as it in

507
00:17:42,406 --> 00:17:44,046
the input, before it goes to the

508
00:17:44,046 --> 00:17:44,466
output.

509
00:17:45,776 --> 00:17:47,736
So, now it can use the Engine in

510
00:17:47,736 --> 00:17:49,456
the real-time Manual Rendering

511
00:17:49,456 --> 00:17:49,796
Mode.

512
00:17:50,766 --> 00:17:52,586
So, it could set up a processing

513
00:17:52,586 --> 00:17:53,896
graph like this.

514
00:17:53,896 --> 00:17:55,656
It can provide the input through

515
00:17:55,856 --> 00:17:58,016
the input node, process it

516
00:17:58,186 --> 00:17:59,836
through an effect node, and then

517
00:17:59,886 --> 00:18:01,306
pull the data from the output

518
00:18:01,356 --> 00:18:04,626
node and then play it back to

519
00:18:05,356 --> 00:18:07,116
the device.

520
00:18:07,246 --> 00:18:09,156
Now, let's see a code example on

521
00:18:09,156 --> 00:18:11,396
how to set up and use the Engine

522
00:18:11,436 --> 00:18:11,956
in this mode.

523
00:18:16,336 --> 00:18:17,616
So, here's the code.

524
00:18:17,996 --> 00:18:20,246
And note that the setting up the

525
00:18:20,246 --> 00:18:22,136
Engine itself, happens from a

526
00:18:22,136 --> 00:18:23,626
non-real-time context.

527
00:18:23,946 --> 00:18:25,886
And it's only rendering part

528
00:18:26,026 --> 00:18:27,276
that actually happens from a

529
00:18:27,276 --> 00:18:28,286
real-time context.

530
00:18:28,836 --> 00:18:30,596
So, here's the setup code, where

531
00:18:30,596 --> 00:18:32,706
you first cleared the Engine,

532
00:18:33,186 --> 00:18:36,306
and by default, on creation, the

533
00:18:36,306 --> 00:18:38,036
Engine will be ready to render

534
00:18:38,206 --> 00:18:40,026
to the device until you switch

535
00:18:40,026 --> 00:18:41,536
it over to the Manual Rendering

536
00:18:41,536 --> 00:18:41,746
Mode.

537
00:18:42,846 --> 00:18:44,376
So, you cleared the Engine, make

538
00:18:44,376 --> 00:18:45,946
your required connections, and

539
00:18:45,946 --> 00:18:47,796
then switch it over to the

540
00:18:47,796 --> 00:18:48,796
Manual Rendering Mode.

541
00:18:49,636 --> 00:18:51,116
So, this is the same API that we

542
00:18:51,116 --> 00:18:52,876
saw in the demo, except that we

543
00:18:52,876 --> 00:18:55,536
are now saying -- now asking the

544
00:18:55,536 --> 00:18:57,106
Engine to operate under

545
00:18:57,106 --> 00:18:58,556
real-time Manual Rendering Mode.

546
00:18:59,326 --> 00:19:01,296
And specifying the format for

547
00:19:01,296 --> 00:19:03,076
the output and maximum number of

548
00:19:03,076 --> 00:19:03,556
frames.

549
00:19:04,546 --> 00:19:07,946
The next thing you do is session

550
00:19:08,056 --> 00:19:09,566
cache, something called a

551
00:19:09,566 --> 00:19:10,396
surrender block.

552
00:19:10,926 --> 00:19:12,546
Now, because the rendering of

553
00:19:12,626 --> 00:19:13,966
the Engine happens from a

554
00:19:13,966 --> 00:19:16,076
real-time context, you will not

555
00:19:16,116 --> 00:19:17,496
be able to use the render

556
00:19:17,596 --> 00:19:19,496
offline Objective-C or Swift

557
00:19:19,496 --> 00:19:20,966
meta that we saw in the demo.

558
00:19:21,346 --> 00:19:23,076
And that is because, it is not

559
00:19:23,146 --> 00:19:25,226
safe to use Objective-C or Swift

560
00:19:25,226 --> 00:19:26,286
runtime from a real-time

561
00:19:26,286 --> 00:19:26,896
context.

562
00:19:27,436 --> 00:19:28,976
So, instead, the engine itself

563
00:19:28,976 --> 00:19:30,826
provides you a render block that

564
00:19:30,826 --> 00:19:32,506
you can search and cache, and

565
00:19:32,506 --> 00:19:34,086
then later use this render block

566
00:19:34,286 --> 00:19:35,626
to render the engine from the

567
00:19:35,626 --> 00:19:36,686
real-time context.

568
00:19:38,256 --> 00:19:40,456
The next thing is -- to do, is

569
00:19:40,456 --> 00:19:42,016
to set up your input node so

570
00:19:42,016 --> 00:19:43,386
that you can provide your input

571
00:19:43,386 --> 00:19:44,646
data to the Engine.

572
00:19:45,416 --> 00:19:48,156
And here, you specify the format

573
00:19:48,156 --> 00:19:49,786
of the input that you will

574
00:19:49,786 --> 00:19:51,536
provide, and this can be a

575
00:19:51,536 --> 00:19:52,586
different format than the

576
00:19:52,626 --> 00:19:53,046
output.

577
00:19:54,016 --> 00:19:55,916
And you also provide a block

578
00:19:55,916 --> 00:19:57,396
which the Engine will call,

579
00:19:57,546 --> 00:19:59,076
whenever it needs the input

580
00:19:59,186 --> 00:19:59,546
data.

581
00:20:01,696 --> 00:20:03,716
And when this block gets called,

582
00:20:03,716 --> 00:20:05,476
the Engine will let you know how

583
00:20:05,476 --> 00:20:07,136
many number of input frames it

584
00:20:07,136 --> 00:20:07,936
actually needs.

585
00:20:08,606 --> 00:20:10,616
And at that point, if you have

586
00:20:10,616 --> 00:20:12,986
the data, you'll fill up an

587
00:20:12,986 --> 00:20:14,646
input audio buffer list and

588
00:20:14,646 --> 00:20:15,986
return it to the engine.

589
00:20:16,846 --> 00:20:18,416
But if you don't have data, you

590
00:20:18,416 --> 00:20:20,096
can return nil at this point.

591
00:20:21,446 --> 00:20:22,876
Now note that the input node can

592
00:20:22,876 --> 00:20:25,156
be used both in the offline and

593
00:20:25,276 --> 00:20:26,696
real-time Manual Rendering Mode.

594
00:20:27,246 --> 00:20:28,886
But when you're using it in the

595
00:20:28,886 --> 00:20:30,316
real-time Manual Rendering Mode,

596
00:20:30,686 --> 00:20:32,576
this input block also gets

597
00:20:32,576 --> 00:20:34,366
called from a real-time context,

598
00:20:34,746 --> 00:20:36,146
which means that you need to

599
00:20:36,146 --> 00:20:38,096
take care not to make any kind

600
00:20:38,096 --> 00:20:39,936
of blocking calls within this

601
00:20:40,556 --> 00:20:42,026
input block.

602
00:20:43,356 --> 00:20:45,236
The next part of the setup is to

603
00:20:45,236 --> 00:20:47,586
clear your output buffer, and

604
00:20:47,586 --> 00:20:49,386
the difference here is you will

605
00:20:49,386 --> 00:20:51,956
create an AVAudioPCMBuffer and

606
00:20:51,956 --> 00:20:53,806
fetch its audio buffer list

607
00:20:54,006 --> 00:20:55,726
which is what you'll use in the

608
00:20:55,726 --> 00:20:57,206
real-time render logic.

609
00:20:57,726 --> 00:21:00,206
And finally, you'll go ahead and

610
00:21:00,206 --> 00:21:00,976
start the Engine.

611
00:21:01,546 --> 00:21:03,286
So, now the Engine is all set up

612
00:21:03,286 --> 00:21:04,646
and ready to render, and is

613
00:21:04,646 --> 00:21:06,706
waiting for the app to pull for

614
00:21:06,776 --> 00:21:08,076
the output data.

615
00:21:08,616 --> 00:21:12,846
Now here comes the actual render

616
00:21:12,886 --> 00:21:13,346
logic.

617
00:21:13,916 --> 00:21:15,626
And note that this part of the

618
00:21:15,666 --> 00:21:17,836
chord is written in C++, and

619
00:21:17,836 --> 00:21:19,516
that is because as I mentioned,

620
00:21:19,716 --> 00:21:21,546
we are -- it's not safe to use

621
00:21:21,546 --> 00:21:24,046
Objective-C or Swift runtime

622
00:21:24,096 --> 00:21:25,386
from a real-time context.

623
00:21:26,546 --> 00:21:28,166
So, what we're doing first is

624
00:21:28,716 --> 00:21:30,156
calling the render block that we

625
00:21:30,246 --> 00:21:32,516
cached earlier, and asking the

626
00:21:32,516 --> 00:21:33,626
Engine to render a certain

627
00:21:33,626 --> 00:21:35,296
number or frames, and giving it

628
00:21:35,296 --> 00:21:36,606
the outputBufferList that we

629
00:21:36,606 --> 00:21:37,076
created.

630
00:21:38,086 --> 00:21:39,606
And finally, depending on the

631
00:21:39,606 --> 00:21:41,856
status, if you get a success, it

632
00:21:41,856 --> 00:21:43,426
means everything went fine and

633
00:21:43,426 --> 00:21:44,726
the data was rendered to the

634
00:21:44,726 --> 00:21:45,416
output buffer.

635
00:21:46,216 --> 00:21:47,976
But you could also get an

636
00:21:47,976 --> 00:21:49,736
insufficient data from input

637
00:21:49,736 --> 00:21:51,776
note as a status, which means

638
00:21:51,776 --> 00:21:54,846
that when your input block was

639
00:21:54,896 --> 00:21:56,526
called by the Engine for input

640
00:21:56,526 --> 00:21:58,386
data, you did not have enough

641
00:21:58,386 --> 00:22:00,276
data in your written nil from

642
00:22:00,276 --> 00:22:01,056
that input block.

643
00:22:01,946 --> 00:22:03,816
And note that in this case, in

644
00:22:03,816 --> 00:22:05,696
case you have other sources in

645
00:22:05,696 --> 00:22:07,116
your processing graph, for

646
00:22:07,116 --> 00:22:08,576
example, you have some of the

647
00:22:08,606 --> 00:22:08,946
[inaudible] notes.

648
00:22:09,396 --> 00:22:10,666
Those notes could have still

649
00:22:10,666 --> 00:22:12,446
rendered the input data, so you

650
00:22:12,446 --> 00:22:14,176
may still have some output in

651
00:22:14,176 --> 00:22:15,096
your output buffer.

652
00:22:15,446 --> 00:22:17,256
So, you can check the sizes of

653
00:22:17,306 --> 00:22:19,076
your output buffer, to determine

654
00:22:19,136 --> 00:22:20,876
whether or not it has any data.

655
00:22:22,276 --> 00:22:23,936
And of course, you handle the

656
00:22:23,936 --> 00:22:26,326
other status which includes the

657
00:22:26,326 --> 00:22:28,196
error, and that is pretty much

658
00:22:28,196 --> 00:22:30,246
the render logic in real-time

659
00:22:30,246 --> 00:22:31,866
Manual Rendering Mode.

660
00:22:33,896 --> 00:22:37,106
Now, lastly a note on the render

661
00:22:37,176 --> 00:22:37,546
cause.

662
00:22:38,276 --> 00:22:39,396
In the offline mode, because

663
00:22:39,396 --> 00:22:40,456
there are no deadlines or

664
00:22:40,506 --> 00:22:42,056
real-time constraints, you can

665
00:22:42,056 --> 00:22:43,796
use either the Objective-C or

666
00:22:43,796 --> 00:22:45,606
the Swift render of line method,

667
00:22:45,966 --> 00:22:47,666
or you could use the render

668
00:22:47,666 --> 00:22:49,246
block based render call in order

669
00:22:49,246 --> 00:22:50,176
to render the Engine.

670
00:22:50,776 --> 00:22:52,116
But in real-time Manual

671
00:22:52,116 --> 00:22:53,956
Rendering Mode, you must use the

672
00:22:53,956 --> 00:22:55,276
block based render call.

673
00:22:55,946 --> 00:22:58,646
So, that brings us to the end of

674
00:22:58,706 --> 00:22:59,866
Manual Rendering Mode.

675
00:23:00,196 --> 00:23:03,836
Now let's now see the next new

676
00:23:03,836 --> 00:23:05,356
mode we have in the Engine,

677
00:23:05,356 --> 00:23:07,306
which is the Auto Shutdown Mode.

678
00:23:09,046 --> 00:23:10,476
Now, normally it is the

679
00:23:10,476 --> 00:23:12,496
responsibility of the app to

680
00:23:12,576 --> 00:23:14,576
pause or stop the Engine when it

681
00:23:14,576 --> 00:23:16,306
is not in use in order to

682
00:23:16,306 --> 00:23:16,976
conserve power.

683
00:23:16,976 --> 00:23:19,766
For example, say we have a music

684
00:23:19,766 --> 00:23:21,236
app that is using one of the

685
00:23:21,276 --> 00:23:22,906
player nodes for playing back

686
00:23:23,626 --> 00:23:26,106
some file, and say the user

687
00:23:26,106 --> 00:23:27,346
stops the playback.

688
00:23:28,156 --> 00:23:29,986
Now the app, should not only

689
00:23:30,126 --> 00:23:32,316
pause or stop the player node,

690
00:23:32,596 --> 00:23:34,356
but it should also pause or stop

691
00:23:34,356 --> 00:23:36,246
the Engine in order to prevent

692
00:23:36,246 --> 00:23:37,436
it from running idle.

693
00:23:38,496 --> 00:23:39,836
But in the past, we have seen

694
00:23:39,836 --> 00:23:41,726
that not all the apps actually

695
00:23:41,726 --> 00:23:43,846
do this, and especially that's

696
00:23:43,846 --> 00:23:44,646
true on watchOS.

697
00:23:45,396 --> 00:23:47,166
And hence, we are now adding the

698
00:23:47,166 --> 00:23:49,546
safety net in order to conserve

699
00:23:49,806 --> 00:23:51,486
power with this auto shutdown

700
00:23:51,486 --> 00:23:51,716
mode.

701
00:23:52,866 --> 00:23:54,136
When the Engine is operating

702
00:23:54,136 --> 00:23:56,246
under this mode, it will

703
00:23:56,246 --> 00:23:58,076
continuously monitor and if it

704
00:23:58,076 --> 00:24:00,276
detects that the Engine is

705
00:24:00,276 --> 00:24:01,826
running idle for a certain

706
00:24:01,826 --> 00:24:03,656
duration, it will go ahead and

707
00:24:03,656 --> 00:24:05,176
stop the audio hardware and

708
00:24:05,176 --> 00:24:05,506
delete.

709
00:24:06,286 --> 00:24:07,966
And later on, suppose any of the

710
00:24:07,966 --> 00:24:09,796
sources become active again, it

711
00:24:09,796 --> 00:24:11,166
will start the audio hardware

712
00:24:11,166 --> 00:24:11,786
dynamically.

713
00:24:12,376 --> 00:24:13,666
And all of this happens under

714
00:24:13,666 --> 00:24:13,966
the hood.

715
00:24:15,196 --> 00:24:16,266
And this is the enforced

716
00:24:16,266 --> 00:24:18,436
behavior on watchOS, but it can

717
00:24:18,436 --> 00:24:20,186
also be optionally enabled on

718
00:24:20,186 --> 00:24:20,986
other platforms.

719
00:24:23,316 --> 00:24:26,106
Now, next onto the enhancements

720
00:24:26,106 --> 00:24:27,326
in AV Audio Player Node.

721
00:24:27,946 --> 00:24:31,196
AV Audio Player Node is one of

722
00:24:31,196 --> 00:24:32,726
the source nodes in the Engine,

723
00:24:33,066 --> 00:24:34,536
through which you could schedule

724
00:24:34,536 --> 00:24:36,466
a buffer or file for playback.

725
00:24:36,966 --> 00:24:39,696
And the existing [inaudible]

726
00:24:39,696 --> 00:24:41,396
methods, take a completion

727
00:24:41,436 --> 00:24:42,956
handler and they call the

728
00:24:42,956 --> 00:24:44,806
completion handler when the data

729
00:24:44,806 --> 00:24:46,246
that you have provided has been

730
00:24:46,246 --> 00:24:47,546
consumed by the player.

731
00:24:49,056 --> 00:24:50,996
We are now adding new completion

732
00:24:50,996 --> 00:24:52,436
handler and new types of

733
00:24:52,526 --> 00:24:54,526
callbacks, in order for you to

734
00:24:54,666 --> 00:24:56,516
know various stages of

735
00:24:56,556 --> 00:24:57,236
completion.

736
00:24:57,776 --> 00:25:01,836
The first new callback type is

737
00:25:01,836 --> 00:25:03,196
the data consumed type.

738
00:25:03,686 --> 00:25:05,396
And this is exactly same as the

739
00:25:05,396 --> 00:25:06,776
existing completion handler.

740
00:25:07,246 --> 00:25:09,536
That is, when the completion

741
00:25:09,536 --> 00:25:11,326
handler gets called, it means

742
00:25:11,326 --> 00:25:12,786
the data has been consumed by

743
00:25:12,786 --> 00:25:13,236
the player.

744
00:25:13,236 --> 00:25:15,386
So, at that point, if you

745
00:25:15,446 --> 00:25:17,106
wanted, you could recycle that

746
00:25:17,106 --> 00:25:19,606
buffer, or if you have more data

747
00:25:19,866 --> 00:25:21,376
to schedule on the player, you

748
00:25:21,416 --> 00:25:21,936
could do that.

749
00:25:22,796 --> 00:25:24,746
The second type of callback is

750
00:25:24,746 --> 00:25:26,076
the data rendered callback.

751
00:25:26,466 --> 00:25:27,896
And that means that the data

752
00:25:28,256 --> 00:25:29,726
that you provided, has been

753
00:25:29,906 --> 00:25:31,316
rendered when the completion

754
00:25:31,316 --> 00:25:32,196
handler gets called.

755
00:25:33,136 --> 00:25:34,446
And this does not account for

756
00:25:34,446 --> 00:25:36,226
any downstream signal processing

757
00:25:36,226 --> 00:25:38,776
latencies in your processing

758
00:25:39,516 --> 00:25:39,666
graph.

759
00:25:40,236 --> 00:25:42,496
The last type is the data played

760
00:25:42,496 --> 00:25:44,016
back type, which is the most

761
00:25:44,016 --> 00:25:44,786
interesting one.

762
00:25:45,286 --> 00:25:46,736
And this means that when your

763
00:25:46,786 --> 00:25:48,226
completion handler gets called,

764
00:25:48,526 --> 00:25:50,176
the buffer or the file that you

765
00:25:50,176 --> 00:25:52,146
scheduled, has actually finished

766
00:25:52,246 --> 00:25:53,476
playing from the listener's

767
00:25:53,516 --> 00:25:54,186
perspective.

768
00:25:55,016 --> 00:25:56,626
And this is applicable only when

769
00:25:56,626 --> 00:25:57,906
the Engine is rendering to the

770
00:25:57,906 --> 00:25:58,396
device.

771
00:25:59,086 --> 00:26:00,546
And this accounts for all the

772
00:26:00,546 --> 00:26:02,026
signal processing latencies,

773
00:26:02,236 --> 00:26:03,846
downstream of the player in your

774
00:26:03,876 --> 00:26:06,246
processing graph, as well as any

775
00:26:06,246 --> 00:26:07,826
latency in the audio playback

776
00:26:07,886 --> 00:26:08,326
device.

777
00:26:09,506 --> 00:26:12,216
So, as a code example, let's see

778
00:26:12,646 --> 00:26:14,416
a scheduled file method through

779
00:26:14,416 --> 00:26:15,666
which you can schedule a file

780
00:26:15,666 --> 00:26:16,386
for playback.

781
00:26:17,266 --> 00:26:19,066
So, here, I'm scheduling a file

782
00:26:19,066 --> 00:26:20,816
for playback and indicating that

783
00:26:20,816 --> 00:26:22,186
I'm interested to know when the

784
00:26:22,186 --> 00:26:23,856
data has played back.

785
00:26:25,186 --> 00:26:26,566
That me -- and I'm providing a

786
00:26:26,566 --> 00:26:27,406
completion handler.

787
00:26:28,076 --> 00:26:29,336
So, when the completion handler

788
00:26:29,336 --> 00:26:31,056
gets called, it means that my

789
00:26:31,056 --> 00:26:32,756
file has finished playing, and

790
00:26:32,756 --> 00:26:33,966
at this point, I can say,

791
00:26:33,966 --> 00:26:35,846
"Notify my UI thread to update

792
00:26:35,846 --> 00:26:38,326
the UI," or I can notify my main

793
00:26:38,326 --> 00:26:39,676
thread to go ahead and stop the

794
00:26:39,676 --> 00:26:40,836
Engine, if that's applicable.

795
00:26:41,446 --> 00:26:45,566
So, that brings us to the end of

796
00:26:45,616 --> 00:26:47,086
the enhancements we have in AV

797
00:26:47,086 --> 00:26:47,726
Audio Engine.

798
00:26:48,376 --> 00:26:49,916
At this point, I would also like

799
00:26:49,966 --> 00:26:52,026
to mention that we will soon be

800
00:26:52,026 --> 00:26:54,726
deprecating the AU Graph API in

801
00:26:54,726 --> 00:26:56,076
the Audio Toolbox framework, in

802
00:26:56,146 --> 00:26:59,256
2018, so please move over to

803
00:26:59,256 --> 00:27:01,076
using AV Audio Engine instead of

804
00:27:01,126 --> 00:27:02,916
AU Graph if you've not already

805
00:27:02,916 --> 00:27:03,926
done that.

806
00:27:06,456 --> 00:27:08,466
Now let's go to the second set

807
00:27:08,466 --> 00:27:10,016
of API in the AV Foundation

808
00:27:10,016 --> 00:27:11,666
framework, AV Audio Session.

809
00:27:12,076 --> 00:27:15,866
AirPlay 2 is a brand-new

810
00:27:15,866 --> 00:27:17,946
technology in this year's iOS,

811
00:27:17,946 --> 00:27:19,396
tvOS, and macOS [inaudible].

812
00:27:19,396 --> 00:27:22,486
And this lets you do multi-room

813
00:27:22,646 --> 00:27:24,546
audio with AirPlay 2 capable

814
00:27:24,546 --> 00:27:26,336
devices, which is for example,

815
00:27:26,336 --> 00:27:26,886
the Homepod.

816
00:27:27,466 --> 00:27:30,036
So, there is a separate

817
00:27:30,036 --> 00:27:31,676
dedicated session called

818
00:27:31,676 --> 00:27:32,946
"Interviews in AirPlay 2,"

819
00:27:33,036 --> 00:27:34,906
happening this Thursday at 4:10

820
00:27:34,956 --> 00:27:37,826
p.m. to go over all the features

821
00:27:37,826 --> 00:27:39,216
of this technology.

822
00:27:39,446 --> 00:27:40,646
So, you can catch that if you're

823
00:27:40,646 --> 00:27:42,826
interested in knowing more

824
00:27:44,096 --> 00:27:44,286
details.

825
00:27:44,406 --> 00:27:45,946
Also seated with AirPlay 2 is

826
00:27:45,946 --> 00:27:47,406
something called Long-Form

827
00:27:47,406 --> 00:27:47,746
audio.

828
00:27:48,486 --> 00:27:49,876
And this is a category of

829
00:27:49,996 --> 00:27:52,536
content, for example music or

830
00:27:52,666 --> 00:27:55,246
podcast, which is typically more

831
00:27:55,246 --> 00:27:57,426
than a few minutes long, and

832
00:27:57,426 --> 00:27:59,116
whose playback can be shared

833
00:27:59,286 --> 00:27:59,776
with others.

834
00:28:01,046 --> 00:28:02,316
For example, say you have a

835
00:28:02,316 --> 00:28:04,036
party at home, and you are

836
00:28:04,036 --> 00:28:05,566
playing back a music playlist

837
00:28:05,566 --> 00:28:07,236
through an AirPlay device.

838
00:28:07,546 --> 00:28:09,656
Now that is categorized as --

839
00:28:09,656 --> 00:28:10,976
that can be categorized as a

840
00:28:10,976 --> 00:28:12,276
long-form audio content.

841
00:28:13,376 --> 00:28:15,856
Now with AirPlay 2 and long-form

842
00:28:15,856 --> 00:28:18,616
audio, we now get a separate

843
00:28:18,616 --> 00:28:20,966
shared route for the long-form

844
00:28:20,966 --> 00:28:22,806
audio apps to the AirPlay 2

845
00:28:22,806 --> 00:28:23,306
devices.

846
00:28:23,896 --> 00:28:26,426
And I'll explain about that in a

847
00:28:26,426 --> 00:28:27,696
little more detail.

848
00:28:28,986 --> 00:28:30,766
And right -- and now, we have

849
00:28:30,766 --> 00:28:33,216
new API in AV Audio Session, for

850
00:28:33,216 --> 00:28:35,496
an app to identify itself as

851
00:28:35,496 --> 00:28:37,056
being long-form and take

852
00:28:37,056 --> 00:28:38,736
advantage of this separate

853
00:28:39,516 --> 00:28:41,146
shared audio route.

854
00:28:42,416 --> 00:28:45,046
So, let's consider the example I

855
00:28:45,046 --> 00:28:45,766
just mentioned.

856
00:28:45,766 --> 00:28:47,626
So, say you have a party at

857
00:28:47,626 --> 00:28:49,056
home, and you're playing back

858
00:28:49,056 --> 00:28:50,776
music to an AirPlay device.

859
00:28:51,476 --> 00:28:52,666
We'll contrast the current

860
00:28:52,666 --> 00:28:54,546
behavior and see how the

861
00:28:54,546 --> 00:28:56,436
behavior changes with long-form

862
00:28:56,436 --> 00:28:57,066
audio routing.

863
00:28:57,456 --> 00:28:58,636
So, here is the current

864
00:28:58,636 --> 00:28:59,076
behavior.

865
00:28:59,606 --> 00:29:01,206
So, you -- the music is now

866
00:29:01,206 --> 00:29:03,476
playing back through the AirPlay

867
00:29:03,476 --> 00:29:05,826
device, and suppose you now get

868
00:29:05,826 --> 00:29:07,896
a phone call.

869
00:29:08,116 --> 00:29:10,586
What happens is, at this point,

870
00:29:10,586 --> 00:29:11,926
your music playback gets

871
00:29:11,926 --> 00:29:13,786
interrupted and it stops.

872
00:29:14,416 --> 00:29:16,286
And the phone call gets routed

873
00:29:16,476 --> 00:29:17,856
to the system audio which could

874
00:29:17,856 --> 00:29:18,586
be receiver or [inaudible]

875
00:29:18,586 --> 00:29:19,186
speaker.

876
00:29:20,236 --> 00:29:21,826
And only when the phone call

877
00:29:21,826 --> 00:29:23,706
ends, is when the music gets a

878
00:29:23,736 --> 00:29:25,936
resumable [inaudible] and it

879
00:29:25,936 --> 00:29:27,026
resumes the playback.

880
00:29:28,186 --> 00:29:30,166
So, as you can see, a phone call

881
00:29:30,166 --> 00:29:32,106
interrupting your party music is

882
00:29:32,106 --> 00:29:34,396
not really an ideal scenario.

883
00:29:35,126 --> 00:29:36,546
So, we'll now see how the

884
00:29:36,546 --> 00:29:38,956
behavior changes with long-form

885
00:29:38,956 --> 00:29:39,566
audio routing.

886
00:29:41,256 --> 00:29:43,586
So lets see the same example.

887
00:29:43,586 --> 00:29:45,536
So, now that we have music

888
00:29:45,756 --> 00:29:47,196
playing back through an AirPlay

889
00:29:47,266 --> 00:29:48,546
2 capable device.

890
00:29:49,416 --> 00:29:51,966
And then, a phone call comes in.

891
00:29:52,706 --> 00:29:54,316
Now because the phone call is

892
00:29:54,316 --> 00:29:56,776
not a long-form audio, it does

893
00:29:56,776 --> 00:29:58,316
not interrupt your music

894
00:29:58,316 --> 00:30:00,256
playback, and it gets routed

895
00:30:00,256 --> 00:30:02,136
independently to the system

896
00:30:02,136 --> 00:30:03,976
audio without any issues.

897
00:30:04,526 --> 00:30:06,216
So, with long-form audio

898
00:30:06,246 --> 00:30:08,636
routing, two of the sessions can

899
00:30:08,636 --> 00:30:10,696
coexist without interrupting

900
00:30:10,956 --> 00:30:12,826
each other, and as you can see,

901
00:30:12,876 --> 00:30:14,666
this is definitely an enhanced

902
00:30:14,786 --> 00:30:15,756
user experience.

903
00:30:16,856 --> 00:30:16,946
So,-- .

904
00:30:18,516 --> 00:30:22,746
[ Applause ]

905
00:30:23,246 --> 00:30:25,206
So, to summarize, with long-form

906
00:30:25,206 --> 00:30:27,606
audio routing, all the apps that

907
00:30:27,606 --> 00:30:29,396
identified themselves as being

908
00:30:29,396 --> 00:30:31,136
long-form, which is for example,

909
00:30:31,276 --> 00:30:33,876
music, podcast, or any other

910
00:30:33,876 --> 00:30:36,396
music streaming app, they get

911
00:30:36,396 --> 00:30:38,126
the dedicated -- they get a

912
00:30:38,126 --> 00:30:39,656
separate shared route to the

913
00:30:39,656 --> 00:30:41,196
AirPlay 2 capable device.

914
00:30:42,006 --> 00:30:43,046
Now, note that there is a

915
00:30:43,046 --> 00:30:44,746
session arbitrated in between.

916
00:30:45,146 --> 00:30:48,036
And that ensures that only one

917
00:30:48,086 --> 00:30:50,006
of these apps is playing to the

918
00:30:50,006 --> 00:30:51,436
AirPlay device at the time.

919
00:30:51,646 --> 00:30:53,776
So, these apps cannot mix with

920
00:30:53,776 --> 00:30:54,546
each other.

921
00:30:55,056 --> 00:30:57,226
And all the other apps that use

922
00:30:57,226 --> 00:30:58,486
the system route, which are

923
00:30:58,486 --> 00:31:00,486
non-long-form, can either

924
00:31:00,616 --> 00:31:02,276
interrupt each other or mix with

925
00:31:02,276 --> 00:31:04,466
each other, and they get routed

926
00:31:04,606 --> 00:31:06,446
to the system audio without

927
00:31:06,446 --> 00:31:07,956
interrupting your long-form

928
00:31:07,956 --> 00:31:08,606
audio playback.

929
00:31:10,336 --> 00:31:13,886
Now, let's see how an app can

930
00:31:13,946 --> 00:31:15,496
identify itself as being

931
00:31:15,496 --> 00:31:17,136
long-form and take advantage of

932
00:31:17,186 --> 00:31:17,796
this routing.

933
00:31:19,176 --> 00:31:21,956
So, on iOS and tvOS, the code is

934
00:31:21,956 --> 00:31:22,646
really simple.

935
00:31:23,006 --> 00:31:24,926
You get shared instance of your

936
00:31:25,026 --> 00:31:26,996
AVAudio session, and you use

937
00:31:27,046 --> 00:31:28,806
this new API to set your

938
00:31:28,806 --> 00:31:31,206
category as playback and route

939
00:31:31,206 --> 00:31:36,096
sharing policy as long-form.

940
00:31:36,276 --> 00:31:38,496
Now, moving over to the macOS,

941
00:31:39,216 --> 00:31:41,726
the routing is very similar to

942
00:31:41,726 --> 00:31:43,026
the iOS and tvOS.

943
00:31:43,376 --> 00:31:45,236
All the long-form audio apps,

944
00:31:45,236 --> 00:31:47,386
for example your iTunes and any

945
00:31:47,386 --> 00:31:49,966
other music streaming app, gets

946
00:31:50,176 --> 00:31:52,216
routed to the AirPlay 2 capable

947
00:31:52,216 --> 00:31:54,506
device, and of course, there is

948
00:31:54,506 --> 00:31:55,856
an arbitrator in between.

949
00:31:57,046 --> 00:31:59,566
And the other system apps like

950
00:31:59,926 --> 00:32:02,626
GarageBand, Safari, or Game App,

951
00:32:02,626 --> 00:32:04,476
do not interrupt your long-form

952
00:32:04,476 --> 00:32:06,506
audio apps, and they always mix

953
00:32:06,506 --> 00:32:08,216
with each other and get routed

954
00:32:08,396 --> 00:32:09,686
to the default device.

955
00:32:10,836 --> 00:32:12,576
And to enable the support of

956
00:32:12,576 --> 00:32:13,926
long-form audio routing on

957
00:32:13,926 --> 00:32:15,696
macOS, we are now bringing a

958
00:32:15,696 --> 00:32:17,596
very small subset of AVAudio

959
00:32:17,596 --> 00:32:19,066
Session to macOS.

960
00:32:19,666 --> 00:32:21,496
So, as an app, in order to

961
00:32:21,496 --> 00:32:23,056
identify yourself as being

962
00:32:23,056 --> 00:32:25,056
long-form, you again get the

963
00:32:25,056 --> 00:32:27,066
shared and sense of your AVAudio

964
00:32:27,066 --> 00:32:28,576
Session, and set the route

965
00:32:28,576 --> 00:32:30,116
sharing policy as being

966
00:32:30,116 --> 00:32:30,636
long-form.

967
00:32:31,166 --> 00:32:34,586
So, that is the end of AVAudio

968
00:32:34,586 --> 00:32:36,476
Session enhancements, and let's

969
00:32:36,476 --> 00:32:38,226
now see the last section in the

970
00:32:38,226 --> 00:32:39,736
AV Foundation framework, that is

971
00:32:39,736 --> 00:32:40,986
the enhancement on watchOS.

972
00:32:41,606 --> 00:32:45,936
So, we introduced the AV -- we

973
00:32:45,936 --> 00:32:47,936
made AVAudio Player API

974
00:32:48,016 --> 00:32:50,336
available in watchOS 3.1SDK.

975
00:32:50,926 --> 00:32:51,786
And this is the first time we

976
00:32:51,786 --> 00:32:53,546
get to mention it at WWDC.

977
00:32:54,116 --> 00:32:55,366
And the nice thing about using

978
00:32:55,366 --> 00:32:57,256
the AVAudio Player for playback

979
00:32:57,536 --> 00:32:59,266
is that it comes associated with

980
00:32:59,266 --> 00:33:01,026
its AVAudio Session, so you

981
00:33:01,026 --> 00:33:02,766
could use the session category

982
00:33:02,766 --> 00:33:04,326
options like [inaudible] or mix

983
00:33:04,376 --> 00:33:06,816
with others, to describe your

984
00:33:06,816 --> 00:33:07,646
app's behavior.

985
00:33:08,396 --> 00:33:10,836
Now starting watchOS 4, we are

986
00:33:11,466 --> 00:33:13,476
exposing more APIs in order to

987
00:33:13,476 --> 00:33:14,896
do recording.

988
00:33:15,176 --> 00:33:17,066
That is, we are making AVAudio

989
00:33:17,096 --> 00:33:19,576
Recorder and AVAudio Input Node

990
00:33:19,576 --> 00:33:21,386
and AVAudio Engine, available.

991
00:33:22,836 --> 00:33:24,186
And with these, comes the

992
00:33:24,186 --> 00:33:25,646
AVAudio recording permissions,

993
00:33:25,816 --> 00:33:27,146
through which an app can

994
00:33:27,146 --> 00:33:28,786
[inaudible] the user permission

995
00:33:28,786 --> 00:33:29,286
to record.

996
00:33:30,126 --> 00:33:31,656
Now, [inaudible] to this you

997
00:33:31,656 --> 00:33:33,136
could use the watch [inaudible]

998
00:33:33,396 --> 00:33:35,186
framework to do the recording,

999
00:33:35,436 --> 00:33:37,106
using the Apple UI.

1000
00:33:37,296 --> 00:33:39,786
But now, with these APIs, you

1001
00:33:39,786 --> 00:33:42,406
could do the recording with your

1002
00:33:42,406 --> 00:33:43,226
own UI.

1003
00:33:44,306 --> 00:33:45,946
With AVAudio Recorder, you could

1004
00:33:45,946 --> 00:33:47,656
record to a file, or if you

1005
00:33:47,656 --> 00:33:49,046
wanted to get access to the

1006
00:33:49,046 --> 00:33:50,256
microphone [inaudible] directly,

1007
00:33:50,436 --> 00:33:51,996
you could use the AVAudio Input

1008
00:33:51,996 --> 00:33:53,916
Node, and also optionally, write

1009
00:33:53,916 --> 00:33:54,506
it to a file.

1010
00:33:55,546 --> 00:33:57,056
And here are the formats that

1011
00:33:57,056 --> 00:33:58,976
are supported on watchOS, both

1012
00:33:58,976 --> 00:34:00,376
for playback and recording.

1013
00:34:01,576 --> 00:34:03,816
A last note on the recording

1014
00:34:03,816 --> 00:34:04,346
policies.

1015
00:34:05,276 --> 00:34:06,966
The recording can start only

1016
00:34:06,966 --> 00:34:08,255
when the app is in foreground.

1017
00:34:08,846 --> 00:34:10,246
But it is allowed to continue

1018
00:34:10,246 --> 00:34:12,326
recording in the background, but

1019
00:34:12,326 --> 00:34:13,946
-- and the right microphone icon

1020
00:34:13,996 --> 00:34:15,676
will be displayed at the top so

1021
00:34:15,676 --> 00:34:17,076
that the user is aware of it.

1022
00:34:18,366 --> 00:34:20,255
And recording in background is

1023
00:34:20,525 --> 00:34:22,275
CPU limited, similar to the

1024
00:34:22,856 --> 00:34:23,936
[inaudible] sessions and you can

1025
00:34:23,936 --> 00:34:25,696
refer to this URL for more

1026
00:34:25,696 --> 00:34:26,136
details.

1027
00:34:28,005 --> 00:34:29,476
Now, let's move over to the

1028
00:34:29,476 --> 00:34:31,246
Audio Toolbox world and look at

1029
00:34:31,246 --> 00:34:33,085
the enhancements in AUAudio Unit

1030
00:34:33,315 --> 00:34:34,706
and audio formats.

1031
00:34:35,235 --> 00:34:38,516
We have two main enhancements in

1032
00:34:38,516 --> 00:34:39,246
AUAudio Unit.

1033
00:34:40,126 --> 00:34:41,466
And at the end of this section,

1034
00:34:41,496 --> 00:34:42,996
we will also show you a demo

1035
00:34:43,196 --> 00:34:44,726
with those two new features in

1036
00:34:47,826 --> 00:34:47,985
action.

1037
00:34:48,166 --> 00:34:49,956
Now, Audio Unit host

1038
00:34:49,956 --> 00:34:51,646
applications choose various

1039
00:34:51,646 --> 00:34:53,656
strategies in order to recommend

1040
00:34:53,766 --> 00:34:56,116
how to display the UI for AU.

1041
00:34:56,426 --> 00:34:58,816
They can decide to say embed the

1042
00:34:58,816 --> 00:35:01,696
AU's UI in their own UI, or they

1043
00:35:01,696 --> 00:35:03,076
could present a full screen

1044
00:35:03,076 --> 00:35:05,146
separate UI for the AU.

1045
00:35:06,106 --> 00:35:07,596
Now, this presents mainly a

1046
00:35:07,626 --> 00:35:08,726
challenge on the [inaudible]

1047
00:35:08,806 --> 00:35:10,706
devices because currently, the

1048
00:35:10,706 --> 00:35:13,006
view sizes are not defined, and

1049
00:35:13,006 --> 00:35:14,716
the audio unit is expected to

1050
00:35:14,716 --> 00:35:17,036
adapt to any UI size that the

1051
00:35:17,036 --> 00:35:18,656
host has actually chosen.

1052
00:35:19,856 --> 00:35:21,056
In order to overcome this

1053
00:35:21,056 --> 00:35:23,126
limitation, we're now adding a

1054
00:35:23,156 --> 00:35:25,506
way in which the host and the AU

1055
00:35:25,656 --> 00:35:27,076
can negotiate with each other

1056
00:35:27,506 --> 00:35:29,556
and the AU can inform the host

1057
00:35:29,846 --> 00:35:30,766
about all the view

1058
00:35:30,766 --> 00:35:32,186
configurations that it actually

1059
00:35:32,186 --> 00:35:32,746
supports.

1060
00:35:33,096 --> 00:35:34,906
Now, let's see how this

1061
00:35:35,256 --> 00:35:38,196
negotiation can take place.

1062
00:35:38,366 --> 00:35:41,336
The host first compiles a list

1063
00:35:41,336 --> 00:35:43,126
of all the available view

1064
00:35:43,126 --> 00:35:45,986
configurations for the AU, and

1065
00:35:45,986 --> 00:35:49,536
then hands the audio over to the

1066
00:35:49,536 --> 00:35:49,603
AU.

1067
00:35:50,006 --> 00:35:51,206
The AU can then [inaudible]

1068
00:35:51,206 --> 00:35:52,616
through all these available

1069
00:35:52,616 --> 00:35:54,376
configurations, and then let the

1070
00:35:54,376 --> 00:35:56,576
host know about the

1071
00:35:57,006 --> 00:35:58,326
configuration that it actually

1072
00:35:58,326 --> 00:35:58,876
supports.

1073
00:35:59,696 --> 00:36:01,466
And then, the host can choose

1074
00:36:01,466 --> 00:36:02,556
one of the supported

1075
00:36:02,596 --> 00:36:04,276
configurations and then it will

1076
00:36:04,276 --> 00:36:06,086
let the AU know about the final

1077
00:36:06,086 --> 00:36:07,266
selected configuration.

1078
00:36:08,416 --> 00:36:10,456
Now, let's see a code example on

1079
00:36:10,456 --> 00:36:12,216
how this negotiation takes

1080
00:36:12,216 --> 00:36:12,546
place.

1081
00:36:13,006 --> 00:36:14,616
We'll first look at the audio

1082
00:36:14,616 --> 00:36:15,996
unit extension site.

1083
00:36:16,596 --> 00:36:19,566
The first thing the AU has to do

1084
00:36:20,356 --> 00:36:22,236
is to override the supported

1085
00:36:22,236 --> 00:36:24,186
view configuration method from

1086
00:36:24,186 --> 00:36:24,846
the base class.

1087
00:36:25,516 --> 00:36:27,156
And this is called by the host

1088
00:36:27,446 --> 00:36:28,986
with the list of all the

1089
00:36:28,986 --> 00:36:31,016
available configurations.

1090
00:36:32,276 --> 00:36:34,526
Then, the AU can iterate through

1091
00:36:34,566 --> 00:36:36,566
each of these configurations and

1092
00:36:36,566 --> 00:36:38,426
decide which ones it actually

1093
00:36:38,426 --> 00:36:38,966
supports.

1094
00:36:39,466 --> 00:36:41,696
Now, the configuration itself,

1095
00:36:41,876 --> 00:36:43,806
contains a width and a height,

1096
00:36:44,066 --> 00:36:46,846
which recommends the view size.

1097
00:36:47,186 --> 00:36:48,906
And also, it has a host test

1098
00:36:48,906 --> 00:36:49,736
controller flag.

1099
00:36:50,636 --> 00:36:52,576
And that flag indicates whether

1100
00:36:52,576 --> 00:36:54,886
or not the host is presenting

1101
00:36:54,886 --> 00:36:56,716
its own controller in this

1102
00:36:56,716 --> 00:36:58,496
particular view configuration.

1103
00:36:59,006 --> 00:37:00,696
So, depending on all these

1104
00:37:00,696 --> 00:37:03,166
factors, an AU can choose

1105
00:37:03,246 --> 00:37:04,396
whether it supports that

1106
00:37:04,466 --> 00:37:05,536
particular configuration.

1107
00:37:06,826 --> 00:37:08,366
Note that there is a wild card

1108
00:37:08,366 --> 00:37:11,466
configuration which is 0x0, and

1109
00:37:11,466 --> 00:37:12,586
that means -- and that

1110
00:37:12,586 --> 00:37:14,976
represents a full default size

1111
00:37:15,296 --> 00:37:17,056
that the AU can support.

1112
00:37:17,696 --> 00:37:19,946
And on macOS, this actually

1113
00:37:19,946 --> 00:37:21,756
translates to a separate,

1114
00:37:21,916 --> 00:37:23,766
resizable window -- full size,

1115
00:37:23,766 --> 00:37:26,996
resizable window, for the AU's

1116
00:37:27,036 --> 00:37:27,296
UI.

1117
00:37:28,156 --> 00:37:31,576
So, the AU has its own logic to

1118
00:37:31,576 --> 00:37:32,966
decide which configuration it

1119
00:37:32,966 --> 00:37:34,796
supports, and then finally, it

1120
00:37:34,906 --> 00:37:36,656
compares a list of the indices

1121
00:37:37,036 --> 00:37:39,466
corresponding to the ones that

1122
00:37:39,466 --> 00:37:40,846
it supports, and [inaudible]

1123
00:37:40,876 --> 00:37:43,746
this index set back to the host.

1124
00:37:44,966 --> 00:37:46,866
The last thing that the AU has

1125
00:37:46,946 --> 00:37:49,266
to do, is to override select

1126
00:37:49,416 --> 00:37:51,116
method, which is called by the

1127
00:37:51,116 --> 00:37:53,086
host with the configuration that

1128
00:37:53,086 --> 00:37:55,206
it has finally selected, and

1129
00:37:55,206 --> 00:37:57,596
then, the AU can let its view

1130
00:37:57,596 --> 00:37:59,346
controller know about the final

1131
00:37:59,346 --> 00:38:00,566
selected configuration.

1132
00:38:02,166 --> 00:38:03,886
Now, let's go to the host site

1133
00:38:04,086 --> 00:38:06,266
and see how the code looks like.

1134
00:38:07,296 --> 00:38:10,566
The host has to compile the list

1135
00:38:10,566 --> 00:38:12,226
of available configurations, and

1136
00:38:12,226 --> 00:38:13,706
in this example, it is saying

1137
00:38:13,926 --> 00:38:15,826
that it has a large and a small

1138
00:38:15,826 --> 00:38:17,096
configuration available.

1139
00:38:17,716 --> 00:38:19,606
And in the last configuration,

1140
00:38:19,796 --> 00:38:21,316
the host is saying it's not

1141
00:38:21,506 --> 00:38:23,586
presenting its controller, so

1142
00:38:23,586 --> 00:38:25,246
the host has controller flag as

1143
00:38:25,346 --> 00:38:25,676
false.

1144
00:38:26,016 --> 00:38:27,326
And in the small configuration,

1145
00:38:27,536 --> 00:38:29,356
the host does present its

1146
00:38:29,356 --> 00:38:30,866
controller, so the flag is true.

1147
00:38:32,096 --> 00:38:34,526
The host then calls the

1148
00:38:34,526 --> 00:38:36,066
supported view configurations

1149
00:38:36,066 --> 00:38:38,626
method on the AU, and provides

1150
00:38:38,626 --> 00:38:40,496
this list of configurations.

1151
00:38:40,976 --> 00:38:42,556
And depending on the return set

1152
00:38:42,556 --> 00:38:44,556
of indices, it goes ahead and

1153
00:38:44,556 --> 00:38:45,596
selects one of the

1154
00:38:45,596 --> 00:38:46,416
configurations.

1155
00:38:46,656 --> 00:38:48,196
And in this particular example,

1156
00:38:48,396 --> 00:38:49,726
the host is just toggling

1157
00:38:49,866 --> 00:38:51,306
between the large and the small

1158
00:38:51,306 --> 00:38:51,986
configuration.

1159
00:38:52,456 --> 00:38:55,576
So, that is end of the preferred

1160
00:38:55,726 --> 00:38:57,286
view configuration negotiation.

1161
00:38:57,706 --> 00:38:59,086
Now, let's see the second main

1162
00:38:59,216 --> 00:39:01,596
new feature we have, which is

1163
00:39:01,596 --> 00:39:03,486
the support for MIDI output in

1164
00:39:03,486 --> 00:39:04,626
an audio unit extension.

1165
00:39:05,916 --> 00:39:07,966
We have now support for an AU to

1166
00:39:07,966 --> 00:39:10,186
emit MIDI output synchronized

1167
00:39:10,306 --> 00:39:11,376
with its audio output.

1168
00:39:12,056 --> 00:39:13,906
And this mainly useful if the

1169
00:39:13,906 --> 00:39:16,146
host wants to record and edit

1170
00:39:16,306 --> 00:39:17,926
both the MIDI performance, as

1171
00:39:17,926 --> 00:39:19,616
well as the audio output, from

1172
00:39:19,766 --> 00:39:20,686
the AU.

1173
00:39:20,996 --> 00:39:23,366
So, the host installs a MIDI

1174
00:39:23,366 --> 00:39:25,176
output event block on the AU,

1175
00:39:25,406 --> 00:39:26,876
and the AU should call this

1176
00:39:26,926 --> 00:39:29,326
block every render cycle and

1177
00:39:29,326 --> 00:39:31,176
provide the MIDI output for that

1178
00:39:31,236 --> 00:39:32,286
particular render cycle.

1179
00:39:34,596 --> 00:39:36,796
We also have a couple of other

1180
00:39:36,796 --> 00:39:37,896
enhancements in the Audio

1181
00:39:37,896 --> 00:39:38,836
Toolbox framework.

1182
00:39:39,136 --> 00:39:40,516
The first one is related to a

1183
00:39:40,516 --> 00:39:42,366
privacy enhancement.

1184
00:39:43,136 --> 00:39:46,346
So, starting iOS 11 SDK, all the

1185
00:39:46,346 --> 00:39:48,166
audio unit extension host apps

1186
00:39:48,746 --> 00:39:50,436
will need the inter-app-audio

1187
00:39:50,436 --> 00:39:51,966
entitlement to be able to

1188
00:39:51,966 --> 00:39:53,626
communicate with the audio unit

1189
00:39:53,626 --> 00:39:54,206
extensions.

1190
00:39:55,166 --> 00:39:57,546
And we also have a new API for

1191
00:39:57,936 --> 00:40:00,926
an AU to publish a very

1192
00:40:00,926 --> 00:40:03,076
meaningful short name so that

1193
00:40:03,076 --> 00:40:05,676
the host say, can use this short

1194
00:40:05,676 --> 00:40:07,356
name if it has to display the

1195
00:40:07,356 --> 00:40:10,286
list of AU names in a space

1196
00:40:10,286 --> 00:40:12,466
constraint list.

1197
00:40:13,826 --> 00:40:17,086
So, that brings us to the end of

1198
00:40:17,086 --> 00:40:18,386
all the enhancements in Audio

1199
00:40:18,386 --> 00:40:19,856
Toolbox framework, and as

1200
00:40:19,946 --> 00:40:23,116
promised, we have a demo to show

1201
00:40:23,116 --> 00:40:24,526
these new features in action.

1202
00:40:24,526 --> 00:40:26,286
And I call upon Bela for that.

1203
00:40:27,516 --> 00:40:33,076
[ Applause ]

1204
00:40:33,576 --> 00:40:38,106
>> Thank you, Akshatha and good

1205
00:40:38,106 --> 00:40:39,006
afternoon everyone.

1206
00:40:39,006 --> 00:40:40,716
My name is Bela Balazs and I am

1207
00:40:40,716 --> 00:40:43,746
an engineer on the Core Audio

1208
00:40:43,746 --> 00:40:44,436
Team.

1209
00:40:44,436 --> 00:40:47,086
Today, we would like to show you

1210
00:40:47,086 --> 00:40:48,956
an application of our newly

1211
00:40:48,956 --> 00:40:50,656
introduced APIs.

1212
00:40:51,116 --> 00:40:52,476
For this purpose, we have

1213
00:40:52,476 --> 00:40:54,226
developed an example audio unit,

1214
00:40:54,316 --> 00:40:55,276
which has the following

1215
00:40:55,276 --> 00:40:56,126
capabilities.

1216
00:40:57,156 --> 00:40:58,986
It supports its preferred view

1217
00:40:58,986 --> 00:41:00,346
configuration with the Audio

1218
00:41:00,346 --> 00:41:01,696
Unit host application.

1219
00:41:02,556 --> 00:41:03,836
It supports multiple view

1220
00:41:03,836 --> 00:41:05,806
configurations, and it uses the

1221
00:41:05,806 --> 00:41:09,286
newly bridged MIDI output API in

1222
00:41:09,286 --> 00:41:11,526
order to pass on MIDI data to

1223
00:41:11,526 --> 00:41:13,266
the Audio Unit host application

1224
00:41:13,266 --> 00:41:14,496
for recording purposes.

1225
00:41:15,746 --> 00:41:17,306
So, here I have an upcoming

1226
00:41:17,306 --> 00:41:18,506
version of GarageBand.

1227
00:41:19,286 --> 00:41:20,926
And I have loaded my example

1228
00:41:20,926 --> 00:41:22,106
audio unit to a track.

1229
00:41:22,756 --> 00:41:24,986
Here you can see the custom view

1230
00:41:24,986 --> 00:41:27,146
of my audio unit, together with

1231
00:41:27,146 --> 00:41:28,256
the GarageBand keyboard.

1232
00:41:28,676 --> 00:41:31,196
In this reconfiguration, I rely

1233
00:41:31,196 --> 00:41:32,576
on the GarageBand keyboard to

1234
00:41:32,576 --> 00:41:33,446
play my instrument.

1235
00:41:34,236 --> 00:41:35,776
I have mapped out three drum

1236
00:41:35,776 --> 00:41:36,936
samples on the keyboard.

1237
00:41:37,166 --> 00:41:39,296
I have a kick, I have a snare,

1238
00:41:39,826 --> 00:41:40,706
and I have a high hat.

1239
00:41:41,486 --> 00:41:43,236
In addition to these, on the

1240
00:41:43,236 --> 00:41:45,206
view of my audio unit, I also

1241
00:41:45,206 --> 00:41:46,796
have a volume slider to control

1242
00:41:46,796 --> 00:41:48,926
the volume of these samples.

1243
00:41:51,476 --> 00:41:53,756
However, my audio unit also has

1244
00:41:53,756 --> 00:41:55,526
a different view configuration,

1245
00:41:55,576 --> 00:41:57,246
and I can switch to it using

1246
00:41:57,246 --> 00:41:58,816
this newly added button on the

1247
00:41:58,816 --> 00:42:00,966
right -- lower, right section of

1248
00:42:00,966 --> 00:42:01,496
the screen.

1249
00:42:02,106 --> 00:42:04,086
When I activate that button, I

1250
00:42:04,086 --> 00:42:05,766
get taken to the large view of

1251
00:42:05,766 --> 00:42:07,556
my audio unit and the GarageBand

1252
00:42:07,556 --> 00:42:08,516
keyboard disappears.

1253
00:42:09,336 --> 00:42:11,226
When I activate it again, I get

1254
00:42:11,286 --> 00:42:12,786
taken back to the small view of

1255
00:42:12,786 --> 00:42:13,536
my audio unit.

1256
00:42:14,086 --> 00:42:15,416
This is made possible by

1257
00:42:15,416 --> 00:42:18,576
GarageBand's publishing all the

1258
00:42:18,576 --> 00:42:20,216
available view configurations to

1259
00:42:20,216 --> 00:42:22,706
my audio unit, and my audio unit

1260
00:42:22,706 --> 00:42:24,226
goes through that list and marks

1261
00:42:24,226 --> 00:42:25,846
each of them as supported or

1262
00:42:25,846 --> 00:42:27,786
unsupported, and at the end of

1263
00:42:27,786 --> 00:42:29,356
this process, GarageBand knows

1264
00:42:29,356 --> 00:42:30,936
that my audio unit supports two

1265
00:42:30,936 --> 00:42:33,076
view configurations and it can

1266
00:42:33,076 --> 00:42:34,096
toggle between them.

1267
00:42:35,176 --> 00:42:36,806
In case my audio unit only

1268
00:42:36,806 --> 00:42:37,766
supported one view

1269
00:42:37,766 --> 00:42:39,956
configuration, then this button

1270
00:42:39,956 --> 00:42:41,396
could be hidden by GarageBand,

1271
00:42:41,396 --> 00:42:42,846
but my audio unit could still

1272
00:42:42,846 --> 00:42:44,036
take full advantage of the

1273
00:42:44,036 --> 00:42:46,396
negotiation process to negotiate

1274
00:42:46,396 --> 00:42:48,446
the preferred view configuration

1275
00:42:48,446 --> 00:42:49,416
for that one view.

1276
00:42:50,226 --> 00:42:53,446
In this small view, the host has

1277
00:42:53,446 --> 00:42:55,276
controller flag as set to true,

1278
00:42:56,026 --> 00:42:57,286
and that is why the GarageBand

1279
00:42:57,286 --> 00:42:58,266
keyboard is visible.

1280
00:42:58,566 --> 00:42:59,596
In the larger view

1281
00:42:59,596 --> 00:43:01,056
configuration, the GarageBand

1282
00:43:01,056 --> 00:43:03,286
keyboard is hidden because that

1283
00:43:03,286 --> 00:43:04,636
flag is set to false.

1284
00:43:05,246 --> 00:43:06,696
In this view configuration, my

1285
00:43:06,696 --> 00:43:08,986
audio unit has its own playing

1286
00:43:08,986 --> 00:43:11,046
surface, which I can use to play

1287
00:43:11,046 --> 00:43:11,726
my instrument.

1288
00:43:12,066 --> 00:43:14,346
I have a kick, a snare, and a

1289
00:43:14,346 --> 00:43:14,826
high hat.

1290
00:43:15,986 --> 00:43:17,486
And in addition to these three

1291
00:43:17,486 --> 00:43:21,086
buttons, I also have a new

1292
00:43:21,086 --> 00:43:22,496
button on the right-hand side

1293
00:43:22,556 --> 00:43:23,716
called Repeat Note.

1294
00:43:23,986 --> 00:43:25,496
And this allows me to repeat

1295
00:43:25,496 --> 00:43:27,996
each sample at the certain rate.

1296
00:43:28,606 --> 00:43:30,126
And I can set those rates

1297
00:43:30,186 --> 00:43:31,516
independently from each other

1298
00:43:31,516 --> 00:43:32,486
using the sliders.

1299
00:43:33,436 --> 00:43:38,436
And I can toggle each sample in

1300
00:43:38,436 --> 00:43:39,556
and out of the drum loop.

1301
00:43:40,516 --> 00:43:50,776
[ Drums playing ]

1302
00:43:51,276 --> 00:43:52,976
This allows me to easily

1303
00:43:52,976 --> 00:43:54,326
construct drum loops that

1304
00:43:54,526 --> 00:43:56,306
respect the tempo of my track.

1305
00:43:57,726 --> 00:43:59,696
So, let's use the MIDI output

1306
00:43:59,696 --> 00:44:01,976
API to record the output of this

1307
00:44:01,976 --> 00:44:03,316
audio unit extension.

1308
00:44:04,046 --> 00:44:05,436
I have the synchronized rates

1309
00:44:05,436 --> 00:44:07,516
button here, which sets my rates

1310
00:44:07,516 --> 00:44:09,766
to 110 BPM.

1311
00:44:09,766 --> 00:44:11,806
And first, I will record a kick,

1312
00:44:11,936 --> 00:44:13,396
snare drum loop.

1313
00:44:13,396 --> 00:44:14,636
And then when the recording

1314
00:44:14,636 --> 00:44:16,406
wraps around, I will add my high

1315
00:44:16,406 --> 00:44:16,806
hats.

1316
00:44:17,236 --> 00:44:18,606
This is made possible by

1317
00:44:18,606 --> 00:44:20,376
GarageBand's merge recording

1318
00:44:20,376 --> 00:44:20,876
feature.

1319
00:44:21,656 --> 00:44:22,826
So, let's do just that.

1320
00:44:23,516 --> 00:44:26,556
[ Drums playing ]

1321
00:44:27,056 --> 00:44:28,686
I will just record four bars of

1322
00:44:28,866 --> 00:44:29,996
that.

1323
00:44:30,476 --> 00:44:36,626
And then add my high hats.

1324
00:44:37,516 --> 00:44:44,176
[ Drums playing ]

1325
00:44:44,676 --> 00:44:46,636
My high hats have been added to

1326
00:44:46,636 --> 00:44:47,326
the recording.

1327
00:44:47,906 --> 00:44:50,876
And now we can go to the track

1328
00:44:50,876 --> 00:44:52,086
view and take a look at our

1329
00:44:52,086 --> 00:44:53,236
recorded media output.

1330
00:44:54,136 --> 00:44:58,826
And I can quantize the track.

1331
00:44:59,516 --> 00:45:05,086
And then we can play it back.

1332
00:45:05,546 --> 00:45:09,076
And we have the full MIDI

1333
00:45:09,076 --> 00:45:10,426
editing capabilities of

1334
00:45:10,426 --> 00:45:12,096
GarageBand at our disposal to

1335
00:45:12,096 --> 00:45:13,476
construct our drum track.

1336
00:45:14,366 --> 00:45:15,716
And this concludes my demo.

1337
00:45:15,766 --> 00:45:16,656
Thank you very much for your

1338
00:45:16,656 --> 00:45:17,066
attention.

1339
00:45:17,066 --> 00:45:18,176
And I would like to hand it back

1340
00:45:18,176 --> 00:45:19,276
to my colleague, Akshatha.

1341
00:45:19,846 --> 00:45:20,156
Thank you.

1342
00:45:21,516 --> 00:45:25,516
[ Applause ]

1343
00:45:26,016 --> 00:45:29,696
>> Thank you, Bela.

1344
00:45:29,886 --> 00:45:31,596
So, now, onto the last set of

1345
00:45:31,726 --> 00:45:32,686
enhancements in the Audio

1346
00:45:32,686 --> 00:45:34,246
Toolbox framework, related to

1347
00:45:34,246 --> 00:45:35,206
the audio formats.

1348
00:45:36,626 --> 00:45:38,396
We now have support for two of

1349
00:45:38,656 --> 00:45:40,286
the popular formats, namely the

1350
00:45:40,286 --> 00:45:42,056
FLAC and the Opus format.

1351
00:45:42,056 --> 00:45:44,706
On the FLAC side, we have the

1352
00:45:44,756 --> 00:45:46,566
codec, file, and the streaming

1353
00:45:46,566 --> 00:45:48,496
support, and for Opus, we have

1354
00:45:48,496 --> 00:45:49,976
the codec, and the file I/O

1355
00:45:49,976 --> 00:45:51,416
support using the code audio

1356
00:45:51,416 --> 00:45:52,266
format container.

1357
00:45:54,376 --> 00:45:56,336
From audio formats to spatial

1358
00:45:56,336 --> 00:45:58,346
audio formats, those of you who

1359
00:45:58,346 --> 00:45:59,326
are interested in [inaudible]

1360
00:45:59,326 --> 00:46:02,096
audio, AR, and VR applications,

1361
00:46:02,416 --> 00:46:04,026
you may be happy to know that we

1362
00:46:04,026 --> 00:46:05,456
now support ambisonics.

1363
00:46:06,106 --> 00:46:07,886
And for those of you who may not

1364
00:46:07,886 --> 00:46:09,016
be really familiar with

1365
00:46:09,016 --> 00:46:11,586
ambisonics like me, ambisonics

1366
00:46:11,686 --> 00:46:14,006
is also a multichannel format,

1367
00:46:14,536 --> 00:46:16,256
but the difference is that the

1368
00:46:16,256 --> 00:46:18,006
traditional surround formats

1369
00:46:18,006 --> 00:46:20,306
that we know of, for example 5.1

1370
00:46:20,466 --> 00:46:22,946
or 7.1, have the signals that

1371
00:46:23,086 --> 00:46:24,606
actually represent the speaker

1372
00:46:24,606 --> 00:46:24,986
layout.

1373
00:46:25,596 --> 00:46:28,466
Whereas ambisonics provide a

1374
00:46:28,606 --> 00:46:29,696
speaker independent

1375
00:46:29,696 --> 00:46:31,176
representation of the sound

1376
00:46:32,226 --> 00:46:32,536
feed.

1377
00:46:32,536 --> 00:46:34,236
So, they are by nature,

1378
00:46:34,346 --> 00:46:35,036
[inaudible] from the playback

1379
00:46:35,036 --> 00:46:35,486
system.

1380
00:46:36,156 --> 00:46:38,256
And at the time of rendering, is

1381
00:46:38,256 --> 00:46:40,076
when they can be decoded to the

1382
00:46:40,076 --> 00:46:41,686
listener's speaker setup.

1383
00:46:42,326 --> 00:46:43,306
And this provides more

1384
00:46:43,306 --> 00:46:44,746
flexibility for the content

1385
00:46:44,746 --> 00:46:45,256
producers.

1386
00:46:46,436 --> 00:46:48,166
We now support the first order

1387
00:46:48,166 --> 00:46:49,856
ambisonics which is called the

1388
00:46:49,856 --> 00:46:52,646
B-format and higher ordered

1389
00:46:52,646 --> 00:46:55,416
ambisonics with the Order N, can

1390
00:46:55,416 --> 00:46:57,696
range from 1 through 254.

1391
00:46:58,076 --> 00:46:59,896
And depending on the order, the

1392
00:47:00,036 --> 00:47:02,276
channels itself can go from zero

1393
00:47:02,516 --> 00:47:03,966
-- the ambisonic channel number

1394
00:47:04,046 --> 00:47:06,986
can go from zero to 65,024.

1395
00:47:07,826 --> 00:47:09,266
And we support two of the

1396
00:47:09,526 --> 00:47:11,576
popular normalized streams,

1397
00:47:12,066 --> 00:47:13,966
namely the SN3D and the N3D

1398
00:47:13,966 --> 00:47:16,336
streams, and we support decoding

1399
00:47:16,336 --> 00:47:19,716
ambisonics to any arbitrary

1400
00:47:19,876 --> 00:47:21,576
speaker layout, and conversion

1401
00:47:21,576 --> 00:47:23,276
between the B-format and these

1402
00:47:23,276 --> 00:47:24,076
normalized streams.

1403
00:47:24,696 --> 00:47:28,906
The last enhancement is on the

1404
00:47:28,906 --> 00:47:30,146
AU Spatial Mixer side.

1405
00:47:30,516 --> 00:47:32,306
So, this is an Apple built-in

1406
00:47:32,556 --> 00:47:34,716
spatial mixer, which is used for

1407
00:47:34,716 --> 00:47:36,236
3D audio spatialization.

1408
00:47:37,006 --> 00:47:39,216
And the AVAudio Environment

1409
00:47:39,216 --> 00:47:40,636
Node, which is a node in the

1410
00:47:40,636 --> 00:47:42,656
AVAudio Engine, also uses the

1411
00:47:42,656 --> 00:47:44,266
Spatial Mixer underneath.

1412
00:47:44,856 --> 00:47:47,046
And we now have a new rendering

1413
00:47:47,046 --> 00:47:48,826
algorithm in this Spatial Mixer,

1414
00:47:49,086 --> 00:47:52,136
called HRTFHQ, high quality.

1415
00:47:52,546 --> 00:47:54,236
And this differs from the

1416
00:47:54,236 --> 00:47:56,946
current existing HRTF algorithm

1417
00:47:57,176 --> 00:47:58,256
in the sense that it has a

1418
00:47:58,256 --> 00:47:59,996
better frequency response and

1419
00:47:59,996 --> 00:48:01,646
better localization of sources

1420
00:48:01,646 --> 00:48:02,566
in the 3D space.

1421
00:48:03,816 --> 00:48:05,056
So, that concludes all the

1422
00:48:05,056 --> 00:48:06,366
enhancements in the Audio

1423
00:48:06,366 --> 00:48:08,266
Toolbox framework and now, I

1424
00:48:08,266 --> 00:48:09,996
hand it over to Torrey to take

1425
00:48:09,996 --> 00:48:11,666
it away from here, and give you

1426
00:48:11,666 --> 00:48:14,016
an update on inter-device audio

1427
00:48:14,386 --> 00:48:14,646
mode.

1428
00:48:15,516 --> 00:48:20,066
[ Applause ]

1429
00:48:20,566 --> 00:48:21,396
>> Thank you, Akshatha.

1430
00:48:21,496 --> 00:48:23,236
I am Torrey Holbrook Walker, and

1431
00:48:23,236 --> 00:48:24,456
I'm going to take you home today

1432
00:48:24,456 --> 00:48:26,236
with inter-device audio mode, or

1433
00:48:26,236 --> 00:48:27,326
if you want to be cool, you can

1434
00:48:27,326 --> 00:48:28,776
just say IDAM for short.

1435
00:48:29,236 --> 00:48:30,386
And you remember IDAM.

1436
00:48:30,596 --> 00:48:32,356
You take your iOS device.

1437
00:48:32,356 --> 00:48:33,326
You plug it into your Mac.

1438
00:48:33,326 --> 00:48:35,006
You open up Audio MIDI setup and

1439
00:48:35,006 --> 00:48:36,216
then it shows right up there in

1440
00:48:36,216 --> 00:48:38,096
the Audio Device Window, you can

1441
00:48:38,136 --> 00:48:38,986
-- there's a button next to it

1442
00:48:38,986 --> 00:48:39,656
that says Enable.

1443
00:48:39,656 --> 00:48:41,076
And if you click it, boom,

1444
00:48:41,266 --> 00:48:42,526
you've immediately got the

1445
00:48:42,526 --> 00:48:44,176
capability to record audio

1446
00:48:44,176 --> 00:48:46,056
digitally over the USB lightning

1447
00:48:46,056 --> 00:48:47,226
cable that came with the device,

1448
00:48:47,636 --> 00:48:49,586
and it looks just like a USB

1449
00:48:49,586 --> 00:48:51,576
audio input to the Mac host.

1450
00:48:51,576 --> 00:48:53,316
So, it uses the same driver, the

1451
00:48:53,316 --> 00:48:54,466
same low latency driver, that's

1452
00:48:54,466 --> 00:48:56,506
used on MacOS 4, class-compliant

1453
00:48:56,506 --> 00:48:57,266
audio devices.

1454
00:48:57,586 --> 00:48:58,936
And you've been able to do this

1455
00:48:58,936 --> 00:49:01,566
since El Capitan and iOS 9.

1456
00:49:01,956 --> 00:49:03,476
Well, today we would like to

1457
00:49:03,476 --> 00:49:06,046
wave a fond farewell to IDAM.

1458
00:49:06,106 --> 00:49:07,936
So, wave goodbye IDAM.

1459
00:49:07,936 --> 00:49:08,966
Goodbye IDAM.

1460
00:49:09,436 --> 00:49:10,736
And while you're waving, say

1461
00:49:10,736 --> 00:49:12,676
hello to IDAM, Inter Device

1462
00:49:12,676 --> 00:49:13,646
Audio and MIDI.

1463
00:49:14,386 --> 00:49:15,936
So, this year, we are adding

1464
00:49:16,046 --> 00:49:18,366
MIDI to IDAM configuration, and

1465
00:49:18,366 --> 00:49:19,956
that will allow you to send and

1466
00:49:19,956 --> 00:49:21,936
receive your musical instrument

1467
00:49:21,936 --> 00:49:23,986
data to your iOS device using

1468
00:49:23,986 --> 00:49:25,296
the same cable that came with

1469
00:49:25,296 --> 00:49:25,846
the device.

1470
00:49:26,206 --> 00:49:28,016
It's class-compliant once again,

1471
00:49:28,276 --> 00:49:31,266
so on the iOS side, you will see

1472
00:49:31,386 --> 00:49:33,086
a MIDI source and destination

1473
00:49:33,086 --> 00:49:34,046
representing the Mac.

1474
00:49:34,046 --> 00:49:35,266
On the Mac, you will see a

1475
00:49:35,266 --> 00:49:36,216
source and destination

1476
00:49:36,216 --> 00:49:37,766
representing your iOS device.

1477
00:49:38,436 --> 00:49:40,806
Now, this will require iOS 11,

1478
00:49:40,806 --> 00:49:42,706
but you can do it as far back as

1479
00:49:42,706 --> 00:49:44,466
MacOS El Capitan or later,

1480
00:49:44,506 --> 00:49:45,616
because it's a class-compliant

1481
00:49:45,616 --> 00:49:46,316
implementation.

1482
00:49:46,846 --> 00:49:47,546
And you don't have to do

1483
00:49:47,546 --> 00:49:48,746
anything special to get MIDI.

1484
00:49:48,746 --> 00:49:49,446
You're going to get it

1485
00:49:49,446 --> 00:49:51,106
automatically anytime you enter

1486
00:49:51,106 --> 00:49:52,286
the item configuration by

1487
00:49:52,286 --> 00:49:53,036
clicking Enable.

1488
00:49:53,036 --> 00:49:54,466
Do you need to do anything to

1489
00:49:54,466 --> 00:49:55,986
your app to support that?

1490
00:49:55,986 --> 00:49:57,256
No. It will just work if it

1491
00:49:57,256 --> 00:49:58,076
works with MIDI.

1492
00:49:59,006 --> 00:50:00,376
So, while you're in the IDAM

1493
00:50:00,376 --> 00:50:01,786
configuration, your device will

1494
00:50:01,786 --> 00:50:03,526
be able to charge and sync, but

1495
00:50:03,526 --> 00:50:04,916
you will temporarily lose the

1496
00:50:04,916 --> 00:50:06,536
ability to photo import and

1497
00:50:06,536 --> 00:50:06,836
tether.

1498
00:50:07,076 --> 00:50:07,986
You can get that back by

1499
00:50:07,986 --> 00:50:09,276
clicking the Disable button or

1500
00:50:09,276 --> 00:50:12,006
hot plugging the device on your

1501
00:50:12,006 --> 00:50:12,356
Mac.

1502
00:50:12,356 --> 00:50:13,796
The input, the audio input, side

1503
00:50:13,796 --> 00:50:15,066
of this can be aggregated, so if

1504
00:50:15,066 --> 00:50:16,616
you've got multiple iOS devices,

1505
00:50:16,616 --> 00:50:18,776
like I do, say, your iPhone and

1506
00:50:18,776 --> 00:50:20,286
your iPad and your kid's iPad,

1507
00:50:20,606 --> 00:50:22,946
you could say enable IDAM

1508
00:50:22,946 --> 00:50:23,966
configuration on all three of

1509
00:50:23,966 --> 00:50:25,256
these and aggregate them into a

1510
00:50:25,256 --> 00:50:27,156
single, six-channel audio input

1511
00:50:27,156 --> 00:50:28,386
device that your digital audio

1512
00:50:28,386 --> 00:50:28,976
workstation can see.

1513
00:50:29,106 --> 00:50:30,996
And because the MIDI

1514
00:50:30,996 --> 00:50:32,336
communication is bidirectional,

1515
00:50:32,626 --> 00:50:34,636
you can use it as -- you could

1516
00:50:34,636 --> 00:50:37,636
say for example, "Send MIDI to a

1517
00:50:37,636 --> 00:50:39,796
synthesizer application," and

1518
00:50:39,796 --> 00:50:41,136
record the audio back from it.

1519
00:50:41,456 --> 00:50:43,056
Or you could just design a MIDI

1520
00:50:43,056 --> 00:50:44,476
controller application for an

1521
00:50:44,476 --> 00:50:45,626
iPad, that magical piece of

1522
00:50:45,626 --> 00:50:47,176
glass, and you could use that to

1523
00:50:47,176 --> 00:50:47,926
control your [inaudible].

1524
00:50:48,396 --> 00:50:50,106
But talk is cheap, and demos pay

1525
00:50:50,106 --> 00:50:50,566
the bills.

1526
00:50:50,856 --> 00:50:53,906
So, let's see this in action.

1527
00:50:54,496 --> 00:50:56,186
So, before I actually bring up

1528
00:50:56,186 --> 00:50:57,816
my demo machine here, I want to

1529
00:50:57,816 --> 00:51:00,006
show you the application that

1530
00:51:00,006 --> 00:51:00,946
I'm going to use here.

1531
00:51:02,306 --> 00:51:04,576
And it is called Feud Machine.

1532
00:51:05,066 --> 00:51:07,296
So, I've got Feud Machine open

1533
00:51:07,296 --> 00:51:07,516
here.

1534
00:51:07,626 --> 00:51:10,156
And on Feud Machine, this is a

1535
00:51:10,156 --> 00:51:12,026
multi-playhead MIDI sequencer.

1536
00:51:12,376 --> 00:51:13,416
So, that means that you can

1537
00:51:13,416 --> 00:51:15,726
actually use one MIDI sequence

1538
00:51:15,766 --> 00:51:17,216
and use different playheads,

1539
00:51:17,506 --> 00:51:18,596
perhaps moving at different

1540
00:51:18,596 --> 00:51:20,646
times, in different directions,

1541
00:51:21,046 --> 00:51:23,136
and use that to create a complex

1542
00:51:23,266 --> 00:51:26,026
arpeggio using phasing and a

1543
00:51:26,026 --> 00:51:26,886
timing relationship.

1544
00:51:27,286 --> 00:51:28,886
So, I'm just going to play this

1545
00:51:28,886 --> 00:51:29,506
pattern here.

1546
00:51:29,606 --> 00:51:31,516
And there are a lot of

1547
00:51:31,516 --> 00:51:33,816
playheads.

1548
00:51:33,816 --> 00:51:36,026
I'll just stop some of them.

1549
00:51:36,026 --> 00:51:40,206
So, this is just one.

1550
00:51:40,206 --> 00:51:43,126
I'll add another.

1551
00:51:43,126 --> 00:51:44,666
Add another.

1552
00:51:44,666 --> 00:51:45,096
Add another.

1553
00:51:45,366 --> 00:51:46,366
As you see, we can create

1554
00:51:46,366 --> 00:51:48,086
arpeggios very easily this way.

1555
00:51:48,646 --> 00:51:49,556
So, there are other patterns

1556
00:51:49,556 --> 00:51:50,456
that I could use.

1557
00:51:50,646 --> 00:51:52,186
For example, this one's called

1558
00:51:52,186 --> 00:51:52,436
"Dotted".

1559
00:51:52,436 --> 00:51:56,206
This one's "Triplet."

1560
00:51:56,206 --> 00:51:59,156
But we'll still with this one,

1561
00:51:59,156 --> 00:52:00,666
and we're going to use this

1562
00:52:00,776 --> 00:52:02,756
actually to control a project

1563
00:52:02,756 --> 00:52:04,016
that we're working on in Logic.

1564
00:52:04,366 --> 00:52:05,356
So, now, I'll move over to my

1565
00:52:05,356 --> 00:52:06,056
demo machine.

1566
00:52:06,786 --> 00:52:08,036
I'm going to click Enable here.

1567
00:52:08,856 --> 00:52:11,136
And I'll see it come up as a USB

1568
00:52:11,136 --> 00:52:12,386
audio input, and if I look at

1569
00:52:12,386 --> 00:52:14,186
the MIDI studio window, I'll

1570
00:52:14,186 --> 00:52:16,116
also see that it shows up here

1571
00:52:16,116 --> 00:52:17,556
as a MIDI source and destination

1572
00:52:17,556 --> 00:52:18,516
that I can use in Logic.

1573
00:52:18,946 --> 00:52:20,136
So, if I launch a project that

1574
00:52:20,136 --> 00:52:21,846
I've been working on here -- now

1575
00:52:26,156 --> 00:52:28,016
this is a short, four-bar loop

1576
00:52:28,016 --> 00:52:29,436
that I'm working on for a gaming

1577
00:52:29,436 --> 00:52:30,246
scoring screen.

1578
00:52:30,246 --> 00:52:32,706
So, after this video game level

1579
00:52:32,706 --> 00:52:34,386
is completed, the player can

1580
00:52:34,386 --> 00:52:35,576
look at their results and they

1581
00:52:35,576 --> 00:52:36,626
will be listening to this loop.

1582
00:52:37,296 --> 00:52:39,496
And the loop right now, before

1583
00:52:39,496 --> 00:52:40,426
I've added anything to it,

1584
00:52:40,426 --> 00:52:40,976
sounds like this.

1585
00:52:41,516 --> 00:52:51,546
[ Music ]

1586
00:52:52,046 --> 00:52:54,316
Now, I want to add the arpeggio

1587
00:52:54,316 --> 00:52:55,286
part over this.

1588
00:52:55,596 --> 00:52:56,566
So, what I'm going to do is I'm

1589
00:52:56,566 --> 00:52:57,526
just going to double-click here

1590
00:52:57,526 --> 00:52:58,466
to add another track.

1591
00:52:58,466 --> 00:53:00,796
I'm going to choose an arpeggio,

1592
00:53:01,686 --> 00:53:03,296
maybe something like a square.

1593
00:53:06,356 --> 00:53:07,126
There we go.

1594
00:53:07,526 --> 00:53:09,236
I'll do percussive squares here.

1595
00:53:09,316 --> 00:53:10,456
And in the channel strip, you

1596
00:53:10,456 --> 00:53:11,696
can actually see an arpeggiator.

1597
00:53:11,696 --> 00:53:12,646
I'm not going to need that

1598
00:53:12,646 --> 00:53:13,676
because I'm going to play this

1599
00:53:13,676 --> 00:53:14,466
with Feud Machine.

1600
00:53:14,936 --> 00:53:17,596
So, if I record enable this, and

1601
00:53:17,596 --> 00:53:20,276
I arm my sequence here, I'll be

1602
00:53:20,276 --> 00:53:23,096
able to hear Feud Machine play

1603
00:53:23,206 --> 00:53:25,296
the soft synth here in Logic.

1604
00:53:26,026 --> 00:53:29,856
So, I'll solo that.

1605
00:53:29,976 --> 00:53:31,516
This is all four playheads

1606
00:53:31,516 --> 00:53:33,016
moving at the same time.

1607
00:53:33,016 --> 00:53:34,136
I could turn them off.

1608
00:53:34,196 --> 00:53:35,616
I could just have one playhead

1609
00:53:35,616 --> 00:53:37,526
if I wanted to.

1610
00:53:37,606 --> 00:53:39,156
Or as many as all four.

1611
00:53:39,156 --> 00:53:40,636
So, I'm going to record this

1612
00:53:40,636 --> 00:53:42,676
into my track, and we'll see

1613
00:53:42,676 --> 00:53:44,276
what that sounds like in

1614
00:53:44,276 --> 00:53:45,056
context.

1615
00:53:45,596 --> 00:53:52,796
Oops, sorry about that.

1616
00:53:52,796 --> 00:53:55,946
I have to record arm here and

1617
00:53:56,636 --> 00:53:56,866
play.

1618
00:53:57,516 --> 00:54:06,546
[ Music ]

1619
00:54:07,046 --> 00:54:11,286
Okay, so I've recorded my

1620
00:54:11,286 --> 00:54:14,266
automation here, and I can use

1621
00:54:14,266 --> 00:54:15,846
this automation and I can

1622
00:54:16,006 --> 00:54:19,246
playback from the iPad here.

1623
00:54:19,246 --> 00:54:20,096
So, if I listen to this in

1624
00:54:20,096 --> 00:54:21,336
context, it sounds like this.

1625
00:54:21,406 --> 00:54:26,466
So, now I've got MIDI going -- a

1626
00:54:26,466 --> 00:54:28,136
MIDI start command going to Feud

1627
00:54:28,136 --> 00:54:28,576
Machine.

1628
00:54:28,576 --> 00:54:30,136
Feud Machine's playing our soft

1629
00:54:30,136 --> 00:54:30,926
synth here.

1630
00:54:30,996 --> 00:54:32,506
And I've got some automation

1631
00:54:32,506 --> 00:54:34,446
here for the recording.

1632
00:54:34,446 --> 00:54:37,116
And that concludes my demo for

1633
00:54:37,116 --> 00:54:39,546
MIDI over IDAM configuration.

1634
00:54:40,666 --> 00:54:41,886
Let's head back to the slides.

1635
00:54:42,516 --> 00:54:46,216
[ Applause ]

1636
00:54:46,716 --> 00:54:47,736
Okay, we've talked about a lot

1637
00:54:47,736 --> 00:54:48,356
of things today.

1638
00:54:48,356 --> 00:54:49,806
We've talked about enhancements

1639
00:54:49,806 --> 00:54:51,046
to AVAudio Engine, including

1640
00:54:51,046 --> 00:54:52,226
Manual Rendering which you can

1641
00:54:52,226 --> 00:54:53,706
now do offline, or you can do

1642
00:54:53,706 --> 00:54:54,246
real-time.

1643
00:54:54,726 --> 00:54:55,866
There's AirPlay 2 support.

1644
00:54:55,866 --> 00:54:57,096
There'll be an entirely other

1645
00:54:57,096 --> 00:54:58,876
session on AirPlay 2 down the

1646
00:54:58,876 --> 00:55:00,226
road in the conference.

1647
00:55:00,226 --> 00:55:01,306
Please make sure to check that

1648
00:55:01,306 --> 00:55:02,176
out if you're interested.

1649
00:55:02,376 --> 00:55:04,506
Watch OS 4, you can now record.

1650
00:55:04,506 --> 00:55:05,236
We've talked about the

1651
00:55:05,236 --> 00:55:07,036
capabilities and the limitations

1652
00:55:07,036 --> 00:55:08,506
and policies regarding that.

1653
00:55:08,506 --> 00:55:09,956
For AUAudio Units, you can now

1654
00:55:09,956 --> 00:55:10,786
negotiate your view

1655
00:55:10,786 --> 00:55:12,076
configurations and you can also

1656
00:55:12,076 --> 00:55:13,576
synchronize your MIDI output

1657
00:55:13,576 --> 00:55:15,186
with your audio output for your

1658
00:55:15,186 --> 00:55:15,253
AU.

1659
00:55:15,253 --> 00:55:16,396
We've talked about some other

1660
00:55:16,396 --> 00:55:18,996
audio enhancements including new

1661
00:55:18,996 --> 00:55:20,906
supported formats, ambisonics,

1662
00:55:20,906 --> 00:55:22,496
head related transfer functions,

1663
00:55:22,826 --> 00:55:24,136
and we wrapped up with talking

1664
00:55:24,136 --> 00:55:25,816
about IDAM, which now stands for

1665
00:55:25,816 --> 00:55:27,176
Inter Device Audio and MIDI.

1666
00:55:27,746 --> 00:55:29,536
The central URL for information

1667
00:55:29,536 --> 00:55:31,646
regarding this particular talk

1668
00:55:31,646 --> 00:55:32,146
is here.

1669
00:55:32,726 --> 00:55:34,696
And if you're interested in

1670
00:55:34,696 --> 00:55:37,206
audio, you may also be

1671
00:55:37,206 --> 00:55:40,006
interested in these related

1672
00:55:40,006 --> 00:55:41,586
sessions later on in the week.

1673
00:55:42,116 --> 00:55:44,636
We thank you very much for your

1674
00:55:44,636 --> 00:55:45,806
time and attention, and have a

1675
00:55:45,806 --> 00:55:46,976
fantastic conference.

1676
00:55:47,516 --> 00:55:51,500
[ Applause ]

