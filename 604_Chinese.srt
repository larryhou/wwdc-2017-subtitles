1
00:00:27,628 --> 00:00:28,962
大家早上好

2
00:00:29,029 --> 00:00:31,865
欢迎参加SceneKit新特性演讲

3
00:00:32,966 --> 00:00:36,904
你们已经知道了
SceneKit是Apple的高层级3D API

4
00:00:36,970 --> 00:00:41,341
它是在Metal之上创建的
并且在我们的全部平台上均可用

5
00:00:42,309 --> 00:00:46,280
这场演讲将会谈谈
我们在SceneKit中添加的新特性

6
00:00:46,647 --> 00:00:48,682
我们今天不讲基础知识

7
00:00:48,749 --> 00:00:50,851
所以若你刚接触SceneKit
我鼓励你看一下

8
00:00:50,918 --> 00:00:53,654
前几年相关的演讲

9
00:00:55,255 --> 00:00:56,990
这是我们今天的大纲

10
00:00:57,858 --> 00:01:01,495
我首先要讲一些相机改进

11
00:01:02,196 --> 00:01:04,397
包括一些新的相机效果

12
00:01:04,464 --> 00:01:07,634
和一些新的API以简化相机控制

13
00:01:08,602 --> 00:01:12,406
然后Amaury将上台讲一下细化和细分

14
00:01:12,706 --> 00:01:16,176
以及关于动画的一些改进和新增API

15
00:01:17,277 --> 00:01:20,414
最后我们会介绍一些新开发者工具

16
00:01:20,480 --> 00:01:24,785
并谈一些相关技术 包括ARKit

17
00:01:26,053 --> 00:01:30,057
现在让我们开始吧
我想先给你们看一个小演示

18
00:01:30,123 --> 00:01:34,695
阐明我稍后要在本场演讲中
详细介绍的新API

19
00:01:40,801 --> 00:01:45,072
这是一个简单的游戏示例
有一个我可以操控的角色

20
00:01:45,138 --> 00:01:46,640
通过虚拟方向键

21
00:01:46,840 --> 00:01:48,976
我可以攻击、跳跃

22
00:01:49,476 --> 00:01:51,812
我们用的是相机和虚拟方向键

23
00:01:53,113 --> 00:01:55,415
在演示中我想要强调的第一点就是

24
00:01:55,749 --> 00:01:57,551
相机的行为

25
00:01:58,018 --> 00:02:01,555
正如你所看到的
相机紧跟着这个角色 很平稳

26
00:02:02,589 --> 00:02:05,492
说到平稳 我是指它没有完全地重现

27
00:02:05,559 --> 00:02:07,261
角色的移动

28
00:02:07,327 --> 00:02:12,199
而是尝试与角色保持恒定的距离和高度

29
00:02:12,499 --> 00:02:16,170
但总是以平稳的加速度和减速度移动

30
00:02:17,104 --> 00:02:20,240
你将看到相机的行为将会适应

31
00:02:20,307 --> 00:02:22,476
根据游戏的不同分区

32
00:02:22,943 --> 00:02:26,580
比如当我接近这个战争区时

33
00:02:27,214 --> 00:02:30,450
相机就向下移动一点儿
并调整了景深

34
00:02:30,517 --> 00:02:33,053
以聚焦于角色和敌人

35
00:02:34,388 --> 00:02:37,858
提到敌人 我们在这里有两名敌人
都有最基本的行为

36
00:02:38,425 --> 00:02:40,994
一个是追我 而另一个是逃跑

37
00:02:41,061 --> 00:02:44,531
我会简单介绍一下如何通过
GameplayKit来实现这种行为

38
00:02:45,132 --> 00:02:46,700
现在让我们杀死他们

39
00:02:49,336 --> 00:02:50,270
还有另一个

40
00:02:52,706 --> 00:02:54,074
然后收集这里的宝石

41
00:02:55,742 --> 00:02:58,979
在这里 相机平稳地
过渡到了一个电影视角

42
00:02:59,479 --> 00:03:01,682
有很强烈的景深效果
非常[听不清]钥匙

43
00:03:01,748 --> 00:03:04,551
并且你还可以注意到背景中
有一些很漂亮的散景

44
00:03:05,219 --> 00:03:06,520
让我们收集那个钥匙

45
00:03:08,288 --> 00:03:10,357
当我[听不清]到这个新区域时

46
00:03:10,424 --> 00:03:12,826
我必须很谨慎地在平台上跳跃

47
00:03:13,060 --> 00:03:16,230
相机平稳地过渡到了一个新行为

48
00:03:16,296 --> 00:03:20,234
现在它停止旋转了 并对准平台

49
00:03:21,034 --> 00:03:25,472
以简化我在平台上的跳跃
那么让我们跳一下

50
00:03:26,874 --> 00:03:28,008
这是很刻意的

51
00:03:29,910 --> 00:03:31,378
让我们收集钥匙

52
00:03:32,913 --> 00:03:36,483
又是一个新区域 相机将自动适应自己

53
00:03:36,550 --> 00:03:38,685
并对准平台

54
00:03:45,058 --> 00:03:47,261
看起来那里有一些需要释放的朋友

55
00:03:47,327 --> 00:03:49,029
而我有钥匙 让我们释放他们

56
00:03:52,099 --> 00:03:58,238
最后是一个新的电影视角
有许多角色跑来跑去

57
00:03:58,505 --> 00:04:02,776
在这里我们要给
3200个机器人制作动画

58
00:04:02,843 --> 00:04:05,179
而我们在半毫秒内就能实现

59
00:04:05,245 --> 00:04:06,680
在这个新iPad Pro上

60
00:04:06,914 --> 00:04:08,682
速度非常快 我们主要关注

61
00:04:08,749 --> 00:04:11,418
角色动画性能 在这次发布中

62
00:04:11,485 --> 00:04:15,822
通过新API实施这些变得更加简单了

63
00:04:15,989 --> 00:04:18,291
通过我稍后要讲到的新动画API

64
00:04:19,192 --> 00:04:20,394
那么这就是这个演示

65
00:04:27,267 --> 00:04:30,637
一如既往 我们真的很高兴
与你们分享这个演示

66
00:04:30,704 --> 00:04:32,072
作为一段示例代码

67
00:04:32,739 --> 00:04:36,310
并且是运行在iOS、tvOS
和macOS上的示例代码

68
00:04:36,376 --> 00:04:39,313
并在Swift和
Objective-C中可用

69
00:04:41,782 --> 00:04:44,818
在演示中 我强调了相机行为

70
00:04:44,885 --> 00:04:48,188
因为这是非常非常难写的部分

71
00:04:48,622 --> 00:04:50,390
我们在开发者论坛上看到了
很多这方面的问题

72
00:04:50,457 --> 00:04:53,060
和相关请求

73
00:04:53,227 --> 00:04:56,730
所以我们在本次发布中
改进了我们的相机API

74
00:04:57,598 --> 00:05:01,668
以简化这个问题并提高产品质量

75
00:05:03,203 --> 00:05:09,009
为此 我们过渡到了一个
基于物理原理的相机API

76
00:05:09,076 --> 00:05:13,113
并且利用这个新API来实施
从物理角度来说貌似合理的景深

77
00:05:13,447 --> 00:05:16,083
我们还改善了运动模糊并添加了内置的

78
00:05:16,149 --> 00:05:17,818
屏幕空间环境光遮蔽支持

79
00:05:18,418 --> 00:05:22,122
然后我接下来要谈新API
关于我是如何

80
00:05:22,189 --> 00:05:24,324
简化相机控制的

81
00:05:25,626 --> 00:05:29,496
那么过渡到基于物理原理的API
相机API

82
00:05:30,230 --> 00:05:33,667
首先我们不再支持旧系统上的投影模型

83
00:05:34,334 --> 00:05:37,304
那么我们将 当然了
确保[听不清]兼容性

84
00:05:37,371 --> 00:05:41,575
但意识到我们正在远离x4和y4属性

85
00:05:41,642 --> 00:05:44,845
而采用一些更匹配真实相机的东西

86
00:05:45,078 --> 00:05:49,183
比如 如果你想配置你的透视投影
你现在可以

87
00:05:49,249 --> 00:05:51,785
设置fieldOfView属性

88
00:05:51,852 --> 00:05:54,454
或配置focalLength和sensorHeight

89
00:05:55,088 --> 00:05:57,991
这些属性是连接在一起的
所以如果你配置了focalLength

90
00:05:58,058 --> 00:06:00,561
比如说它将会相应地更新fieldOfView

91
00:06:00,627 --> 00:06:01,595
反过来也一样

92
00:06:03,063 --> 00:06:07,334
然后SceneKit会给一个
真实的相机景深建模

93
00:06:07,668 --> 00:06:09,136
为了实现景深

94
00:06:09,203 --> 00:06:13,006
将wantsDepthOfField属性设为真
然后进行配置

95
00:06:13,073 --> 00:06:16,176
通过设置focusDistance和fStop属性

96
00:06:17,244 --> 00:06:20,480
SceneKit将粗略估计
真实的相机景深

97
00:06:20,547 --> 00:06:24,918
并模糊场景 通过与这些摄影界的参数

98
00:06:24,985 --> 00:06:27,020
保持一致的方式

99
00:06:28,755 --> 00:06:32,826
所以新景深也会模拟

100
00:06:32,893 --> 00:06:34,194
你通过真实相机获得的散景

101
00:06:35,262 --> 00:06:39,566
散景出现在明亮的对象上 模糊不清

102
00:06:39,633 --> 00:06:44,438
因为它们是由像素生成的 强度很高

103
00:06:44,505 --> 00:06:48,375
如果你通过HDR相机渲染场景
那么这个功能会非常好用

104
00:06:48,509 --> 00:06:51,011
要配置这个
只需要将wantsHDR属性

105
00:06:51,078 --> 00:06:52,779
在SCNcamera上设为真即可

106
00:06:54,548 --> 00:06:58,685
然后散景的形状
取决于光圈的叶片数量

107
00:06:58,919 --> 00:07:01,889
并且你还可以在
SCNcamera上配置它

108
00:07:02,222 --> 00:07:05,492
这里有一些关于
这个属性的不同的值的例子

109
00:07:08,729 --> 00:07:11,999
那么我们在本次发布中
改善了我们的运动模糊

110
00:07:12,065 --> 00:07:15,636
我们去年已经发布了
运动模糊的第一次报告

111
00:07:15,702 --> 00:07:19,907
即可以根据相机运动模糊场景

112
00:07:19,973 --> 00:07:22,776
意思就是如果你的相机
在场景中快速移动

113
00:07:22,843 --> 00:07:25,913
你将会获得运动模糊
但如果你的相机保持静止

114
00:07:25,979 --> 00:07:29,082
而对象动来动去
你将不会获得任何运动模糊

115
00:07:29,449 --> 00:07:33,987
那么在本次发布中
我们添加了对象运动模糊支持

116
00:07:34,054 --> 00:07:39,293
当你在相机上启动运动模糊时
你将自动获得对象模糊

117
00:07:41,395 --> 00:07:45,199
SCNcamera现在提供的另一种
效果是环境光遮蔽

118
00:07:46,867 --> 00:07:49,369
环境光遮蔽的原理很简单

119
00:07:50,237 --> 00:07:53,273
平面上的一个

120
00:07:53,340 --> 00:07:56,543
点能接收全部环境光

121
00:07:57,144 --> 00:08:01,048
而洞中的点却只能接收一部分环境光

122
00:08:01,114 --> 00:08:04,551
因为有些环境光被表面挡住了

123
00:08:05,953 --> 00:08:08,689
SceneKit支持
屏幕空间环境光遮蔽

124
00:08:08,755 --> 00:08:11,091
意思是这个遮蔽因素

125
00:08:11,158 --> 00:08:14,328
将在屏幕空间中的每一个像素上计算

126
00:08:15,629 --> 00:08:18,765
这是通过分析深度缓存
和正常缓存实现的

127
00:08:18,832 --> 00:08:22,503
SceneKit将决定
点是否存在于洞中

128
00:08:22,569 --> 00:08:26,106
通过与临近的正常碎片比较其深度实现

129
00:08:27,407 --> 00:08:31,712
那么这是一个
没有环境光遮蔽的一个对象

130
00:08:31,778 --> 00:08:35,414
而这里有很强的环境光遮蔽
以实现幻灯片上所使用的效果

131
00:08:37,650 --> 00:08:39,820
要启动屏幕空间环境光遮蔽

132
00:08:40,254 --> 00:08:42,856
只需要将screenSpaceAmbient
OcclusionIntensity

133
00:08:42,923 --> 00:08:44,825
的值设置为大于零即可

134
00:08:45,325 --> 00:08:48,729
然后你有一些参数 你可以进行调整

135
00:08:48,795 --> 00:08:51,632
根据你想要实现的效果以及场景的尺寸

136
00:08:51,698 --> 00:08:53,267
和拓扑

137
00:08:53,333 --> 00:08:56,136
让我们在演示中实际看一下这些效果

138
00:08:56,203 --> 00:08:58,338
关于这个 让我们欢迎Anatole上台

139
00:09:01,508 --> 00:09:02,342
谢谢Thomas

140
00:09:03,644 --> 00:09:04,778
大家早上好

141
00:09:07,214 --> 00:09:11,518
那么让我们回到第一个演示中
并打开一些调试UI帮助我

142
00:09:11,585 --> 00:09:13,453
给你们展示新的景深效果

143
00:09:15,222 --> 00:09:17,191
这里我们有…抱歉

144
00:09:19,126 --> 00:09:22,062
在这里在前景中
我们有一个很漂亮的金钥匙

145
00:09:22,129 --> 00:09:24,665
焦距被设为短距离

146
00:09:24,731 --> 00:09:26,700
因为钥匙离相机很近

147
00:09:27,568 --> 00:09:29,937
效果数量也被设为了一个小值

148
00:09:30,003 --> 00:09:31,772
因为我们想要一个很强烈的模糊

149
00:09:32,272 --> 00:09:34,808
正如你所看到的
在背景中出现了一个很漂亮的散景

150
00:09:34,875 --> 00:09:37,110
由于微粒的照明度

151
00:09:39,246 --> 00:09:42,716
现在通过第二个相机
我现在有一个远焦距

152
00:09:43,317 --> 00:09:46,153
那么背景中的对象很鲜明

153
00:09:46,220 --> 00:09:48,589
前景中的花很模糊

154
00:09:50,357 --> 00:09:53,360
另一种视角 在这里我可以 比如说

155
00:09:53,427 --> 00:09:56,530
玩一下FStop的值
获取更多或更少的模糊

156
00:09:57,865 --> 00:09:59,299
就像一台真实的相机一样

157
00:10:00,834 --> 00:10:02,469
然后通过第二个滑块

158
00:10:02,536 --> 00:10:05,138
我们定义了要在场景中的哪里聚焦

159
00:10:07,407 --> 00:10:11,111
那么这个新的景深效果非常有用
比如说

160
00:10:11,178 --> 00:10:13,614
在视频游戏中创建电影效果

161
00:10:15,115 --> 00:10:19,019
现在让我们打开另一个应用
给你们展示一下新的对象运动模糊

162
00:10:20,654 --> 00:10:23,090
在这里我们有一个场景
是木格箱堆起来的塔

163
00:10:23,390 --> 00:10:26,894
如果我点击射击按钮
我会向那座塔丢小球

164
00:10:29,530 --> 00:10:32,766
这是默认没有任何运动模糊时的样子

165
00:10:33,634 --> 00:10:36,036
现在我重设场景 启动运动模糊

166
00:10:36,103 --> 00:10:37,804
然后用小球扔那座塔

167
00:10:41,175 --> 00:10:43,310
你可以看到运动模糊的效果

168
00:10:43,377 --> 00:10:45,712
是那些小球的运动模糊
因为它们的移动速度很快

169
00:10:46,313 --> 00:10:50,517
你还可以看到当塔爆炸时
应用在木格箱上的效果

170
00:10:51,318 --> 00:10:52,953
但现在让我们近距离地看一下

171
00:10:53,487 --> 00:10:56,857
我可以冻结场景 稍微离近一点儿

172
00:10:57,925 --> 00:11:00,494
我们的大脑把这种模糊阐述为移动

173
00:11:00,661 --> 00:11:04,631
你甚至可以在静态图像中
看到这些对象的运动

174
00:11:05,732 --> 00:11:07,334
我们甚至可以修改视角

175
00:11:07,401 --> 00:11:10,537
我们仍然对每个对象的方向
把握得很好

176
00:11:12,272 --> 00:11:15,809
所以这真的改善了场景中的运动感知

177
00:11:15,876 --> 00:11:18,145
结果看起来更贴近现实了

178
00:11:19,479 --> 00:11:22,516
现在让我们看一下
屏幕空间[听不清]演示

179
00:11:24,017 --> 00:11:28,155
你可以看到一些小球被天空照亮
也能看到光的方向

180
00:11:29,456 --> 00:11:33,227
通过第一个滑块
我可以向场景中添加一些环境光遮蔽

181
00:11:33,861 --> 00:11:36,196
你可以看到 添加了一些环境光阴影

182
00:11:36,263 --> 00:11:39,733
并且我可以修改强度
增加或减少小球的阴影

183
00:11:41,435 --> 00:11:45,005
遮蔽的面积取决于表面的曲率

184
00:11:45,706 --> 00:11:50,344
要了解像素是否处于洞中
我们要检查与之相邻的像素

185
00:11:50,811 --> 00:11:53,146
所以我们有这个半径参数

186
00:11:53,213 --> 00:11:56,517
可以让我们定义
要查找多少距离之内的临近像素

187
00:11:57,484 --> 00:12:01,688
结果是小半径 环境光遮蔽更尖锐

188
00:12:02,089 --> 00:12:04,725
大半径 获得的多面体阴影最多

189
00:12:06,660 --> 00:12:09,396
这是实时计算的 所以这很好用

190
00:12:09,463 --> 00:12:13,400
如果你正在处理动态对象
当[听不清]环境光遮蔽映射[听不清]

191
00:12:15,235 --> 00:12:19,006
那添加了深处 抱歉是深度的感知细节

192
00:12:19,072 --> 00:12:21,975
并把全局光照的效果带到了你的场景中

193
00:12:23,310 --> 00:12:24,344
这就是这个演示

194
00:12:24,411 --> 00:12:27,281
让我们返回到幻灯片中
我要把舞台交还给Thomas

195
00:12:29,917 --> 00:12:34,021
（演示）

196
00:12:34,221 --> 00:12:35,322
谢谢Anatole

197
00:12:35,622 --> 00:12:38,091
那么我们讲了一些新相机效果

198
00:12:38,225 --> 00:12:40,661
现在让我们谈谈相机控制

199
00:12:41,061 --> 00:12:43,096
我之前的确说过 这是个很困难的难题

200
00:12:43,163 --> 00:12:45,032
且我们也看到了与它相关的许多问题

201
00:12:45,098 --> 00:12:47,901
我们认定了两个主要用例

202
00:12:48,502 --> 00:12:52,172
人们可能会想检验一个3D对象

203
00:12:52,239 --> 00:12:55,642
通过旋转3D对象或围绕3D对象旋转

204
00:12:55,742 --> 00:13:01,415
比如正在创建一个
简单3D观察器的开发者

205
00:13:01,481 --> 00:13:06,220
或需要一些更复杂的
相机行为的编辑和开发者

206
00:13:06,286 --> 00:13:08,989
比如一个游戏或更高级的应用

207
00:13:09,690 --> 00:13:11,859
让我们先从第一个用例开始看

208
00:13:12,793 --> 00:13:16,663
直到现在 如果你想操纵一个3D对象

209
00:13:16,830 --> 00:13:19,933
你必须实施你自己的事件管理

210
00:13:20,200 --> 00:13:22,703
并移动相机位置和方向

211
00:13:22,769 --> 00:13:24,905
根据手势或鼠标事件

212
00:13:25,806 --> 00:13:30,677
为了方便 我们在SCNView上
提供了一个allowCameraControl

213
00:13:31,144 --> 00:13:34,781
但这些只能为你提供
一个默认的相机行为

214
00:13:34,848 --> 00:13:36,783
是不可配置的

215
00:13:36,850 --> 00:13:39,620
这其实是用于调试的

216
00:13:41,188 --> 00:13:45,993
在这次新发布中 我们引入了一个新类
叫作SCNCameraController

217
00:13:46,527 --> 00:13:50,597
SCNCameraController允许你操纵相机

218
00:13:50,664 --> 00:13:54,368
获得你在3D软件中
所能看到的最常用的相机行为

219
00:13:55,802 --> 00:13:58,739
那么这些行为被内嵌到相机控制器中

220
00:13:58,805 --> 00:14:02,276
并且SCNView有一个
内嵌默认相机控制器

221
00:14:02,342 --> 00:14:05,979
你可以根据你应用的需要直接配置

222
00:14:06,947 --> 00:14:08,982
现在如果你需要更具体的行为

223
00:14:09,049 --> 00:14:12,186
你仍可以实例化
你自己的SCNCameraController

224
00:14:12,252 --> 00:14:14,288
并且只要你想
你就可以通过编程驱动它

225
00:14:15,856 --> 00:14:18,859
SCNCameraController
提供立即可用的

226
00:14:18,926 --> 00:14:21,795
绝大部分常用相机操作工具

227
00:14:22,229 --> 00:14:27,100
举例来说 轨道转盘允许你

228
00:14:27,167 --> 00:14:31,438
让你的相机绕着3D对象转
并防止摇晃

229
00:14:31,505 --> 00:14:35,175
意思是地平线总是保持水平

230
00:14:35,242 --> 00:14:37,644
无论你正在实施哪种旋转

231
00:14:39,046 --> 00:14:44,651
轨道轨迹球会让相机通过屏幕
空间中的横轴和竖轴绕着转

232
00:14:44,718 --> 00:14:48,856
所以这种模式在某些情况下更直观

233
00:14:48,922 --> 00:14:53,527
但它不能防止摇晃
所以它真的取决于你应用的需求

234
00:14:55,262 --> 00:14:57,197
另一个是飞行模式

235
00:14:57,264 --> 00:15:01,335
更适用于成圈的场景
你可能想获得一个圈场景

236
00:15:02,035 --> 00:15:06,473
在那种情况下
相机的旋转中心就是相机自己

237
00:15:06,540 --> 00:15:09,276
意思就是你旋转相机

238
00:15:09,343 --> 00:15:13,013
在一个位置查看四周以围着对象转

239
00:15:15,415 --> 00:15:18,418
我们再次相信场景相机控制器会提供

240
00:15:18,952 --> 00:15:21,588
绝大部分常用相机操作工具

241
00:15:21,655 --> 00:15:23,991
如果你需要很具体的效果
没有什么能阻拦你

242
00:15:24,057 --> 00:15:27,728
你仍然可以尝试以编程方式
使用你的相机控制器和相机

243
00:15:28,829 --> 00:15:30,697
现在让我们来看看程序的第二个类

244
00:15:31,431 --> 00:15:35,135
显影 我们需要一个更复杂的相机行为
比如游戏

245
00:15:35,736 --> 00:15:39,239
我们通过链接约束

246
00:15:39,306 --> 00:15:41,308
以定义相机行为来解决这个问题

247
00:15:43,310 --> 00:15:47,948
SceneKit已经提供了
许多内嵌约束

248
00:15:48,015 --> 00:15:50,584
我们今年又增加了一些新约束

249
00:15:50,651 --> 00:15:55,322
可以应用到任意节点中
但尤其适用于相机

250
00:15:56,356 --> 00:16:01,562
让我们来阐述其中一些约束
SCNDistanceConstraint强制节点

251
00:16:01,628 --> 00:16:06,700
与另一个指定目标节点
保持最小和最大距离

252
00:16:08,101 --> 00:16:11,638
要复制我们的约束
我们需要复制节点位置

253
00:16:11,705 --> 00:16:15,075
和方向 通过一个可选的偏移

254
00:16:16,610 --> 00:16:20,347
而加速度约束
会确保节点的移动或加速不会

255
00:16:20,414 --> 00:16:25,085
比最大指定速度和加速度更快

256
00:16:26,119 --> 00:16:29,423
那么这些只是一些例子
让我们看看可以用这些约束做什么

257
00:16:30,724 --> 00:16:34,094
那么在这里我们有一个角色
正在场景中移动

258
00:16:34,161 --> 00:16:37,164
相机目前没有约束 因此他是静态的

259
00:16:38,465 --> 00:16:41,902
如果我给相机添加一个看约束
并将角色

260
00:16:41,969 --> 00:16:43,303
作为目标节点

261
00:16:43,370 --> 00:16:47,441
那么现在相机会旋转以实现看约束

262
00:16:47,508 --> 00:16:50,377
相机会朝角色的方向看

263
00:16:51,645 --> 00:16:57,784
如果我添加一个重复约束
并且我有基本的相机行为

264
00:16:57,851 --> 00:17:01,788
那就会重复角色的移动 会有一些偏移

265
00:17:01,855 --> 00:17:04,391
并继续朝角色的方向看

266
00:17:05,291 --> 00:17:08,161
如果我添加一个加速度约束

267
00:17:08,228 --> 00:17:09,997
我现在拥有同样的行为

268
00:17:10,063 --> 00:17:13,599
那最应该感谢加速度约束

269
00:17:13,666 --> 00:17:16,036
在另一个约束之后应用的

270
00:17:17,905 --> 00:17:22,509
并且如果我用距离约束替换重复约束

271
00:17:22,576 --> 00:17:24,678
我现在就有了一个新的相机行为

272
00:17:24,744 --> 00:17:28,248
现在是跟随角色以实现距离约束

273
00:17:29,049 --> 00:17:31,785
它继续朝角色的方向看 当然了

274
00:17:31,852 --> 00:17:35,255
并且总是在移动 而不管角色的移动

275
00:17:35,322 --> 00:17:38,625
这是由于加速度约束

276
00:17:39,793 --> 00:17:42,563
这是如何定义相机行为 很简单

277
00:17:42,629 --> 00:17:46,333
这是在我们的小狐狸2示例中实现的

278
00:17:47,234 --> 00:17:50,170
只是定义了一组不同的约束

279
00:17:50,237 --> 00:17:52,806
根据游戏的不同区域

280
00:17:52,873 --> 00:17:57,344
我们可以为整个游戏定义相机行为

281
00:17:59,813 --> 00:18:02,049
关于相机控制还需要注意一点

282
00:18:03,083 --> 00:18:08,555
我们扩展了SCNNode的类别
为你们提供更多的实用工具

283
00:18:08,622 --> 00:18:11,892
以在不同的空间转换和获取矢量

284
00:18:12,559 --> 00:18:15,929
但最重要的是 全部节点转换属性

285
00:18:15,996 --> 00:18:20,234
现有位置、旋转、
比例和矩阵以及转换

286
00:18:20,300 --> 00:18:24,605
现在都能直接在SIMD属性中使用

287
00:18:24,671 --> 00:18:26,540
以减少数学运算

288
00:18:27,107 --> 00:18:28,575
那么由于SIMD类型

289
00:18:29,409 --> 00:18:32,346
四元数、矢量和矩阵的运算的

290
00:18:32,412 --> 00:18:35,749
写入变得更简单了
并且优先级也更高了

291
00:18:36,416 --> 00:18:39,720
请了解一些SMD类型的限制
因为它们不是KVO

292
00:18:39,786 --> 00:18:43,724
和KVC约束 并且它们不能
作为S值被包含在内

293
00:18:45,425 --> 00:18:46,760
那么这就是相机控制器

294
00:18:46,827 --> 00:18:49,863
现在让我们把舞台交给Amaury
让他谈谈细化和细分

295
00:18:49,930 --> 00:18:53,534
（细化和细分曲面）

296
00:18:53,600 --> 00:18:54,535
谢谢Thomas

297
00:18:56,436 --> 00:18:59,740
那么我们知道好的图形
对于你的应用来说非常重要

298
00:18:59,806 --> 00:19:02,609
可以实现用户胶着和取悦用户

299
00:19:02,676 --> 00:19:05,212
要做出好的图形有很多方面需要关注

300
00:19:05,612 --> 00:19:08,182
比如 增加真实性

301
00:19:08,248 --> 00:19:10,617
这也是为什么我们这么多年一直引入

302
00:19:10,684 --> 00:19:14,621
新的渲染功能的原因
比如基于物理原理着色

303
00:19:14,688 --> 00:19:18,091
以及[听不清]更真实的相机光学

304
00:19:19,693 --> 00:19:24,698
但高分辨率资产
是另一个非常重要的因素

305
00:19:25,933 --> 00:19:30,370
在你的应用中
你想同时拥有非常平滑的表面

306
00:19:30,437 --> 00:19:33,340
以及非常丰富和精细的表面

307
00:19:34,007 --> 00:19:37,444
现在问题是当你处理高分辨率资产时

308
00:19:37,511 --> 00:19:41,548
它们需要更多的内存
都在磁盘上运行

309
00:19:41,615 --> 00:19:43,750
并且它们需要更多的处理时间

310
00:19:44,384 --> 00:19:48,355
那么在这部分
我们将会看一下允许设计师

311
00:19:48,422 --> 00:19:52,059
以及你们开发者
处理当在屏幕上渲染时

312
00:19:52,125 --> 00:19:55,495
可以变成高质量的
低分辨率模型的适当技巧

313
00:19:56,730 --> 00:20:00,901
那么我想先解释一下什么是细化
及其工作原理

314
00:20:00,968 --> 00:20:04,338
然后展示如何在
SceneKit中利用它

315
00:20:04,571 --> 00:20:07,207
最后看一点儿不一样的东西

316
00:20:07,274 --> 00:20:08,775
细分曲面

317
00:20:10,511 --> 00:20:11,445
那么细化

318
00:20:12,312 --> 00:20:15,682
细化是去年在Metal中
应用的一个功能

319
00:20:15,749 --> 00:20:17,551
这个功能背后的理念是

320
00:20:17,618 --> 00:20:20,988
提供低分辨率网格或粗网格GPU

321
00:20:21,054 --> 00:20:25,392
然后让GPU生成更多几何体

322
00:20:25,459 --> 00:20:29,596
拥有更多的至高点
当模型被渲染时

323
00:20:31,298 --> 00:20:34,568
那么细化的确是一个很强大的工具

324
00:20:34,902 --> 00:20:37,538
它们用于

325
00:20:37,604 --> 00:20:42,943
创建、存储和推动低分辨率模型

326
00:20:43,010 --> 00:20:45,812
当渲染这些低分辨率模型时
它们可能会拥有超高的品质

327
00:20:46,013 --> 00:20:48,315
让我们看一下 这是一个三角形

328
00:20:48,882 --> 00:20:51,185
这是它的一个细化版本

329
00:20:52,786 --> 00:20:57,624
那么SceneKit就要决定
可以把一条边分成多少份

330
00:20:57,925 --> 00:21:01,895
它可以决定可以在第一条边
和第二条边上

331
00:21:01,962 --> 00:21:03,130
创建多少至高点

332
00:21:03,430 --> 00:21:05,966
当然了 它同样也可以决定第三条边

333
00:21:06,700 --> 00:21:10,571
很棒的是SceneKit还会生成更多至高点

334
00:21:10,637 --> 00:21:12,539
在三角形内

335
00:21:14,107 --> 00:21:16,810
那么这些就叫作细化因素

336
00:21:16,877 --> 00:21:19,213
SceneKit是一个高层级API

337
00:21:19,279 --> 00:21:22,316
我们把它变得非常简单易用
以便让你控制细化

338
00:21:23,050 --> 00:21:27,120
我们新添加了
SCNGeometryTessellator类

339
00:21:27,187 --> 00:21:30,357
并在SCNGeometry上添加了细化属性

340
00:21:31,058 --> 00:21:34,027
细化公开了一些属性

341
00:21:34,094 --> 00:21:35,596
考虑到了不同的模式

342
00:21:36,597 --> 00:21:39,700
让我们首先来看一下最简单的例子

343
00:21:40,968 --> 00:21:45,038
在这种模式中
你给SceneKit提供恒定的边

344
00:21:45,105 --> 00:21:47,374
和内部细化因素

345
00:21:47,441 --> 00:21:50,777
将被应用于全部粗网格的三角形

346
00:21:51,178 --> 00:21:54,481
那么通过这种模式
你将拥有统一的细化

347
00:21:54,548 --> 00:21:56,683
并且你将添加同等数量的几何体

348
00:21:56,750 --> 00:21:58,886
在整个粗网格内

349
00:22:00,521 --> 00:22:04,024
现在让我们看一个更复杂的例子

350
00:22:05,225 --> 00:22:09,229
在这里你可以请求SceneKit
提供特别的细化因素

351
00:22:09,296 --> 00:22:11,331
从而防止边太长

352
00:22:11,798 --> 00:22:15,802
那么在这里 你在局部空间内
提供一个最大边长

353
00:22:16,904 --> 00:22:22,109
甚至再强大点 你可以请求
SceneKit不断评估每一帧的

354
00:22:22,176 --> 00:22:27,548
细化因素 根据对象内的项目

355
00:22:28,182 --> 00:22:32,553
那么在这种模式中
你将提供屏幕空间中的

356
00:22:32,619 --> 00:22:35,656
最大边长 以像素为单位

357
00:22:39,126 --> 00:22:40,661
这是细化

358
00:22:41,128 --> 00:22:44,364
现在如果你看一下原始三角形

359
00:22:44,431 --> 00:22:48,669
及其细化版本 你可能会感到有点失望

360
00:22:48,735 --> 00:22:50,804
这是因为全部新几何数据

361
00:22:50,871 --> 00:22:54,041
实际上是位于原始三角形内

362
00:22:54,541 --> 00:22:56,443
那么对于你高度细化的网格

363
00:22:56,510 --> 00:23:00,514
你想要通过这种额外的网格
来实现一些别的东西

364
00:23:01,048 --> 00:23:04,952
这就将我们引入了
基于细化的几何API

365
00:23:07,221 --> 00:23:10,057
那么首先 我们回顾一下着色器修改器

366
00:23:10,858 --> 00:23:15,229
着色器修改器完全支持新的细化管道

367
00:23:15,329 --> 00:23:19,066
只需要通过几行代码
你就可以创建自定义效果了

368
00:23:19,466 --> 00:23:22,736
那么比如说 如果你有一个应用
应用中涉及到水

369
00:23:22,803 --> 00:23:26,807
你想模拟大海和波浪或任何其它想法

370
00:23:26,874 --> 00:23:28,141
是你自己的效果

371
00:23:28,909 --> 00:23:32,212
着色器修改器正是你所需要的工具
功能非常强大

372
00:23:32,513 --> 00:23:35,749
当然了 我们还添加了一些
开箱即用的效果

373
00:23:35,816 --> 00:23:37,551
比如使几何体平滑

374
00:23:38,452 --> 00:23:39,853
这是一个新功能

375
00:23:40,287 --> 00:23:44,858
比如如果你指定
pnTriangles smoothingMode

376
00:23:44,925 --> 00:23:50,731
SceneKit将考虑每个顶点
在法线上的位置

377
00:23:50,797 --> 00:23:55,102
及其临近的点在法线上的位置

378
00:23:55,169 --> 00:23:57,237
从而把它们放在一个平滑的表面上

379
00:23:58,038 --> 00:24:00,407
你可能听说过的另一种效果

380
00:24:00,474 --> 00:24:02,142
位移图和高度图

381
00:24:03,310 --> 00:24:04,444
那么什么是高度图？

382
00:24:05,112 --> 00:24:07,281
高度图是一个灰度图像

383
00:24:07,347 --> 00:24:12,653
存储了表面上
任意点的海拔或高度

384
00:24:13,420 --> 00:24:17,858
这种技术通常用于创建
比如地形渲染这样的效果

385
00:24:17,925 --> 00:24:20,561
让我们看一个例子

386
00:24:21,695 --> 00:24:25,232
这是一个平面 然后我们进行细化

387
00:24:26,433 --> 00:24:29,136
然后通过高度图使其变形

388
00:24:31,338 --> 00:24:35,275
那么这是一个很简单的例子
但这非常有效

389
00:24:36,210 --> 00:24:38,245
API也很简单

390
00:24:38,579 --> 00:24:43,116
我们在SCNMaterial上
添加了新位移材料属性

391
00:24:43,183 --> 00:24:45,118
所以我敢说你们已经知道如何使用它了

392
00:24:45,285 --> 00:24:49,890
你只需要指定它的内容
然后如果你修改它的强度

393
00:24:49,957 --> 00:24:52,326
你就可以获得我刚刚所展示的动画

394
00:24:53,327 --> 00:24:57,030
现在让我们更进一步 看看矢量位移图

395
00:24:58,165 --> 00:25:01,969
矢量位移图是高度图的扩展

396
00:25:02,035 --> 00:25:04,505
它不仅存储海拔

397
00:25:04,571 --> 00:25:08,242
你还可以存储全部三个方位的位移

398
00:25:08,308 --> 00:25:10,143
这就是为什么
你会拥有横断面图像

399
00:25:10,777 --> 00:25:16,083
比如绿色是法线上的位移
而蓝色和红色

400
00:25:16,149 --> 00:25:17,951
是切线和双切线上的位移

401
00:25:19,253 --> 00:25:22,155
那么你猜到那有什么用吗？
让我们来看一下

402
00:25:26,527 --> 00:25:28,529
好的 那么这是一个很傻的例子

403
00:25:28,595 --> 00:25:31,865
但在你的应用中 你可以使用位移图

404
00:25:31,932 --> 00:25:35,102
添加细节
给你的几何体添加精美的细节

405
00:25:35,235 --> 00:25:39,406
那么比如说
如果你有一个变色龙的演示

406
00:25:39,473 --> 00:25:41,408
你可以给它的皮肤添加细节

407
00:25:41,742 --> 00:25:45,078
或者如果你有一个应用
应用中涉及到岩石

408
00:25:45,145 --> 00:25:46,747
你可以近距离地接触到

409
00:25:46,813 --> 00:25:49,249
那么正好可以使用矢量位移图

410
00:25:50,217 --> 00:25:55,989
API是一样的 除了只有红色
你可以指定“全部”

411
00:25:56,056 --> 00:26:00,861
纹理组件以表明你将包含一种以上的

412
00:26:00,928 --> 00:26:03,130
色彩通道或输入图像

413
00:26:05,299 --> 00:26:08,435
那么这就是细化和基于细化的效果

414
00:26:08,502 --> 00:26:10,838
现在让我们看看细分曲面

415
00:26:13,707 --> 00:26:16,977
那么你可能已经听说过我们的细分曲面

416
00:26:17,044 --> 00:26:18,779
和[听不清]

417
00:26:19,279 --> 00:26:21,515
它是一个标准化算法

418
00:26:21,582 --> 00:26:26,220
从粗网格开始 反复改善它

419
00:26:31,859 --> 00:26:34,862
那么你可以看到我们从粗网格

420
00:26:34,928 --> 00:26:36,697
到一个非常平滑和精制的网格是多么快

421
00:26:37,698 --> 00:26:40,367
现在并不是所有东西都是完美的圆形

422
00:26:40,434 --> 00:26:44,905
所以对于细分曲面
你可以指定褶皱和转角

423
00:26:44,972 --> 00:26:49,977
以使边和至高点拥有明显的锐利度

424
00:26:52,312 --> 00:26:54,014
那么细分曲面

425
00:26:54,515 --> 00:27:00,954
它们被广泛用于创建、存储和推动

426
00:27:01,021 --> 00:27:04,324
分辨率模型
当在屏幕上渲染这些分辨率模型时

427
00:27:04,391 --> 00:27:05,726
可能会变成高品质的模型

428
00:27:06,927 --> 00:27:10,197
并且几年前我们已经

429
00:27:10,264 --> 00:27:11,932
在SceneKit中添加了
细分曲面的支持

430
00:27:12,332 --> 00:27:16,103
但我们过去是在CPU上运行细分代码

431
00:27:16,937 --> 00:27:20,274
那么那需要一些时间以及大量的内存

432
00:27:20,340 --> 00:27:23,577
尤其是当你进入较高细分等级时

433
00:27:23,644 --> 00:27:27,848
因为至高点的数量将呈指数增长

434
00:27:29,650 --> 00:27:31,151
那么我们今年有个好消息

435
00:27:32,819 --> 00:27:36,089
你可能听说了Pixar的
OpenSubdiv项目

436
00:27:36,156 --> 00:27:38,292
这是一个开源的工具实施

437
00:27:38,358 --> 00:27:41,361
用于细分曲面的高效评估

438
00:27:41,662 --> 00:27:43,864
去年的WWDC时

439
00:27:43,931 --> 00:27:47,167
Apple宣布我们将给这个项目

440
00:27:47,234 --> 00:27:49,703
提供基于Metal的实施

441
00:27:49,770 --> 00:27:53,807
以便你可以在GPU上
通过Metal运行细分代码

442
00:27:54,875 --> 00:27:58,078
那么今年你可以利用
全部这些很棒的技术

443
00:27:58,145 --> 00:27:59,279
非常简单

444
00:28:00,714 --> 00:28:04,418
基于Metal的实施有许多好处

445
00:28:04,818 --> 00:28:07,254
首先我们利用细分

446
00:28:07,387 --> 00:28:10,858
它伴随着我之前讲过的
全部内存相关的优点

447
00:28:11,191 --> 00:28:13,060
并且通过细分

448
00:28:13,126 --> 00:28:17,397
我们甚至将会使低等级的细分
拥有更平滑的表面

449
00:28:18,098 --> 00:28:22,903
现在除了统一细分
我们还支持功能适应性细分

450
00:28:23,170 --> 00:28:25,005
我稍后会解释

451
00:28:25,105 --> 00:28:27,908
最后我们还有全部GPU管道

452
00:28:27,975 --> 00:28:31,178
用于细分网格的高效动画

453
00:28:32,646 --> 00:28:34,982
那么让我们看一下这个例子

454
00:28:35,048 --> 00:28:39,753
这是你在演示中看到的那把钥匙
正如你所看到的 它是一个很粗的网格

455
00:28:40,087 --> 00:28:41,288
并没有那么精细

456
00:28:42,222 --> 00:28:45,192
这是一个细化版本 细分版

457
00:28:46,026 --> 00:28:49,263
那么通过这个资产
你可以看到你拥有很硬的边

458
00:28:49,329 --> 00:28:50,931
但还有很漂亮的曲线

459
00:28:51,598 --> 00:28:54,601
那么我们是如何实现的呢？通过褶皱

460
00:28:56,236 --> 00:28:58,205
通过细分曲面

461
00:28:58,272 --> 00:29:01,008
设计师们可以实现很棒的设计

462
00:29:01,074 --> 00:29:03,143
他们可以简便地创建

463
00:29:03,210 --> 00:29:07,080
并调整 获得他们想要的效果

464
00:29:09,650 --> 00:29:12,352
现在功能适应性细分

465
00:29:14,621 --> 00:29:18,392
当统一细分在一个有限的表面上实施时

466
00:29:18,458 --> 00:29:22,729
这是通过呈指数增长的多边形数量
的增加而移动的

467
00:29:23,764 --> 00:29:28,535
功能适应性细分可以
隔离你网格中的不规则部分

468
00:29:28,602 --> 00:29:30,771
并创建很多补丁

469
00:29:31,271 --> 00:29:34,007
那么然后 通过细化
我们可以创建新至高点

470
00:29:34,074 --> 00:29:36,276
在这些完美的数学曲线上

471
00:29:36,343 --> 00:29:41,014
因此它会生成非常平滑的表面
但却占用较低的内存

472
00:29:42,783 --> 00:29:44,551
现在 API非常简单

473
00:29:45,252 --> 00:29:50,624
你只需要指定细分等级
然后选择加入细化

474
00:29:51,525 --> 00:29:55,395
然后对于功能适应性细分
配置起来也很简单

475
00:29:56,897 --> 00:30:00,167
最后细分曲面的动画

476
00:30:00,968 --> 00:30:05,339
今年我们有了全部GPU管道
非常高效

477
00:30:05,439 --> 00:30:11,111
你可以有一个粗网格
并通过变形技术使其变形

478
00:30:11,178 --> 00:30:14,114
那么只要你想
你就可以通过剥皮添加骨骼动画

479
00:30:14,481 --> 00:30:18,619
最后作为最后一步
我们在GPU上运行精制代码

480
00:30:18,819 --> 00:30:22,122
性能非常好
因为我们正在GPU上实现

481
00:30:22,189 --> 00:30:25,559
在低分辨率的网格上
然后这个是非常精制的

482
00:30:25,626 --> 00:30:29,062
是由GPU通过细化生成的

483
00:30:30,964 --> 00:30:33,567
那么现在 你想试试细分曲面

484
00:30:33,634 --> 00:30:38,205
你只需要记住两点
第一 如果你从文件中加载集合

485
00:30:38,939 --> 00:30:42,142
请指定preserveOriginalTopology选项

486
00:30:42,843 --> 00:30:45,579
如果你以编程方式创建几何体

487
00:30:45,646 --> 00:30:47,915
请记住使用多边形原始类型

488
00:30:48,515 --> 00:30:52,085
这是因为对于细分 处理三角形

489
00:30:52,152 --> 00:30:53,554
与处理四边形并不一样

490
00:30:54,588 --> 00:30:56,490
然后让我们来看一个快速演示

491
00:31:05,566 --> 00:31:08,769
好的 那么这是一个简单的制陶应用

492
00:31:08,836 --> 00:31:10,170
我要制作一件陶器

493
00:31:10,938 --> 00:31:17,177
那么我可以缩放 并且可以拖动旋转

494
00:31:17,945 --> 00:31:18,912
非常简单

495
00:31:19,546 --> 00:31:23,750
现在如果我放大 然后关注对象的轮廓

496
00:31:24,251 --> 00:31:26,553
正如你所看到的 非常平滑

497
00:31:26,620 --> 00:31:31,491
你可以使用法线图
给表面添加一些细节

498
00:31:32,793 --> 00:31:37,631
现在这个应用的目的很简单
我可以用我的手指

499
00:31:38,398 --> 00:31:40,634
在网格上进行雕刻

500
00:31:41,768 --> 00:31:45,239
让我们清除它 然后写一些东西

501
00:31:45,806 --> 00:31:49,343
随着我的绘制 请看对象的轮廓

502
00:31:51,111 --> 00:31:53,847
在这里我实际上正在修改几何体

503
00:31:54,281 --> 00:31:58,652
我不只是添加表面细节
就像我们用法线图做的那样

504
00:32:06,393 --> 00:32:07,961
好的 那么是如何实现的呢？

505
00:32:08,195 --> 00:32:12,132
嗯 细分曲面、细化和高度图

506
00:32:12,199 --> 00:32:13,267
让我们来看一下

507
00:32:15,802 --> 00:32:19,106
我们所做的是
从一个非常粗的网格开始

508
00:32:19,173 --> 00:32:21,708
正如你所看到的
分辨率非常低的多边形

509
00:32:23,010 --> 00:32:26,747
它并没有法线
所以我们在这里有平坦阴影

510
00:32:26,813 --> 00:32:32,419
但它有纹理坐标 所以我们可以
在它上面映射一个法线图

511
00:32:32,486 --> 00:32:33,987
稍后再映射一个高度图

512
00:32:34,855 --> 00:32:36,857
那么现在 让我们细分它

513
00:32:38,091 --> 00:32:41,595
让我们看看所生成的平滑法线

514
00:32:43,163 --> 00:32:44,631
然后让我们看看

515
00:32:45,465 --> 00:32:49,069
线框以及创建了多少个至高点

516
00:32:50,537 --> 00:32:54,474
当我启动细分时创建了多少个至高点

517
00:32:56,043 --> 00:33:00,914
当我抬起手指时
我是在高度图上绘制图形

518
00:33:02,115 --> 00:33:04,318
全部至高点都被移动了

519
00:33:06,086 --> 00:33:07,354
现在让我们清除它

520
00:33:07,621 --> 00:33:11,325
只是为了更有意思
让我们启用屏幕空间细化

521
00:33:12,059 --> 00:33:16,797
现在我会放大 看看当我离对象
更近或更远时会怎么样

522
00:33:17,898 --> 00:33:20,567
SceneKit将提供新的细化因素

523
00:33:20,634 --> 00:33:23,837
它会在过程中创建新的至高点

524
00:33:27,374 --> 00:33:28,609
这就是这个演示

525
00:33:35,082 --> 00:33:37,684
谢谢 那么总的来说

526
00:33:38,819 --> 00:33:41,755
细化和依赖于细化的功能

527
00:33:41,822 --> 00:33:44,558
都能在全部Mac上的
Metal中

528
00:33:44,625 --> 00:33:49,029
在拥有A9或更高版本芯片的
iOS设备上也有

529
00:33:49,096 --> 00:33:53,767
那么包括iPhone 6S
以及全部iPad Pro型号

530
00:33:55,969 --> 00:33:59,706
现在让我们一些完全不同的东西

531
00:33:59,773 --> 00:34:02,075
我们对动画API的改进

532
00:34:02,142 --> 00:34:07,948
（动画改进）

533
00:34:08,014 --> 00:34:08,849
那么…

534
00:34:10,851 --> 00:34:14,855
今年我们引入了新SCNAnimation协议

535
00:34:15,088 --> 00:34:19,126
以及SCNAnimationPlayer类

536
00:34:19,860 --> 00:34:24,531
使动画变得更简单了

537
00:34:24,598 --> 00:34:28,068
当动画运行时
也使对它的操纵变得更简单了

538
00:34:28,869 --> 00:34:33,172
那么比如说 现在你可以
轻松地修改动画速度

539
00:34:33,239 --> 00:34:35,909
并且你可以在融合正在发生的动画

540
00:34:36,376 --> 00:34:41,047
当然 我们仍完全支持CA动画API

541
00:34:41,114 --> 00:34:44,318
CA动画遵从我们的新协议

542
00:34:44,851 --> 00:34:51,625
但通过新API 变得更简单了
你可以动态地操纵动画

543
00:34:51,692 --> 00:34:52,960
当动画在运行时

544
00:34:53,025 --> 00:34:57,231
并且这些API在全部平台上都可用
包括watchOS

545
00:34:58,498 --> 00:35:00,367
那么让我们看看老的方式

546
00:35:01,134 --> 00:35:04,605
那么假如你有一个角色 会走会跳

547
00:35:05,072 --> 00:35:07,774
你首先要添加行走动画

548
00:35:07,841 --> 00:35:10,377
然后当你想让角色跳跃时

549
00:35:10,444 --> 00:35:13,714
你就需要添加跳跃动画
取代另一个动画

550
00:35:15,816 --> 00:35:17,484
现在通过新API

551
00:35:17,551 --> 00:35:21,555
你开始可以创建和配置动画播放器

552
00:35:21,622 --> 00:35:25,325
然后当你想让角色跳跃时
你就操纵播放器

553
00:35:25,392 --> 00:35:29,630
而不是直接操纵动画
所以这是一个很相似的API

554
00:35:30,497 --> 00:35:34,268
不同点是你现在可以操纵
正在运行中的动画

555
00:35:34,334 --> 00:35:37,638
所以你可以修改动画的速度
并且可以混合动画

556
00:35:38,505 --> 00:35:40,941
动画混合实际上是今年的新功能

557
00:35:41,942 --> 00:35:46,680
那么让我们来看一个例子
这是马克斯 他可以走、跑、迈步

558
00:35:47,314 --> 00:35:51,018
每种运动都有不同的动画文件

559
00:35:52,653 --> 00:35:56,990
通过新的混合API 你可以很简便地

560
00:35:57,057 --> 00:35:59,927
从迈步动画过渡到行走动画

561
00:35:59,993 --> 00:36:04,097
那么你可以引入流动性
并让你的应用更具有表现力

562
00:36:04,898 --> 00:36:08,135
在你混合动画之后
你还可以调一下速度

563
00:36:08,202 --> 00:36:12,840
马克斯可以跑慢点儿

564
00:36:14,441 --> 00:36:19,680
最后让我提一下动画评估代码的改进

565
00:36:20,514 --> 00:36:26,019
那么我们有一个新的实施
可以使在场景中

566
00:36:26,086 --> 00:36:28,355
开启任意对象的动画变得更快

567
00:36:29,323 --> 00:36:33,594
并且我们对骨骼动画的评估性能更好

568
00:36:33,660 --> 00:36:38,398
那么如果你有许多角色
在你的场景中就会有很多骨骼

569
00:36:38,465 --> 00:36:41,468
比如你刚才看到的小狐狸演示

570
00:36:42,269 --> 00:36:45,506
那么通过我们这个新实施
可以让速度变得更快

571
00:36:46,874 --> 00:36:49,510
然后让我把舞台交给Sebastien

572
00:36:49,576 --> 00:36:51,812
他会给大家讲开发者工具的更新

573
00:36:51,879 --> 00:36:54,648
（开发者工具）

574
00:36:54,715 --> 00:36:55,716
谢谢Amaury

575
00:36:58,785 --> 00:37:01,488
那么去年我们引入了FPS计量

576
00:37:02,089 --> 00:37:05,092
那是一个了解你应用

577
00:37:05,158 --> 00:37:06,426
对于SceneKit的性能概览的
一个很好的方式

578
00:37:06,660 --> 00:37:09,696
并且它们进行了分类
所以你可以看到

579
00:37:09,763 --> 00:37:12,332
CPU和GPU的具体信息

580
00:37:12,399 --> 00:37:14,034
那么你可以了解是否正在渲染

581
00:37:14,101 --> 00:37:15,736
和物理处理或微粒处理

582
00:37:16,336 --> 00:37:18,772
它被整合在Xcode中
你可以始终看到

583
00:37:18,839 --> 00:37:20,407
它的具体情况

584
00:37:20,908 --> 00:37:22,576
能具体了解

585
00:37:22,643 --> 00:37:27,814
哪些占用了时间很酷 所以你可以
减少网格或动画 比如说

586
00:37:28,282 --> 00:37:30,317
但当你跳过某一帧时会发生什么呢？

587
00:37:30,384 --> 00:37:35,589
你如何知道具体发生了什么？
到底是什么导致了跳帧？

588
00:37:36,790 --> 00:37:38,926
今年我们引入了新工具

589
00:37:39,226 --> 00:37:41,495
是SceneKit的模板

590
00:37:41,562 --> 00:37:44,398
你可以用于记录你应用的踪迹

591
00:37:44,464 --> 00:37:47,334
并具体了解每一帧到底发生了什么

592
00:37:48,769 --> 00:37:51,371
非常简单易用 你只需要创建一个模板

593
00:37:52,039 --> 00:37:54,474
就跟你创建用于其它追踪的模板一样

594
00:37:54,541 --> 00:37:57,010
那么它将会记录你应用的性能

595
00:37:57,077 --> 00:37:58,645
并且你会得到这个视图

596
00:37:58,946 --> 00:38:02,783
它是全长的 显示了你应用中
所发生的具体细节

597
00:38:02,850 --> 00:38:05,786
第一个是帧 它显示了所占用的时间

598
00:38:05,853 --> 00:38:11,592
在应用中渲染某一个帧
并且你可以看到具体用了多少时间

599
00:38:12,459 --> 00:38:15,128
第二个提供了渲染时间

600
00:38:15,195 --> 00:38:18,899
是由SceneKit收集全部数据

601
00:38:18,966 --> 00:38:20,434
并将其发送到GPU所占用的时间

602
00:38:21,635 --> 00:38:25,739
第三个提供了更新过程

603
00:38:25,806 --> 00:38:28,909
是用于更新物理处理、微粒处理

604
00:38:28,976 --> 00:38:32,045
以及自定义委托（如果你有的话）
所占用的时间

605
00:38:33,146 --> 00:38:35,148
最后一个但也是非常重要的一个

606
00:38:35,215 --> 00:38:38,018
是将纹理上传到GPU

607
00:38:38,085 --> 00:38:39,686
以及编译着色器所占用的时间

608
00:38:40,821 --> 00:38:44,458
让我们看看跳帧时是什么样的

609
00:38:44,525 --> 00:38:46,059
这是一个很简单的例子

610
00:38:46,927 --> 00:38:49,229
你可以看到所有帧的渲染时间都很短

611
00:38:49,296 --> 00:38:53,600
并且在某一点上来说
我们有一个帧占用的时间

612
00:38:53,667 --> 00:38:56,570
与正常的四帧占用的时间一样

613
00:38:56,937 --> 00:39:01,175
我们向下深挖
我们要看到底发生了什么

614
00:39:01,241 --> 00:39:04,745
我们可以看到编译了一个新着色器
占用了很多时间

615
00:39:04,811 --> 00:39:10,417
在这种情况下我们就可以了解
也许是在尝试找一种加载着色器的方式

616
00:39:11,585 --> 00:39:13,187
在应用刚开启的时候

617
00:39:14,421 --> 00:39:17,391
我们还添加了一种方式 可以结合

618
00:39:18,325 --> 00:39:20,561
SceneKit工具和
Metal工具追踪

619
00:39:20,627 --> 00:39:25,499
那么你可以同时看到这两者的结合
并查看具体

620
00:39:25,566 --> 00:39:28,502
后台发生了什么

621
00:39:28,569 --> 00:39:30,971
以便了解你的应用中发生了什么

622
00:39:32,439 --> 00:39:34,608
今年我们还添加了一个新调试工具

623
00:39:35,375 --> 00:39:38,478
是Xcode中视图调试器的改进

624
00:39:38,545 --> 00:39:41,315
简单易用 你只需要使用
常规的视图调试器

625
00:39:41,381 --> 00:39:42,683
就跟你往常的用法一样

626
00:39:43,350 --> 00:39:48,722
它将自动捕捉视图等级以及场景

627
00:39:49,256 --> 00:39:50,991
那么如果有SceneKit场景

628
00:39:51,225 --> 00:39:55,028
在你应用的SceneKit视图中
它将捕捉场景

629
00:39:55,095 --> 00:39:57,965
如果你在视图等级中选择场景

630
00:39:58,465 --> 00:40:00,000
它将自动把它发送到

631
00:40:00,234 --> 00:40:03,337
SceneKit编辑器
你可以检查你的全部对象

632
00:40:03,403 --> 00:40:06,507
移动相机 看具体…

633
00:40:06,940 --> 00:40:09,276
你的应用中发生了什么
以及场景中发生了什么

634
00:40:12,045 --> 00:40:14,848
我们今年的新功能还有附加支持

635
00:40:14,915 --> 00:40:19,052
那么我们有一种新方式
在Xcode中处理相机

636
00:40:19,419 --> 00:40:23,290
你可以看到有一种新方式
来选择你想要的行为

637
00:40:24,892 --> 00:40:27,528
我们添加了远景相机和自动绘图相机

638
00:40:27,594 --> 00:40:30,764
因此你可以更简单地检验你的场景

639
00:40:31,198 --> 00:40:34,368
你仍然可以获取全部常规相机

640
00:40:35,936 --> 00:40:40,007
我们还添加了新行为
所以你可以在拐角处飞来飞去

641
00:40:40,073 --> 00:40:41,375
并使用轨迹球

642
00:40:41,441 --> 00:40:44,745
检验很大的场景变得更简单了

643
00:40:47,214 --> 00:40:50,517
我们还完全修订了着色器修改器编辑器

644
00:40:50,584 --> 00:40:55,189
那么现在你可以在一个屏幕上同时编辑

645
00:40:55,255 --> 00:40:56,690
你的着色器修改器以及你的素材了

646
00:40:56,757 --> 00:40:59,560
你不必来回选择对象

647
00:41:00,394 --> 00:41:02,329
这是一个全新的实施

648
00:41:02,396 --> 00:41:04,932
并且它支持自定义素材属性

649
00:41:04,998 --> 00:41:09,570
那么如果你的素材中
没有足够多的属性slot

650
00:41:09,636 --> 00:41:13,273
你可以添加颜色、浮动或矢量

651
00:41:13,340 --> 00:41:16,977
以在你的着色器修改器中
添加你自己的实施

652
00:41:17,211 --> 00:41:18,312
非常简单易用

653
00:41:19,746 --> 00:41:23,116
我们今年添加的许多功能都有附加支持

654
00:41:23,417 --> 00:41:27,221
首先是有一个新的位移素材slot

655
00:41:27,287 --> 00:41:29,790
你可以用于细化

656
00:41:30,757 --> 00:41:32,292
当然了 我们有细化

657
00:41:33,160 --> 00:41:35,229
新的约束也有附加支持

658
00:41:35,295 --> 00:41:39,800
那么你可以将它们添加到你的节点中
并在Xcode中进行实时测试

659
00:41:39,867 --> 00:41:41,702
然后在检验器中编辑它们

660
00:41:42,636 --> 00:41:46,473
我们有级联式阴影的支持
我们稍后会讲到

661
00:41:47,374 --> 00:41:51,111
我们还有一个新的程序化天空
简单易用 可以作为背景

662
00:41:51,178 --> 00:41:53,113
或照亮环境 比如说

663
00:41:53,180 --> 00:41:57,017
测试你的PBM素材
当你没有合适的Qmap设置时

664
00:41:57,451 --> 00:42:00,954
并且它是完全可配置的
所以你可以得到白天或晚上的天空

665
00:42:01,021 --> 00:42:01,922
比如说

666
00:42:03,423 --> 00:42:07,594
最后也是最重要的 我们添加了
用引用节点覆盖素材的可能性

667
00:42:07,661 --> 00:42:11,298
什么是引用节点？

668
00:42:11,431 --> 00:42:18,272
引用节点其实是指向一个
仅指向一个 场景文件的节点

669
00:42:18,338 --> 00:42:21,008
但可在你的场景中多次使用

670
00:42:21,975 --> 00:42:26,246
直到现在 我们只能对两者
执行完全一样的渲染

671
00:42:26,313 --> 00:42:28,582
对于全部节点 不只是两个节点

672
00:42:28,849 --> 00:42:32,619
但现在 你可以覆盖某些或全部素材

673
00:42:32,686 --> 00:42:35,656
你正在场景中使用的素材
并修改其中一些

674
00:42:35,722 --> 00:42:37,624
或全部素材的外观 比如说

675
00:42:38,659 --> 00:42:42,663
接下来我要把舞台交给Thomas
他会跟大家谈谈相关技术

676
00:42:42,996 --> 00:42:45,232
（相关技术）

677
00:42:45,332 --> 00:42:46,266
谢谢

678
00:42:49,436 --> 00:42:54,174
好的 让我们谈谈相关技术
从ARKit开始讲

679
00:42:54,408 --> 00:42:56,176
那么你…是的

680
00:42:58,679 --> 00:43:03,550
那么你们已经
都看到了周一的Keynote演讲

681
00:43:03,617 --> 00:43:05,152
以及国情咨文中针对ARKit的介绍

682
00:43:05,219 --> 00:43:10,390
你可能注意到ARKit
提供了一个ARSCNView

683
00:43:10,557 --> 00:43:15,395
ARSCNView为AR提供了一个
很简单的方案 开箱即用

684
00:43:16,029 --> 00:43:20,634
事实上 ARSCNView
是SCNView的一个子类

685
00:43:20,701 --> 00:43:24,705
意思是通过ARKit
你可以获得SceneKit的全部权限

686
00:43:24,805 --> 00:43:26,440
你可以获取场景图

687
00:43:26,507 --> 00:43:31,478
你可以添加后置处理、粒子系统、
物理系统、压力推进、自定义着色器

688
00:43:31,545 --> 00:43:33,814
只要你想 你基本可以实现一切

689
00:43:34,615 --> 00:43:36,783
通过ARKit和SceneKit

690
00:43:36,850 --> 00:43:41,255
设置场景真的非常简单
就像这里的这个例子一样

691
00:43:41,321 --> 00:43:44,291
我想让你猜一下这个视频的拍摄地

692
00:43:44,358 --> 00:43:47,928
背景中有一条线索
我的口音是另一条线索

693
00:43:49,062 --> 00:43:54,601
在这里要设施这样的一个场景
我们只需要加载一个SceneKit对象

694
00:43:55,135 --> 00:43:59,673
就像你通常做的那样 并设置一个
AR视图 然后运行AR会话

695
00:43:59,873 --> 00:44:05,212
然后从ARSCNView委托中
你只需要将你的3D对象附加

696
00:44:05,279 --> 00:44:10,450
到ARKit所检测到的锚点上即可
就是那么简单

697
00:44:11,451 --> 00:44:18,425
为了支持ARSCNView
我们扩展了素材属性 使其支持

698
00:44:18,559 --> 00:44:24,164
AVCaptureDevice和AVPlayer
作为内容的原生支持类型

699
00:44:24,898 --> 00:44:27,534
那么那意味着非常简单
只需要一行代码

700
00:44:27,601 --> 00:44:31,438
你就可以直接连接了
所以如果你远离iPhone

701
00:44:31,505 --> 00:44:36,210
或iPad直接在SceneKit的纹理
或场景背景执行feed

702
00:44:37,644 --> 00:44:38,512
是的

703
00:44:42,282 --> 00:44:45,919
现在我希望给你提供一些小技巧
关于增强现实

704
00:44:45,986 --> 00:44:47,354
和阴影

705
00:44:47,421 --> 00:44:50,591
那么事实是你的对象
看起来整合地更好

706
00:44:50,657 --> 00:44:55,762
如果你的对象在地面上投有阴影的话
就像这个例子这样

707
00:44:57,197 --> 00:45:03,570
那么这个小技巧就是为了实现这种效果
我们在Xcode中编辑了对象

708
00:45:03,637 --> 00:45:06,773
我们添加了平行光 投射了一些阴影

709
00:45:07,875 --> 00:45:11,011
然后我们添加了一个平面
来接收这些阴影

710
00:45:11,078 --> 00:45:13,914
现在的目标是隐藏平面
因为我们不想在场景中看到它

711
00:45:13,981 --> 00:45:18,151
但我们不能就那样使平面藏起来

712
00:45:18,218 --> 00:45:20,687
否则阴影就会消失

713
00:45:21,355 --> 00:45:27,261
那么技巧就是配置平面
使其不写入色彩缓冲器

714
00:45:27,327 --> 00:45:32,599
这可以通过编程实现
或在Xcode中使用检验器实现

715
00:45:32,666 --> 00:45:36,103
如果这样做平面将会消失
而阴影也会消失

716
00:45:36,803 --> 00:45:39,940
但平面仍会写入深度缓冲器

717
00:45:40,240 --> 00:45:44,077
意思就是我不能配置
我的光照并修改阴影技术

718
00:45:44,144 --> 00:45:49,316
以及从这前边移动到延迟的阴影

719
00:45:50,284 --> 00:45:54,855
现在阴影又回来了 因为延迟的阴影

720
00:45:54,922 --> 00:45:57,057
是整个屏幕的第二个步骤

721
00:45:57,491 --> 00:46:02,629
它会根据场景的深度缓存
以及光照图的深度缓存

722
00:46:02,696 --> 00:46:04,598
在图像上制造阴影

723
00:46:05,098 --> 00:46:08,435
那么对于延迟的阴影
平面仍然存在 因为平面

724
00:46:08,502 --> 00:46:10,771
仍渲染到深度缓存中

725
00:46:12,105 --> 00:46:14,208
这是在ARKit中关于阴影的小技巧

726
00:46:14,274 --> 00:46:16,643
现在我想谈谈GamePlayKit

727
00:46:17,811 --> 00:46:22,416
GamePlayKit实体和组件现在
支持驱动SceneKit对象

728
00:46:22,482 --> 00:46:25,786
典型用例就是当你想实施角色行为时

729
00:46:25,853 --> 00:46:29,256
这是我们在小狐狸2示例中对敌人做的

730
00:46:29,556 --> 00:46:34,094
在我们的示例中有一个GKScene
有两个实体 一个是另一个的敌人

731
00:46:34,862 --> 00:46:37,965
并且我们实施了两个行为
作为GKComponent

732
00:46:38,465 --> 00:46:42,936
现在关键点在Xcode整合允许我们

733
00:46:43,003 --> 00:46:47,174
在Xcode中直接给敌人分配行为

734
00:46:47,541 --> 00:46:49,643
我们还可以使用Xcode检验器

735
00:46:49,710 --> 00:46:54,615
直接编辑我们行为的属性

736
00:46:56,617 --> 00:46:58,185
接下来Model I/O

737
00:46:59,286 --> 00:47:02,689
Model I/O改进了
对3D中的USD的支持

738
00:47:02,756 --> 00:47:06,193
提示一下 USD指的是通用场景描述

739
00:47:06,260 --> 00:47:09,796
它是一个3D文件格式
由Pixar开发

740
00:47:11,365 --> 00:47:14,368
SceneKit和Model I/O
改进了对USD的支持

741
00:47:14,434 --> 00:47:17,938
且特别是对Metal I/O
和动画的支持

742
00:47:18,005 --> 00:47:23,343
如果你想了解更多关于USD的信息
你可以参考我们去年的演讲

743
00:47:23,410 --> 00:47:27,648
也可以参加周五下午
我们的另一场演讲

744
00:47:27,714 --> 00:47:29,950
从艺术到引擎 Model I/O

745
00:47:31,685 --> 00:47:33,120
接下来是UIFocus

746
00:47:33,420 --> 00:47:38,192
UIFocus引擎是UIKit的
一部分 允许你

747
00:47:38,258 --> 00:47:43,463
选择对象并将其聚焦在你的Apple TV上
通过Siri Remote

748
00:47:44,331 --> 00:47:51,338
现在SCN遵从UIFocusItem
意味着你可以决定

749
00:47:51,405 --> 00:47:56,343
在你的场景中放哪个对象
并聚焦于哪个对象

750
00:47:57,110 --> 00:48:00,414
然后聚焦引擎将回调你并告诉你

751
00:48:00,480 --> 00:48:02,149
现在应该聚焦于哪个对象

752
00:48:02,216 --> 00:48:04,751
在响应Apple Siri Remote上
的手势时

753
00:48:06,119 --> 00:48:08,455
然后由你决定你要采取哪些行动

754
00:48:08,522 --> 00:48:10,824
以及你想提供哪些视觉反馈

755
00:48:11,225 --> 00:48:12,960
简要地解释一下

756
00:48:13,594 --> 00:48:16,964
假如我把白色象棋配置为可聚焦

757
00:48:17,931 --> 00:48:22,102
SceneKit将自动计算
你对象的投影区域

758
00:48:22,169 --> 00:48:24,137
并将其提供给聚焦引擎

759
00:48:25,005 --> 00:48:31,111
然后聚焦引擎会选择合适的对象

760
00:48:31,178 --> 00:48:33,413
根据遥控上的手势

761
00:48:34,648 --> 00:48:39,486
并且SceneKit会保持
屏幕上的投影区域持续更新

762
00:48:39,553 --> 00:48:42,523
如果你移动对象或移动相机的话

763
00:48:43,423 --> 00:48:45,058
那么你要做的唯一一件事就是

764
00:48:45,125 --> 00:48:48,829
定义哪些对象是可聚焦的 仅此而已

765
00:48:54,468 --> 00:48:56,103
现在让我们来总结一下

766
00:48:56,170 --> 00:48:58,205
我想提一些渲染附件

767
00:48:58,272 --> 00:48:59,973
是我们添加到我们的渲染器中的
一些渲染附加

768
00:49:00,307 --> 00:49:03,810
第一个是对点云渲染的支持

769
00:49:04,611 --> 00:49:08,015
我们改善了我们的SCN几何体对象
并添加了这些属性

770
00:49:08,081 --> 00:49:11,685
这将允许你配置点云的外观

771
00:49:12,452 --> 00:49:15,822
那么这些属性适用于是点云的几何体
意思就是

772
00:49:15,889 --> 00:49:19,660
通过一堆点和一个原始类型点
创建的几何体

773
00:49:20,160 --> 00:49:23,630
有了这些属性 你可以配置
屏幕空间和世界空间中的尺寸

774
00:49:23,697 --> 00:49:27,568
并且SceneKit将渲染你的点云

775
00:49:27,634 --> 00:49:29,536
给它们添加纹理和光照

776
00:49:29,603 --> 00:49:32,806
根据附属于你几何体的素材

777
00:49:35,909 --> 00:49:41,615
然后我们给我们的素材添加了两个
新透明度模式来解决

778
00:49:41,682 --> 00:49:46,887
双面对象或凹面对象半透明的问题

779
00:49:47,387 --> 00:49:49,857
那么如果你看一下左侧的对象

780
00:49:49,923 --> 00:49:54,194
你可以看到一个双面球体
半透明 你会注意到

781
00:49:54,261 --> 00:49:58,232
工件 因为多边形不是从后往前渲染的

782
00:49:58,799 --> 00:50:03,070
那么SceneKit将从后往前渲染
你的对象以获得更好的透明度

783
00:50:03,136 --> 00:50:07,908
但它并不会处理几何体的单一多边形

784
00:50:08,475 --> 00:50:12,312
那么要解决这个问题
我们引入了两种新的透明度模式

785
00:50:12,379 --> 00:50:17,317
那么第一个 单层
它将以两个步骤渲染你的对象

786
00:50:17,384 --> 00:50:20,787
在第二个步骤中只渲染最靠前的面

787
00:50:21,288 --> 00:50:22,990
那么这就修复了工件

788
00:50:23,056 --> 00:50:25,559
但正如你所看到的
对象看起来并不像是双面的

789
00:50:25,626 --> 00:50:30,163
这个模式的一个典型用例就是
当你想要淡出某个对象

790
00:50:30,230 --> 00:50:32,599
并避免工件时

791
00:50:32,666 --> 00:50:36,837
由于在淡出时对多边形的覆盖

792
00:50:38,138 --> 00:50:39,806
那么第二个模式是双层

793
00:50:39,873 --> 00:50:42,409
双层也会以两个步骤渲染你的对象

794
00:50:42,476 --> 00:50:44,678
那么第一个步骤是渲染后面的面

795
00:50:44,745 --> 00:50:47,281
第二个步骤是渲染前面的面

796
00:50:47,347 --> 00:50:50,717
它允许我们正确地渲染这个双面球体

797
00:50:50,784 --> 00:50:55,255
还有小狐狸演示中的宝石
这个宝石来自

798
00:50:55,322 --> 00:50:58,358
Swift Playground Learn to Code课程

799
00:51:00,227 --> 00:51:01,528
最后一个添加

800
00:51:01,595 --> 00:51:04,364
是对级联式阴影图的支持

801
00:51:04,431 --> 00:51:08,202
那么级联式阴影图是阴影图的一个优化

802
00:51:08,268 --> 00:51:12,773
概念是它会把你的阴影图分成多个纹理

803
00:51:12,840 --> 00:51:18,412
或多个级联 以更准确地分配给
距相机较近的区域

804
00:51:18,478 --> 00:51:22,115
更模糊地分配给距相机较远的区域

805
00:51:23,183 --> 00:51:27,087
要配置级联式阴影图 你只需要
告诉我们你想要多少个级联

806
00:51:27,154 --> 00:51:29,323
你可以配置级联的侧面

807
00:51:29,790 --> 00:51:34,695
然后你有一个参数
叫作shadowCascadeSplittingFactor

808
00:51:35,562 --> 00:51:40,567
你可以调整它以控制级联的分配

809
00:51:40,634 --> 00:51:42,970
根据距离视点的距离

810
00:51:43,704 --> 00:51:47,941
比如这是一个片段
来自我们的小狐狸2示例

811
00:51:48,375 --> 00:51:50,544
在我们的例子中 我们用了四个级联

812
00:51:50,611 --> 00:51:53,413
呈现为不同的色彩

813
00:51:54,448 --> 00:51:58,519
在这里我正在用拆分因素

814
00:51:58,585 --> 00:52:02,089
那么你可以了解这是如何
影响在级联的分配了吧

815
00:52:02,155 --> 00:52:05,192
取决于距离视点的距离

816
00:52:05,926 --> 00:52:09,196
正如你所看到的
右侧区域代表第一级联

817
00:52:09,263 --> 00:52:12,032
那么它呈现了世界中较小的一个区域

818
00:52:12,099 --> 00:52:14,201
那么我们在这里有较高的精确度

819
00:52:14,601 --> 00:52:18,572
而后面的绿色级联式一片较大的区域

820
00:52:18,639 --> 00:52:21,508
那么我们对于绿色级联有较小的精确度

821
00:52:22,476 --> 00:52:27,548
请注意你可以
你还可以可视化级联式阴影图

822
00:52:27,614 --> 00:52:29,883
在你自己的场景中
通过Xcode实现

823
00:52:32,386 --> 00:52:33,620
好了 总结一下

824
00:52:34,454 --> 00:52:38,659
那么SceneKit的新版本
引入了新相机API

825
00:52:38,725 --> 00:52:40,594
用于简化相机控制

826
00:52:40,661 --> 00:52:44,131
通过一些新的很棒的效果
比如景深、运动模糊

827
00:52:44,198 --> 00:52:46,066
和屏幕空间环境光遮蔽

828
00:52:47,401 --> 00:52:50,904
同时针对细化和细分
有不错的GPU支持

829
00:52:50,971 --> 00:52:52,439
一些新API

830
00:52:52,506 --> 00:52:56,376
对于动画和动画混合有更好的性能

831
00:52:57,244 --> 00:53:01,648
一些新的很棒的工具
可用于捕捉、追踪和编辑你的场景

832
00:53:01,715 --> 00:53:06,086
当然了 因为有ARKit
还有一个很棒的增强现实模式

833
00:53:08,055 --> 00:53:11,091
要获取更多信息
请参考我们的开发者网站

834
00:53:11,225 --> 00:53:14,061
你可以从那里获取我们的示例代码

835
00:53:15,863 --> 00:53:17,631
一些相关演讲

836
00:53:19,833 --> 00:53:24,538
SceneKit整合了00图形技术

837
00:53:24,605 --> 00:53:27,574
如Metal、SpriteKit
当然还有Model I/O

838
00:53:29,343 --> 00:53:33,413
有一个演讲
是关于tvOS和UIFocus支持的

839
00:53:33,480 --> 00:53:36,149
明天还有一场很棒的演讲
是关于SceneKit的

840
00:53:36,216 --> 00:53:40,187
时间是明天早上
在Swift Playground中使用SceneKit

841
00:53:40,554 --> 00:53:41,522
这就是全部内容了

842
00:53:41,989 --> 00:53:42,823
谢谢大家

