1
00:00:30,076 --> 00:00:32,006
欢迎参加“Metal 2

2
00:00:32,006 --> 00:00:32,946
的计算功能”会议

3
00:00:33,886 --> 00:00:35,296
我叫 Anna Tikhonova

4
00:00:35,296 --> 00:00:36,686
是 GPU 软件团队的

5
00:00:36,686 --> 00:00:37,976
工程师 现在就开始吧

6
00:00:42,156 --> 00:00:44,046
Metal 2 回波系统的功能

7
00:00:44,046 --> 00:00:45,836
比 Metal API 和语言要

8
00:00:45,836 --> 00:00:46,356
多得多

9
00:00:46,796 --> 00:00:48,946
我们还拥有 GPU 工具

10
00:00:48,946 --> 00:00:50,336
以及 MetalKit 和

11
00:00:50,336 --> 00:00:51,586
Metal Performance Shader 框架

12
00:00:53,006 --> 00:00:54,146
你可能会认为 Metal 是

13
00:00:54,496 --> 00:00:56,376
开发高端游戏和图像

14
00:00:56,376 --> 00:00:57,566
的优秀技术

15
00:00:58,396 --> 00:00:59,616
但它同时也用于

16
00:00:59,616 --> 00:01:00,506
计算处理

17
00:01:01,626 --> 00:01:02,806
事实上 Metal 在计算方面

18
00:01:02,806 --> 00:01:04,616
非常强大和灵活

19
00:01:04,616 --> 00:01:06,526
以至于 Metal

20
00:01:06,526 --> 00:01:08,196
Performance Shader 框架

21
00:01:08,196 --> 00:01:09,326
完全建立在

22
00:01:09,406 --> 00:01:09,756
计算之上

23
00:01:11,026 --> 00:01:12,486
在本次会议中 我们将介绍

24
00:01:12,486 --> 00:01:14,076
Metal Performance Shader 框架

25
00:01:14,076 --> 00:01:15,176
的新功能

26
00:01:17,956 --> 00:01:19,596
我们在 2015 年推出了

27
00:01:19,596 --> 00:01:21,026
Metal Performers Shader 框架

28
00:01:21,026 --> 00:01:22,756
简称 MPS

29
00:01:23,486 --> 00:01:24,546
之前的会议视频

30
00:01:24,546 --> 00:01:25,916
可以在我们的开发者

31
00:01:25,916 --> 00:01:28,906
网站上找到

32
00:01:29,266 --> 00:01:30,686
MPS 利用 GPU 的

33
00:01:30,686 --> 00:01:33,446
计算功能为 GPU 提供

34
00:01:33,446 --> 00:01:33,816
加速图元

35
00:01:34,286 --> 00:01:35,886
用于图像处理

36
00:01:35,926 --> 00:01:37,416
线性代数和机器学习

37
00:01:39,146 --> 00:01:40,416
这个框架针对 iOS

38
00:01:40,416 --> 00:01:42,336
进行了优化 我们很高兴地宣布

39
00:01:42,336 --> 00:01:44,096
今年 MPS 也将在

40
00:01:44,096 --> 00:01:44,836
Mac 上应用

41
00:01:45,516 --> 00:01:49,786
[掌声]

42
00:01:50,286 --> 00:01:50,716
谢谢

43
00:01:51,926 --> 00:01:53,366
整个功能集都

44
00:01:53,366 --> 00:01:55,616
可以在 iOS 和 macOS 系统中使用

45
00:01:55,616 --> 00:01:58,476
所以我们先来快速地

46
00:01:58,476 --> 00:02:00,336
看一下图像处理支持的

47
00:02:00,336 --> 00:02:00,686
新进展

48
00:02:02,046 --> 00:02:03,866
这里列出了

49
00:02:03,866 --> 00:02:05,576
在 iOS 10 中可以使用的

50
00:02:05,696 --> 00:02:07,486
所有图像处理图元

51
00:02:08,106 --> 00:02:09,675
有 Convolution Gaussian Blur

52
00:02:09,675 --> 00:02:11,586
Lanczos Resampling

53
00:02:11,586 --> 00:02:12,196
就举几个例子

54
00:02:13,126 --> 00:02:14,726
这些现在都可以在 macOS 系统中

55
00:02:14,726 --> 00:02:14,996
使用了

56
00:02:16,146 --> 00:02:17,656
今年我们为大家带来

57
00:02:17,656 --> 00:02:18,926
四种新的图像处理

58
00:02:18,926 --> 00:02:19,336
图元

59
00:02:20,466 --> 00:02:21,816
Image Keypoint

60
00:02:22,206 --> 00:02:24,316
图元可以用于 通常用于

61
00:02:24,316 --> 00:02:26,256
计算机视觉算法 例如

62
00:02:26,256 --> 00:02:28,596
稳像和

63
00:02:28,596 --> 00:02:29,926
双线性缩放

64
00:02:29,926 --> 00:02:31,726
图像统计

65
00:02:31,726 --> 00:02:33,246
元素级算术运算符

66
00:02:33,326 --> 00:02:34,826
通常用于图像

67
00:02:34,826 --> 00:02:35,156
预处理

68
00:02:35,466 --> 00:02:36,386
例如在机器

69
00:02:36,386 --> 00:02:36,656
学习中

70
00:02:37,556 --> 00:02:38,926
算术递增滤色镜也

71
00:02:38,926 --> 00:02:40,446
支持广播操作

72
00:02:41,256 --> 00:02:42,716
例如 允许

73
00:02:42,716 --> 00:02:44,766
添加 2D 图像或 1D 图像

74
00:02:46,176 --> 00:02:48,406
这就是我们对图像处理

75
00:02:48,406 --> 00:02:49,606
新进展的快速介绍

76
00:02:49,986 --> 00:02:51,286
现在我们来谈谈新的

77
00:02:51,286 --> 00:02:52,386
线性代数运算

78
00:02:54,286 --> 00:02:55,686
没有矩阵乘法

79
00:02:55,686 --> 00:02:57,436
矩阵向量

80
00:02:57,436 --> 00:02:59,736
乘法 三角

81
00:03:00,076 --> 00:03:01,866
矩阵因式分解和

82
00:03:01,866 --> 00:03:02,306
线性求解器的支持

83
00:03:05,356 --> 00:03:06,376
为了支持线性代数

84
00:03:06,376 --> 00:03:09,256
运算 我们现在有了很多

85
00:03:09,256 --> 00:03:10,356
新的数据表示

86
00:03:11,066 --> 00:03:13,076
首先是 MPSVector 对象

87
00:03:13,076 --> 00:03:15,186
它可以将 Metal

88
00:03:15,186 --> 00:03:16,496
缓冲区中的数据解释为

89
00:03:16,496 --> 00:03:17,416
一维数组

90
00:03:19,106 --> 00:03:21,506
然后是 MPSMatrix 对象

91
00:03:22,076 --> 00:03:23,276
它可以将 Metal 缓冲区中的

92
00:03:23,276 --> 00:03:24,886
数据解释为矩形

93
00:03:24,886 --> 00:03:25,156
数组

94
00:03:25,886 --> 00:03:27,656
而 MPS 矩阵以行序为

95
00:03:27,656 --> 00:03:28,176
主序

96
00:03:28,956 --> 00:03:30,166
你可以将

97
00:03:30,166 --> 00:03:32,956
MPSVector 和 MPSMatrice 都看作是

98
00:03:33,456 --> 00:03:34,736
用户数据缓冲区周围的

99
00:03:34,736 --> 00:03:35,096
封装

100
00:03:37,436 --> 00:03:39,296
而且我们也支持 MPSMatrix 的

101
00:03:39,296 --> 00:03:40,926
临时变化

102
00:03:42,296 --> 00:03:45,196
MPS 图像 临时图像

103
00:03:45,196 --> 00:03:47,056
和 MPS 临时矩阵从

104
00:03:47,056 --> 00:03:48,666
与命令缓冲区相关联的

105
00:03:48,906 --> 00:03:49,956
Metal 堆中分配

106
00:03:49,956 --> 00:03:50,216
出来

107
00:03:50,766 --> 00:03:51,856
之所以称为临时的

108
00:03:52,226 --> 00:03:54,066
是因为它们的寿命

109
00:03:54,216 --> 00:03:55,996
受限于命令缓冲区的

110
00:03:55,996 --> 00:03:56,516
使用寿命

111
00:03:57,546 --> 00:03:58,866
我们建议

112
00:03:58,896 --> 00:04:00,176
在大多数中间存储器中

113
00:04:00,636 --> 00:04:02,526
使用临时映像和

114
00:04:03,006 --> 00:04:03,206
矩阵

115
00:04:04,316 --> 00:04:07,416
MPSVector 和 MPSMatrix 都

116
00:04:07,576 --> 00:04:09,116
支持多种输入类型

117
00:04:09,646 --> 00:04:11,596
我们支持单精度

118
00:04:11,596 --> 00:04:14,236
半精度输入类型以及

119
00:04:14,236 --> 00:04:15,266
浮点输入类型

120
00:04:15,756 --> 00:04:17,696
还有 16 位和 8 位带符号

121
00:04:17,986 --> 00:04:19,125
整数输入类型

122
00:04:21,016 --> 00:04:22,136
现在我们来看看怎样

123
00:04:22,136 --> 00:04:24,446
创建大小为 N 的

124
00:04:24,536 --> 00:04:24,886
MPS 向量

125
00:04:24,886 --> 00:04:26,856
如果你还没有

126
00:04:26,856 --> 00:04:28,346
Metal 缓冲区 那就需要先

127
00:04:28,346 --> 00:04:28,606
创建一个

128
00:04:29,666 --> 00:04:30,666
然后再为你的向量

129
00:04:30,666 --> 00:04:31,686
创建一个描述符

130
00:04:32,526 --> 00:04:34,546
请注意 你需要指定

131
00:04:34,726 --> 00:04:36,086
向量的长度

132
00:04:36,666 --> 00:04:38,146
因为向量可以

133
00:04:38,146 --> 00:04:39,946
由原来 Metal 缓冲区的

134
00:04:39,946 --> 00:04:40,926
一部分形成

135
00:04:41,716 --> 00:04:43,236
并且可以在使用该向量

136
00:04:43,236 --> 00:04:44,556
的内核中设置其他相关的

137
00:04:44,556 --> 00:04:45,016
偏移量

138
00:04:45,996 --> 00:04:47,406
最后使用

139
00:04:47,466 --> 00:04:49,586
描述符从缓冲区

140
00:04:49,586 --> 00:04:50,906
创建一个向量

141
00:04:52,966 --> 00:04:53,976
现在我们来看看

142
00:04:53,976 --> 00:04:56,256
如何创建一个 M 行

143
00:04:56,326 --> 00:04:57,906
N 列的 MPS 矩阵

144
00:04:59,516 --> 00:05:00,906
这和创建 MPS 向量

145
00:05:00,906 --> 00:05:02,916
的方式非常类似

146
00:05:02,916 --> 00:05:04,006
但有几点

147
00:05:04,006 --> 00:05:04,726
需要注意

148
00:05:06,176 --> 00:05:08,256
我们提供了一个方便的 API

149
00:05:08,256 --> 00:05:09,606
你可以用它来查找

150
00:05:09,606 --> 00:05:11,966
每个行值的推荐字节数

151
00:05:12,556 --> 00:05:13,756
用于调整 Metal 缓冲区的大小

152
00:05:14,666 --> 00:05:15,716
如果你选择使用 API

153
00:05:15,796 --> 00:05:17,246
那么这就是

154
00:05:17,246 --> 00:05:18,816
使用这个推荐值创建 Metal 缓冲区

155
00:05:18,816 --> 00:05:19,596
的方法

156
00:05:20,596 --> 00:05:22,106
并且这个 API 是完全

157
00:05:22,106 --> 00:05:24,416
可以选择性使用的 但我们推荐使用

158
00:05:24,416 --> 00:05:25,136
因为它的性能更好

159
00:05:25,986 --> 00:05:27,156
其余的就简单了

160
00:05:28,256 --> 00:05:29,356
你先为矩阵创建一个

161
00:05:29,356 --> 00:05:30,886
描述符 然后创建一个

162
00:05:30,886 --> 00:05:32,346
带有描述符的矩阵

163
00:05:34,936 --> 00:05:36,506
既然刚刚我们讲过了

164
00:05:36,506 --> 00:05:37,806
数据表示 那么现在

165
00:05:37,806 --> 00:05:39,046
我们来看一下图元

166
00:05:39,896 --> 00:05:41,176
对于矩阵-矩阵和

167
00:05:41,176 --> 00:05:43,136
矩阵-向量的乘法 我们的

168
00:05:43,136 --> 00:05:44,586
API 以

169
00:05:44,586 --> 00:05:46,036
标准的 BLAS GEMM 和 GEMV

170
00:05:46,036 --> 00:05:46,766
界面为模型

171
00:05:47,646 --> 00:05:48,846
对于三角矩阵

172
00:05:48,846 --> 00:05:50,196
矢量化和线性

173
00:05:50,196 --> 00:05:52,216
求解器 我们的 API 以

174
00:05:52,216 --> 00:05:53,246
标准的 LAPACK

175
00:05:53,246 --> 00:05:54,916
分解和求解

176
00:05:54,916 --> 00:05:55,486
界面为模型

177
00:05:55,846 --> 00:05:57,036
所以如果你熟悉这些

178
00:05:57,036 --> 00:05:59,106
界面 那对我们的 API

179
00:05:59,106 --> 00:06:00,526
你也不会陌生

180
00:06:02,576 --> 00:06:04,216
现在我们来看一个

181
00:06:04,216 --> 00:06:05,546
非常简单的代码示例

182
00:06:05,836 --> 00:06:07,536
我们要做矩阵的

183
00:06:07,536 --> 00:06:08,996
乘法和计算

184
00:06:08,996 --> 00:06:10,426
C = A 乘以 B

185
00:06:10,426 --> 00:06:12,716
所以首先我们需要创建

186
00:06:12,716 --> 00:06:14,476
矩阵 A B 和 C

187
00:06:14,706 --> 00:06:15,646
但我知道大家已经知道怎么

188
00:06:15,646 --> 00:06:16,786
操作了 因为在前一张幻灯片里我已经

189
00:06:16,836 --> 00:06:18,306
讲过 所以我们继续往下看

190
00:06:19,336 --> 00:06:21,116
现在我们要在 GPU 上

191
00:06:21,116 --> 00:06:22,596
运行矩阵的乘法

192
00:06:23,886 --> 00:06:25,386
首先像往常一样进行 Metal

193
00:06:25,466 --> 00:06:27,446
设置来获取设备

194
00:06:27,446 --> 00:06:29,076
命令队列和命令

195
00:06:29,076 --> 00:06:29,356
缓冲区

196
00:06:29,356 --> 00:06:31,766
然后我们需要创建

197
00:06:31,846 --> 00:06:33,186
矩阵乘法内核

198
00:06:33,766 --> 00:06:35,196
注意 你这里需要

199
00:06:35,196 --> 00:06:36,296
指定结果的大小

200
00:06:36,826 --> 00:06:38,216
因为这个内核可以

201
00:06:38,216 --> 00:06:39,896
在矩阵的子区域上

202
00:06:39,896 --> 00:06:40,436
运行

203
00:06:41,066 --> 00:06:45,576
然后将这个内核编码

204
00:06:45,656 --> 00:06:47,056
到 GPU 上 并让它开始

205
00:06:47,056 --> 00:06:47,476
工作

206
00:06:47,476 --> 00:06:51,036
我们已经在

207
00:06:51,036 --> 00:06:52,346
开发者网站上提供了

208
00:06:52,586 --> 00:06:53,906
矩阵乘法的示例代码

209
00:06:53,906 --> 00:06:56,096
以及三角矩阵

210
00:06:56,096 --> 00:06:57,896
向量化的代码

211
00:06:58,206 --> 00:06:59,556
求解线性方程组的示例代码

212
00:06:59,556 --> 00:07:00,986
很快也要发布

213
00:07:03,026 --> 00:07:05,526
这就是我们关于

214
00:07:05,756 --> 00:07:07,026
线性代数运算的内容

215
00:07:07,386 --> 00:07:08,996
现在我们来看下一个

216
00:07:08,996 --> 00:07:10,756
主题 也就是

217
00:07:10,756 --> 00:07:12,156
在 GPU 上加速机器

218
00:07:12,156 --> 00:07:12,636
学习图元

219
00:07:14,116 --> 00:07:16,246
在今年的 WWDC

220
00:07:16,246 --> 00:07:17,906
大会上有很多关于

221
00:07:17,906 --> 00:07:19,156
机器学习的会议

222
00:07:19,456 --> 00:07:20,346
而我们就是机器学习

223
00:07:20,346 --> 00:07:21,416
团体的一部分

224
00:07:22,306 --> 00:07:23,586
这一页展示了

225
00:07:23,586 --> 00:07:24,206
整体的架构

226
00:07:25,086 --> 00:07:26,606
作为一名应用程序开发人员

227
00:07:26,816 --> 00:07:27,876
你可以通过使用

228
00:07:27,876 --> 00:07:28,816
高级域

229
00:07:28,816 --> 00:07:30,956
特定框架

230
00:07:30,996 --> 00:07:32,856
比如分区框架

231
00:07:32,856 --> 00:07:34,456
和依赖于 Core ML 框架的

232
00:07:34,456 --> 00:07:35,566
自然语言处理框架

233
00:07:35,616 --> 00:07:37,496
为应用程序添加

234
00:07:37,496 --> 00:07:38,366
机器学习功能

235
00:07:39,216 --> 00:07:40,376
Core ML 框架由

236
00:07:40,446 --> 00:07:42,316
CPU 上的

237
00:07:42,316 --> 00:07:44,076
加速框架 BNNS

238
00:07:44,076 --> 00:07:44,606
原语

239
00:07:45,066 --> 00:07:46,176
以及 GPU 上的

240
00:07:47,066 --> 00:07:49,046
机器学习和

241
00:07:49,046 --> 00:07:51,946
MPS 框架驱动构成

242
00:07:51,946 --> 00:07:52,706
但是如果你正在编写一个

243
00:07:52,706 --> 00:07:54,556
使用 Metal 的应用程序

244
00:07:54,906 --> 00:07:56,046
那么你可以直接使用

245
00:07:56,046 --> 00:07:58,176
MPS框架 我稍后

246
00:07:58,176 --> 00:07:59,386
将在这个会议中向你展示如何操作

247
00:08:01,666 --> 00:08:02,676
让我们从正在讲的

248
00:08:02,736 --> 00:08:03,486
这个部分开始

249
00:08:04,246 --> 00:08:05,116
什么是深度学习

250
00:08:05,366 --> 00:08:06,236
什么是机器学习

251
00:08:07,686 --> 00:08:08,766
想象一下这是你

252
00:08:08,766 --> 00:08:11,436
当你看到一个图像

253
00:08:11,436 --> 00:08:13,076
你立刻就能知道上面描绘的

254
00:08:13,076 --> 00:08:13,316
是什么

255
00:08:13,416 --> 00:08:13,956
这是一只熊猫

256
00:08:14,936 --> 00:08:16,686
现在想一想你的

257
00:08:16,686 --> 00:08:18,006
iPhone 上所有的图像

258
00:08:18,596 --> 00:08:20,206
或者你家庭相册中的

259
00:08:20,206 --> 00:08:20,996
所有照片

260
00:08:21,606 --> 00:08:22,646
或者互联网上的

261
00:08:22,646 --> 00:08:22,966
所有图像

262
00:08:23,816 --> 00:08:27,096
没有人可以

263
00:08:27,096 --> 00:08:28,816
将这么多的图像分类

264
00:08:29,086 --> 00:08:30,506
但深度学习算法就是

265
00:08:30,506 --> 00:08:32,056
专门为此而

266
00:08:32,056 --> 00:08:32,196
设计的

267
00:08:33,186 --> 00:08:34,416
它们可以用于筛选

268
00:08:34,416 --> 00:08:35,576
大量数据

269
00:08:36,015 --> 00:08:37,866
并回答诸如

270
00:08:37,996 --> 00:08:41,676
图像的内容是什么 等一系列问题

271
00:08:42,236 --> 00:08:43,306
深度学习算法有

272
00:08:43,405 --> 00:08:43,905
两个阶段

273
00:08:44,206 --> 00:08:45,156
训练和推理

274
00:08:45,426 --> 00:08:46,426
让我们先来讲一下

275
00:08:46,426 --> 00:08:46,736
训练

276
00:08:47,946 --> 00:08:49,246
让我们用一个

277
00:08:49,246 --> 00:08:49,676
例子

278
00:08:49,676 --> 00:08:51,326
我们训练一个系统来进行

279
00:08:51,326 --> 00:08:51,716
图像分类

280
00:08:52,586 --> 00:08:53,536
这个系统训练可以

281
00:08:53,536 --> 00:08:56,696
进行图像分类 例如

282
00:08:56,696 --> 00:08:58,066
你想让系统识别

283
00:08:58,126 --> 00:08:58,536
动物

284
00:08:58,966 --> 00:09:00,516
要让它识别猫

285
00:09:00,516 --> 00:09:02,126
那么你就需要为这个系统输入

286
00:09:02,556 --> 00:09:04,196
大量的包含

287
00:09:04,196 --> 00:09:06,126
猫 兔子和

288
00:09:06,126 --> 00:09:07,336
所有其他你希望

289
00:09:07,336 --> 00:09:08,406
系统能识别动物的

290
00:09:08,406 --> 00:09:08,866
标签的图像

291
00:09:10,546 --> 00:09:12,316
而这个训练步骤是

292
00:09:12,316 --> 00:09:13,916
一次性的

293
00:09:13,916 --> 00:09:16,476
它消耗计算能力且劳动

294
00:09:16,566 --> 00:09:16,786
强度大

295
00:09:17,896 --> 00:09:19,076
它通常是离线完成的

296
00:09:19,696 --> 00:09:20,896
但是训练阶段的结果

297
00:09:20,896 --> 00:09:22,336
是下一阶段

298
00:09:23,306 --> 00:09:24,656
也就是推理阶段

299
00:09:24,656 --> 00:09:25,856
所需要的训练参数

300
00:09:26,906 --> 00:09:28,096
这时候可以将一个从未见过的

301
00:09:28,186 --> 00:09:30,156
新图像呈现在

302
00:09:30,156 --> 00:09:31,736
你的系统中

303
00:09:31,736 --> 00:09:33,186
并对其进行分类

304
00:09:33,186 --> 00:09:33,396
这是一个帽子

305
00:09:35,126 --> 00:09:37,016
我们为第二阶段

306
00:09:37,016 --> 00:09:38,306
也就是推理阶段提供视图

307
00:09:38,306 --> 00:09:38,526
加速

308
00:09:39,096 --> 00:09:40,966
具体来说 去年我们

309
00:09:40,966 --> 00:09:42,936
讨论了在 GPU 上

310
00:09:43,056 --> 00:09:44,296
构建卷积神经网络的

311
00:09:44,296 --> 00:09:45,716
构建块 用于

312
00:09:45,716 --> 00:09:46,146
推理

313
00:09:48,466 --> 00:09:50,176
所以在继续介绍

314
00:09:50,176 --> 00:09:51,966
今年推出的

315
00:09:51,966 --> 00:09:52,826
机器学习的新功能

316
00:09:52,856 --> 00:09:53,936
之前 我们将

317
00:09:53,936 --> 00:09:55,136
回顾一下

318
00:09:55,136 --> 00:09:56,886
去年演讲中介绍的

319
00:09:56,886 --> 00:09:58,146
一些核心信息

320
00:09:58,736 --> 00:10:00,416
比如 什么是卷积

321
00:10:00,416 --> 00:10:00,966
神经网络

322
00:10:02,396 --> 00:10:04,326
在这之后 我们才会

323
00:10:04,326 --> 00:10:06,056
谈到今年为

324
00:10:06,106 --> 00:10:06,836
卷积神经网络添加的

325
00:10:06,836 --> 00:10:07,906
新原语

326
00:10:07,966 --> 00:10:09,426
然后我们将

327
00:10:09,426 --> 00:10:11,146
介绍一种新的 易用的

328
00:10:11,516 --> 00:10:12,636
神经网络图像 API

329
00:10:13,166 --> 00:10:14,746
而我们最后一个话题是

330
00:10:14,746 --> 00:10:15,726
循环神经网络

331
00:10:18,606 --> 00:10:20,976
让我们按照刚才的概述开始讲

332
00:10:21,106 --> 00:10:22,066
那么 什么是卷积神经

333
00:10:22,066 --> 00:10:22,366
网络

334
00:10:24,446 --> 00:10:25,576
卷积神经网络

335
00:10:25,576 --> 00:10:27,426
受生物学启发而设计出来

336
00:10:27,426 --> 00:10:28,836
用于近似

337
00:10:28,836 --> 00:10:29,246
视觉皮质

338
00:10:29,796 --> 00:10:31,406
所以让我们想一下

339
00:10:31,406 --> 00:10:33,076
大脑是如何处理视觉输入的

340
00:10:34,256 --> 00:10:35,636
在视觉皮质中

341
00:10:35,736 --> 00:10:37,056
接收信息的第一层

342
00:10:37,056 --> 00:10:39,396
神经元对

343
00:10:39,396 --> 00:10:40,786
特定的边缘和色块很

344
00:10:40,886 --> 00:10:41,196
敏感

345
00:10:42,366 --> 00:10:43,466
而大脑区域进一步的

346
00:10:43,466 --> 00:10:45,966
视觉传递会对

347
00:10:45,966 --> 00:10:47,596
更复杂的结构做出反应

348
00:10:47,596 --> 00:10:49,366
比如朋友的面孔或者

349
00:10:49,366 --> 00:10:50,166
动物 比如猫

350
00:10:50,996 --> 00:10:53,646
所以类似的 卷积神经网络

351
00:10:53,646 --> 00:10:55,836
是多层次结构

352
00:10:55,836 --> 00:10:58,176
其中高级特征

353
00:10:58,296 --> 00:10:59,836
源于低级

354
00:10:59,836 --> 00:11:00,246
特征

355
00:11:01,156 --> 00:11:02,516
因此你的网络中的前几个

356
00:11:02,516 --> 00:11:04,566
层次会对低级特征

357
00:11:04,566 --> 00:11:06,766
比如边缘和色块做出

358
00:11:06,826 --> 00:11:07,196
响应

359
00:11:07,886 --> 00:11:10,646
而随后的层次

360
00:11:10,766 --> 00:11:12,516
对逐渐复杂的特征

361
00:11:12,616 --> 00:11:14,886
比如面孔 做出响应

362
00:11:16,106 --> 00:11:17,406
我一直在说特征

363
00:11:17,846 --> 00:11:19,556
你可以将特征视为

364
00:11:19,556 --> 00:11:21,176
一个过滤器 可以过滤输入的

365
00:11:21,176 --> 00:11:22,706
数据 就是那个特征

366
00:11:25,316 --> 00:11:26,906
这里列出了我们在

367
00:11:26,976 --> 00:11:28,076
iOS 10 中提供的

368
00:11:28,076 --> 00:11:29,356
所有卷积神经网络原语

369
00:11:29,756 --> 00:11:31,806
在这个概述中我将

370
00:11:31,806 --> 00:11:33,686
只讲核心

371
00:11:34,176 --> 00:11:35,146
卷积层

372
00:11:35,216 --> 00:11:36,426
CNN 的核心

373
00:11:36,546 --> 00:11:36,756
构建块

374
00:11:36,756 --> 00:11:39,046
这些原语的其余部分

375
00:11:39,106 --> 00:11:40,906
在我们的演讲文档中

376
00:11:40,906 --> 00:11:42,266
有很详细的

377
00:11:42,266 --> 00:11:43,076
介绍

378
00:11:43,196 --> 00:11:44,566
Pooling Fully-Connected 和

379
00:11:44,616 --> 00:11:45,156
SoftMax.

380
00:11:45,746 --> 00:11:46,856
你可以找到和这些相关的

381
00:11:46,856 --> 00:11:47,056
信息

382
00:11:48,626 --> 00:11:50,386
所以让我们来谈谈

383
00:11:50,386 --> 00:11:51,186
核心构建块

384
00:11:52,596 --> 00:11:54,216
这个核心卷积层的功能

385
00:11:54,216 --> 00:11:56,196
是识别输入

386
00:11:56,196 --> 00:11:57,766
数据中的特征

387
00:11:57,766 --> 00:11:58,906
它之所以被称为

388
00:11:58,906 --> 00:12:01,076
卷积层是因为

389
00:12:01,126 --> 00:12:02,576
它对输入进行

390
00:12:02,576 --> 00:12:02,846
卷积操作

391
00:12:03,916 --> 00:12:05,246
我们回想一下常规的

392
00:12:05,246 --> 00:12:06,076
卷积如何进行

393
00:12:06,906 --> 00:12:08,146
你有输入

394
00:12:08,186 --> 00:12:09,366
输出和过滤器

395
00:12:10,366 --> 00:12:12,386
使用输入数据来

396
00:12:12,386 --> 00:12:14,506
调用过滤器 你需要将

397
00:12:14,756 --> 00:12:16,626
过滤器中的

398
00:12:16,626 --> 00:12:18,446
每个值与输入数据中的值相乘

399
00:12:18,446 --> 00:12:19,686
并将该信息组合

400
00:12:19,686 --> 00:12:21,106
从而计算出单个输出值

401
00:12:22,046 --> 00:12:23,536
对于其余的输出像素

402
00:12:23,636 --> 00:12:25,166
你也进行同样的操作

403
00:12:27,596 --> 00:12:29,856
而现在卷积层则是

404
00:12:29,856 --> 00:12:31,606
常规卷积的

405
00:12:31,606 --> 00:12:32,226
一般化

406
00:12:32,396 --> 00:12:34,666
它允许你拥有多个

407
00:12:34,666 --> 00:12:35,136
过滤器

408
00:12:35,526 --> 00:12:37,536
所以你可以拥有和输出通道

409
00:12:37,536 --> 00:12:38,916
一样多的过滤器

410
00:12:38,916 --> 00:12:39,816
这种情况下是 16 个

411
00:12:41,666 --> 00:12:43,046
这些过滤器将

412
00:12:43,046 --> 00:12:44,656
过滤具有特定

413
00:12:44,656 --> 00:12:46,006
特征的输入数据

414
00:12:47,726 --> 00:12:49,016
现在想象一下你正在

415
00:12:49,016 --> 00:12:50,266
使用 RGB 数据

416
00:12:50,356 --> 00:12:52,186
那么你的输入实际上

417
00:12:52,186 --> 00:12:53,266
有三个通道

418
00:12:54,156 --> 00:12:56,276
鉴于 CNN 的工作原理

419
00:12:56,476 --> 00:12:58,816
这意味着你需要三组过滤器

420
00:12:58,886 --> 00:13:00,156
每组 16 个

421
00:13:00,866 --> 00:13:02,576
每个输入通道一组

422
00:13:03,856 --> 00:13:05,916
然后将这些滤波器

423
00:13:05,916 --> 00:13:07,296
分别应用于

424
00:13:08,486 --> 00:13:09,036
输入数据

425
00:13:09,036 --> 00:13:10,816
然后最后一步将

426
00:13:10,816 --> 00:13:12,386
所有这些信息合并

427
00:13:12,386 --> 00:13:13,796
计算出单个输出像素

428
00:13:15,516 --> 00:13:17,156
这就是我们对

429
00:13:17,156 --> 00:13:18,006
卷积层的概述

430
00:13:18,536 --> 00:13:19,526
现在我们来谈谈

431
00:13:19,576 --> 00:13:20,846
为卷积神经网络

432
00:13:20,846 --> 00:13:22,026
添加的新原语

433
00:13:22,116 --> 00:13:25,176
如你所见 我们添加了

434
00:13:25,176 --> 00:13:25,686
不少原语

435
00:13:27,736 --> 00:13:29,096
但我接下来只讲一下

436
00:13:29,096 --> 00:13:31,476
黄色的部分

437
00:13:31,476 --> 00:13:33,206
其他的比如 L2Norm

438
00:13:33,256 --> 00:13:34,686
Pooling Resampling

439
00:13:34,686 --> 00:13:36,086
和 Up-sampling 这些都将

440
00:13:36,086 --> 00:13:37,396
在我们的文档中介绍

441
00:13:39,286 --> 00:13:40,986
那让我们来看看对核心

442
00:13:40,986 --> 00:13:42,786
卷积层进行的更新

443
00:13:43,916 --> 00:13:45,146
我们过去只支持

444
00:13:45,186 --> 00:13:46,716
单精度浮点权重

445
00:13:46,716 --> 00:13:47,026
类型

446
00:13:47,466 --> 00:13:49,076
现在为了帮你减少

447
00:13:49,076 --> 00:13:51,126
内存占用并

448
00:13:51,126 --> 00:13:51,966
提高网络

449
00:13:51,966 --> 00:13:52,326
性能

450
00:13:52,876 --> 00:13:54,546
我们还支持半精度

451
00:13:54,546 --> 00:13:56,466
浮点 8 位整数

452
00:13:56,806 --> 00:13:58,076
和二进制权重类型

453
00:13:59,496 --> 00:14:01,006
我们过去只支持标准

454
00:14:01,006 --> 00:14:02,676
卷积 现在

455
00:14:02,736 --> 00:14:03,926
我们也支持二进制和

456
00:14:03,926 --> 00:14:04,646
XNOR 卷积

457
00:14:04,986 --> 00:14:06,096
扩张卷积

458
00:14:06,096 --> 00:14:08,406
子像素卷积和

459
00:14:08,406 --> 00:14:09,366
卷积转置

460
00:14:09,366 --> 00:14:09,996
操作

461
00:14:11,056 --> 00:14:12,156
其中许多是

462
00:14:12,156 --> 00:14:13,716
正交的 所以如果你愿意的话

463
00:14:14,006 --> 00:14:15,946
甚至可以进行

464
00:14:15,946 --> 00:14:16,276
扩大子像素卷积

465
00:14:17,706 --> 00:14:18,486
让我们一个一个地

466
00:14:18,486 --> 00:14:19,046
看一下

467
00:14:20,806 --> 00:14:22,216
二进制和 XNOR 卷积

468
00:14:22,256 --> 00:14:24,276
与常规卷积执行

469
00:14:24,306 --> 00:14:26,336
相同的精确操作 但它们具有

470
00:14:26,336 --> 00:14:28,016
更好的性能 而且能够

471
00:14:28,476 --> 00:14:29,566
节省极大的空间

472
00:14:30,016 --> 00:14:31,726
所以在常规卷积中

473
00:14:31,726 --> 00:14:33,546
你可能有浮点输入

474
00:14:33,846 --> 00:14:35,166
和浮点权重

475
00:14:36,036 --> 00:14:37,446
而二进制卷积能够

476
00:14:37,516 --> 00:14:39,236
允许你

477
00:14:39,236 --> 00:14:41,266
使用二进制权重的全尺寸

478
00:14:41,266 --> 00:14:41,486
输入

479
00:14:42,416 --> 00:14:44,776
而对于 XNOR 卷积

480
00:14:44,776 --> 00:14:46,706
首先

481
00:14:47,226 --> 00:14:48,626
你的输入会被转换为

482
00:14:48,626 --> 00:14:50,826
二进制的 从而使输入

483
00:14:51,176 --> 00:14:52,396
和权重都是二进制的

484
00:14:53,476 --> 00:14:55,286
在常规卷积中

485
00:14:55,286 --> 00:14:57,066
输入必须与权重

486
00:14:57,106 --> 00:14:57,446
相乘

487
00:14:57,886 --> 00:14:59,876
而对于 XNOR 卷积

488
00:14:59,876 --> 00:15:01,806
分离变成了一个简单的 XNOR

489
00:15:01,806 --> 00:15:02,336
操作

490
00:15:04,746 --> 00:15:06,066
现在我们来谈谈扩张

491
00:15:06,066 --> 00:15:06,656
卷积

492
00:15:07,626 --> 00:15:08,996
我们已经知道常规

493
00:15:08,996 --> 00:15:09,786
卷积如何工作

494
00:15:10,486 --> 00:15:12,396
你需要用过滤器对

495
00:15:12,396 --> 00:15:13,656
输入数据进行计算

496
00:15:13,656 --> 00:15:14,706
来得到单个输出值

497
00:15:17,526 --> 00:15:18,786
但如果你正在研究一种

498
00:15:18,786 --> 00:15:21,736
需要将更广泛的

499
00:15:21,736 --> 00:15:24,846
输入数据进行

500
00:15:25,216 --> 00:15:26,166
全局集成的算法

501
00:15:26,816 --> 00:15:28,466
那么你就不能用 3 乘 3 的内核

502
00:15:28,536 --> 00:15:30,496
而应该用一个 5 乘 5 的内核

503
00:15:31,736 --> 00:15:32,476
来进一步研究

504
00:15:33,026 --> 00:15:33,666
但是这样的话就要进行

505
00:15:33,666 --> 00:15:34,756
更加大量的计算

506
00:15:35,256 --> 00:15:37,266
另外一种方法是使用

507
00:15:37,266 --> 00:15:39,046
扩展卷积这样

508
00:15:39,046 --> 00:15:43,206
你就可以使用

509
00:15:43,206 --> 00:15:45,256
扩展因子在卷积

510
00:15:45,256 --> 00:15:46,836
内核里引入间隔

511
00:15:46,836 --> 00:15:48,836
从而可以

512
00:15:48,836 --> 00:15:50,576
只使用 3 乘 3 的内核

513
00:15:50,576 --> 00:15:52,676
就能够进行进一步的

514
00:15:52,676 --> 00:15:53,016
研究

515
00:15:54,996 --> 00:15:55,876
现在我们来谈谈

516
00:15:55,946 --> 00:15:57,266
亚光圈卷积和

517
00:15:57,266 --> 00:15:58,846
卷积转置原语

518
00:15:59,766 --> 00:16:01,266
常用于图像

519
00:16:01,266 --> 00:16:01,836
放大

520
00:16:03,066 --> 00:16:04,126
让我们想一下图象放大

521
00:16:04,176 --> 00:16:05,366
通常是如何进行的

522
00:16:05,456 --> 00:16:07,456
现在你有输入数据

523
00:16:07,516 --> 00:16:09,196
并想用因子 2

524
00:16:09,196 --> 00:16:09,956
将其放大

525
00:16:12,336 --> 00:16:13,376
所以你将有一些

526
00:16:13,376 --> 00:16:14,566
缺失的像素需要计算

527
00:16:15,216 --> 00:16:16,536
并且通常扩大是

528
00:16:16,536 --> 00:16:18,156
用恒定过滤器进行的

529
00:16:18,156 --> 00:16:18,606
固定操作

530
00:16:18,766 --> 00:16:20,336
例如 盒式

531
00:16:20,336 --> 00:16:22,336
过滤器如何帮助你进行图像

532
00:16:22,386 --> 00:16:22,756
扩大

533
00:16:23,416 --> 00:16:25,146
盒式过滤器获取

534
00:16:25,316 --> 00:16:28,006
已知像素 并将

535
00:16:28,006 --> 00:16:29,326
已知的数据复制到缺失的

536
00:16:29,326 --> 00:16:30,786
位置从而获得

537
00:16:30,786 --> 00:16:31,216
扩大的结果

538
00:16:33,326 --> 00:16:35,196
对于子像素卷积

539
00:16:35,196 --> 00:16:36,646
你的过滤器不是常数

540
00:16:36,976 --> 00:16:38,226
过滤器会从数据中

541
00:16:38,226 --> 00:16:38,626
学习

542
00:16:38,766 --> 00:16:40,286
它们是经过训练的参数

543
00:16:40,716 --> 00:16:41,786
你可以从训练阶段

544
00:16:41,786 --> 00:16:42,906
获得这些参数 系统接受

545
00:16:42,986 --> 00:16:45,106
训练从而完成这个任务

546
00:16:45,106 --> 00:16:45,946
完成图像扩大

547
00:16:47,086 --> 00:16:49,176
所以对于 2 倍放大有 4 个

548
00:16:49,236 --> 00:16:49,686
过滤器

549
00:16:49,806 --> 00:16:51,656
对于 4 倍放大有 16 个

550
00:16:51,656 --> 00:16:52,656
过滤器等等

551
00:16:53,566 --> 00:16:55,446
所以对于 2 倍放大

552
00:16:55,446 --> 00:16:57,456
我们需要用 4 个过滤器

553
00:16:57,456 --> 00:16:58,166
并把它应用在输入数据上

554
00:16:58,166 --> 00:17:00,216
然后对刚才的操作输出

555
00:17:00,216 --> 00:17:02,076
进行重新调整 从而获得

556
00:17:02,076 --> 00:17:03,476
最终的全分辨率

557
00:17:03,476 --> 00:17:03,856
图像

558
00:17:04,925 --> 00:17:06,445
现在让我们来谈谈

559
00:17:06,445 --> 00:17:08,076
如何使用卷积转置原语

560
00:17:08,156 --> 00:17:09,536
来放大图像

561
00:17:10,435 --> 00:17:12,026
我们有输入

562
00:17:12,026 --> 00:17:13,466
但还需要计算

563
00:17:13,465 --> 00:17:14,146
缺失的数据

564
00:17:14,945 --> 00:17:16,665
所以这个原语计算

565
00:17:17,156 --> 00:17:18,616
缺失数据的方法是

566
00:17:18,616 --> 00:17:19,586
它使用一种

567
00:17:19,586 --> 00:17:21,296
卷积传递给

568
00:17:21,296 --> 00:17:23,165
有间隙的中间结果

569
00:17:23,166 --> 00:17:24,596
然后计算每个输出像素

570
00:17:25,185 --> 00:17:27,316
这就是如何得到

571
00:17:27,356 --> 00:17:28,256
放大的结果

572
00:17:31,136 --> 00:17:32,216
现在我们将向你展示

573
00:17:32,216 --> 00:17:33,556
如何使用这些新的

574
00:17:33,556 --> 00:17:35,046
卷积原语在

575
00:17:35,046 --> 00:17:36,626
真实世界的网络中如何操作

576
00:17:37,096 --> 00:17:38,606
我们选用了这个着色

577
00:17:38,606 --> 00:17:41,486
网络 它可以输入黑白

578
00:17:41,486 --> 00:17:42,886
图像 然后输出

579
00:17:42,886 --> 00:17:44,356
彩色图像

580
00:17:44,356 --> 00:17:47,156
而这个特定的网络能够

581
00:17:47,236 --> 00:17:48,426
使用扩张卷积原语

582
00:17:48,426 --> 00:17:50,396
更快地整合更广泛

583
00:17:50,396 --> 00:17:52,296
全局环境

584
00:17:52,926 --> 00:17:54,756
并且它使用卷积

585
00:17:54,756 --> 00:17:56,726
转置原语来提高

586
00:17:56,726 --> 00:17:57,776
网络的结果

587
00:18:00,166 --> 00:18:01,276
现在我们来看看这个

588
00:18:01,666 --> 00:18:03,966
着色网络怎样运行

589
00:18:10,226 --> 00:18:11,466
在这个演示中 我们

590
00:18:11,466 --> 00:18:12,886
收集了一些黑白

591
00:18:12,886 --> 00:18:14,046
图像 比如这个

592
00:18:14,046 --> 00:18:14,406
狮子

593
00:18:15,046 --> 00:18:16,416
一旦我点击这个

594
00:18:16,416 --> 00:18:17,796
图像 着色网络

595
00:18:17,796 --> 00:18:20,046
将在这个设备上

596
00:18:20,046 --> 00:18:21,126
运行 然后我们将看到一个

597
00:18:21,126 --> 00:18:21,946
彩色的图像

598
00:18:23,906 --> 00:18:25,456
让我们再试试另外一个例子

599
00:18:25,456 --> 00:18:27,046
这是一座美丽的雪山

600
00:18:27,046 --> 00:18:27,616
图像

601
00:18:28,836 --> 00:18:30,036
我们看到现在它是彩色的了

602
00:18:31,586 --> 00:18:33,756
还有这个美丽可爱的图像

603
00:18:33,756 --> 00:18:35,016
一位爸爸和女儿在弹

604
00:18:35,016 --> 00:18:35,366
吉他

605
00:18:35,366 --> 00:18:37,386
你可以看到现在图像

606
00:18:37,386 --> 00:18:38,026
是彩色的了

607
00:18:39,516 --> 00:18:40,896
还有这个图像我真的很喜欢

608
00:18:40,896 --> 00:18:42,306
一只棕熊在森林里

609
00:18:42,356 --> 00:18:42,696
散步

610
00:18:42,696 --> 00:18:43,756
所以我觉得这个网络

611
00:18:43,786 --> 00:18:45,146
效果非常不错

612
00:18:46,886 --> 00:18:48,726
好了 这就是现场

613
00:18:48,726 --> 00:18:48,916
演示

614
00:18:49,516 --> 00:18:54,686
[掌声]

615
00:18:55,186 --> 00:18:55,796
谢谢

616
00:18:57,766 --> 00:18:59,216
所以我们添加了所有这些新的

617
00:18:59,216 --> 00:19:01,456
卷积 CNN 原语 但

618
00:19:01,456 --> 00:19:02,056
这并不是全部

619
00:19:02,976 --> 00:19:04,666
我们还返回并改进了

620
00:19:04,666 --> 00:19:06,046
iOS 10 中可用的

621
00:19:06,206 --> 00:19:07,936
一些核心 CNN 内核

622
00:19:07,936 --> 00:19:09,646
的性能

623
00:19:10,406 --> 00:19:11,776
这个图像会显示

624
00:19:11,806 --> 00:19:13,846
Inception-v3 网络的

625
00:19:13,846 --> 00:19:15,386
性能 这是一种常用的

626
00:19:15,386 --> 00:19:16,936
图像识别

627
00:19:17,056 --> 00:19:17,546
网络

628
00:19:18,756 --> 00:19:20,396
它显示了这个网络

629
00:19:20,396 --> 00:19:22,196
在 iOS 11 中的性能

630
00:19:22,196 --> 00:19:23,786
正如你所看到的 我们

631
00:19:23,786 --> 00:19:25,866
在不同的 iOS 硬件上

632
00:19:25,866 --> 00:19:27,546
为你带来了至少 20％

633
00:19:27,756 --> 00:19:28,696
的性能提升

634
00:19:30,406 --> 00:19:33,786
现在我们来谈谈新的

635
00:19:33,786 --> 00:19:37,096
神经网络图像 API

636
00:19:37,716 --> 00:19:40,036
神经网络通常

637
00:19:40,036 --> 00:19:41,416
使用图像抽象化来

638
00:19:41,416 --> 00:19:42,476
描述 就像这个

639
00:19:42,476 --> 00:19:43,506
Inception-v3 网络的

640
00:19:43,506 --> 00:19:44,616
可视化一样

641
00:19:44,616 --> 00:19:46,696
我们现在可以使用

642
00:19:46,696 --> 00:19:48,706
新的图像 API 来做到

643
00:19:48,706 --> 00:19:48,966
这一点

644
00:19:50,446 --> 00:19:51,556
所以让我们将这些初始模块中的一个

645
00:19:51,556 --> 00:19:53,186
放大一下

646
00:19:54,676 --> 00:19:56,496
你有过滤节点可以

647
00:19:56,496 --> 00:19:58,176
描述对数据

648
00:19:58,176 --> 00:19:59,216
执行的操作

649
00:19:59,526 --> 00:20:01,146
比如卷积

650
00:20:01,146 --> 00:20:01,566
池化等

651
00:20:02,556 --> 00:20:04,316
同时你有图像节点

652
00:20:04,316 --> 00:20:05,736
可以描述数据如何在

653
00:20:05,786 --> 00:20:06,546
这些不同操作之间

654
00:20:06,546 --> 00:20:07,096
流动

655
00:20:07,826 --> 00:20:11,306
那么我们为什么要添加这个新的图像

656
00:20:11,306 --> 00:20:11,556
API 呢

657
00:20:11,926 --> 00:20:13,156
因为它很好使用

658
00:20:13,686 --> 00:20:14,656
你可以获得整个

659
00:20:14,656 --> 00:20:16,116
网络的紧凑

660
00:20:16,116 --> 00:20:18,326
表示 并将其保存到

661
00:20:18,326 --> 00:20:20,356
磁盘里 还可以将其还原

662
00:20:20,466 --> 00:20:21,546
它可以在平台间运行

663
00:20:23,166 --> 00:20:24,426
你只需要将图形

664
00:20:24,426 --> 00:20:26,366
进行一次初始化 然后就可以

665
00:20:26,366 --> 00:20:27,716
重新用在多个输入

666
00:20:27,716 --> 00:20:28,106
图像里了

667
00:20:29,516 --> 00:20:31,476
仅仅通过一次调用

668
00:20:31,476 --> 00:20:34,056
你就可以在 GPU 上对整个图形

669
00:20:34,056 --> 00:20:34,346
进行操作

670
00:20:36,276 --> 00:20:37,536
没有中间的图像

671
00:20:37,536 --> 00:20:39,196
需要管理 你只需要

672
00:20:39,196 --> 00:20:40,756
做好输入和

673
00:20:40,756 --> 00:20:41,036
输出

674
00:20:42,146 --> 00:20:45,016
在内部我们使用 Metal 堆

675
00:20:45,016 --> 00:20:46,796
来确保所有

676
00:20:46,796 --> 00:20:47,916
中间图像的

677
00:20:47,916 --> 00:20:49,506
内存占用

678
00:20:49,506 --> 00:20:50,126
尽可能小

679
00:20:50,606 --> 00:20:51,296
例如 对于

680
00:20:51,296 --> 00:20:53,376
Inception-v3 网络来说

681
00:20:53,826 --> 00:20:56,856
这意味着能节省 5 倍的内存空间

682
00:20:56,856 --> 00:20:58,496
和 10 倍的检查器分配

683
00:20:58,556 --> 00:20:59,256
我觉得这是相当令人惊叹的

684
00:21:00,836 --> 00:21:02,926
正如我所说 图像为你

685
00:21:02,926 --> 00:21:03,956
做了所有的基础工作

686
00:21:04,316 --> 00:21:05,646
它会创建

687
00:21:05,846 --> 00:21:06,846
中间图像

688
00:21:06,996 --> 00:21:08,706
并管理图像的大小

689
00:21:09,296 --> 00:21:11,086
它甚至会管理

690
00:21:11,086 --> 00:21:11,366
输出的大小

691
00:21:11,786 --> 00:21:12,766
它负责处理

692
00:21:12,766 --> 00:21:13,406
填充策略

693
00:21:13,796 --> 00:21:15,016
它也会进行审查

694
00:21:15,426 --> 00:21:17,516
简而言之 它能让你

695
00:21:17,566 --> 00:21:19,406
少写很多代码

696
00:21:19,486 --> 00:21:20,746
也就能避免产生很多

697
00:21:20,746 --> 00:21:20,956
错误

698
00:21:21,956 --> 00:21:24,066
当我说较少的代码时

699
00:21:24,596 --> 00:21:25,376
我是说少了非常多的代码

700
00:21:26,206 --> 00:21:27,906
所以去年我们发布了

701
00:21:27,996 --> 00:21:30,726
使用 Inception-v3 网络

702
00:21:30,726 --> 00:21:32,036
进行图像识别的 Metal

703
00:21:32,036 --> 00:21:33,286
识别样本

704
00:21:34,326 --> 00:21:36,026
我们把这个样本

705
00:21:36,026 --> 00:21:37,576
转换了一下 从而能够使用

706
00:21:37,806 --> 00:21:40,036
新的图像 API 然后发现我们

707
00:21:40,036 --> 00:21:41,956
可以少编写四倍的代码

708
00:21:42,356 --> 00:21:43,956
少写的代码行数与为了

709
00:21:43,956 --> 00:21:45,846
执行相同的网络

710
00:21:46,226 --> 00:21:47,916
需要在开源传感器

711
00:21:47,916 --> 00:21:48,886
流程框架中编写的

712
00:21:48,886 --> 00:21:50,436
Python 代码行数

713
00:21:50,436 --> 00:21:50,846
一样多

714
00:21:51,476 --> 00:21:52,956
我们只是想提一下

715
00:21:52,956 --> 00:21:54,046
我们将发布这个升级的

716
00:21:54,086 --> 00:21:57,196
示例代码 升级的示例作为

717
00:21:57,196 --> 00:21:58,346
示例代码

718
00:21:59,026 --> 00:22:01,796
拥有关于你的整个网络的

719
00:22:01,796 --> 00:22:03,276
所有信息 使我们能够

720
00:22:03,276 --> 00:22:06,116
在不同的视图中

721
00:22:06,116 --> 00:22:07,956
提供最佳

722
00:22:08,106 --> 00:22:08,866
性能

723
00:22:09,336 --> 00:22:10,946
让你可以轻松地在

724
00:22:10,946 --> 00:22:12,766
CPU 和 GPU 之间进行

725
00:22:12,766 --> 00:22:13,206
并行处理

726
00:22:13,976 --> 00:22:15,876
当图像正在执行

727
00:22:16,326 --> 00:22:18,076
当 GPU 执行一个

728
00:22:18,076 --> 00:22:19,986
输入图像的图形时

729
00:22:19,986 --> 00:22:21,686
CPU 已经准备好执行

730
00:22:21,686 --> 00:22:22,776
不同的输入

731
00:22:22,776 --> 00:22:23,716
图像图形了

732
00:22:25,176 --> 00:22:26,606
我们还可以将图形节点

733
00:22:26,676 --> 00:22:28,446
融合在一起 比如卷积和

734
00:22:28,856 --> 00:22:29,966
神经元节点

735
00:22:31,856 --> 00:22:33,746
我们可以同时操作

736
00:22:33,746 --> 00:22:34,386
这些图形节点

737
00:22:34,386 --> 00:22:36,256
所以如果我们再看一下

738
00:22:36,256 --> 00:22:38,056
这个初始模块的话

739
00:22:38,056 --> 00:22:39,886
你就可以看到很多行

740
00:22:39,886 --> 00:22:41,386
节点可以

741
00:22:41,456 --> 00:22:43,036
完全彼此独立的

742
00:22:43,036 --> 00:22:43,236
操作

743
00:22:44,176 --> 00:22:45,486
当然 这些独立执行的

744
00:22:45,486 --> 00:22:47,326
输出需要通过

745
00:22:47,926 --> 00:22:49,216
相关节点进行

746
00:22:49,216 --> 00:22:50,216
连接

747
00:22:51,206 --> 00:22:52,656
而且这个图像也足够智能

748
00:22:52,656 --> 00:22:54,276
可以将这些进行优化处理

749
00:22:54,886 --> 00:22:57,706
现在我们来看看如何使用

750
00:22:57,706 --> 00:22:59,586
新的图形 API

751
00:23:00,296 --> 00:23:02,176
所以这是使用

752
00:23:02,176 --> 00:23:04,126
图形 API 创建

753
00:23:04,126 --> 00:23:04,646
卷积节点的代码

754
00:23:05,826 --> 00:23:07,256
它需要一个图像作为源

755
00:23:08,226 --> 00:23:09,486
而且它也有权重

756
00:23:09,486 --> 00:23:10,926
所以让我们谈一下

757
00:23:10,926 --> 00:23:11,176
权重

758
00:23:13,056 --> 00:23:14,256
神经网络规模

759
00:23:14,256 --> 00:23:15,396
变得越来越大

760
00:23:16,136 --> 00:23:17,736
如果你的网络中有

761
00:23:17,736 --> 00:23:19,346
很多卷积节点

762
00:23:19,346 --> 00:23:21,436
那就意味着

763
00:23:21,496 --> 00:23:22,466
你的整个网络的

764
00:23:22,466 --> 00:23:23,616
总体权重可能

765
00:23:23,616 --> 00:23:24,246
相当大

766
00:23:25,216 --> 00:23:27,016
为了解决这个问题

767
00:23:27,016 --> 00:23:30,126
我们添加了一个

768
00:23:30,186 --> 00:23:31,296
可以执行的卷积数据源协议

769
00:23:31,656 --> 00:23:33,186
它能够及时

770
00:23:33,606 --> 00:23:35,036
加载和清除

771
00:23:35,076 --> 00:23:35,276
权重数据

772
00:23:36,296 --> 00:23:40,046
所以我们的想法是

773
00:23:40,046 --> 00:23:41,546
你的整个网络的

774
00:23:41,546 --> 00:23:43,196
权重就不用同时

775
00:23:43,196 --> 00:23:44,086
全部加载到内存中

776
00:23:44,626 --> 00:23:45,956
它们也不必

777
00:23:45,956 --> 00:23:46,886
提前加载

778
00:23:48,396 --> 00:23:49,656
为了帮助将内存空间

779
00:23:49,656 --> 00:23:51,556
占用降到最小 当我们初始化

780
00:23:51,556 --> 00:23:53,136
图形并处理

781
00:23:53,136 --> 00:23:54,516
一个特定的卷积层时

782
00:23:55,096 --> 00:23:56,126
我们将为这个卷积层

783
00:23:56,126 --> 00:23:57,726
加载权重 然后

784
00:23:57,856 --> 00:23:59,486
将它们清除之后

785
00:23:59,486 --> 00:24:00,726
再进入下一个卷积层

786
00:24:02,226 --> 00:24:03,586
你要做的就是使用

787
00:24:03,586 --> 00:24:05,146
这个初始化方法

788
00:24:05,146 --> 00:24:06,916
它知道数据的

789
00:24:06,916 --> 00:24:08,376
位置 但实际上并不会

790
00:24:08,376 --> 00:24:09,086
加载数据

791
00:24:10,096 --> 00:24:11,256
然后当图像调用

792
00:24:11,256 --> 00:24:13,266
加载功能的时候

793
00:24:13,266 --> 00:24:14,846
会提醒你需要

794
00:24:14,846 --> 00:24:15,236
加载权重

795
00:24:15,366 --> 00:24:16,546
然后当图像调用

796
00:24:16,546 --> 00:24:18,166
清除函数功能时

797
00:24:18,166 --> 00:24:19,316
你可以释放权重

798
00:24:21,586 --> 00:24:22,526
现在我们来构建一个图像

799
00:24:23,446 --> 00:24:24,926
这里我们正在使用

800
00:24:24,926 --> 00:24:26,116
这个 makeGraph 函数

801
00:24:26,596 --> 00:24:28,366
而在左边 你可以看到

802
00:24:28,366 --> 00:24:29,636
构建网络所需的

803
00:24:29,636 --> 00:24:30,826
所有节点

804
00:24:31,256 --> 00:24:32,926
然后我们创建节点

805
00:24:33,226 --> 00:24:34,446
创建卷积

806
00:24:34,446 --> 00:24:34,836
节点

807
00:24:35,016 --> 00:24:35,616
池化节点

808
00:24:35,616 --> 00:24:37,456
和剩下的节点

809
00:24:37,756 --> 00:24:38,606
现在节点有了

810
00:24:38,606 --> 00:24:40,226
那我们如何将节点

811
00:24:40,226 --> 00:24:40,446
连接成图像呢

812
00:24:41,646 --> 00:24:43,186
我们只需把一个节点的

813
00:24:43,186 --> 00:24:44,986
结果图像作为

814
00:24:45,066 --> 00:24:46,516
源图像传递给下一个节点

815
00:24:46,516 --> 00:24:48,106
就形成了图像

816
00:24:49,736 --> 00:24:51,236
现在让我们在 GPU 上运行这个图表

817
00:24:51,906 --> 00:24:54,066
首先像往常一样进行 Metal

818
00:24:54,066 --> 00:24:54,456
设置

819
00:24:54,886 --> 00:24:56,016
我们初始化这个图像

820
00:24:56,676 --> 00:24:58,166
要管理好输入数据

821
00:24:58,866 --> 00:25:01,066
然后将图像编码到

822
00:25:01,066 --> 00:25:01,506
GPU 上

823
00:25:02,276 --> 00:25:04,026
输出图像中的数据

824
00:25:04,556 --> 00:25:06,546
将会在命令缓冲区

825
00:25:06,546 --> 00:25:08,466
完成时 将数据填充到

826
00:25:08,466 --> 00:25:09,576
输出图像中

827
00:25:10,086 --> 00:25:11,526
然后我们可以选择

828
00:25:11,526 --> 00:25:12,996
等待 GPU 完成

829
00:25:13,406 --> 00:25:14,686
但我们并不推荐

830
00:25:14,686 --> 00:25:14,956
这样做

831
00:25:15,886 --> 00:25:17,506
因为如果这样做的话

832
00:25:17,506 --> 00:25:19,246
CPU 就会等 GPU 完成之后

833
00:25:19,836 --> 00:25:21,486
才能开始对下一轮

834
00:25:21,486 --> 00:25:22,846
图像进行编码

835
00:25:23,486 --> 00:25:25,256
而这样会将气泡引入你的

836
00:25:25,256 --> 00:25:26,266
传输途径 并对

837
00:25:26,526 --> 00:25:28,036
性能产生不利影响

838
00:25:29,816 --> 00:25:30,686
所以我们推荐

839
00:25:30,686 --> 00:25:32,606
使用新的

840
00:25:32,606 --> 00:25:34,596
异步执行的 API

841
00:25:35,426 --> 00:25:37,896
使用这个 API 能让你的 Metal

842
00:25:37,966 --> 00:25:39,436
设置甚至变得更小

843
00:25:39,626 --> 00:25:41,076
这样你只需要准备好

844
00:25:41,076 --> 00:25:41,736
Metal 设备

845
00:25:42,136 --> 00:25:43,096
然后需要

846
00:25:43,096 --> 00:25:44,016
初始化图像

847
00:25:44,056 --> 00:25:46,426
准备好输入数据 然后

848
00:25:46,426 --> 00:25:47,856
执行异步调用

849
00:25:49,586 --> 00:25:52,376
它会立即返回

850
00:25:52,376 --> 00:25:54,216
然后当这个代码

851
00:25:55,196 --> 00:25:56,236
闭包执行时 输出图像

852
00:25:56,236 --> 00:25:57,086
就已经准备好了

853
00:25:57,796 --> 00:25:59,056
但在此期间 你不需要

854
00:25:59,056 --> 00:26:00,136
等待 GPU 完成

855
00:26:00,306 --> 00:26:02,056
就可以继续进行

856
00:26:02,056 --> 00:26:03,676
编码和新的 GPU 任务。

857
00:26:04,396 --> 00:26:07,236
这样 CPU 和 GPU 就

858
00:26:07,236 --> 00:26:08,846
可以同时工作

859
00:26:09,406 --> 00:26:10,316
并且你的传输途经中

860
00:26:10,316 --> 00:26:12,756
没有气泡 两者都

861
00:26:12,756 --> 00:26:14,376
被充分地利用了起来

862
00:26:16,756 --> 00:26:18,996
好了 现在我来做一次

863
00:26:18,996 --> 00:26:21,106
现场演示 演示

864
00:26:21,146 --> 00:26:22,846
同步和异步 API

865
00:26:22,966 --> 00:26:24,526
之间的

866
00:26:24,526 --> 00:26:24,786
性能差异

867
00:26:24,786 --> 00:26:27,576
这个演示将使用

868
00:26:27,576 --> 00:26:29,576
Inception-v3 网络

869
00:26:29,576 --> 00:26:30,116
进行图像识别

870
00:26:30,516 --> 00:26:30,806
好的

871
00:26:31,136 --> 00:26:32,726
我将从同步

872
00:26:32,726 --> 00:26:34,416
API 开始 在这里我们正在

873
00:26:34,416 --> 00:26:35,706
检测一个水瓶

874
00:26:35,706 --> 00:26:38,276
平均每个

875
00:26:38,276 --> 00:26:41,756
图像大约有 50

876
00:26:41,756 --> 00:26:42,596
毫秒

877
00:26:42,826 --> 00:26:44,066
现在我将切换到

878
00:26:44,066 --> 00:26:44,956
异步 API

879
00:26:44,956 --> 00:26:47,586
现在平均每个图像的

880
00:26:47,586 --> 00:26:49,546
时间约为 36

881
00:26:49,546 --> 00:26:49,936
毫秒

882
00:26:49,936 --> 00:26:51,656
所以性能

883
00:26:51,686 --> 00:26:52,666
有了很大提升

884
00:26:54,776 --> 00:26:55,066
好的

885
00:26:55,196 --> 00:26:56,436
这就是现场演示

886
00:26:58,516 --> 00:27:04,016
[掌声]

887
00:27:04,516 --> 00:27:04,876
谢谢你们

888
00:27:06,566 --> 00:27:07,656
好的 既然我们已经谈过了

889
00:27:07,656 --> 00:27:08,626
新的神经网络图像

890
00:27:08,626 --> 00:27:10,926
API 并且向你展示了

891
00:27:10,956 --> 00:27:12,716
它使用起来多么简单

892
00:27:12,716 --> 00:27:14,016
性能多么强大

893
00:27:14,016 --> 00:27:16,086
现在让我们来换个话题

894
00:27:16,086 --> 00:27:17,166
谈谈循环神经

895
00:27:17,166 --> 00:27:17,566
网络

896
00:27:19,416 --> 00:27:20,386
什么是循环神经

897
00:27:20,386 --> 00:27:20,786
网络呢

898
00:27:23,406 --> 00:27:25,456
CNN 的一个缺点是

899
00:27:25,456 --> 00:27:27,276
无法记住过去

900
00:27:27,306 --> 00:27:28,326
发生的

901
00:27:28,326 --> 00:27:28,466
事情

902
00:27:29,456 --> 00:27:31,226
它们可以将一个图像

903
00:27:31,896 --> 00:27:33,926
作为输入 并生成单个输出

904
00:27:34,446 --> 00:27:36,316
例如图像中所描绘

905
00:27:36,356 --> 00:27:37,396
内容的一组

906
00:27:37,396 --> 00:27:37,836
可能性

907
00:27:39,056 --> 00:27:41,016
但 RNN 是有

908
00:27:41,016 --> 00:27:41,446
记忆的

909
00:27:42,346 --> 00:27:43,466
而且它们擅长按顺序

910
00:27:43,546 --> 00:27:44,066
进行操作

911
00:27:44,536 --> 00:27:48,256
所以它们可以通过一个输入

912
00:27:48,256 --> 00:27:49,576
比如图像中所

913
00:27:49,636 --> 00:27:51,016
描绘内容的一组

914
00:27:51,616 --> 00:27:52,966
可能性 然后产生一个

915
00:27:53,036 --> 00:27:53,366
输出序列

916
00:27:53,366 --> 00:27:56,196
一组有逻辑顺序的单词

917
00:27:56,196 --> 00:27:57,586
成为这个图像的标题

918
00:27:59,416 --> 00:28:01,716
它们还可以通过一个

919
00:28:01,806 --> 00:28:03,506
序列输入 比如英语句子

920
00:28:03,506 --> 00:28:06,626
产生多个序列

921
00:28:06,626 --> 00:28:08,506
输出 比如同一个句子翻译成

922
00:28:08,666 --> 00:28:09,946
不同的语言

923
00:28:09,946 --> 00:28:12,376
比如俄语

924
00:28:12,466 --> 00:28:13,056
或芬兰语

925
00:28:13,366 --> 00:28:16,356
而且我们还支持许多

926
00:28:16,356 --> 00:28:17,756
不同的 RNN 变体

927
00:28:18,586 --> 00:28:20,146
单门限 RNN

928
00:28:20,146 --> 00:28:22,156
长短期记忆 RNN 或者说 LSTM

929
00:28:22,596 --> 00:28:24,586
以及 LSTM 的多种变体

930
00:28:24,866 --> 00:28:26,336
GRU 和 MGU

931
00:28:27,766 --> 00:28:29,336
那么让我们来谈谈最简单的

932
00:28:29,366 --> 00:28:31,326
RNN 类型 单门限

933
00:28:31,326 --> 00:28:31,526
RNN

934
00:28:33,666 --> 00:28:34,966
单门限 RNN 具有

935
00:28:34,966 --> 00:28:37,006
循环单元 这使得

936
00:28:37,066 --> 00:28:38,676
RNN 之前的输出

937
00:28:38,996 --> 00:28:40,346
能够影响同一个

938
00:28:40,406 --> 00:28:41,846
RNN 的后续

939
00:28:41,846 --> 00:28:42,406
迭代输出

940
00:28:43,606 --> 00:28:45,496
但是单门限 RNN 的功能

941
00:28:45,546 --> 00:28:47,466
还不够强大 不能将

942
00:28:47,466 --> 00:28:48,746
重要信息对多次

943
00:28:48,746 --> 00:28:49,286
迭代输出构成影响

944
00:28:50,136 --> 00:28:51,676
因为单门限 RNN 的

945
00:28:51,786 --> 00:28:53,976
当前输出也是

946
00:28:53,976 --> 00:28:54,996
它的当前状态

947
00:28:54,996 --> 00:28:55,976
没有别的东西

948
00:28:57,146 --> 00:28:59,426
解决这个问题的方法是

949
00:28:59,476 --> 00:29:01,596
长短期记忆 RNN 或简称 LSTM

950
00:29:02,376 --> 00:29:03,906
它由单门限 RNN 构成

951
00:29:03,906 --> 00:29:06,246
并具有内部存储

952
00:29:06,246 --> 00:29:06,506
单元

953
00:29:07,436 --> 00:29:08,856
一个特定的

954
00:29:08,956 --> 00:29:10,596
门限组合可以控制

955
00:29:10,596 --> 00:29:13,106
信息在 LSTM 内如何流动

956
00:29:13,436 --> 00:29:15,016
并有选择的让信息

957
00:29:15,136 --> 00:29:16,266
存入存储单元

958
00:29:16,846 --> 00:29:19,656
让我们更详细地

959
00:29:19,656 --> 00:29:21,316
看一下 LSTM 的

960
00:29:21,316 --> 00:29:21,776
架构

961
00:29:22,206 --> 00:29:25,246
正如我所说 LSTM 中

962
00:29:25,356 --> 00:29:27,846
最重要的实体是存储

963
00:29:27,886 --> 00:29:30,406
单元 它在 LSTM 的每个循环期内

964
00:29:30,476 --> 00:29:31,536
都会进行更新

965
00:29:31,536 --> 00:29:33,426
所以你可以想到

966
00:29:33,846 --> 00:29:35,246
LSTM 的每一次迭代

967
00:29:35,306 --> 00:29:37,456
都是这种新旧

968
00:29:37,456 --> 00:29:38,016
内存之间的转换

969
00:29:38,676 --> 00:29:40,786
现在让我们谈谈

970
00:29:40,816 --> 00:29:41,036
门限

971
00:29:41,566 --> 00:29:43,376
首先是遗忘门限

972
00:29:44,216 --> 00:29:45,876
它决定旧的内存中

973
00:29:45,876 --> 00:29:47,206
哪些能够保留

974
00:29:47,206 --> 00:29:47,566
哪些不能保留

975
00:29:48,966 --> 00:29:50,456
然后是输入和

976
00:29:50,456 --> 00:29:51,836
单元门限

977
00:29:51,836 --> 00:29:53,996
它们的相互组合决定了

978
00:29:54,066 --> 00:29:55,786
当前输入的什么信息

979
00:29:55,786 --> 00:29:56,936
将影响新的内存

980
00:29:56,936 --> 00:29:59,136
然后这三个门限

981
00:29:59,136 --> 00:30:00,866
组合在一起来

982
00:30:01,226 --> 00:30:04,596
更新存储单元

983
00:30:05,696 --> 00:30:07,576
最后是输出门限

984
00:30:07,626 --> 00:30:09,656
它决定了

985
00:30:09,656 --> 00:30:11,976
以前的输入

986
00:30:12,476 --> 00:30:14,076
输出 当前的

987
00:30:14,076 --> 00:30:16,126
输入和新的内存中

988
00:30:16,126 --> 00:30:17,936
哪些信息将会影响 LSTM 的输出

989
00:30:19,196 --> 00:30:20,626
所以现在你知道 LSTM

990
00:30:20,626 --> 00:30:22,206
是由什么组成的了 让我们来看看

991
00:30:22,206 --> 00:30:24,006
你如何使用我们的框架

992
00:30:24,006 --> 00:30:24,576
来创建一个 LSTM

993
00:30:25,616 --> 00:30:27,536
首先创建一个 LSTM 的

994
00:30:27,756 --> 00:30:28,576
描述符

995
00:30:29,146 --> 00:30:31,306
然后你需要将门限

996
00:30:31,526 --> 00:30:31,876
初始化

997
00:30:32,436 --> 00:30:33,676
那么门限由什么控制呢

998
00:30:33,676 --> 00:30:35,146
什么能够控制门限

999
00:30:35,306 --> 00:30:36,156
控制门限

1000
00:30:36,156 --> 00:30:37,756
如何操作的是经过

1001
00:30:37,756 --> 00:30:38,386
训练的参数

1002
00:30:39,146 --> 00:30:40,156
这些参数来自

1003
00:30:40,156 --> 00:30:41,726
为使系统执行一项特定任务

1004
00:30:41,726 --> 00:30:43,526
而对其进行训练的步骤

1005
00:30:45,566 --> 00:30:47,496
而且你可以看到

1006
00:30:47,496 --> 00:30:48,586
这里有很多门限

1007
00:30:48,646 --> 00:30:49,856
供你进行初始化

1008
00:30:49,856 --> 00:30:52,356
但为了简要说明

1009
00:30:52,356 --> 00:30:52,726
我们只展示两个初始化

1010
00:30:53,206 --> 00:30:54,336
正如你所看到的 我们也

1011
00:30:54,336 --> 00:30:56,046
在使用一个数据源供应程序

1012
00:30:56,046 --> 00:30:57,446
和之前给你看过的一样

1013
00:30:57,556 --> 00:30:58,606
它用来初始化权重

1014
00:30:59,656 --> 00:31:01,536
下一步是创建

1015
00:31:01,536 --> 00:31:03,606
我们的 LSTM 层 现在我们

1016
00:31:03,606 --> 00:31:04,876
把它放在 GPU 上运行

1017
00:31:06,586 --> 00:31:08,646
我们需要创建数组

1018
00:31:08,646 --> 00:31:10,976
保存 LSTM

1019
00:31:10,976 --> 00:31:13,236
执行序列的

1020
00:31:13,236 --> 00:31:14,266
输入和输出

1021
00:31:14,886 --> 00:31:16,076
然后将序列编码到

1022
00:31:16,076 --> 00:31:16,716
GPU 上

1023
00:31:17,416 --> 00:31:19,446
在这里 我们向你展示

1024
00:31:19,666 --> 00:31:21,546
一种基于矩阵的 RNN 但我们

1025
00:31:21,546 --> 00:31:22,646
想提一下 我们

1026
00:31:22,686 --> 00:31:25,726
也支持通过卷积在

1027
00:31:25,726 --> 00:31:27,636
MPS 图像上操作的 RNN

1028
00:31:30,176 --> 00:31:31,216
现在我们来看一个

1029
00:31:31,216 --> 00:31:32,016
实际的例子

1030
00:31:32,596 --> 00:31:34,366
我们将使用图片字幕

1031
00:31:34,366 --> 00:31:35,706
作为使用 LSTM 的例子

1032
00:31:36,726 --> 00:31:38,566
你应该记得 我跟你讲过

1033
00:31:38,896 --> 00:31:40,646
深度学习算法

1034
00:31:40,646 --> 00:31:42,076
有两个阶段

1035
00:31:42,346 --> 00:31:43,316
训练阶段和

1036
00:31:43,316 --> 00:31:44,026
推理阶段

1037
00:31:44,816 --> 00:31:46,816
所以要想训练一个系统

1038
00:31:46,816 --> 00:31:49,196
为图像添加说明文字

1039
00:31:49,196 --> 00:31:51,056
你需要给它输入大量的带有

1040
00:31:51,056 --> 00:31:52,356
人为添加说明文字的图像

1041
00:31:53,836 --> 00:31:56,606
那么这个系统有什么呢

1042
00:31:56,656 --> 00:31:57,686
它是由什么构成的

1043
00:31:58,536 --> 00:32:02,016
这个系统有一个 CNN 和一个

1044
00:32:02,016 --> 00:32:03,906
RNN 一起工作来生成

1045
00:32:03,906 --> 00:32:04,346
说明文字

1046
00:32:04,746 --> 00:32:07,316
CNN 用于确定

1047
00:32:07,316 --> 00:32:09,316
图像中描述的内容

1048
00:32:09,316 --> 00:32:10,886
然后经 RNN 生成

1049
00:32:10,956 --> 00:32:11,806
实际的说明文字

1050
00:32:13,256 --> 00:32:15,076
而该过程的输出

1051
00:32:15,156 --> 00:32:17,006
是经过训练的参数

1052
00:32:17,006 --> 00:32:19,036
它们是下一步也就是

1053
00:32:20,186 --> 00:32:20,886
推理阶段需要的

1054
00:32:21,676 --> 00:32:25,606
因此 在推理阶段

1055
00:32:25,656 --> 00:32:27,766
经过训练的参数控制

1056
00:32:27,766 --> 00:32:29,826
CNN 层

1057
00:32:29,826 --> 00:32:31,866
和 RNN

1058
00:32:31,866 --> 00:32:32,146
门限的运行

1059
00:32:33,206 --> 00:32:37,276
然后每个图像

1060
00:32:37,336 --> 00:32:39,166
都由 CNN 和 RNN 进行处理

1061
00:32:39,446 --> 00:32:41,326
从而生成说明文字

1062
00:32:42,216 --> 00:32:43,246
我们已经知道有一个很好的

1063
00:32:43,246 --> 00:32:44,636
网络可以确定

1064
00:32:44,706 --> 00:32:45,816
图像中描绘的内容

1065
00:32:46,086 --> 00:32:47,506
就是 Inception-v3 网络

1066
00:32:47,876 --> 00:32:48,626
所以我们将使用它

1067
00:32:49,186 --> 00:32:50,456
而且我们刚刚谈到了 LSTM

1068
00:32:50,456 --> 00:32:52,236
所以让我们用它来生成

1069
00:32:52,446 --> 00:32:53,036
说明文字

1070
00:32:53,996 --> 00:32:56,456
说明文字生成阶段

1071
00:32:57,266 --> 00:32:58,176
说明文字生成过程

1072
00:32:58,176 --> 00:32:59,726
也分为两个阶段

1073
00:33:00,006 --> 00:33:02,206
首先我们有 LSTM

1074
00:33:02,486 --> 00:33:03,646
初始化阶段

1075
00:33:04,846 --> 00:33:06,126
然后我们运行 Inception-v3

1076
00:33:06,126 --> 00:33:08,616
网络 实际上我们运行了所有的

1077
00:33:08,616 --> 00:33:10,496
层 除了最后一个

1078
00:33:10,496 --> 00:33:11,986
SoftMax 层

1079
00:33:12,236 --> 00:33:13,386
而输出是一个

1080
00:33:13,386 --> 00:33:15,016
特征向量 它含有

1081
00:33:15,016 --> 00:33:16,196
关于图像描绘

1082
00:33:16,196 --> 00:33:17,226
内容的信息

1083
00:33:17,906 --> 00:33:19,016
然后我们将该

1084
00:33:19,016 --> 00:33:20,566
特征向量转换为

1085
00:33:20,566 --> 00:33:23,246
LSTM 所需的

1086
00:33:23,246 --> 00:33:24,286
紧凑表示

1087
00:33:24,286 --> 00:33:26,596
然后通过 LSTM 运行

1088
00:33:26,946 --> 00:33:27,746
将其初始化

1089
00:33:28,736 --> 00:33:30,466
然后一旦我们有了

1090
00:33:30,466 --> 00:33:32,436
初始化的 LSTM 那就

1091
00:33:32,436 --> 00:33:33,586
准备好可以进入下一个阶段了

1092
00:33:34,606 --> 00:33:36,066
即实际说明文字

1093
00:33:36,066 --> 00:33:36,376
生成阶段

1094
00:33:38,116 --> 00:33:39,676
我们通过向 LSTM 传递

1095
00:33:39,676 --> 00:33:41,366
一个特殊的句子开始令牌 ID

1096
00:33:41,436 --> 00:33:44,026
来启动这个过程

1097
00:33:44,236 --> 00:33:45,046
并且该操作的输出

1098
00:33:45,046 --> 00:33:46,756
是一个单词序列

1099
00:33:46,756 --> 00:33:50,006
你知道的 就是

1100
00:33:50,006 --> 00:33:51,276
和图像中所描绘的

1101
00:33:51,276 --> 00:33:52,666
内容相关的单词

1102
00:33:53,526 --> 00:33:55,806
然后我们将这些单词传递给

1103
00:33:55,806 --> 00:33:57,226
一个 SoftMax 层 该层可以计算

1104
00:33:57,226 --> 00:33:58,796
这些单词的概率

1105
00:33:59,326 --> 00:34:01,176
我们选择三个概率最高的

1106
00:34:01,326 --> 00:34:03,276
这三个概率最高的单词也是

1107
00:34:03,276 --> 00:34:05,816
我们对于特定图像的

1108
00:34:05,816 --> 00:34:07,546
说明文字中的单字部分

1109
00:34:08,126 --> 00:34:09,726
所以我们将这些单词拿出来

1110
00:34:09,806 --> 00:34:11,856
并传递给下一个状态的

1111
00:34:11,946 --> 00:34:15,045
LSTM 它的功能是

1112
00:34:15,096 --> 00:34:16,886
为图像算出三组

1113
00:34:16,916 --> 00:34:19,216
最好的双字组合

1114
00:34:19,216 --> 00:34:19,386
说明文字

1115
00:34:19,466 --> 00:34:21,416
我们执行 N 次迭代

1116
00:34:21,886 --> 00:34:23,076
直到达到停止的

1117
00:34:23,076 --> 00:34:25,596
条件 也就是当

1118
00:34:25,626 --> 00:34:27,116
达到我们想要的说明文字

1119
00:34:27,116 --> 00:34:28,966
字数上限的时候

1120
00:34:28,966 --> 00:34:30,856
或者当

1121
00:34:30,856 --> 00:34:32,136
新生成的说明文字

1122
00:34:32,136 --> 00:34:33,906
概率下降到 0 的时候

1123
00:34:34,985 --> 00:34:35,996
我知道这仍然

1124
00:34:35,996 --> 00:34:36,505
很抽象

1125
00:34:36,846 --> 00:34:39,005
所以让我们来看看

1126
00:34:39,386 --> 00:34:42,266
LSTM 的输出 也就是

1127
00:34:42,326 --> 00:34:44,556
LSTM 为了一个特定图像

1128
00:34:44,556 --> 00:34:45,545
进行多次迭代之后的实际输出

1129
00:34:46,216 --> 00:34:49,786
在这个图像中 你看到

1130
00:34:49,786 --> 00:34:51,636
有冲浪者驾驭在一个波浪上

1131
00:34:51,636 --> 00:34:53,146
我们想计算出匹配这张图像的

1132
00:34:53,146 --> 00:34:54,666
三句最好的说明文字

1133
00:34:55,696 --> 00:34:57,286
在 LSTM 的第一次迭代中

1134
00:34:57,366 --> 00:34:59,936
生成了三个最好的

1135
00:34:59,936 --> 00:35:00,306
单词

1136
00:35:02,336 --> 00:35:04,446
所以 这是匹配

1137
00:35:04,446 --> 00:35:05,686
这张图像的最好的

1138
00:35:05,686 --> 00:35:05,996
文字说明

1139
00:35:06,506 --> 00:35:07,596
“man”“a”和“the”

1140
00:35:08,316 --> 00:35:10,596
“a”一词的概率

1141
00:35:10,596 --> 00:35:11,186
最高

1142
00:35:11,936 --> 00:35:13,546
然后我们把这三个字

1143
00:35:13,546 --> 00:35:15,196
传递给下一个

1144
00:35:15,196 --> 00:35:16,436
LSTM 的迭代

1145
00:35:17,166 --> 00:35:19,356
在这个迭代中

1146
00:35:19,356 --> 00:35:21,416
对于这三个起始单词中的

1147
00:35:22,436 --> 00:35:24,416
每一个 LSTM 都生成了三个新词

1148
00:35:24,416 --> 00:35:26,026
它们有和这些

1149
00:35:26,026 --> 00:35:28,496
起始单词组合的

1150
00:35:28,496 --> 00:35:29,606
最高概率

1151
00:35:30,666 --> 00:35:31,966
对吧 所以我们有三个

1152
00:35:31,966 --> 00:35:33,556
新词可以和“man”组合

1153
00:35:33,946 --> 00:35:35,256
三个新词和“a”

1154
00:35:35,256 --> 00:35:37,766
组合 还有三个新词

1155
00:35:37,826 --> 00:35:38,976
和“the”组合

1156
00:35:40,686 --> 00:35:42,296
现在你可以看到

1157
00:35:42,296 --> 00:35:44,486
每一个双字组合说明

1158
00:35:44,486 --> 00:35:45,486
也都有概率

1159
00:35:46,026 --> 00:35:47,866
而且由于“a”

1160
00:35:47,936 --> 00:35:49,286
在第一次迭代中具有

1161
00:35:49,286 --> 00:35:53,366
如此高的概率 所以

1162
00:35:53,366 --> 00:35:54,646
在第二次迭代中

1163
00:35:54,646 --> 00:35:56,426
以“a”开头的双字组合

1164
00:35:56,476 --> 00:35:58,156
最后也具有最高的

1165
00:35:58,156 --> 00:35:58,796
概率

1166
00:35:58,896 --> 00:36:00,916
这是为什么 因为双字

1167
00:36:00,916 --> 00:36:02,506
说明的概率

1168
00:36:02,536 --> 00:36:04,516
只是其中两个单词

1169
00:36:04,516 --> 00:36:05,706
概率的

1170
00:36:05,706 --> 00:36:06,006
乘积

1171
00:36:07,116 --> 00:36:08,886
这就是我们如何获得这三个的最好

1172
00:36:08,886 --> 00:36:09,396
方法

1173
00:36:09,696 --> 00:36:11,226
然后我们留下它们并

1174
00:36:11,226 --> 00:36:12,836
继续下一个迭代

1175
00:36:13,186 --> 00:36:14,406
而在下一次迭代中

1176
00:36:14,406 --> 00:36:15,936
我们只需为已有说明文字

1177
00:36:15,936 --> 00:36:17,536
再添加一个单词

1178
00:36:17,846 --> 00:36:18,806
这样就有了三字说明

1179
00:36:19,206 --> 00:36:19,996
然后我们计算这些

1180
00:36:19,996 --> 00:36:21,836
说明文字的概率

1181
00:36:21,836 --> 00:36:22,886
并挑选三个概率最高的

1182
00:36:23,936 --> 00:36:25,106
我们继续进行下一次

1183
00:36:25,106 --> 00:36:27,026
迭代 只需再添加

1184
00:36:27,026 --> 00:36:28,746
一个词到

1185
00:36:28,746 --> 00:36:29,186
文字说明中

1186
00:36:29,186 --> 00:36:30,566
然后我们有了四字文字说明

1187
00:36:30,976 --> 00:36:31,876
然后我们计算

1188
00:36:31,926 --> 00:36:33,186
所有这些文字说明的

1189
00:36:33,236 --> 00:36:34,546
概率 并挑选概率

1190
00:36:34,606 --> 00:36:34,816
最高的三个

1191
00:36:36,176 --> 00:36:37,306
等等 我觉得你已经

1192
00:36:37,306 --> 00:36:37,646
了解这个方法了

1193
00:36:37,866 --> 00:36:38,936
那就让我们跳到最后吧

1194
00:36:39,296 --> 00:36:41,416
所以最后 我们得到了三个

1195
00:36:41,416 --> 00:36:43,506
最好的文字说明来匹配

1196
00:36:43,506 --> 00:36:43,936
这个特定的图象

1197
00:36:43,936 --> 00:36:45,906
而其中最好的是一个男人

1198
00:36:45,906 --> 00:36:47,426
踏着冲浪板冲浪

1199
00:36:47,656 --> 00:36:48,616
我觉得意思已经非常接近了

1200
00:36:50,966 --> 00:36:52,346
所以现在我们来

1201
00:36:52,346 --> 00:36:52,726
演示一下

1202
00:36:53,508 --> 00:36:55,508
[掌声]

1203
00:36:58,476 --> 00:37:00,116
所以现在我们来做一个

1204
00:37:00,606 --> 00:37:02,206
这个字幕网络的演示

1205
00:37:03,346 --> 00:37:04,856
我们在这里收集了

1206
00:37:04,856 --> 00:37:07,156
一些图像 一旦我点击

1207
00:37:07,156 --> 00:37:09,036
一张图像 CNN

1208
00:37:09,136 --> 00:37:10,826
就会运行并确定

1209
00:37:10,826 --> 00:37:12,526
图像中描绘的内容

1210
00:37:12,526 --> 00:37:14,046
然后 RNN 将运行

1211
00:37:14,046 --> 00:37:15,226
并生成实际的说明文字

1212
00:37:15,356 --> 00:37:16,036
所以让我们试试吧

1213
00:37:17,826 --> 00:37:19,446
>>一个男人踏着

1214
00:37:19,446 --> 00:37:19,766
冲浪板冲浪

1215
00:37:19,766 --> 00:37:22,356
>>这个我们已经知道了

1216
00:37:23,526 --> 00:37:24,566
现在让我们试试另一张

1217
00:37:24,996 --> 00:37:26,536
>>一辆旧卡车停放在

1218
00:37:26,536 --> 00:37:27,106
野外

1219
00:37:27,626 --> 00:37:28,936
>>所以网络实际上知道

1220
00:37:28,976 --> 00:37:30,356
这是一辆旧卡车

1221
00:37:30,356 --> 00:37:31,786
它是停放着的 不动的

1222
00:37:31,966 --> 00:37:33,336
我觉得这非常

1223
00:37:33,556 --> 00:37:34,156
令人惊叹

1224
00:37:34,786 --> 00:37:35,656
再试一次

1225
00:37:37,026 --> 00:37:38,496
>>一只黑白花纹的狗

1226
00:37:38,496 --> 00:37:39,086
躺在草地上

1227
00:37:39,796 --> 00:37:40,896
>>所以网络知道

1228
00:37:40,896 --> 00:37:42,176
这是一只黑白色的狗

1229
00:37:42,176 --> 00:37:43,636
它躺在草地上

1230
00:37:44,326 --> 00:37:45,106
并没有跑

1231
00:37:45,236 --> 00:37:46,356
没有走路

1232
00:37:46,726 --> 00:37:47,876
也没有坐着

1233
00:37:48,336 --> 00:37:50,266
而是躺在草地上

1234
00:37:50,766 --> 00:37:52,796
太酷了

1235
00:37:53,516 --> 00:37:57,786
[掌声]

1236
00:37:58,286 --> 00:37:58,726
谢谢

1237
00:37:59,306 --> 00:38:01,166
借着这个说明 我们来

1238
00:38:01,236 --> 00:38:01,586
总结一下

1239
00:38:02,066 --> 00:38:03,536
所以在本次会议中

1240
00:38:03,536 --> 00:38:05,246
我们讨论了今年在

1241
00:38:05,276 --> 00:38:07,006
MPS 框架中

1242
00:38:07,336 --> 00:38:08,206
添加的所有新原语。

1243
00:38:08,586 --> 00:38:10,236
我们扩大了对

1244
00:38:10,236 --> 00:38:12,386
图像处理原语和

1245
00:38:12,786 --> 00:38:13,736
卷积神经网络的

1246
00:38:13,736 --> 00:38:14,136
支持

1247
00:38:15,006 --> 00:38:16,596
我们还增加了对

1248
00:38:16,596 --> 00:38:18,886
线性代数和循环

1249
00:38:18,886 --> 00:38:22,226
神经网络的支持

1250
00:38:23,096 --> 00:38:24,666
该框架针对针对

1251
00:38:24,666 --> 00:38:26,146
iOS 进行了优化 正如我所说的那样

1252
00:38:26,596 --> 00:38:29,226
现在这些原语也都在

1253
00:38:29,226 --> 00:38:30,016
Mac 上可用

1254
00:38:31,116 --> 00:38:32,416
我们还讨论了新的

1255
00:38:32,416 --> 00:38:34,676
神经网络图像 API

1256
00:38:34,676 --> 00:38:36,406
并向你展示了如何

1257
00:38:36,406 --> 00:38:38,336
在 GPU 上构建和运行

1258
00:38:38,336 --> 00:38:39,666
你的网络

1259
00:38:40,426 --> 00:38:42,186
而且 这使我们有可能

1260
00:38:42,186 --> 00:38:43,586
在不同的 GPU 上

1261
00:38:43,666 --> 00:38:45,346
为你的网络提供

1262
00:38:45,346 --> 00:38:46,336
最佳性能

1263
00:38:46,336 --> 00:38:49,776
我们希望大家能够

1264
00:38:49,776 --> 00:38:51,976
使用所有这些新功能

1265
00:38:51,976 --> 00:38:53,526
来创建非常好的应用程序

1266
00:38:53,526 --> 00:38:55,836
并告诉我们

1267
00:38:56,116 --> 00:38:57,296
所以 请查看 Metal 2 相关的

1268
00:38:57,296 --> 00:38:58,856
会议和有关

1269
00:38:58,856 --> 00:39:01,186
核心 ML

1270
00:39:01,676 --> 00:39:03,006
Accelerate 和 Vision

1271
00:39:03,006 --> 00:39:03,486
框架的会议

1272
00:39:04,716 --> 00:39:06,036
有关此会议的更多信息

1273
00:39:06,096 --> 00:39:07,636
以及示例代码的链接

1274
00:39:07,706 --> 00:39:09,936
请登陆我们的

1275
00:39:09,986 --> 00:39:11,426
开发者网站查看这个链接

1276
00:39:11,426 --> 00:39:14,276
非常感谢大家的

1277
00:39:14,276 --> 00:39:15,636
出席 祝大家在

1278
00:39:15,636 --> 00:39:15,846
WWDC 大会期间有更多收获

1279
00:39:16,516 --> 00:39:20,500
[掌声]

